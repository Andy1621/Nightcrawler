[04/28 17:04:13][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 17:04:13][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 17:04:23][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 17:04:23][INFO] misc.py: 184: Params: 52,816,139
[04/28 17:04:23][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 17:04:27][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 17:04:27][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 17:04:27][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 17:04:27][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 17:04:27][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 17:04:27][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 17:04:27][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 17:04:28][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 17:04:28][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 17:04:28][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 17:04:28][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 17:04:28][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 17:04:28][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 17:04:28][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 17:04:28][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 17:04:28][INFO] misc.py: 196: nvidia-smi
[04/28 17:04:29][INFO] checkpoint_amp.py: 563: Load from given checkpoint file.
[04/28 17:04:29][INFO] checkpoint_amp.py: 262: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/28 17:04:31][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 17:04:31][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:04:31][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:04:32][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:04:33][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:04:33][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:04:33][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:04:33][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f4a7e5f5290>
[04/28 17:04:34][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:04:34][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f4a7e61f830>
[04/28 17:04:34][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f4acc0823b0>
[04/28 17:04:34][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f4a7e61f5f0>
[04/28 17:04:34][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:04:34][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:04:34][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:04:34][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:04:34][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:04:34][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:04:34][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:04:34][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f4a7e5f5290>
[04/28 17:04:34][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:04:34][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f4a7e61f830>
[04/28 17:04:34][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f49cceb9c20>
[04/28 17:04:34][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f4a7e61f5f0>
[04/28 17:04:34][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:04:34][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:04:34][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:04:34][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:04:34][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:46:30][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 17:46:30][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 17:46:40][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 17:46:40][INFO] misc.py: 184: Params: 52,816,139
[04/28 17:46:40][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 17:46:45][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 17:46:45][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 17:46:45][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 17:46:45][INFO] misc.py: 196: nvidia-smi
[04/28 17:46:46][INFO] checkpoint_amp.py: 563: Load from given checkpoint file.
[04/28 17:46:46][INFO] checkpoint_amp.py: 262: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/28 17:46:47][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 17:46:47][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:46:47][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:46:49][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:46:50][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0774b07290>
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:46:50][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0774b32830>
[04/28 17:46:50][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f07b00f93b0>
[04/28 17:46:50][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0774b325f0>
[04/28 17:46:50][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:46:50][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:46:50][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:46:50][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:46:50][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:46:50][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0774b07290>
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0774b32830>
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f07742cec20>
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0774b325f0>
[04/28 17:46:51][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:46:51][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:46:51][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:46:51][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0774b07290>
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0774b32830>
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f06b7be9cb0>
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0774b325f0>
[04/28 17:46:51][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:46:51][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:46:51][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:46:51][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0774b07290>
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0774b32830>
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f06b6d0ed40>
[04/28 17:46:51][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0774b325f0>
[04/28 17:46:51][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:46:51][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:46:51][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:46:51][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:46:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:46:51][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0774b07290>
[04/28 17:46:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:46:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0774b32830>
[04/28 17:46:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f06b66ba9e0>
[04/28 17:46:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0774b325f0>
[04/28 17:46:52][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:46:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:46:52][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:46:52][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:46:52][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:46:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:46:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:46:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:46:52][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0774b07290>
[04/28 17:46:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:46:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0774b32830>
[04/28 17:46:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f06b5fe5b00>
[04/28 17:46:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0774b325f0>
[04/28 17:46:52][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:46:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:46:52][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:46:52][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:46:52][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 17:46:52][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:46:52][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 17:46:52][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 17:46:52][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:46:52][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 17:46:52][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 17:46:52][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:46:52][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 17:46:52][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 17:46:52][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:46:52][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 17:46:52][INFO] train_net_bn_pseudo.py: 526: Start epoch: 1
[04/28 17:49:00][INFO] distributed.py: 788: Reducer buckets have been rebuilt in this iteration.
[04/28 17:50:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 7.02104, "dt_data": 0.04905, "dt_net": 6.97199, "epoch": "1/30", "eta": "5:21:47", "gpu_mem": "24.42G", "iter": "10/92", "loss": 1.14460, "lr": 0.00000, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 17:51:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81532, "dt_data": 0.04841, "dt_net": 6.76691, "epoch": "1/30", "eta": "5:11:13", "gpu_mem": "24.42G", "iter": "20/92", "loss": 1.19307, "lr": 0.00000, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 17:52:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82085, "dt_data": 0.04790, "dt_net": 6.77295, "epoch": "1/30", "eta": "5:10:20", "gpu_mem": "24.42G", "iter": "30/92", "loss": 1.12619, "lr": 0.00000, "target_top1_err": 10.93750, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 17:53:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84862, "dt_data": 0.04868, "dt_net": 6.79994, "epoch": "1/30", "eta": "5:10:28", "gpu_mem": "24.42G", "iter": "40/92", "loss": 1.07234, "lr": 0.00001, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 17:54:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84108, "dt_data": 0.05291, "dt_net": 6.78817, "epoch": "1/30", "eta": "5:08:59", "gpu_mem": "24.42G", "iter": "50/92", "loss": 0.98652, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 17:55:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84690, "dt_data": 0.04845, "dt_net": 6.79844, "epoch": "1/30", "eta": "5:08:06", "gpu_mem": "24.42G", "iter": "60/92", "loss": 1.16007, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 17:59:32][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 17:59:32][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 17:59:42][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 17:59:42][INFO] misc.py: 184: Params: 52,816,139
[04/28 17:59:42][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 17:59:48][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 17:59:48][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 17:59:48][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 17:59:48][INFO] misc.py: 196: nvidia-smi
[04/28 17:59:49][INFO] checkpoint_amp.py: 563: Load from given checkpoint file.
[04/28 17:59:49][INFO] checkpoint_amp.py: 262: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/28 17:59:50][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 17:59:50][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:59:50][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:59:51][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:59:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:59:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:59:51][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:59:51][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f18fd651290>
[04/28 17:59:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:59:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f18fd67c830>
[04/28 17:59:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f19d81243b0>
[04/28 17:59:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f18fd67c5f0>
[04/28 17:59:52][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:59:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:59:52][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:59:52][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:59:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:59:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:59:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:59:52][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f18fd651290>
[04/28 17:59:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:59:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f18fd67c830>
[04/28 17:59:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f18fce18c20>
[04/28 17:59:52][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f18fd67c5f0>
[04/28 17:59:52][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:59:52][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:59:52][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:59:52][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:59:52][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:59:53][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f18fd651290>
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:59:53][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f18fd67c830>
[04/28 17:59:53][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f18fc750cb0>
[04/28 17:59:53][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f18fd67c5f0>
[04/28 17:59:53][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:59:53][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:59:53][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:59:53][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f18fd651290>
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:59:53][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f18fd67c830>
[04/28 17:59:53][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f18fc077d40>
[04/28 17:59:53][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f18fd67c5f0>
[04/28 17:59:53][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:59:53][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:59:53][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:59:53][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:59:53][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:59:53][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f18fd651290>
[04/28 17:59:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:59:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f18fd67c830>
[04/28 17:59:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f18e50a89e0>
[04/28 17:59:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f18fd67c5f0>
[04/28 17:59:54][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:59:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:59:54][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:59:54][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 17:59:54][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 17:59:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 17:59:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 17:59:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 17:59:54][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f18fd651290>
[04/28 17:59:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 17:59:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f18fd67c830>
[04/28 17:59:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f18e49d3b00>
[04/28 17:59:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f18fd67c5f0>
[04/28 17:59:54][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 17:59:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 17:59:54][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 17:59:54][DEBUG] factory.py:  66: Loading s3:s3
[04/28 17:59:54][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 17:59:54][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:59:54][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 17:59:54][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 17:59:54][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:59:54][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 17:59:54][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 17:59:54][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:59:54][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 17:59:54][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 17:59:54][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 17:59:54][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 17:59:54][INFO] train_net_bn_pseudo.py: 526: Start epoch: 1
[04/28 18:14:30][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 18:14:30][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 18:14:47][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 18:14:47][INFO] misc.py: 184: Params: 52,816,139
[04/28 18:14:47][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 18:14:52][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 18:14:52][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 18:14:52][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 18:14:52][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 18:14:52][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 18:14:52][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 18:14:52][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 18:14:53][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 18:14:53][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 18:14:53][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 18:14:53][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 18:14:53][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 18:14:53][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 18:14:53][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 18:14:53][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 18:14:53][INFO] misc.py: 196: nvidia-smi
[04/28 18:14:55][INFO] checkpoint_amp.py: 563: Load from given checkpoint file.
[04/28 18:14:55][INFO] checkpoint_amp.py: 262: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/28 18:14:55][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 18:14:55][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 18:14:55][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 18:14:57][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 18:14:58][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 18:14:58][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 18:14:58][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 18:14:58][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f9e301f3290>
[04/28 18:14:58][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 18:14:58][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f9e3021d830>
[04/28 18:14:58][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f9e9c0e83b0>
[04/28 18:14:58][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f9e3021d5f0>
[04/28 18:14:58][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 18:14:58][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 18:14:58][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 18:14:58][DEBUG] factory.py:  66: Loading s3:s3
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 18:14:58][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 18:14:59][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f9e301f3290>
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 18:14:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f9e3021d830>
[04/28 18:14:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f9ded9b1c20>
[04/28 18:14:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f9e3021d5f0>
[04/28 18:14:59][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 18:14:59][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 18:14:59][DEBUG] factory.py:  66: Loading s3:s3
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 18:14:59][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f9e301f3290>
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 18:14:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f9e3021d830>
[04/28 18:14:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f9ded2e9cb0>
[04/28 18:14:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f9e3021d5f0>
[04/28 18:14:59][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 18:14:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 18:14:59][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 18:14:59][DEBUG] factory.py:  66: Loading s3:s3
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 18:14:59][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 18:15:00][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f9e301f3290>
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f9e3021d830>
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f9decc10d40>
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f9e3021d5f0>
[04/28 18:15:00][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 18:15:00][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 18:15:00][DEBUG] factory.py:  66: Loading s3:s3
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 18:15:00][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f9e301f3290>
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f9e3021d830>
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f9dec5bc9e0>
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f9e3021d5f0>
[04/28 18:15:00][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 18:15:00][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 18:15:00][DEBUG] factory.py:  66: Loading s3:s3
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 18:15:00][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 18:15:00][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f9e301f3290>
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f9e3021d830>
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f9de68e1b00>
[04/28 18:15:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f9e3021d5f0>
[04/28 18:15:00][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 18:15:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 18:15:00][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 18:15:00][DEBUG] factory.py:  66: Loading s3:s3
[04/28 18:15:00][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 18:15:00][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 18:15:01][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 18:15:01][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 18:15:01][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 18:15:01][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 18:15:01][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 18:15:01][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 18:15:01][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 18:15:01][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 18:15:01][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 18:15:01][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 18:15:01][INFO] train_net_bn_pseudo.py: 526: Start epoch: 1
[04/28 18:17:53][INFO] distributed.py: 788: Reducer buckets have been rebuilt in this iteration.
[04/28 18:18:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.57033, "dt_data": 0.04936, "dt_net": 6.52096, "epoch": "1/30", "eta": "5:01:08", "gpu_mem": "24.42G", "iter": "10/92", "loss": 1.14473, "lr": 0.00000, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 18:20:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.71291, "dt_data": 0.05006, "dt_net": 6.66285, "epoch": "1/30", "eta": "5:06:33", "gpu_mem": "24.42G", "iter": "20/92", "loss": 1.19306, "lr": 0.00000, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 18:21:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.64353, "dt_data": 0.04932, "dt_net": 6.59421, "epoch": "1/30", "eta": "5:02:16", "gpu_mem": "24.42G", "iter": "30/92", "loss": 1.12621, "lr": 0.00000, "target_top1_err": 10.93750, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 20:55:55][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 20:55:55][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 20:56:11][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 20:56:11][INFO] misc.py: 184: Params: 52,816,139
[04/28 20:56:11][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 20:56:17][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 20:56:17][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 20:56:17][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 20:56:17][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 20:56:17][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 20:56:17][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 20:56:17][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 20:56:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 20:56:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 20:56:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 20:56:18][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 20:56:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 20:56:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 20:56:18][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 20:56:18][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 20:56:18][INFO] misc.py: 196: nvidia-smi
[04/28 20:56:19][INFO] checkpoint_amp.py: 563: Load from given checkpoint file.
[04/28 20:56:19][INFO] checkpoint_amp.py: 262: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/28 20:56:20][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 20:56:20][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 20:56:20][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 20:56:21][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f052a0e7290>
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 20:56:21][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f052a112830>
[04/28 20:56:21][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f05680d33b0>
[04/28 20:56:21][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f052a1125f0>
[04/28 20:56:21][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 20:56:21][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 20:56:21][DEBUG] factory.py:  66: Loading s3:s3
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 20:56:21][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 20:56:21][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 20:56:21][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f052a0e7290>
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f052a112830>
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0523e79c20>
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f052a1125f0>
[04/28 20:56:22][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 20:56:22][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 20:56:22][DEBUG] factory.py:  66: Loading s3:s3
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 20:56:22][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f052a0e7290>
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f052a112830>
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f05237b1cb0>
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f052a1125f0>
[04/28 20:56:22][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 20:56:22][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 20:56:22][DEBUG] factory.py:  66: Loading s3:s3
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 20:56:22][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f052a0e7290>
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f052a112830>
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f05230d8d40>
[04/28 20:56:22][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f052a1125f0>
[04/28 20:56:22][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 20:56:22][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 20:56:22][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 20:56:22][DEBUG] factory.py:  66: Loading s3:s3
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 20:56:22][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 20:56:23][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f052a0e7290>
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 20:56:23][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f052a112830>
[04/28 20:56:23][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0522a849e0>
[04/28 20:56:23][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f052a1125f0>
[04/28 20:56:23][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 20:56:23][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 20:56:23][DEBUG] factory.py:  66: Loading s3:s3
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 20:56:23][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 20:56:23][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f052a0e7290>
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 20:56:23][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f052a112830>
[04/28 20:56:23][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f05223afb00>
[04/28 20:56:23][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f052a1125f0>
[04/28 20:56:23][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 20:56:23][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 20:56:23][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 20:56:23][DEBUG] factory.py:  66: Loading s3:s3
[04/28 20:56:23][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 20:56:23][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 20:56:23][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 20:56:23][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 20:56:23][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 20:56:23][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 20:56:23][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 20:56:23][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 20:56:24][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 20:56:24][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 20:56:24][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 20:56:24][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 20:56:24][INFO] train_net_bn_pseudo.py: 526: Start epoch: 1
[04/28 20:59:06][INFO] distributed.py: 788: Reducer buckets have been rebuilt in this iteration.
[04/28 21:00:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.57942, "dt_data": 0.02766, "dt_net": 6.55175, "epoch": "1/30", "eta": "5:01:33", "gpu_mem": "24.42G", "iter": "10/92", "loss": 1.14458, "lr": 0.00000, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 21:01:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.56905, "dt_data": 0.02685, "dt_net": 6.54220, "epoch": "1/30", "eta": "4:59:59", "gpu_mem": "24.42G", "iter": "20/92", "loss": 1.19287, "lr": 0.00000, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 21:12:14][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 21:12:14][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 21:49:02][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 21:49:02][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 21:49:13][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 21:49:13][INFO] misc.py: 184: Params: 52,816,139
[04/28 21:49:13][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 21:49:18][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 21:49:18][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 21:49:18][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 21:49:18][INFO] misc.py: 196: nvidia-smi
[04/28 21:49:20][INFO] checkpoint_amp.py: 563: Load from given checkpoint file.
[04/28 21:49:20][INFO] checkpoint_amp.py: 262: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/28 21:49:22][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 21:49:22][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 21:49:22][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 21:49:24][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 21:49:25][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 21:49:25][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 21:49:25][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 21:49:25][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f51b8104290>
[04/28 21:49:25][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 21:49:25][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f51b812e830>
[04/28 21:49:25][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f52784033b0>
[04/28 21:49:25][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f51b812e5f0>
[04/28 21:49:25][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 21:49:25][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 21:49:25][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 21:49:25][DEBUG] factory.py:  66: Loading s3:s3
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 21:49:25][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 21:49:26][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f51b8104290>
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 21:49:26][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f51b812e830>
[04/28 21:49:26][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f51aa991c20>
[04/28 21:49:26][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f51b812e5f0>
[04/28 21:49:26][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 21:49:26][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 21:49:26][DEBUG] factory.py:  66: Loading s3:s3
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 21:49:26][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f51b8104290>
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 21:49:26][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f51b812e830>
[04/28 21:49:26][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f51a9345cb0>
[04/28 21:49:26][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f51b812e5f0>
[04/28 21:49:26][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 21:49:26][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 21:49:26][DEBUG] factory.py:  66: Loading s3:s3
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 21:49:26][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 21:49:26][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 21:49:26][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f51b8104290>
[04/28 21:49:27][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 21:49:27][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f51b812e830>
[04/28 21:49:27][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f51a8c6cd40>
[04/28 21:49:27][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f51b812e5f0>
[04/28 21:49:27][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 21:49:27][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 21:49:27][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 21:49:27][DEBUG] factory.py:  66: Loading s3:s3
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 21:49:27][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 21:49:27][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 21:49:27][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 21:49:27][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f51b8104290>
[04/28 21:49:27][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 21:49:27][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f51b812e830>
[04/28 21:49:27][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f51a86179e0>
[04/28 21:49:27][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f51b812e5f0>
[04/28 21:49:27][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 21:49:27][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 21:49:27][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 21:49:27][DEBUG] factory.py:  66: Loading s3:s3
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 21:49:27][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 21:49:28][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 21:49:28][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 21:49:28][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 21:49:28][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f51b8104290>
[04/28 21:49:28][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 21:49:28][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f51b812e830>
[04/28 21:49:28][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f51a3f27b00>
[04/28 21:49:28][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f51b812e5f0>
[04/28 21:49:28][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 21:49:28][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 21:49:28][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 21:49:28][DEBUG] factory.py:  66: Loading s3:s3
[04/28 21:49:28][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 21:49:28][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 21:49:28][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 21:49:28][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 21:49:28][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 21:49:28][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 21:49:28][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 21:49:28][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 21:49:28][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 21:49:28][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 21:49:28][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 21:49:28][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 21:49:28][INFO] train_net_bn_pseudo.py: 526: Start epoch: 1
[04/28 21:52:16][INFO] distributed.py: 788: Reducer buckets have been rebuilt in this iteration.
[04/28 21:53:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.63078, "dt_data": 0.04861, "dt_net": 6.58217, "epoch": "1/30", "eta": "5:03:54", "gpu_mem": "24.42G", "iter": "10/92", "loss": 1.14466, "lr": 0.00000, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 21:54:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.53249, "dt_data": 0.04853, "dt_net": 6.48395, "epoch": "1/30", "eta": "4:58:19", "gpu_mem": "24.42G", "iter": "20/92", "loss": 1.19450, "lr": 0.00000, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 21:55:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.55046, "dt_data": 0.04879, "dt_net": 6.50166, "epoch": "1/30", "eta": "4:58:02", "gpu_mem": "24.42G", "iter": "30/92", "loss": 1.12632, "lr": 0.00000, "target_top1_err": 10.93750, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 21:56:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.56630, "dt_data": 0.04853, "dt_net": 6.51777, "epoch": "1/30", "eta": "4:57:40", "gpu_mem": "24.42G", "iter": "40/92", "loss": 1.07238, "lr": 0.00001, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 21:57:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.63248, "dt_data": 0.04909, "dt_net": 6.58339, "epoch": "1/30", "eta": "4:59:34", "gpu_mem": "24.42G", "iter": "50/92", "loss": 0.98639, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 21:58:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.63001, "dt_data": 0.04198, "dt_net": 6.58803, "epoch": "1/30", "eta": "4:58:21", "gpu_mem": "24.42G", "iter": "60/92", "loss": 1.15893, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/28 21:59:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.57495, "dt_data": 0.04899, "dt_net": 6.52596, "epoch": "1/30", "eta": "4:54:46", "gpu_mem": "24.42G", "iter": "70/92", "loss": 1.07450, "lr": 0.00001, "target_top1_err": 16.40625, "target_top5_err": 4.68750, "top1_err": 3.90625, "top5_err": 0.00000}
[04/28 22:01:01][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.60228, "dt_data": 0.04852, "dt_net": 6.55376, "epoch": "1/30", "eta": "4:54:54", "gpu_mem": "24.42G", "iter": "80/92", "loss": 1.16784, "lr": 0.00001, "target_top1_err": 14.84375, "target_top5_err": 3.90625, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:02:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.57799, "dt_data": 0.04863, "dt_net": 6.52935, "epoch": "1/30", "eta": "4:52:43", "gpu_mem": "24.42G", "iter": "90/92", "loss": 0.99490, "lr": 0.00001, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 22:02:20][INFO] logging.py:  99: json_stats: {"RAM": "137.43/1007.34G", "_type": "train_epoch", "dt": 0.14381, "dt_data": 0.14392, "dt_net": 6.50973, "epoch": "1/30", "eta": "0:00:00", "gpu_mem": "24.42G", "loss": 1.08247, "lr": 0.00001, "target_top1_err": 3.14198, "target_top5_err": 0.28872, "top1_err": 3.14198, "top5_err": 0.28872}
[04/28 22:02:20][INFO] train_net_bn_pseudo.py: 569: Epoch 0 takes 772.26s. Epochs from 0 to 0 take 772.26s in average and 772.26s in median.
[04/28 22:02:20][INFO] train_net_bn_pseudo.py: 575: For epoch 0, each iteraction takes 8.39s in average. From epoch 0 to 0, each iteraction takes 8.39s in average.
[04/28 22:03:12][INFO] logging.py:  99: json_stats: {"RAM": "141.32/1007.34G", "_type": "val_epoch", "epoch": "1/30", "gpu_mem": "24.42G", "min_top1_err": 0.30120, "min_top5_err": 0.00000, "time_diff": 0.00008, "top1_err": 0.30120, "top5_err": 0.00000}
[04/28 22:04:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:03:04", "gpu_mem": "24.42G", "iter": "10/146", "time_diff": 1.36012, "top1_err": 12.50000, "top5_err": 7.03125}
[04/28 22:04:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:54", "gpu_mem": "24.42G", "iter": "20/146", "time_diff": 0.43438, "top1_err": 10.93750, "top5_err": 5.46875}
[04/28 22:04:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:57", "gpu_mem": "24.42G", "iter": "30/146", "time_diff": 0.49375, "top1_err": 10.15625, "top5_err": 4.68750}
[04/28 22:04:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:52", "gpu_mem": "24.42G", "iter": "40/146", "time_diff": 0.49855, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 22:04:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:01:08", "gpu_mem": "24.42G", "iter": "50/146", "time_diff": 0.71787, "top1_err": 12.50000, "top5_err": 5.46875}
[04/28 22:05:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:45", "gpu_mem": "24.42G", "iter": "60/146", "time_diff": 0.53338, "top1_err": 10.15625, "top5_err": 3.12500}
[04/28 22:05:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:38", "gpu_mem": "24.42G", "iter": "70/146", "time_diff": 0.50825, "top1_err": 11.71875, "top5_err": 3.90625}
[04/28 22:05:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:33", "gpu_mem": "24.42G", "iter": "80/146", "time_diff": 0.50074, "top1_err": 11.71875, "top5_err": 5.46875}
[04/28 22:05:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:01:35", "gpu_mem": "24.42G", "iter": "90/146", "time_diff": 1.71033, "top1_err": 10.93750, "top5_err": 4.68750}
[04/28 22:05:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:23", "gpu_mem": "24.42G", "iter": "100/146", "time_diff": 0.51285, "top1_err": 14.84375, "top5_err": 4.68750}
[04/28 22:05:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:20", "gpu_mem": "24.42G", "iter": "110/146", "time_diff": 0.55718, "top1_err": 10.15625, "top5_err": 4.68750}
[04/28 22:05:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:11", "gpu_mem": "24.42G", "iter": "120/146", "time_diff": 0.44796, "top1_err": 10.15625, "top5_err": 3.90625}
[04/28 22:05:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:33", "gpu_mem": "24.42G", "iter": "130/146", "time_diff": 2.09453, "top1_err": 10.93750, "top5_err": 2.34375}
[04/28 22:05:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "1/30", "eta": "0:00:02", "gpu_mem": "24.42G", "iter": "140/146", "time_diff": 0.44219, "top1_err": 11.71875, "top5_err": 5.46875}
[04/28 22:06:01][INFO] logging.py:  99: json_stats: {"RAM": "166.27/1007.34G", "_type": "val_epoch", "epoch": "1/30", "gpu_mem": "24.42G", "min_top1_err": 11.26291, "min_top5_err": 5.04518, "time_diff": 0.00007, "top1_err": 11.26291, "top5_err": 5.04518}
[04/28 22:07:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.53009, "dt_data": 0.04854, "dt_net": 6.48155, "epoch": "2/30", "eta": "4:49:16", "gpu_mem": "25.00G", "iter": "10/92", "loss": 0.91255, "lr": 0.00001, "target_top1_err": 16.40625, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 22:08:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.60103, "dt_data": 0.04896, "dt_net": 6.55207, "epoch": "2/30", "eta": "4:51:19", "gpu_mem": "25.00G", "iter": "20/92", "loss": 0.95617, "lr": 0.00001, "target_top1_err": 11.71875, "target_top5_err": 2.34375, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:09:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.53897, "dt_data": 0.04845, "dt_net": 6.49051, "epoch": "2/30", "eta": "4:47:29", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.08094, "lr": 0.00001, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:10:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.95332, "dt_data": 0.04844, "dt_net": 6.90488, "epoch": "2/30", "eta": "5:04:33", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.11970, "lr": 0.00002, "target_top1_err": 8.59375, "target_top5_err": 0.00000, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:11:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.57776, "dt_data": 0.04843, "dt_net": 6.52934, "epoch": "2/30", "eta": "4:47:00", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.03234, "lr": 0.00002, "target_top1_err": 11.71875, "target_top5_err": 3.12500, "top1_err": 0.78125, "top5_err": 0.00000}
[04/28 22:33:41][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 22:33:41][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 22:33:50][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 22:33:50][INFO] misc.py: 184: Params: 52,816,139
[04/28 22:33:50][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 22:33:55][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 22:33:55][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 22:33:55][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 22:33:55][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 22:33:55][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 22:33:55][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 22:33:55][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 22:33:56][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 22:33:56][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 22:33:56][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 22:33:56][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 22:33:56][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 22:33:56][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 22:33:56][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 22:33:56][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 22:33:56][INFO] misc.py: 196: nvidia-smi
[04/28 22:33:57][INFO] checkpoint_amp.py: 550: Load from last checkpoint, ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/checkpoints/checkpoint_latest.pyth.
[04/28 22:33:57][INFO] checkpoint_amp.py: 262: Loading network weights from ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/checkpoints/checkpoint_latest.pyth.
[04/28 22:33:59][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 22:33:59][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:33:59][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:34:00][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:34:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:34:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:34:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:34:01][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8ec8284320>
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:34:02][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8ec82b08c0>
[04/28 22:34:02][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f91648247a0>
[04/28 22:34:02][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8ec82b0680>
[04/28 22:34:02][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:34:02][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:34:02][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:34:02][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8ec8284320>
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:34:02][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8ec82b08c0>
[04/28 22:34:02][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f8ec1670cb0>
[04/28 22:34:02][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8ec82b0680>
[04/28 22:34:02][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:34:02][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:34:02][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:34:02][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:34:02][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8ec8284320>
[04/28 22:34:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8ec82b08c0>
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f8ec0fa8d40>
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8ec82b0680>
[04/28 22:34:03][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:34:03][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:34:03][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:34:03][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8ec8284320>
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8ec82b08c0>
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f8ec08d3dd0>
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8ec82b0680>
[04/28 22:34:03][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:34:03][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:34:03][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:34:03][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8ec8284320>
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8ec82b08c0>
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f8ec027fa70>
[04/28 22:34:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8ec82b0680>
[04/28 22:34:03][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:34:03][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:34:03][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:34:03][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:34:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:34:03][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8ec8284320>
[04/28 22:34:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:34:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8ec82b08c0>
[04/28 22:34:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f8eb8f93b00>
[04/28 22:34:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8ec82b0680>
[04/28 22:34:04][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:34:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:34:04][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:34:04][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:34:04][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 22:34:04][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:34:04][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 22:34:04][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 22:34:04][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:34:04][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 22:34:04][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 22:34:04][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:34:04][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 22:34:04][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 22:34:04][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:34:04][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 22:34:04][INFO] train_net_bn_pseudo.py: 526: Start epoch: 2
[04/28 22:36:49][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 22:36:49][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 22:37:03][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 22:37:03][INFO] misc.py: 184: Params: 52,816,139
[04/28 22:37:03][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 22:37:09][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 22:37:09][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 22:37:09][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 22:37:09][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 22:37:09][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 22:37:09][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 22:37:09][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 22:37:10][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 22:37:10][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 22:37:10][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 22:37:10][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 22:37:10][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 22:37:10][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 22:37:10][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 22:37:10][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 22:37:10][INFO] misc.py: 196: nvidia-smi
[04/28 22:37:11][INFO] checkpoint_amp.py: 550: Load from last checkpoint, ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/checkpoints/checkpoint_latest.pyth.
[04/28 22:37:11][INFO] checkpoint_amp.py: 262: Loading network weights from ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/checkpoints/checkpoint_latest.pyth.
[04/28 22:37:12][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 22:37:12][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:37:12][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:37:12][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:37:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:37:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:37:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:37:12][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fe38514d320>
[04/28 22:37:13][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:37:13][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fe3851778c0>
[04/28 22:37:13][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fe5880157a0>
[04/28 22:37:13][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fe385177680>
[04/28 22:37:13][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:37:13][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:37:13][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:37:13][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:37:13][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:37:14][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fe38514d320>
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:37:14][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fe3851778c0>
[04/28 22:37:14][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fe38490fcb0>
[04/28 22:37:14][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fe385177680>
[04/28 22:37:14][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:37:14][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:37:14][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:37:14][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fe38514d320>
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:37:14][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fe3851778c0>
[04/28 22:37:14][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fe384247d40>
[04/28 22:37:14][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fe385177680>
[04/28 22:37:14][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:37:14][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:37:14][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:37:14][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:37:14][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:37:15][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fe38514d320>
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fe3851778c0>
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fe30ca8cdd0>
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fe385177680>
[04/28 22:37:15][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:37:15][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:37:15][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:37:15][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fe38514d320>
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fe3851778c0>
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fe30c439a70>
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fe385177680>
[04/28 22:37:15][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:37:15][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:37:15][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 22:37:15][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 22:37:15][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fe38514d320>
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fe3851778c0>
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fe304952b00>
[04/28 22:37:15][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fe385177680>
[04/28 22:37:15][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 22:37:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 22:37:15][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 22:37:15][DEBUG] factory.py:  66: Loading s3:s3
[04/28 22:37:15][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 22:37:15][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:37:16][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 22:37:16][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 22:37:16][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:37:16][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 22:37:16][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 22:37:16][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:37:16][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 22:37:16][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 22:37:16][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 22:37:16][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 22:37:16][INFO] train_net_bn_pseudo.py: 526: Start epoch: 2
[04/28 22:39:57][INFO] distributed.py: 788: Reducer buckets have been rebuilt in this iteration.
[04/28 22:41:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.90101, "dt_data": 0.04905, "dt_net": 6.85196, "epoch": "2/30", "eta": "5:05:42", "gpu_mem": "24.43G", "iter": "10/92", "loss": 1.11297, "lr": 0.00001, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 22:42:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88084, "dt_data": 0.04930, "dt_net": 6.83154, "epoch": "2/30", "eta": "5:03:40", "gpu_mem": "24.43G", "iter": "20/92", "loss": 1.14838, "lr": 0.00001, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 22:43:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.96480, "dt_data": 0.04984, "dt_net": 6.91496, "epoch": "2/30", "eta": "5:06:13", "gpu_mem": "24.43G", "iter": "30/92", "loss": 1.10453, "lr": 0.00001, "target_top1_err": 13.28125, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:44:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86433, "dt_data": 0.04893, "dt_net": 6.81540, "epoch": "2/30", "eta": "5:00:39", "gpu_mem": "24.43G", "iter": "40/92", "loss": 1.09790, "lr": 0.00002, "target_top1_err": 12.50000, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:45:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83823, "dt_data": 0.04876, "dt_net": 6.78947, "epoch": "2/30", "eta": "4:58:22", "gpu_mem": "24.43G", "iter": "50/92", "loss": 1.08823, "lr": 0.00002, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 22:46:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83290, "dt_data": 0.04895, "dt_net": 6.78395, "epoch": "2/30", "eta": "4:57:00", "gpu_mem": "24.43G", "iter": "60/92", "loss": 1.10169, "lr": 0.00002, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:47:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85969, "dt_data": 0.05649, "dt_net": 6.80320, "epoch": "2/30", "eta": "4:57:01", "gpu_mem": "24.43G", "iter": "70/92", "loss": 1.12924, "lr": 0.00002, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 22:49:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88893, "dt_data": 0.04888, "dt_net": 6.84005, "epoch": "2/30", "eta": "4:57:08", "gpu_mem": "24.43G", "iter": "80/92", "loss": 1.17978, "lr": 0.00002, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 22:50:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.90699, "dt_data": 0.05068, "dt_net": 6.85631, "epoch": "2/30", "eta": "4:56:46", "gpu_mem": "24.43G", "iter": "90/92", "loss": 1.12492, "lr": 0.00002, "target_top1_err": 12.50000, "target_top5_err": 5.46875, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 22:50:29][INFO] logging.py:  99: json_stats: {"RAM": "130.92/1007.34G", "_type": "train_epoch", "dt": 0.00206, "dt_data": 0.00206, "dt_net": 6.76970, "epoch": "2/30", "eta": "0:00:00", "gpu_mem": "24.43G", "loss": 1.08398, "lr": 0.00002, "target_top1_err": 2.85326, "target_top5_err": 0.30571, "top1_err": 2.85326, "top5_err": 0.30571}
[04/28 22:50:29][INFO] train_net_bn_pseudo.py: 569: Epoch 1 takes 793.00s. Epochs from 1 to 1 take 793.00s in average and 793.00s in median.
[04/28 22:50:29][INFO] train_net_bn_pseudo.py: 575: For epoch 1, each iteraction takes 8.62s in average. From epoch 1 to 1, each iteraction takes 8.62s in average.
[04/28 22:51:26][INFO] logging.py:  99: json_stats: {"RAM": "141.60/1007.34G", "_type": "val_epoch", "epoch": "2/30", "gpu_mem": "24.43G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[04/28 22:52:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:03:08", "gpu_mem": "24.43G", "iter": "10/146", "time_diff": 1.38965, "top1_err": 11.71875, "top5_err": 5.46875}
[04/28 22:52:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:01:01", "gpu_mem": "24.43G", "iter": "20/146", "time_diff": 0.48992, "top1_err": 10.15625, "top5_err": 5.46875}
[04/28 22:53:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:01:02", "gpu_mem": "24.43G", "iter": "30/146", "time_diff": 0.53500, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 22:53:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:57", "gpu_mem": "24.43G", "iter": "40/146", "time_diff": 0.53774, "top1_err": 9.37500, "top5_err": 3.12500}
[04/28 22:53:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:02:29", "gpu_mem": "24.43G", "iter": "50/146", "time_diff": 1.55785, "top1_err": 11.71875, "top5_err": 5.46875}
[04/28 22:53:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:42", "gpu_mem": "24.43G", "iter": "60/146", "time_diff": 0.49961, "top1_err": 10.93750, "top5_err": 3.12500}
[04/28 22:53:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:46", "gpu_mem": "24.43G", "iter": "70/146", "time_diff": 0.60576, "top1_err": 10.93750, "top5_err": 3.12500}
[04/28 22:53:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:34", "gpu_mem": "24.43G", "iter": "80/146", "time_diff": 0.52269, "top1_err": 11.71875, "top5_err": 3.12500}
[04/28 22:53:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:01:06", "gpu_mem": "24.43G", "iter": "90/146", "time_diff": 1.18675, "top1_err": 10.93750, "top5_err": 4.68750}
[04/28 22:53:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:24", "gpu_mem": "24.43G", "iter": "100/146", "time_diff": 0.52233, "top1_err": 13.28125, "top5_err": 4.68750}
[04/28 22:53:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:18", "gpu_mem": "24.43G", "iter": "110/146", "time_diff": 0.50333, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 22:54:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:15", "gpu_mem": "24.43G", "iter": "120/146", "time_diff": 0.61180, "top1_err": 9.37500, "top5_err": 3.90625}
[04/28 22:54:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:19", "gpu_mem": "24.43G", "iter": "130/146", "time_diff": 1.21095, "top1_err": 10.15625, "top5_err": 2.34375}
[04/28 22:54:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "2/30", "eta": "0:00:02", "gpu_mem": "24.43G", "iter": "140/146", "time_diff": 0.49684, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 22:54:15][INFO] logging.py:  99: json_stats: {"RAM": "162.00/1007.34G", "_type": "val_epoch", "epoch": "2/30", "gpu_mem": "24.43G", "min_top1_err": 10.84337, "min_top5_err": 4.60413, "time_diff": 0.00007, "top1_err": 10.84337, "top5_err": 4.60413}
[04/28 22:55:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84289, "dt_data": 0.04703, "dt_net": 6.79587, "epoch": "3/30", "eta": "4:52:38", "gpu_mem": "24.78G", "iter": "10/92", "loss": 0.90253, "lr": 0.00002, "target_top1_err": 11.71875, "target_top5_err": 2.34375, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 22:56:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85363, "dt_data": 0.04894, "dt_net": 6.80468, "epoch": "3/30", "eta": "4:51:57", "gpu_mem": "24.78G", "iter": "20/92", "loss": 1.03460, "lr": 0.00002, "target_top1_err": 7.81250, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:01:19][INFO] train_net_bn_pseudo.py: 474: Train with config:
[04/28 23:01:19][INFO] train_net_bn_pseudo.py: 475: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'INTERPOLATION': 'bicubic',
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'decord',
          'ENSEMBLE_METHOD': 'sum',
          'FRAME_PATH': '',
          'IMAGE_TEMPLATE': '{:05d}.jpg',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',
          'MC': True,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'PSEUDO_CSV': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 3,
          'SPECIAL_LABEL_LIST': [5, 9],
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'EVL': {'ADD_RESIDUAL': False,
         'AFTER_ME': False,
         'BACKBONE': 'vit_b16',
         'BEFORE_ME': False,
         'CLS_DROPOUT': 0.5,
         'FIRST_N': 0,
         'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],
         'MLP_FACTOR': 4.0,
         'N_DIM': 768,
         'N_HEAD': 12,
         'N_LAYERS': 4,
         'SHIFT_INIT': False,
         'SPATAIL_SIZE': 14,
         'USE_IMAGE_ATTNMAP': True,
         'USE_T_CONV': True,
         'USE_T_POS_EMBED': True},
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'CHECKPOINT_NUM': [0, 0, 0, 0],
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 11,
           'PSEUDO_LOSS_FUNC': '',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'uniformer',
                                   'vip',
                                   'swin',
                                   'sf',
                                   'evl'],
           'SOFT_T': 1,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': None,
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]],
          'QKV_BIAS': True,
          'SEP_POS_EMBED': True,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False},
 'RNG_SEED': 6666,
 'SF': {'DROPOUT_RATE': 0.2,
        'FROZEN_BN': False,
        'NONLOCAL': CfgNode({'FROZEN_BN': False}),
        'PRETRAIN_NAME': 'SlowFast-ResNet101-8x8'},
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'CLIP_GRADIENT': 20,
            'CLIP_GRAD_L2NORM': 1.0,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 30,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 10.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.1,
            'ZERO_WD_1D_PARAM': True},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 64,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ug2_sparse',
          'DATA_SELECT': 'real_unlabel',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 1,
          'NUM_SPATIAL_CROPS': 1,
          'SAVE_RESULTS_PATH': '',
          'TEST_BEST': True},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ug2_sparse',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'SAVE_LATEST': True,
           'THRESHOLD': -1},
 'UNIFORMER': {'ADD_MLP': True,
               'ATTENTION_DROPOUT_RATE': 0,
               'DEPTH': [3, 4, 8, 3],
               'DPE': True,
               'DROPOUT_RATE': 0,
               'DROP_DEPTH_RATE': 0.1,
               'EMBED_DIM': [64, 128, 320, 512],
               'HEAD_DIM': 64,
               'KS': 5,
               'MBCONV': False,
               'MLP_RATIO': 4,
               'NUM_HEADS': [1, 2, 5, 8],
               'PRETRAIN_NAME': None,
               'PRUNE_RATIO': [[],
                               [],
                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                               [0.5, 0.5, 0.5]],
               'QKV_BIAS': True,
               'QKV_SCALE': None,
               'RATIO': 1,
               'REPRESENTATION_SIZE': None,
               'SPLIT': False,
               'STAGE_TYPE': [0, 0, 1, 1],
               'STD': False,
               'TAU': 3,
               'TRADE_OFF': [[],
                             [],
                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5]]},
 'VIP': {'ATTENTION_DROPOUT_RATE': 0,
         'DROP_DEPTH_RATE': 0.1,
         'EMBED_DIMS': [192, 384, 384, 384],
         'LAYERS': [4, 3, 8, 3],
         'MLP_RATIOS': [3, 3, 3, 3],
         'PATCH_SIZE': 7,
         'PRETRAIN_NAME': None,
         'QKV_BIAS': True,
         'QKV_SCALE': None,
         'SEGMENT_DIM': [32, 16, 16, 16],
         'ST_TYPE': 'st_skip',
         'TRANSITIONS': [True, False, False, False],
         'T_STRIDE': 1},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[04/28 23:01:31][INFO] misc.py: 183: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 9, 9), stride=(1, 8, 8), padding=(0, 4, 4), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 5, 5), stride=(1, 4, 4), padding=(0, 2, 2), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=11, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[04/28 23:01:31][INFO] misc.py: 184: Params: 52,816,139
[04/28 23:01:31][INFO] misc.py: 185: Mem: 0.39524316787719727 MB
[04/28 23:01:35][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 23:01:35][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 23:01:35][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 23:01:35][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 23:01:35][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 23:01:35][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 23:01:36][INFO] misc.py: 188: Flops: 2.127273984 G
[04/28 23:01:36][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat encountered 1 time(s)
[04/28 23:01:36][WARNING] jit_analysis.py: 500: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[04/28 23:01:36][WARNING] jit_analysis.py: 500: Unsupported operator aten::add encountered 2 time(s)
[04/28 23:01:36][WARNING] jit_analysis.py: 500: Unsupported operator prim::PythonOp.CheckpointFunction encountered 24 time(s)
[04/28 23:01:36][WARNING] jit_analysis.py: 500: Unsupported operator aten::layer_norm encountered 1 time(s)
[04/28 23:01:36][WARNING] jit_analysis.py: 500: Unsupported operator aten::softmax encountered 1 time(s)
[04/28 23:01:36][WARNING] jit_analysis.py: 518: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.0, module.blocks.0.attn, module.blocks.0.attn.norm_k, module.blocks.0.attn.norm_v, module.blocks.0.attn.pool_k, module.blocks.0.attn.pool_v, module.blocks.0.attn.proj, module.blocks.0.attn.qkv, module.blocks.0.mlp, module.blocks.0.mlp.act, module.blocks.0.mlp.fc1, module.blocks.0.mlp.fc2, module.blocks.0.norm1, module.blocks.0.norm2, module.blocks.1, module.blocks.1.attn, module.blocks.1.attn.norm_k, module.blocks.1.attn.norm_v, module.blocks.1.attn.pool_k, module.blocks.1.attn.pool_v, module.blocks.1.attn.proj, module.blocks.1.attn.qkv, module.blocks.1.drop_path, module.blocks.1.mlp, module.blocks.1.mlp.act, module.blocks.1.mlp.fc1, module.blocks.1.mlp.fc2, module.blocks.1.norm1, module.blocks.1.norm2, module.blocks.1.proj, module.blocks.10, module.blocks.10.attn, module.blocks.10.attn.norm_k, module.blocks.10.attn.norm_v, module.blocks.10.attn.pool_k, module.blocks.10.attn.pool_v, module.blocks.10.attn.proj, module.blocks.10.attn.qkv, module.blocks.10.drop_path, module.blocks.10.mlp, module.blocks.10.mlp.act, module.blocks.10.mlp.fc1, module.blocks.10.mlp.fc2, module.blocks.10.norm1, module.blocks.10.norm2, module.blocks.11, module.blocks.11.attn, module.blocks.11.attn.norm_k, module.blocks.11.attn.norm_v, module.blocks.11.attn.pool_k, module.blocks.11.attn.pool_v, module.blocks.11.attn.proj, module.blocks.11.attn.qkv, module.blocks.11.drop_path, module.blocks.11.mlp, module.blocks.11.mlp.act, module.blocks.11.mlp.fc1, module.blocks.11.mlp.fc2, module.blocks.11.norm1, module.blocks.11.norm2, module.blocks.12, module.blocks.12.attn, module.blocks.12.attn.norm_k, module.blocks.12.attn.norm_v, module.blocks.12.attn.pool_k, module.blocks.12.attn.pool_v, module.blocks.12.attn.proj, module.blocks.12.attn.qkv, module.blocks.12.drop_path, module.blocks.12.mlp, module.blocks.12.mlp.act, module.blocks.12.mlp.fc1, module.blocks.12.mlp.fc2, module.blocks.12.norm1, module.blocks.12.norm2, module.blocks.13, module.blocks.13.attn, module.blocks.13.attn.norm_k, module.blocks.13.attn.norm_v, module.blocks.13.attn.pool_k, module.blocks.13.attn.pool_v, module.blocks.13.attn.proj, module.blocks.13.attn.qkv, module.blocks.13.drop_path, module.blocks.13.mlp, module.blocks.13.mlp.act, module.blocks.13.mlp.fc1, module.blocks.13.mlp.fc2, module.blocks.13.norm1, module.blocks.13.norm2, module.blocks.14, module.blocks.14.attn, module.blocks.14.attn.norm_k, module.blocks.14.attn.norm_v, module.blocks.14.attn.pool_k, module.blocks.14.attn.pool_v, module.blocks.14.attn.proj, module.blocks.14.attn.qkv, module.blocks.14.drop_path, module.blocks.14.mlp, module.blocks.14.mlp.act, module.blocks.14.mlp.fc1, module.blocks.14.mlp.fc2, module.blocks.14.norm1, module.blocks.14.norm2, module.blocks.15, module.blocks.15.attn, module.blocks.15.attn.norm_k, module.blocks.15.attn.norm_v, module.blocks.15.attn.pool_k, module.blocks.15.attn.pool_v, module.blocks.15.attn.proj, module.blocks.15.attn.qkv, module.blocks.15.drop_path, module.blocks.15.mlp, module.blocks.15.mlp.act, module.blocks.15.mlp.fc1, module.blocks.15.mlp.fc2, module.blocks.15.norm1, module.blocks.15.norm2, module.blocks.16, module.blocks.16.attn, module.blocks.16.attn.norm_k, module.blocks.16.attn.norm_v, module.blocks.16.attn.pool_k, module.blocks.16.attn.pool_v, module.blocks.16.attn.proj, module.blocks.16.attn.qkv, module.blocks.16.drop_path, module.blocks.16.mlp, module.blocks.16.mlp.act, module.blocks.16.mlp.fc1, module.blocks.16.mlp.fc2, module.blocks.16.norm1, module.blocks.16.norm2, module.blocks.17, module.blocks.17.attn, module.blocks.17.attn.norm_k, module.blocks.17.attn.norm_v, module.blocks.17.attn.pool_k, module.blocks.17.attn.pool_v, module.blocks.17.attn.proj, module.blocks.17.attn.qkv, module.blocks.17.drop_path, module.blocks.17.mlp, module.blocks.17.mlp.act, module.blocks.17.mlp.fc1, module.blocks.17.mlp.fc2, module.blocks.17.norm1, module.blocks.17.norm2, module.blocks.18, module.blocks.18.attn, module.blocks.18.attn.norm_k, module.blocks.18.attn.norm_v, module.blocks.18.attn.pool_k, module.blocks.18.attn.pool_v, module.blocks.18.attn.proj, module.blocks.18.attn.qkv, module.blocks.18.drop_path, module.blocks.18.mlp, module.blocks.18.mlp.act, module.blocks.18.mlp.fc1, module.blocks.18.mlp.fc2, module.blocks.18.norm1, module.blocks.18.norm2, module.blocks.19, module.blocks.19.attn, module.blocks.19.attn.norm_k, module.blocks.19.attn.norm_v, module.blocks.19.attn.pool_k, module.blocks.19.attn.pool_v, module.blocks.19.attn.proj, module.blocks.19.attn.qkv, module.blocks.19.drop_path, module.blocks.19.mlp, module.blocks.19.mlp.act, module.blocks.19.mlp.fc1, module.blocks.19.mlp.fc2, module.blocks.19.norm1, module.blocks.19.norm2, module.blocks.2, module.blocks.2.attn, module.blocks.2.attn.norm_k, module.blocks.2.attn.norm_q, module.blocks.2.attn.norm_v, module.blocks.2.attn.pool_k, module.blocks.2.attn.pool_q, module.blocks.2.attn.pool_v, module.blocks.2.attn.proj, module.blocks.2.attn.qkv, module.blocks.2.drop_path, module.blocks.2.mlp, module.blocks.2.mlp.act, module.blocks.2.mlp.fc1, module.blocks.2.mlp.fc2, module.blocks.2.norm1, module.blocks.2.norm2, module.blocks.2.pool_skip, module.blocks.20, module.blocks.20.attn, module.blocks.20.attn.norm_k, module.blocks.20.attn.norm_v, module.blocks.20.attn.pool_k, module.blocks.20.attn.pool_v, module.blocks.20.attn.proj, module.blocks.20.attn.qkv, module.blocks.20.drop_path, module.blocks.20.mlp, module.blocks.20.mlp.act, module.blocks.20.mlp.fc1, module.blocks.20.mlp.fc2, module.blocks.20.norm1, module.blocks.20.norm2, module.blocks.20.proj, module.blocks.21, module.blocks.21.attn, module.blocks.21.attn.norm_q, module.blocks.21.attn.pool_q, module.blocks.21.attn.proj, module.blocks.21.attn.qkv, module.blocks.21.drop_path, module.blocks.21.mlp, module.blocks.21.mlp.act, module.blocks.21.mlp.fc1, module.blocks.21.mlp.fc2, module.blocks.21.norm1, module.blocks.21.norm2, module.blocks.21.pool_skip, module.blocks.22, module.blocks.22.attn, module.blocks.22.attn.proj, module.blocks.22.attn.qkv, module.blocks.22.drop_path, module.blocks.22.mlp, module.blocks.22.mlp.act, module.blocks.22.mlp.fc1, module.blocks.22.mlp.fc2, module.blocks.22.norm1, module.blocks.22.norm2, module.blocks.23, module.blocks.23.attn, module.blocks.23.attn.proj, module.blocks.23.attn.qkv, module.blocks.23.drop_path, module.blocks.23.mlp, module.blocks.23.mlp.act, module.blocks.23.mlp.fc1, module.blocks.23.mlp.fc2, module.blocks.23.norm1, module.blocks.23.norm2, module.blocks.3, module.blocks.3.attn, module.blocks.3.attn.norm_k, module.blocks.3.attn.norm_v, module.blocks.3.attn.pool_k, module.blocks.3.attn.pool_v, module.blocks.3.attn.proj, module.blocks.3.attn.qkv, module.blocks.3.drop_path, module.blocks.3.mlp, module.blocks.3.mlp.act, module.blocks.3.mlp.fc1, module.blocks.3.mlp.fc2, module.blocks.3.norm1, module.blocks.3.norm2, module.blocks.4, module.blocks.4.attn, module.blocks.4.attn.norm_k, module.blocks.4.attn.norm_v, module.blocks.4.attn.pool_k, module.blocks.4.attn.pool_v, module.blocks.4.attn.proj, module.blocks.4.attn.qkv, module.blocks.4.drop_path, module.blocks.4.mlp, module.blocks.4.mlp.act, module.blocks.4.mlp.fc1, module.blocks.4.mlp.fc2, module.blocks.4.norm1, module.blocks.4.norm2, module.blocks.4.proj, module.blocks.5, module.blocks.5.attn, module.blocks.5.attn.norm_k, module.blocks.5.attn.norm_q, module.blocks.5.attn.norm_v, module.blocks.5.attn.pool_k, module.blocks.5.attn.pool_q, module.blocks.5.attn.pool_v, module.blocks.5.attn.proj, module.blocks.5.attn.qkv, module.blocks.5.drop_path, module.blocks.5.mlp, module.blocks.5.mlp.act, module.blocks.5.mlp.fc1, module.blocks.5.mlp.fc2, module.blocks.5.norm1, module.blocks.5.norm2, module.blocks.5.pool_skip, module.blocks.6, module.blocks.6.attn, module.blocks.6.attn.norm_k, module.blocks.6.attn.norm_v, module.blocks.6.attn.pool_k, module.blocks.6.attn.pool_v, module.blocks.6.attn.proj, module.blocks.6.attn.qkv, module.blocks.6.drop_path, module.blocks.6.mlp, module.blocks.6.mlp.act, module.blocks.6.mlp.fc1, module.blocks.6.mlp.fc2, module.blocks.6.norm1, module.blocks.6.norm2, module.blocks.7, module.blocks.7.attn, module.blocks.7.attn.norm_k, module.blocks.7.attn.norm_v, module.blocks.7.attn.pool_k, module.blocks.7.attn.pool_v, module.blocks.7.attn.proj, module.blocks.7.attn.qkv, module.blocks.7.drop_path, module.blocks.7.mlp, module.blocks.7.mlp.act, module.blocks.7.mlp.fc1, module.blocks.7.mlp.fc2, module.blocks.7.norm1, module.blocks.7.norm2, module.blocks.8, module.blocks.8.attn, module.blocks.8.attn.norm_k, module.blocks.8.attn.norm_v, module.blocks.8.attn.pool_k, module.blocks.8.attn.pool_v, module.blocks.8.attn.proj, module.blocks.8.attn.qkv, module.blocks.8.drop_path, module.blocks.8.mlp, module.blocks.8.mlp.act, module.blocks.8.mlp.fc1, module.blocks.8.mlp.fc2, module.blocks.8.norm1, module.blocks.8.norm2, module.blocks.9, module.blocks.9.attn, module.blocks.9.attn.norm_k, module.blocks.9.attn.norm_v, module.blocks.9.attn.pool_k, module.blocks.9.attn.pool_v, module.blocks.9.attn.proj, module.blocks.9.attn.qkv, module.blocks.9.drop_path, module.blocks.9.mlp, module.blocks.9.mlp.act, module.blocks.9.mlp.fc1, module.blocks.9.mlp.fc2, module.blocks.9.norm1, module.blocks.9.norm2
[04/28 23:01:36][INFO] misc.py: 193: Activations: 4.816907 M
[04/28 23:01:36][INFO] misc.py: 196: nvidia-smi
[04/28 23:01:38][INFO] checkpoint_amp.py: 550: Load from last checkpoint, ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/checkpoints/checkpoint_latest.pyth.
[04/28 23:01:38][INFO] checkpoint_amp.py: 262: Loading network weights from ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/checkpoints/checkpoint_latest.pyth.
[04/28 23:01:42][INFO] ug2_sparse.py:  90: Constructing Ug2 train_label...
[04/28 23:01:42][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 23:01:42][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 2955) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/train_label+val_dry.csv
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 23:01:44][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 23:01:44][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 23:01:44][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 23:01:44][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 23:01:44][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fc0f7891320>
[04/28 23:01:45][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 23:01:45][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fc0f78bc8c0>
[04/28 23:01:45][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fc2f0ebf7a0>
[04/28 23:01:45][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fc0f78bc680>
[04/28 23:01:45][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 23:01:45][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 23:01:45][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 23:01:45][DEBUG] factory.py:  66: Loading s3:s3
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 23:01:45][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 23:01:45][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 23:01:45][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 23:01:45][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 23:01:45][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fc0f7891320>
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 23:01:46][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fc0f78bc8c0>
[04/28 23:01:46][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fc0f481dcb0>
[04/28 23:01:46][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fc0f78bc680>
[04/28 23:01:46][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 23:01:46][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 23:01:46][DEBUG] factory.py:  66: Loading s3:s3
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 23:01:46][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fc0f7891320>
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 23:01:46][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fc0f78bc8c0>
[04/28 23:01:46][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fc0f3130d40>
[04/28 23:01:46][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fc0f78bc680>
[04/28 23:01:46][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 23:01:46][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 23:01:46][DEBUG] factory.py:  66: Loading s3:s3
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 23:01:46][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 23:01:46][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 23:01:46][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fc0f7891320>
[04/28 23:01:47][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 23:01:47][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fc0f78bc8c0>
[04/28 23:01:47][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fc0f2a5bdd0>
[04/28 23:01:47][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fc0f78bc680>
[04/28 23:01:47][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 23:01:47][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 23:01:47][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 23:01:47][DEBUG] factory.py:  66: Loading s3:s3
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 23:01:47][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 23:01:47][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 23:01:47][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 23:01:47][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fc0f7891320>
[04/28 23:01:47][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 23:01:47][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fc0f78bc8c0>
[04/28 23:01:47][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fc0f2409a70>
[04/28 23:01:47][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fc0f78bc680>
[04/28 23:01:47][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 23:01:47][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 23:01:47][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 23:01:47][DEBUG] factory.py:  66: Loading s3:s3
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/28 23:01:47][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/28 23:01:48][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/28 23:01:48][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/28 23:01:48][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/28 23:01:48][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fc0f7891320>
[04/28 23:01:48][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/28 23:01:48][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fc0f78bc8c0>
[04/28 23:01:48][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fc0f1d32b00>
[04/28 23:01:48][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fc0f78bc680>
[04/28 23:01:48][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/28 23:01:48][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/28 23:01:48][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/28 23:01:48][DEBUG] factory.py:  66: Loading s3:s3
[04/28 23:01:48][INFO] ug2_sparse.py:  90: Constructing Ug2 train_pseudo_label...
[04/28 23:01:48][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 23:01:48][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
[04/28 23:01:48][INFO] ug2_sparse.py:  90: Constructing Ug2 val_dry...
[04/28 23:01:48][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 23:01:48][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 330) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/val_dry.csv
[04/28 23:01:48][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/28 23:01:48][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 23:01:48][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/28 23:01:48][INFO] ug2_sparse.py:  90: Constructing Ug2 train_unlabel...
[04/28 23:01:48][INFO] ug2_sparse.py:  91: Number of clips 1
[04/28 23:01:48][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/total_unlabel.csv
[04/28 23:01:48][INFO] train_net_bn_pseudo.py: 526: Start epoch: 3
[04/28 23:04:07][INFO] distributed.py: 788: Reducer buckets have been rebuilt in this iteration.
[04/28 23:05:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82097, "dt_data": 0.02563, "dt_net": 6.79534, "epoch": "3/30", "eta": "4:51:42", "gpu_mem": "24.43G", "iter": "10/92", "loss": 1.14068, "lr": 0.00002, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:06:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.97426, "dt_data": 0.02544, "dt_net": 6.94882, "epoch": "3/30", "eta": "4:57:06", "gpu_mem": "24.43G", "iter": "20/92", "loss": 1.21967, "lr": 0.00002, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:07:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84664, "dt_data": 0.02526, "dt_net": 6.82137, "epoch": "3/30", "eta": "4:50:31", "gpu_mem": "24.43G", "iter": "30/92", "loss": 1.04373, "lr": 0.00002, "target_top1_err": 15.62500, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:08:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83058, "dt_data": 0.02586, "dt_net": 6.80472, "epoch": "3/30", "eta": "4:48:42", "gpu_mem": "24.43G", "iter": "40/92", "loss": 1.10092, "lr": 0.00002, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:09:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82528, "dt_data": 0.02590, "dt_net": 6.79938, "epoch": "3/30", "eta": "4:47:20", "gpu_mem": "24.43G", "iter": "50/92", "loss": 1.07325, "lr": 0.00003, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:10:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.91183, "dt_data": 0.03270, "dt_net": 6.87912, "epoch": "3/30", "eta": "4:49:50", "gpu_mem": "24.43G", "iter": "60/92", "loss": 1.15278, "lr": 0.00003, "target_top1_err": 10.15625, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:12:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88634, "dt_data": 0.02591, "dt_net": 6.86043, "epoch": "3/30", "eta": "4:47:37", "gpu_mem": "24.43G", "iter": "70/92", "loss": 1.14230, "lr": 0.00003, "target_top1_err": 13.28125, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:13:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83941, "dt_data": 0.02547, "dt_net": 6.81394, "epoch": "3/30", "eta": "4:44:31", "gpu_mem": "24.43G", "iter": "80/92", "loss": 1.22477, "lr": 0.00003, "target_top1_err": 12.50000, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:14:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83242, "dt_data": 0.02541, "dt_net": 6.80700, "epoch": "3/30", "eta": "4:43:05", "gpu_mem": "24.43G", "iter": "90/92", "loss": 1.07306, "lr": 0.00003, "target_top1_err": 11.71875, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:14:35][INFO] logging.py:  99: json_stats: {"RAM": "149.37/1007.34G", "_type": "train_epoch", "dt": 0.00016, "dt_data": 0.00016, "dt_net": 6.80628, "epoch": "3/30", "eta": "0:00:00", "gpu_mem": "24.43G", "loss": 1.09944, "lr": 0.00003, "target_top1_err": 3.29484, "target_top5_err": 0.30571, "top1_err": 3.29484, "top5_err": 0.30571}
[04/28 23:14:35][INFO] train_net_bn_pseudo.py: 569: Epoch 2 takes 766.58s. Epochs from 2 to 2 take 766.58s in average and 766.58s in median.
[04/28 23:14:35][INFO] train_net_bn_pseudo.py: 575: For epoch 2, each iteraction takes 8.33s in average. From epoch 2 to 2, each iteraction takes 8.33s in average.
[04/28 23:15:26][INFO] logging.py:  99: json_stats: {"RAM": "159.91/1007.34G", "_type": "val_epoch", "epoch": "3/30", "gpu_mem": "24.43G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00015, "top1_err": 0.00000, "top5_err": 0.00000}
[04/28 23:16:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:03:30", "gpu_mem": "24.43G", "iter": "10/146", "time_diff": 1.54713, "top1_err": 12.50000, "top5_err": 5.46875}
[04/28 23:16:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:01:04", "gpu_mem": "24.43G", "iter": "20/146", "time_diff": 0.51488, "top1_err": 10.93750, "top5_err": 6.25000}
[04/28 23:16:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:52", "gpu_mem": "24.43G", "iter": "30/146", "time_diff": 0.45442, "top1_err": 10.15625, "top5_err": 4.68750}
[04/28 23:17:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:56", "gpu_mem": "24.43G", "iter": "40/146", "time_diff": 0.52912, "top1_err": 8.59375, "top5_err": 3.90625}
[04/28 23:17:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:02:06", "gpu_mem": "24.43G", "iter": "50/146", "time_diff": 1.31646, "top1_err": 13.28125, "top5_err": 4.68750}
[04/28 23:17:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:01:25", "gpu_mem": "24.43G", "iter": "60/146", "time_diff": 0.99418, "top1_err": 10.93750, "top5_err": 3.12500}
[04/28 23:17:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:42", "gpu_mem": "24.43G", "iter": "70/146", "time_diff": 0.55410, "top1_err": 11.71875, "top5_err": 4.68750}
[04/28 23:17:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:35", "gpu_mem": "24.43G", "iter": "80/146", "time_diff": 0.54011, "top1_err": 11.71875, "top5_err": 3.12500}
[04/28 23:17:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:46", "gpu_mem": "24.43G", "iter": "90/146", "time_diff": 0.83038, "top1_err": 10.93750, "top5_err": 4.68750}
[04/28 23:17:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:34", "gpu_mem": "24.43G", "iter": "100/146", "time_diff": 0.74042, "top1_err": 14.06250, "top5_err": 4.68750}
[04/28 23:17:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:19", "gpu_mem": "24.43G", "iter": "110/146", "time_diff": 0.53365, "top1_err": 10.93750, "top5_err": 4.68750}
[04/28 23:17:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:13", "gpu_mem": "24.43G", "iter": "120/146", "time_diff": 0.52465, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 23:18:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:17", "gpu_mem": "24.43G", "iter": "130/146", "time_diff": 1.12218, "top1_err": 10.15625, "top5_err": 3.12500}
[04/28 23:18:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "3/30", "eta": "0:00:02", "gpu_mem": "24.43G", "iter": "140/146", "time_diff": 0.44179, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 23:18:13][INFO] logging.py:  99: json_stats: {"RAM": "176.98/1007.34G", "_type": "val_epoch", "epoch": "3/30", "gpu_mem": "24.43G", "min_top1_err": 11.10155, "min_top5_err": 4.60413, "time_diff": 0.00009, "top1_err": 11.10155, "top5_err": 4.60413}
[04/28 23:19:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85244, "dt_data": 0.02847, "dt_net": 6.82397, "epoch": "4/30", "eta": "4:42:32", "gpu_mem": "25.00G", "iter": "10/92", "loss": 0.87364, "lr": 0.00003, "target_top1_err": 10.93750, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:20:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85001, "dt_data": 0.02605, "dt_net": 6.82396, "epoch": "4/30", "eta": "4:41:18", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.02006, "lr": 0.00003, "target_top1_err": 13.28125, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:21:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82483, "dt_data": 0.02566, "dt_net": 6.79917, "epoch": "4/30", "eta": "4:39:08", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.14051, "lr": 0.00003, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.78125}
[04/28 23:23:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82293, "dt_data": 0.02611, "dt_net": 6.79681, "epoch": "4/30", "eta": "4:37:55", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.07928, "lr": 0.00003, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:24:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83891, "dt_data": 0.02594, "dt_net": 6.81297, "epoch": "4/30", "eta": "4:37:25", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.02586, "lr": 0.00004, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:25:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82067, "dt_data": 0.02593, "dt_net": 6.79473, "epoch": "4/30", "eta": "4:35:33", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.18055, "lr": 0.00004, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:26:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89479, "dt_data": 0.02604, "dt_net": 6.86875, "epoch": "4/30", "eta": "4:37:24", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.17153, "lr": 0.00004, "target_top1_err": 14.06250, "target_top5_err": 2.34375, "top1_err": 5.46875, "top5_err": 0.00000}
[04/28 23:27:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82846, "dt_data": 0.02590, "dt_net": 6.80256, "epoch": "4/30", "eta": "4:33:35", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.08968, "lr": 0.00004, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:28:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85105, "dt_data": 0.02572, "dt_net": 6.82532, "epoch": "4/30", "eta": "4:33:21", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.15614, "lr": 0.00004, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/28 23:28:59][INFO] logging.py:  99: json_stats: {"RAM": "178.29/1007.34G", "_type": "train_epoch", "dt": 0.00020, "dt_data": 0.00019, "dt_net": 6.81185, "epoch": "4/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.05300, "lr": 0.00004, "target_top1_err": 6.57269, "target_top5_err": 0.62840, "top1_err": 3.27785, "top5_err": 0.32269}
[04/28 23:28:59][INFO] train_net_bn_pseudo.py: 569: Epoch 3 takes 641.28s. Epochs from 2 to 3 take 703.93s in average and 703.93s in median.
[04/28 23:28:59][INFO] train_net_bn_pseudo.py: 575: For epoch 3, each iteraction takes 6.97s in average. From epoch 2 to 3, each iteraction takes 7.65s in average.
[04/28 23:29:12][INFO] logging.py:  99: json_stats: {"RAM": "180.44/1007.34G", "_type": "val_epoch", "epoch": "4/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[04/28 23:29:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:01:15", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 0.55482, "top1_err": 10.93750, "top5_err": 6.25000}
[04/28 23:29:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:01:39", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.79181, "top1_err": 10.93750, "top5_err": 5.46875}
[04/28 23:29:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:01:15", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.65289, "top1_err": 9.37500, "top5_err": 5.46875}
[04/28 23:29:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.55768, "top1_err": 9.37500, "top5_err": 3.12500}
[04/28 23:29:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:02:10", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.35422, "top1_err": 11.71875, "top5_err": 5.46875}
[04/28 23:30:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:01:02", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.72567, "top1_err": 10.15625, "top5_err": 3.90625}
[04/28 23:30:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:41", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.55149, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 23:30:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.53184, "top1_err": 10.15625, "top5_err": 4.68750}
[04/28 23:30:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:39", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.70532, "top1_err": 10.93750, "top5_err": 5.46875}
[04/28 23:30:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:55", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 1.20633, "top1_err": 13.28125, "top5_err": 6.25000}
[04/28 23:30:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.54347, "top1_err": 8.59375, "top5_err": 4.68750}
[04/28 23:30:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:11", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.44084, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 23:30:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:11", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.71218, "top1_err": 9.37500, "top5_err": 3.90625}
[04/28 23:30:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "4/30", "eta": "0:00:06", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 1.06614, "top1_err": 10.93750, "top5_err": 5.46875}
[04/28 23:31:00][INFO] logging.py:  99: json_stats: {"RAM": "183.97/1007.34G", "_type": "val_epoch", "epoch": "4/30", "gpu_mem": "25.00G", "min_top1_err": 10.59596, "min_top5_err": 4.60413, "time_diff": 0.00010, "top1_err": 10.59596, "top5_err": 5.13124}
[04/28 23:32:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.97516, "dt_data": 0.02540, "dt_net": 6.94976, "epoch": "5/30", "eta": "4:36:54", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.09852, "lr": 0.00004, "target_top1_err": 10.93750, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:33:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82650, "dt_data": 0.02615, "dt_net": 6.80035, "epoch": "5/30", "eta": "4:29:52", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.20649, "lr": 0.00004, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/28 23:34:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84042, "dt_data": 0.02609, "dt_net": 6.81433, "epoch": "5/30", "eta": "4:29:17", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.15050, "lr": 0.00004, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:35:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82031, "dt_data": 0.02599, "dt_net": 6.79432, "epoch": "5/30", "eta": "4:27:21", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.11309, "lr": 0.00004, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:37:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83835, "dt_data": 0.02843, "dt_net": 6.80991, "epoch": "5/30", "eta": "4:26:55", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.08536, "lr": 0.00005, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/28 23:38:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84860, "dt_data": 0.02581, "dt_net": 6.82278, "epoch": "5/30", "eta": "4:26:10", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.21653, "lr": 0.00005, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:39:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83124, "dt_data": 0.02684, "dt_net": 6.80440, "epoch": "5/30", "eta": "4:24:22", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.13558, "lr": 0.00005, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:40:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84992, "dt_data": 0.02546, "dt_net": 6.82446, "epoch": "5/30", "eta": "4:23:57", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.07363, "lr": 0.00005, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:41:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82534, "dt_data": 0.02639, "dt_net": 6.79893, "epoch": "5/30", "eta": "4:21:51", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.10248, "lr": 0.00005, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/28 23:41:54][INFO] logging.py:  99: json_stats: {"RAM": "184.77/1007.34G", "_type": "train_epoch", "dt": 0.00814, "dt_data": 0.00814, "dt_net": 6.82084, "epoch": "5/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.09867, "lr": 0.00005, "target_top1_err": 9.64674, "target_top5_err": 1.08696, "top1_err": 3.07405, "top5_err": 0.45856}
[04/28 23:41:54][INFO] train_net_bn_pseudo.py: 569: Epoch 4 takes 651.37s. Epochs from 2 to 4 take 686.41s in average and 651.37s in median.
[04/28 23:41:54][INFO] train_net_bn_pseudo.py: 575: For epoch 4, each iteraction takes 7.08s in average. From epoch 2 to 4, each iteraction takes 7.46s in average.
[04/28 23:42:05][INFO] logging.py:  99: json_stats: {"RAM": "185.86/1007.34G", "_type": "val_epoch", "epoch": "5/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00014, "top1_err": 0.00000, "top5_err": 0.00000}
[04/28 23:42:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:04:21", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.92091, "top1_err": 10.93750, "top5_err": 5.46875}
[04/28 23:42:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:01:08", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.54606, "top1_err": 11.71875, "top5_err": 4.68750}
[04/28 23:42:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:53", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.46374, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 23:42:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.55941, "top1_err": 9.37500, "top5_err": 3.12500}
[04/28 23:42:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:02:21", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.47670, "top1_err": 11.71875, "top5_err": 5.46875}
[04/28 23:42:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:01:11", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.83626, "top1_err": 9.37500, "top5_err": 3.12500}
[04/28 23:43:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.62978, "top1_err": 10.15625, "top5_err": 3.90625}
[04/28 23:43:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:44", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.67635, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 23:43:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.66095, "top1_err": 10.93750, "top5_err": 4.68750}
[04/28 23:43:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.82599, "top1_err": 12.50000, "top5_err": 6.25000}
[04/28 23:43:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:20", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.55573, "top1_err": 8.59375, "top5_err": 4.68750}
[04/28 23:43:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.54601, "top1_err": 9.37500, "top5_err": 3.90625}
[04/28 23:43:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:22", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.42018, "top1_err": 9.37500, "top5_err": 2.34375}
[04/28 23:43:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "5/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.49929, "top1_err": 9.37500, "top5_err": 5.46875}
[04/28 23:43:52][INFO] logging.py:  99: json_stats: {"RAM": "184.28/1007.34G", "_type": "val_epoch", "epoch": "5/30", "gpu_mem": "25.00G", "min_top1_err": 10.55293, "min_top5_err": 4.60413, "time_diff": 0.00008, "top1_err": 10.55293, "top5_err": 4.91609}
[04/28 23:45:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81775, "dt_data": 0.02595, "dt_net": 6.79180, "epoch": "6/30", "eta": "4:20:12", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.11265, "lr": 0.00005, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/28 23:46:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83424, "dt_data": 0.02694, "dt_net": 6.80729, "epoch": "6/30", "eta": "4:19:42", "gpu_mem": "25.00G", "iter": "20/92", "loss": 0.93437, "lr": 0.00005, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/28 23:47:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83008, "dt_data": 0.03186, "dt_net": 6.79822, "epoch": "6/30", "eta": "4:18:24", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.12319, "lr": 0.00005, "target_top1_err": 15.62500, "target_top5_err": 3.90625, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:48:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82162, "dt_data": 0.02585, "dt_net": 6.79576, "epoch": "6/30", "eta": "4:16:56", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.01659, "lr": 0.00005, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/28 23:49:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82230, "dt_data": 0.02727, "dt_net": 6.79503, "epoch": "6/30", "eta": "4:15:50", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.24639, "lr": 0.00006, "target_top1_err": 15.62500, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:51:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.92060, "dt_data": 0.02554, "dt_net": 6.89506, "epoch": "6/30", "eta": "4:18:22", "gpu_mem": "25.00G", "iter": "60/92", "loss": 0.99078, "lr": 0.00006, "target_top1_err": 14.06250, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:52:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81912, "dt_data": 0.02563, "dt_net": 6.79349, "epoch": "6/30", "eta": "4:13:26", "gpu_mem": "25.00G", "iter": "70/92", "loss": 0.87020, "lr": 0.00006, "target_top1_err": 15.62500, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:53:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89756, "dt_data": 0.02510, "dt_net": 6.87246, "epoch": "6/30", "eta": "4:15:12", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.23705, "lr": 0.00006, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:54:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81825, "dt_data": 0.02582, "dt_net": 6.79243, "epoch": "6/30", "eta": "4:11:08", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.10844, "lr": 0.00006, "target_top1_err": 12.50000, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/28 23:54:44][INFO] logging.py:  99: json_stats: {"RAM": "187.88/1007.34G", "_type": "train_epoch", "dt": 0.00529, "dt_data": 0.00529, "dt_net": 6.89854, "epoch": "6/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.06389, "lr": 0.00006, "target_top1_err": 13.07745, "target_top5_err": 1.49457, "top1_err": 3.43071, "top5_err": 0.40761}
[04/28 23:54:44][INFO] train_net_bn_pseudo.py: 569: Epoch 5 takes 648.34s. Epochs from 2 to 5 take 676.89s in average and 649.86s in median.
[04/28 23:54:44][INFO] train_net_bn_pseudo.py: 575: For epoch 5, each iteraction takes 7.05s in average. From epoch 2 to 5, each iteraction takes 7.36s in average.
[04/28 23:54:53][INFO] logging.py:  99: json_stats: {"RAM": "190.86/1007.34G", "_type": "val_epoch", "epoch": "6/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[04/28 23:55:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:04:03", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.78908, "top1_err": 11.71875, "top5_err": 5.46875}
[04/28 23:55:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:56", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.45198, "top1_err": 10.93750, "top5_err": 6.25000}
[04/28 23:55:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:01:32", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.80101, "top1_err": 8.59375, "top5_err": 4.68750}
[04/28 23:55:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:55", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.52820, "top1_err": 10.15625, "top5_err": 3.12500}
[04/28 23:55:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:01:57", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.22523, "top1_err": 13.28125, "top5_err": 5.46875}
[04/28 23:55:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:46", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.54174, "top1_err": 10.15625, "top5_err": 3.90625}
[04/28 23:55:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:33", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.44027, "top1_err": 10.93750, "top5_err": 3.90625}
[04/28 23:55:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:38", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.58452, "top1_err": 9.37500, "top5_err": 3.12500}
[04/28 23:56:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:01:35", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.71304, "top1_err": 9.37500, "top5_err": 4.68750}
[04/28 23:56:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.55884, "top1_err": 12.50000, "top5_err": 4.68750}
[04/28 23:56:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:20", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.55609, "top1_err": 10.15625, "top5_err": 4.68750}
[04/28 23:56:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:15", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.57821, "top1_err": 10.93750, "top5_err": 4.68750}
[04/28 23:56:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:27", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.70813, "top1_err": 10.15625, "top5_err": 3.90625}
[04/28 23:56:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "6/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.44345, "top1_err": 10.15625, "top5_err": 3.90625}
[04/28 23:56:41][INFO] logging.py:  99: json_stats: {"RAM": "187.87/1007.34G", "_type": "val_epoch", "epoch": "6/30", "gpu_mem": "25.00G", "min_top1_err": 10.55293, "min_top5_err": 4.60413, "time_diff": 0.00010, "top1_err": 10.88640, "top5_err": 4.98064}
[04/28 23:58:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85409, "dt_data": 0.02529, "dt_net": 6.82880, "epoch": "7/30", "eta": "4:11:05", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.00512, "lr": 0.00006, "target_top1_err": 12.50000, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/28 23:59:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81806, "dt_data": 0.02527, "dt_net": 6.79279, "epoch": "7/30", "eta": "4:08:37", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.09829, "lr": 0.00006, "target_top1_err": 15.62500, "target_top5_err": 4.68750, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:00:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.94264, "dt_data": 0.02910, "dt_net": 6.91354, "epoch": "7/30", "eta": "4:12:01", "gpu_mem": "25.00G", "iter": "30/92", "loss": 0.97563, "lr": 0.00006, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 00:01:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82721, "dt_data": 0.02703, "dt_net": 6.80018, "epoch": "7/30", "eta": "4:06:41", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.17362, "lr": 0.00006, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 5.46875, "top5_err": 0.00000}
[04/29 00:02:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82483, "dt_data": 0.02631, "dt_net": 6.79852, "epoch": "7/30", "eta": "4:05:27", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.16144, "lr": 0.00007, "target_top1_err": 18.75000, "target_top5_err": 3.12500, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 00:03:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84123, "dt_data": 0.02521, "dt_net": 6.81602, "epoch": "7/30", "eta": "4:04:54", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.09406, "lr": 0.00007, "target_top1_err": 14.06250, "target_top5_err": 0.00000, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:05:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86791, "dt_data": 0.02631, "dt_net": 6.84160, "epoch": "7/30", "eta": "4:04:43", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.21992, "lr": 0.00007, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:06:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81797, "dt_data": 0.02499, "dt_net": 6.79298, "epoch": "7/30", "eta": "4:01:48", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.07206, "lr": 0.00007, "target_top1_err": 16.40625, "target_top5_err": 3.90625, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:07:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83460, "dt_data": 0.02689, "dt_net": 6.80771, "epoch": "7/30", "eta": "4:01:15", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.18274, "lr": 0.00007, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:07:35][INFO] logging.py:  99: json_stats: {"RAM": "184.02/1007.34G", "_type": "train_epoch", "dt": 0.00381, "dt_data": 0.00381, "dt_net": 6.79802, "epoch": "7/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.09695, "lr": 0.00007, "target_top1_err": 17.06861, "target_top5_err": 1.95312, "top1_err": 3.99117, "top5_err": 0.45856}
[04/29 00:07:35][INFO] train_net_bn_pseudo.py: 569: Epoch 6 takes 653.78s. Epochs from 2 to 6 take 672.27s in average and 651.37s in median.
[04/29 00:07:35][INFO] train_net_bn_pseudo.py: 575: For epoch 6, each iteraction takes 7.11s in average. From epoch 2 to 6, each iteraction takes 7.31s in average.
[04/29 00:07:44][INFO] logging.py:  99: json_stats: {"RAM": "183.69/1007.34G", "_type": "val_epoch", "epoch": "7/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 00:07:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:03:34", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.57542, "top1_err": 10.93750, "top5_err": 6.25000}
[04/29 00:08:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:01:05", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.51798, "top1_err": 11.71875, "top5_err": 5.46875}
[04/29 00:08:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.50715, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 00:08:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:01:00", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.57197, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 00:08:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:02:40", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.67704, "top1_err": 11.71875, "top5_err": 5.46875}
[04/29 00:08:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:44", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.51833, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 00:08:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53703, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 00:08:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:36", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.55001, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 00:08:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:29", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.53548, "top1_err": 11.71875, "top5_err": 5.46875}
[04/29 00:09:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:24", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.54032, "top1_err": 13.28125, "top5_err": 6.25000}
[04/29 00:09:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:17", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.49988, "top1_err": 10.93750, "top5_err": 5.46875}
[04/29 00:09:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:12", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.48067, "top1_err": 9.37500, "top5_err": 5.46875}
[04/29 00:09:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:18", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.17712, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 00:09:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "7/30", "eta": "0:00:04", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.68360, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 00:09:32][INFO] logging.py:  99: json_stats: {"RAM": "187.49/1007.34G", "_type": "val_epoch", "epoch": "7/30", "gpu_mem": "25.00G", "min_top1_err": 10.55293, "min_top5_err": 4.60413, "time_diff": 0.00009, "top1_err": 10.67126, "top5_err": 5.42169}
[04/29 00:11:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.90253, "dt_data": 0.02633, "dt_net": 6.87619, "epoch": "8/30", "eta": "4:02:16", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.15864, "lr": 0.00007, "target_top1_err": 18.75000, "target_top5_err": 3.90625, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:12:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82320, "dt_data": 0.02572, "dt_net": 6.79748, "epoch": "8/30", "eta": "3:58:21", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.13319, "lr": 0.00007, "target_top1_err": 12.50000, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:13:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.94453, "dt_data": 0.02792, "dt_net": 6.91660, "epoch": "8/30", "eta": "4:01:26", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.04779, "lr": 0.00007, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 00:14:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82541, "dt_data": 0.02610, "dt_net": 6.79930, "epoch": "8/30", "eta": "3:56:09", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.16244, "lr": 0.00007, "target_top1_err": 19.53125, "target_top5_err": 5.46875, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:15:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85819, "dt_data": 0.02665, "dt_net": 6.83154, "epoch": "8/30", "eta": "3:56:09", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.22656, "lr": 0.00008, "target_top1_err": 11.71875, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:16:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82785, "dt_data": 0.02587, "dt_net": 6.80198, "epoch": "8/30", "eta": "3:53:58", "gpu_mem": "25.00G", "iter": "60/92", "loss": 0.93418, "lr": 0.00008, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:17:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83442, "dt_data": 0.02575, "dt_net": 6.80867, "epoch": "8/30", "eta": "3:53:03", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.22657, "lr": 0.00008, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:19:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.96812, "dt_data": 0.02527, "dt_net": 6.94284, "epoch": "8/30", "eta": "3:56:27", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.13247, "lr": 0.00008, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:20:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82124, "dt_data": 0.02501, "dt_net": 6.79622, "epoch": "8/30", "eta": "3:50:19", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.05642, "lr": 0.00008, "target_top1_err": 14.84375, "target_top5_err": 0.78125, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 00:20:22][INFO] logging.py:  99: json_stats: {"RAM": "190.54/1007.34G", "_type": "train_epoch", "dt": 0.00011, "dt_data": 0.00011, "dt_net": 6.80273, "epoch": "8/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.08027, "lr": 0.00008, "target_top1_err": 20.97486, "target_top5_err": 2.32677, "top1_err": 3.90625, "top5_err": 0.37364}
[04/29 00:20:22][INFO] train_net_bn_pseudo.py: 569: Epoch 7 takes 650.31s. Epochs from 2 to 7 take 668.61s in average and 650.84s in median.
[04/29 00:20:22][INFO] train_net_bn_pseudo.py: 575: For epoch 7, each iteraction takes 7.07s in average. From epoch 2 to 7, each iteraction takes 7.27s in average.
[04/29 00:20:32][INFO] logging.py:  99: json_stats: {"RAM": "189.53/1007.34G", "_type": "val_epoch", "epoch": "8/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 00:20:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:02:52", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.26931, "top1_err": 11.71875, "top5_err": 5.46875}
[04/29 00:20:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:01:10", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.55685, "top1_err": 10.15625, "top5_err": 6.25000}
[04/29 00:21:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:01:01", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.52821, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 00:21:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:57", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.54636, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 00:21:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:01:52", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.17678, "top1_err": 12.50000, "top5_err": 6.25000}
[04/29 00:21:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.54917, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 00:21:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:41", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.54939, "top1_err": 10.93750, "top5_err": 5.46875}
[04/29 00:21:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.56638, "top1_err": 11.71875, "top5_err": 4.68750}
[04/29 00:21:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:01:01", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.10644, "top1_err": 10.93750, "top5_err": 5.46875}
[04/29 00:21:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:34", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.74565, "top1_err": 14.84375, "top5_err": 5.46875}
[04/29 00:21:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 1.04865, "top1_err": 9.37500, "top5_err": 5.46875}
[04/29 00:22:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.56038, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 00:22:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:10", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.63465, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 00:22:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "8/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.45170, "top1_err": 9.37500, "top5_err": 5.46875}
[04/29 00:22:19][INFO] logging.py:  99: json_stats: {"RAM": "191.21/1007.34G", "_type": "val_epoch", "epoch": "8/30", "gpu_mem": "25.00G", "min_top1_err": 10.55293, "min_top5_err": 4.60413, "time_diff": 0.00012, "top1_err": 11.05852, "top5_err": 5.57229}
[04/29 00:23:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81939, "dt_data": 0.02567, "dt_net": 6.79372, "epoch": "9/30", "eta": "3:48:54", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.15025, "lr": 0.00008, "target_top1_err": 13.28125, "target_top5_err": 4.68750, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:24:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89199, "dt_data": 0.02632, "dt_net": 6.86566, "epoch": "9/30", "eta": "3:50:11", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.17000, "lr": 0.00008, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:26:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83138, "dt_data": 0.02556, "dt_net": 6.80581, "epoch": "9/30", "eta": "3:47:01", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.01112, "lr": 0.00008, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 00:27:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83801, "dt_data": 0.02576, "dt_net": 6.81225, "epoch": "9/30", "eta": "3:46:06", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.23368, "lr": 0.00008, "target_top1_err": 14.84375, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 00:28:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81851, "dt_data": 0.02559, "dt_net": 6.79292, "epoch": "9/30", "eta": "3:44:19", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.17166, "lr": 0.00009, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 5.46875, "top5_err": 0.78125}
[04/29 00:29:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87329, "dt_data": 0.02978, "dt_net": 6.84351, "epoch": "9/30", "eta": "3:44:59", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.13903, "lr": 0.00009, "target_top1_err": 17.18750, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:30:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84195, "dt_data": 0.02531, "dt_net": 6.81663, "epoch": "9/30", "eta": "3:42:49", "gpu_mem": "25.00G", "iter": "70/92", "loss": 0.94594, "lr": 0.00009, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 5.46875, "top5_err": 0.00000}
[04/29 00:31:49][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85672, "dt_data": 0.02580, "dt_net": 6.83092, "epoch": "9/30", "eta": "3:42:09", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.18874, "lr": 0.00009, "target_top1_err": 13.28125, "target_top5_err": 3.90625, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:32:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84649, "dt_data": 0.02488, "dt_net": 6.82162, "epoch": "9/30", "eta": "3:40:41", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.25200, "lr": 0.00009, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 00:33:12][INFO] logging.py:  99: json_stats: {"RAM": "190.42/1007.34G", "_type": "train_epoch", "dt": 0.00013, "dt_data": 0.00013, "dt_net": 6.79686, "epoch": "9/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.10968, "lr": 0.00009, "target_top1_err": 25.06793, "target_top5_err": 2.78533, "top1_err": 4.09307, "top5_err": 0.45856}
[04/29 00:33:12][INFO] train_net_bn_pseudo.py: 569: Epoch 8 takes 652.81s. Epochs from 2 to 8 take 666.35s in average and 651.37s in median.
[04/29 00:33:12][INFO] train_net_bn_pseudo.py: 575: For epoch 8, each iteraction takes 7.10s in average. From epoch 2 to 8, each iteraction takes 7.24s in average.
[04/29 00:33:20][INFO] logging.py:  99: json_stats: {"RAM": "190.20/1007.34G", "_type": "val_epoch", "epoch": "9/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 00:33:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:02:25", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.07308, "top1_err": 12.50000, "top5_err": 3.90625}
[04/29 00:33:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:01:06", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.52383, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 00:33:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:01:10", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.60988, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 00:33:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.55439, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 00:34:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:55", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.57326, "top1_err": 12.50000, "top5_err": 4.68750}
[04/29 00:34:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:01:34", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 1.09576, "top1_err": 7.81250, "top5_err": 1.56250}
[04/29 00:34:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:52", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.69116, "top1_err": 11.71875, "top5_err": 3.12500}
[04/29 00:34:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:38", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.57760, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 00:34:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:53", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.95969, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 00:34:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:26", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.58108, "top1_err": 13.28125, "top5_err": 3.90625}
[04/29 00:34:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:21", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.58429, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 00:34:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:13", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.53783, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 00:35:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:21", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.36730, "top1_err": 8.59375, "top5_err": 3.90625}
[04/29 00:35:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "9/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.50759, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 00:35:07][INFO] logging.py:  99: json_stats: {"RAM": "190.02/1007.34G", "_type": "val_epoch", "epoch": "9/30", "gpu_mem": "25.00G", "min_top1_err": 10.55293, "min_top5_err": 4.21687, "time_diff": 0.00126, "top1_err": 10.57444, "top5_err": 4.21687}
[04/29 00:36:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81947, "dt_data": 0.02572, "dt_net": 6.79375, "epoch": "10/30", "eta": "3:38:27", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.13585, "lr": 0.00009, "target_top1_err": 16.40625, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:37:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83137, "dt_data": 0.02690, "dt_net": 6.80447, "epoch": "10/30", "eta": "3:37:41", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.23228, "lr": 0.00009, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:38:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82704, "dt_data": 0.02590, "dt_net": 6.80114, "epoch": "10/30", "eta": "3:36:25", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.06828, "lr": 0.00009, "target_top1_err": 14.84375, "target_top5_err": 3.12500, "top1_err": 7.03125, "top5_err": 0.00000}
[04/29 00:40:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82878, "dt_data": 0.03290, "dt_net": 6.79588, "epoch": "10/30", "eta": "3:35:20", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.21530, "lr": 0.00009, "target_top1_err": 11.71875, "target_top5_err": 2.34375, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 00:41:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84460, "dt_data": 0.02583, "dt_net": 6.81877, "epoch": "10/30", "eta": "3:34:41", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.15690, "lr": 0.00010, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 4.68750, "top5_err": 0.78125}
[04/29 00:42:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85585, "dt_data": 0.02654, "dt_net": 6.82930, "epoch": "10/30", "eta": "3:33:54", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.21926, "lr": 0.00010, "target_top1_err": 15.62500, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.78125}
[04/29 00:43:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84753, "dt_data": 0.02620, "dt_net": 6.82133, "epoch": "10/30", "eta": "3:32:30", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.15131, "lr": 0.00010, "target_top1_err": 13.28125, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:44:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82909, "dt_data": 0.02602, "dt_net": 6.80307, "epoch": "10/30", "eta": "3:30:47", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.15170, "lr": 0.00010, "target_top1_err": 11.71875, "target_top5_err": 0.00000, "top1_err": 6.25000, "top5_err": 0.00000}
[04/29 00:45:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84150, "dt_data": 0.02491, "dt_net": 6.81659, "epoch": "10/30", "eta": "3:30:02", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.16412, "lr": 0.00010, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:46:00][INFO] logging.py:  99: json_stats: {"RAM": "191.34/1007.34G", "_type": "train_epoch", "dt": 0.00014, "dt_data": 0.00014, "dt_net": 6.91793, "epoch": "10/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.12301, "lr": 0.00010, "target_top1_err": 29.12704, "target_top5_err": 3.27785, "top1_err": 4.05910, "top5_err": 0.49253}
[04/29 00:46:00][INFO] train_net_bn_pseudo.py: 569: Epoch 9 takes 652.96s. Epochs from 2 to 9 take 664.68s in average and 652.09s in median.
[04/29 00:46:00][INFO] train_net_bn_pseudo.py: 575: For epoch 9, each iteraction takes 7.10s in average. From epoch 2 to 9, each iteraction takes 7.22s in average.
[04/29 00:46:09][INFO] logging.py:  99: json_stats: {"RAM": "190.58/1007.34G", "_type": "val_epoch", "epoch": "10/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 00:46:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:04:13", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.86125, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 00:46:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:01:04", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.50887, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 00:46:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.50867, "top1_err": 8.59375, "top5_err": 3.90625}
[04/29 00:46:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:56", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.52955, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 00:46:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:01:51", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.16003, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 00:46:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.55577, "top1_err": 9.37500, "top5_err": 1.56250}
[04/29 00:47:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53208, "top1_err": 10.15625, "top5_err": 2.34375}
[04/29 00:47:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:33", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.51175, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 00:47:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:01:15", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.34300, "top1_err": 10.93750, "top5_err": 2.34375}
[04/29 00:47:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 1.27634, "top1_err": 12.50000, "top5_err": 3.12500}
[04/29 00:47:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:18", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.51238, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 00:47:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:15", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.60053, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 00:47:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:20", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.30782, "top1_err": 8.59375, "top5_err": 1.56250}
[04/29 00:47:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "10/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.50411, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 00:47:57][INFO] logging.py:  99: json_stats: {"RAM": "190.15/1007.34G", "_type": "val_epoch", "epoch": "10/30", "gpu_mem": "25.00G", "min_top1_err": 10.55293, "min_top5_err": 3.56067, "time_diff": 0.00116, "top1_err": 10.58520, "top5_err": 3.56067}
[04/29 00:49:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82634, "dt_data": 0.02551, "dt_net": 6.80083, "epoch": "11/30", "eta": "3:28:12", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.07185, "lr": 0.00010, "target_top1_err": 13.28125, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:50:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82128, "dt_data": 0.02598, "dt_net": 6.79530, "epoch": "11/30", "eta": "3:26:54", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.07216, "lr": 0.00010, "target_top1_err": 14.06250, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:51:40][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88173, "dt_data": 0.02546, "dt_net": 6.85627, "epoch": "11/30", "eta": "3:27:35", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.19788, "lr": 0.00010, "target_top1_err": 14.84375, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 00:52:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83930, "dt_data": 0.02589, "dt_net": 6.81341, "epoch": "11/30", "eta": "3:25:10", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.23735, "lr": 0.00010, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 00:53:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89715, "dt_data": 0.02644, "dt_net": 6.87071, "epoch": "11/30", "eta": "3:25:45", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.15741, "lr": 0.00010, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 00:55:06][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81854, "dt_data": 0.02639, "dt_net": 6.79215, "epoch": "11/30", "eta": "3:22:17", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.15820, "lr": 0.00010, "target_top1_err": 14.06250, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:56:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82580, "dt_data": 0.02735, "dt_net": 6.79845, "epoch": "11/30", "eta": "3:21:21", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.22663, "lr": 0.00010, "target_top1_err": 16.40625, "target_top5_err": 4.68750, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 00:57:23][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84788, "dt_data": 0.02521, "dt_net": 6.82267, "epoch": "11/30", "eta": "3:20:52", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.20889, "lr": 0.00010, "target_top1_err": 12.50000, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 00:58:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81913, "dt_data": 0.02507, "dt_net": 6.79405, "epoch": "11/30", "eta": "3:18:53", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.25140, "lr": 0.00010, "target_top1_err": 15.62500, "target_top5_err": 4.68750, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 00:58:45][INFO] logging.py:  99: json_stats: {"RAM": "189.46/1007.34G", "_type": "train_epoch", "dt": 0.00013, "dt_data": 0.00013, "dt_net": 6.85623, "epoch": "11/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.15338, "lr": 0.00010, "target_top1_err": 32.93139, "target_top5_err": 3.78736, "top1_err": 3.80435, "top5_err": 0.50951}
[04/29 00:58:45][INFO] train_net_bn_pseudo.py: 569: Epoch 10 takes 647.72s. Epochs from 2 to 10 take 662.80s in average and 651.37s in median.
[04/29 00:58:45][INFO] train_net_bn_pseudo.py: 575: For epoch 10, each iteraction takes 7.04s in average. From epoch 2 to 10, each iteraction takes 7.20s in average.
[04/29 00:58:54][INFO] logging.py:  99: json_stats: {"RAM": "191.97/1007.34G", "_type": "val_epoch", "epoch": "11/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00012, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 00:59:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:04:06", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.81446, "top1_err": 10.93750, "top5_err": 6.25000}
[04/29 00:59:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:01:37", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.77240, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 00:59:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:01:03", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.55143, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 00:59:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:57", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.53983, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 00:59:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:01:16", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.79477, "top1_err": 10.93750, "top5_err": 5.46875}
[04/29 00:59:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.54872, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 00:59:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:41", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.55068, "top1_err": 12.50000, "top5_err": 4.68750}
[04/29 00:59:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:41", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.63227, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 01:00:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:56", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.01703, "top1_err": 10.15625, "top5_err": 5.46875}
[04/29 01:00:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:39", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.85892, "top1_err": 14.06250, "top5_err": 4.68750}
[04/29 01:00:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.54554, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 01:00:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.56812, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 01:00:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:22", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.38720, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 01:00:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "11/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.66267, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 01:00:43][INFO] logging.py:  99: json_stats: {"RAM": "189.87/1007.34G", "_type": "val_epoch", "epoch": "11/30", "gpu_mem": "25.00G", "min_top1_err": 10.55293, "min_top5_err": 3.56067, "time_diff": 0.00009, "top1_err": 11.12306, "top5_err": 5.08821}
[04/29 01:02:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.94738, "dt_data": 0.02491, "dt_net": 6.92247, "epoch": "12/30", "eta": "3:21:14", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.20662, "lr": 0.00010, "target_top1_err": 15.62500, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:03:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88242, "dt_data": 0.02792, "dt_net": 6.85449, "epoch": "12/30", "eta": "3:18:12", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.04415, "lr": 0.00010, "target_top1_err": 14.84375, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:04:32][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87014, "dt_data": 0.02534, "dt_net": 6.84480, "epoch": "12/30", "eta": "3:16:42", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.02938, "lr": 0.00010, "target_top1_err": 16.40625, "target_top5_err": 5.46875, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:05:41][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81796, "dt_data": 0.02635, "dt_net": 6.79161, "epoch": "12/30", "eta": "3:14:05", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.18771, "lr": 0.00010, "target_top1_err": 11.71875, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:06:50][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82843, "dt_data": 0.02548, "dt_net": 6.80294, "epoch": "12/30", "eta": "3:13:14", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.19056, "lr": 0.00010, "target_top1_err": 15.62500, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 01:07:58][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88401, "dt_data": 0.02594, "dt_net": 6.85807, "epoch": "12/30", "eta": "3:13:40", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.21052, "lr": 0.00010, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:09:07][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.94024, "dt_data": 0.02640, "dt_net": 6.91383, "epoch": "12/30", "eta": "3:14:05", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.21108, "lr": 0.00010, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:10:15][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87699, "dt_data": 0.02503, "dt_net": 6.85195, "epoch": "12/30", "eta": "3:11:10", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.13226, "lr": 0.00010, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:11:24][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84949, "dt_data": 0.02508, "dt_net": 6.82441, "epoch": "12/30", "eta": "3:09:16", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.27864, "lr": 0.00010, "target_top1_err": 16.40625, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:11:38][INFO] logging.py:  99: json_stats: {"RAM": "189.05/1007.34G", "_type": "train_epoch", "dt": 0.00012, "dt_data": 0.00012, "dt_net": 6.80644, "epoch": "12/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.11277, "lr": 0.00010, "target_top1_err": 37.19429, "target_top5_err": 4.24592, "top1_err": 4.26291, "top5_err": 0.45856}
[04/29 01:11:38][INFO] train_net_bn_pseudo.py: 569: Epoch 11 takes 654.28s. Epochs from 2 to 11 take 661.94s in average and 652.09s in median.
[04/29 01:11:38][INFO] train_net_bn_pseudo.py: 575: For epoch 11, each iteraction takes 7.11s in average. From epoch 2 to 11, each iteraction takes 7.20s in average.
[04/29 01:11:46][INFO] logging.py:  99: json_stats: {"RAM": "190.07/1007.34G", "_type": "val_epoch", "epoch": "12/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 01:12:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:03:19", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.46832, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 01:12:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:01:08", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.54271, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 01:12:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:01:00", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.52002, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 01:12:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:54", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.51120, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 01:12:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:01:15", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.78767, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 01:12:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:49", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.57254, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 01:12:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:41", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.54236, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 01:12:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:29", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.45385, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 01:12:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:01:23", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.49971, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 01:13:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.54919, "top1_err": 11.71875, "top5_err": 6.25000}
[04/29 01:13:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:20", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.57090, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 01:13:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.54656, "top1_err": 8.59375, "top5_err": 3.90625}
[04/29 01:13:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:24", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.50361, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 01:13:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "12/30", "eta": "0:00:04", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.67365, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 01:13:34][INFO] logging.py:  99: json_stats: {"RAM": "191.62/1007.34G", "_type": "val_epoch", "epoch": "12/30", "gpu_mem": "25.00G", "min_top1_err": 10.46687, "min_top5_err": 3.56067, "time_diff": 0.00013, "top1_err": 10.46687, "top5_err": 4.21687}
[04/29 01:15:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84429, "dt_data": 0.02649, "dt_net": 6.81779, "epoch": "13/30", "eta": "3:07:45", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.22071, "lr": 0.00010, "target_top1_err": 17.18750, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:16:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86258, "dt_data": 0.02862, "dt_net": 6.83396, "epoch": "13/30", "eta": "3:07:07", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.16300, "lr": 0.00010, "target_top1_err": 12.50000, "target_top5_err": 3.90625, "top1_err": 5.46875, "top5_err": 0.00000}
[04/29 01:17:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88697, "dt_data": 0.02543, "dt_net": 6.86153, "epoch": "13/30", "eta": "3:06:38", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.08688, "lr": 0.00010, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:18:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81750, "dt_data": 0.02499, "dt_net": 6.79250, "epoch": "13/30", "eta": "3:03:37", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.23550, "lr": 0.00010, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:19:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87390, "dt_data": 0.02575, "dt_net": 6.84815, "epoch": "13/30", "eta": "3:03:59", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.17217, "lr": 0.00010, "target_top1_err": 10.93750, "target_top5_err": 0.78125, "top1_err": 7.03125, "top5_err": 0.00000}
[04/29 01:20:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82076, "dt_data": 0.02561, "dt_net": 6.79514, "epoch": "13/30", "eta": "3:01:25", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.03458, "lr": 0.00010, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 5.46875, "top5_err": 0.00000}
[04/29 01:21:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82693, "dt_data": 0.02572, "dt_net": 6.80121, "epoch": "13/30", "eta": "3:00:27", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.17697, "lr": 0.00010, "target_top1_err": 14.06250, "target_top5_err": 3.90625, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:23:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84911, "dt_data": 0.02553, "dt_net": 6.82358, "epoch": "13/30", "eta": "2:59:54", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.17920, "lr": 0.00010, "target_top1_err": 16.40625, "target_top5_err": 4.68750, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:24:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88911, "dt_data": 0.02490, "dt_net": 6.86421, "epoch": "13/30", "eta": "2:59:48", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.18202, "lr": 0.00009, "target_top1_err": 11.71875, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:24:27][INFO] logging.py:  99: json_stats: {"RAM": "189.54/1007.34G", "_type": "train_epoch", "dt": 0.00017, "dt_data": 0.00016, "dt_net": 6.83543, "epoch": "13/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.11389, "lr": 0.00009, "target_top1_err": 41.28736, "target_top5_err": 4.73845, "top1_err": 4.09307, "top5_err": 0.49253}
[04/29 01:24:27][INFO] train_net_bn_pseudo.py: 569: Epoch 12 takes 650.21s. Epochs from 2 to 12 take 660.88s in average and 651.37s in median.
[04/29 01:24:27][INFO] train_net_bn_pseudo.py: 575: For epoch 12, each iteraction takes 7.07s in average. From epoch 2 to 12, each iteraction takes 7.18s in average.
[04/29 01:24:36][INFO] logging.py:  99: json_stats: {"RAM": "191.80/1007.34G", "_type": "val_epoch", "epoch": "13/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 01:24:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:04:11", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.84858, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 01:24:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:01:07", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.53795, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 01:25:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:01:03", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.54436, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 01:25:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.56297, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 01:25:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:02:24", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.50474, "top1_err": 12.50000, "top5_err": 3.12500}
[04/29 01:25:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:01:04", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.75074, "top1_err": 9.37500, "top5_err": 1.56250}
[04/29 01:25:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:39", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.52600, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 01:25:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.53759, "top1_err": 7.81250, "top5_err": 2.34375}
[04/29 01:25:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:01:14", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.33583, "top1_err": 11.71875, "top5_err": 2.34375}
[04/29 01:25:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:21", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.46977, "top1_err": 13.28125, "top5_err": 4.68750}
[04/29 01:25:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:21", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.59864, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 01:26:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.55461, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 01:26:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:15", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.97568, "top1_err": 7.81250, "top5_err": 1.56250}
[04/29 01:26:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "13/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.63995, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 01:26:22][INFO] logging.py:  99: json_stats: {"RAM": "189.57/1007.34G", "_type": "val_epoch", "epoch": "13/30", "gpu_mem": "25.00G", "min_top1_err": 10.31627, "min_top5_err": 3.32401, "time_diff": 0.00010, "top1_err": 10.31627, "top5_err": 3.32401}
[04/29 01:27:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85234, "dt_data": 0.02563, "dt_net": 6.82671, "epoch": "14/30", "eta": "2:57:28", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.19393, "lr": 0.00009, "target_top1_err": 14.84375, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:29:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82837, "dt_data": 0.02506, "dt_net": 6.80331, "epoch": "14/30", "eta": "2:55:43", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.25551, "lr": 0.00009, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:30:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88348, "dt_data": 0.02593, "dt_net": 6.85755, "epoch": "14/30", "eta": "2:55:59", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.22175, "lr": 0.00009, "target_top1_err": 16.40625, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 01:31:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86608, "dt_data": 0.02691, "dt_net": 6.83917, "epoch": "14/30", "eta": "2:54:23", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.20061, "lr": 0.00009, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 01:32:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85057, "dt_data": 0.02596, "dt_net": 6.82461, "epoch": "14/30", "eta": "2:52:51", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.09419, "lr": 0.00009, "target_top1_err": 15.62500, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:33:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88649, "dt_data": 0.02639, "dt_net": 6.86010, "epoch": "14/30", "eta": "2:52:37", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.19575, "lr": 0.00009, "target_top1_err": 12.50000, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:34:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81981, "dt_data": 0.02571, "dt_net": 6.79409, "epoch": "14/30", "eta": "2:49:48", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.05012, "lr": 0.00009, "target_top1_err": 16.40625, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:35:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83890, "dt_data": 0.02536, "dt_net": 6.81354, "epoch": "14/30", "eta": "2:49:08", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.19115, "lr": 0.00009, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:37:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82659, "dt_data": 0.02514, "dt_net": 6.80145, "epoch": "14/30", "eta": "2:47:42", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.16457, "lr": 0.00009, "target_top1_err": 14.84375, "target_top5_err": 4.68750, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:37:13][INFO] logging.py:  99: json_stats: {"RAM": "192.02/1007.34G", "_type": "train_epoch", "dt": 0.00298, "dt_data": 0.00298, "dt_net": 6.79167, "epoch": "14/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.14604, "lr": 0.00009, "target_top1_err": 45.34647, "target_top5_err": 4.94226, "top1_err": 4.05910, "top5_err": 0.20380}
[04/29 01:37:13][INFO] train_net_bn_pseudo.py: 569: Epoch 13 takes 646.58s. Epochs from 2 to 13 take 659.69s in average and 650.84s in median.
[04/29 01:37:13][INFO] train_net_bn_pseudo.py: 575: For epoch 13, each iteraction takes 7.03s in average. From epoch 2 to 13, each iteraction takes 7.17s in average.
[04/29 01:37:22][INFO] logging.py:  99: json_stats: {"RAM": "190.78/1007.34G", "_type": "val_epoch", "epoch": "14/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 01:37:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:02:05", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 0.92590, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 01:37:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:57", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.45383, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 01:37:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:01:03", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.54386, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 01:37:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:01:02", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.58997, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 01:38:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:53", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.56080, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 01:38:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.55472, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 01:38:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:42", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.56177, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 01:38:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:34", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.52897, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 01:38:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:44", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.79469, "top1_err": 10.93750, "top5_err": 5.46875}
[04/29 01:38:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.76368, "top1_err": 12.50000, "top5_err": 3.90625}
[04/29 01:38:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.54411, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 01:38:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.54439, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 01:39:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:13", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.84396, "top1_err": 7.81250, "top5_err": 3.90625}
[04/29 01:39:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "14/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.48593, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 01:39:10][INFO] logging.py:  99: json_stats: {"RAM": "188.99/1007.34G", "_type": "val_epoch", "epoch": "14/30", "gpu_mem": "25.00G", "min_top1_err": 10.31627, "min_top5_err": 3.32401, "time_diff": 0.00009, "top1_err": 10.52065, "top5_err": 4.36747}
[04/29 01:40:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85906, "dt_data": 0.02562, "dt_net": 6.83344, "epoch": "15/30", "eta": "2:47:07", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.12135, "lr": 0.00009, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 01:41:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84958, "dt_data": 0.02601, "dt_net": 6.82356, "epoch": "15/30", "eta": "2:45:45", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.12956, "lr": 0.00009, "target_top1_err": 13.28125, "target_top5_err": 2.34375, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:43:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82011, "dt_data": 0.02628, "dt_net": 6.79384, "epoch": "15/30", "eta": "2:43:54", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.06424, "lr": 0.00009, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:44:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82141, "dt_data": 0.02500, "dt_net": 6.79640, "epoch": "15/30", "eta": "2:42:48", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.02685, "lr": 0.00009, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 01:45:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87034, "dt_data": 0.02590, "dt_net": 6.84444, "epoch": "15/30", "eta": "2:42:49", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.17890, "lr": 0.00009, "target_top1_err": 11.71875, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:46:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81779, "dt_data": 0.02552, "dt_net": 6.79227, "epoch": "15/30", "eta": "2:40:26", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.12283, "lr": 0.00009, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:47:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82528, "dt_data": 0.02611, "dt_net": 6.79917, "epoch": "15/30", "eta": "2:39:29", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.16868, "lr": 0.00009, "target_top1_err": 17.18750, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:48:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85728, "dt_data": 0.02552, "dt_net": 6.83176, "epoch": "15/30", "eta": "2:39:05", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.13844, "lr": 0.00009, "target_top1_err": 17.18750, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:49:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82274, "dt_data": 0.02518, "dt_net": 6.79756, "epoch": "15/30", "eta": "2:37:09", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.05842, "lr": 0.00009, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 01:50:06][INFO] logging.py:  99: json_stats: {"RAM": "192.38/1007.34G", "_type": "train_epoch", "dt": 0.00239, "dt_data": 0.00239, "dt_net": 6.79709, "epoch": "15/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.08528, "lr": 0.00009, "target_top1_err": 49.45652, "target_top5_err": 5.45177, "top1_err": 4.11005, "top5_err": 0.50951}
[04/29 01:50:06][INFO] train_net_bn_pseudo.py: 569: Epoch 14 takes 655.83s. Epochs from 2 to 14 take 659.39s in average and 651.37s in median.
[04/29 01:50:06][INFO] train_net_bn_pseudo.py: 575: For epoch 14, each iteraction takes 7.13s in average. From epoch 2 to 14, each iteraction takes 7.17s in average.
[04/29 01:50:14][INFO] logging.py:  99: json_stats: {"RAM": "194.97/1007.34G", "_type": "val_epoch", "epoch": "15/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 01:50:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:02:26", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.07858, "top1_err": 10.93750, "top5_err": 2.34375}
[04/29 01:50:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:01:05", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.52236, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 01:50:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:01:05", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.56350, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 01:50:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:01:00", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.56682, "top1_err": 8.59375, "top5_err": 2.34375}
[04/29 01:50:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:02:36", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.63106, "top1_err": 11.71875, "top5_err": 3.12500}
[04/29 01:51:04][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:46", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.54229, "top1_err": 8.59375, "top5_err": 2.34375}
[04/29 01:51:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53237, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 01:51:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.56642, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 01:51:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:01:04", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.14318, "top1_err": 10.15625, "top5_err": 2.34375}
[04/29 01:51:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.87322, "top1_err": 14.06250, "top5_err": 3.12500}
[04/29 01:51:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.53754, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 01:51:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.56075, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 01:51:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:16", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.04653, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 01:52:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "15/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.53962, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 01:52:02][INFO] logging.py:  99: json_stats: {"RAM": "188.33/1007.34G", "_type": "val_epoch", "epoch": "15/30", "gpu_mem": "25.00G", "min_top1_err": 10.13339, "min_top5_err": 3.06583, "time_diff": 0.00016, "top1_err": 10.13339, "top5_err": 3.06583}
[04/29 01:53:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82619, "dt_data": 0.02562, "dt_net": 6.80057, "epoch": "16/30", "eta": "2:35:51", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.04027, "lr": 0.00008, "target_top1_err": 13.28125, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 01:54:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83573, "dt_data": 0.02596, "dt_net": 6.80977, "epoch": "16/30", "eta": "2:34:56", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.09894, "lr": 0.00008, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 01:55:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87088, "dt_data": 0.03604, "dt_net": 6.83484, "epoch": "16/30", "eta": "2:34:35", "gpu_mem": "25.00G", "iter": "30/92", "loss": 0.91745, "lr": 0.00008, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:57:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82447, "dt_data": 0.02624, "dt_net": 6.79822, "epoch": "16/30", "eta": "2:32:24", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.18819, "lr": 0.00008, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:58:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86314, "dt_data": 0.02672, "dt_net": 6.83641, "epoch": "16/30", "eta": "2:32:07", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.22646, "lr": 0.00008, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 01:59:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86509, "dt_data": 0.02547, "dt_net": 6.83961, "epoch": "16/30", "eta": "2:31:01", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.16625, "lr": 0.00008, "target_top1_err": 13.28125, "target_top5_err": 0.78125, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 02:00:27][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82868, "dt_data": 0.02627, "dt_net": 6.80241, "epoch": "16/30", "eta": "2:29:05", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.22007, "lr": 0.00008, "target_top1_err": 13.28125, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:01:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81694, "dt_data": 0.02574, "dt_net": 6.79119, "epoch": "16/30", "eta": "2:27:42", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.12649, "lr": 0.00008, "target_top1_err": 17.96875, "target_top5_err": 3.90625, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 02:02:44][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.99953, "dt_data": 0.02526, "dt_net": 6.97426, "epoch": "16/30", "eta": "2:30:29", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.19351, "lr": 0.00008, "target_top1_err": 12.50000, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:02:58][INFO] logging.py:  99: json_stats: {"RAM": "192.11/1007.34G", "_type": "train_epoch", "dt": 0.01319, "dt_data": 0.01319, "dt_net": 6.83741, "epoch": "16/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.08608, "lr": 0.00008, "target_top1_err": 53.20992, "target_top5_err": 5.77446, "top1_err": 3.75340, "top5_err": 0.32269}
[04/29 02:02:58][INFO] train_net_bn_pseudo.py: 569: Epoch 15 takes 650.80s. Epochs from 2 to 15 take 658.78s in average and 651.09s in median.
[04/29 02:02:58][INFO] train_net_bn_pseudo.py: 575: For epoch 15, each iteraction takes 7.07s in average. From epoch 2 to 15, each iteraction takes 7.16s in average.
[04/29 02:03:07][INFO] logging.py:  99: json_stats: {"RAM": "191.11/1007.34G", "_type": "val_epoch", "epoch": "16/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00008, "top1_err": 0.60241, "top5_err": 0.00000}
[04/29 02:03:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:02:54", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.28244, "top1_err": 11.71875, "top5_err": 5.46875}
[04/29 02:03:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:56", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.45160, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 02:03:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:01:00", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.51734, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 02:03:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:55", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.52235, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:03:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:02:04", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.29240, "top1_err": 12.50000, "top5_err": 3.90625}
[04/29 02:03:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:38", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.44436, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:04:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:01:02", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.82558, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 02:04:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.56701, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:04:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:01:08", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.22314, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 02:04:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:26", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.56730, "top1_err": 13.28125, "top5_err": 3.90625}
[04/29 02:04:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:18", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.52550, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 02:04:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:15", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.58267, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 02:04:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:13", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.82326, "top1_err": 8.59375, "top5_err": 3.90625}
[04/29 02:04:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "16/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.52675, "top1_err": 11.71875, "top5_err": 4.68750}
[04/29 02:04:54][INFO] logging.py:  99: json_stats: {"RAM": "193.80/1007.34G", "_type": "val_epoch", "epoch": "16/30", "gpu_mem": "25.00G", "min_top1_err": 10.13339, "min_top5_err": 3.06583, "time_diff": 0.00008, "top1_err": 10.77883, "top5_err": 4.23838}
[04/29 02:06:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85408, "dt_data": 0.02687, "dt_net": 6.82720, "epoch": "17/30", "eta": "2:25:59", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.06303, "lr": 0.00008, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:07:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81852, "dt_data": 0.02622, "dt_net": 6.79231, "epoch": "17/30", "eta": "2:24:05", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.12586, "lr": 0.00008, "target_top1_err": 12.50000, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:08:38][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81924, "dt_data": 0.02569, "dt_net": 6.79355, "epoch": "17/30", "eta": "2:22:58", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.20129, "lr": 0.00008, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:09:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82798, "dt_data": 0.02671, "dt_net": 6.80127, "epoch": "17/30", "eta": "2:22:01", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.21716, "lr": 0.00008, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:10:55][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82679, "dt_data": 0.02573, "dt_net": 6.80106, "epoch": "17/30", "eta": "2:20:51", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.13465, "lr": 0.00008, "target_top1_err": 14.84375, "target_top5_err": 4.68750, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 02:12:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83820, "dt_data": 0.02631, "dt_net": 6.81189, "epoch": "17/30", "eta": "2:19:57", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.17880, "lr": 0.00008, "target_top1_err": 18.75000, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:13:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81958, "dt_data": 0.02531, "dt_net": 6.79427, "epoch": "17/30", "eta": "2:18:26", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.29789, "lr": 0.00007, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 6.25000, "top5_err": 0.00000}
[04/29 02:14:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81976, "dt_data": 0.02543, "dt_net": 6.79433, "epoch": "17/30", "eta": "2:17:18", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.17685, "lr": 0.00007, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.78125}
[04/29 02:15:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.94213, "dt_data": 0.02611, "dt_net": 6.91602, "epoch": "17/30", "eta": "2:18:36", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.18869, "lr": 0.00007, "target_top1_err": 14.06250, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:15:43][INFO] logging.py:  99: json_stats: {"RAM": "192.00/1007.34G", "_type": "train_epoch", "dt": 0.00012, "dt_data": 0.00012, "dt_net": 6.79295, "epoch": "17/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.12350, "lr": 0.00007, "target_top1_err": 56.48777, "target_top5_err": 6.28397, "top1_err": 3.27785, "top5_err": 0.50951}
[04/29 02:15:43][INFO] train_net_bn_pseudo.py: 569: Epoch 16 takes 649.19s. Epochs from 2 to 16 take 658.14s in average and 650.80s in median.
[04/29 02:15:43][INFO] train_net_bn_pseudo.py: 575: For epoch 16, each iteraction takes 7.06s in average. From epoch 2 to 16, each iteraction takes 7.15s in average.
[04/29 02:15:52][INFO] logging.py:  99: json_stats: {"RAM": "191.37/1007.34G", "_type": "val_epoch", "epoch": "17/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 02:16:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:02:32", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.12367, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 02:16:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:01:48", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.86236, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:16:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:01:04", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.55185, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:16:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.56417, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 02:16:34][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:51", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.54162, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 02:16:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:53", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.62239, "top1_err": 7.81250, "top5_err": 1.56250}
[04/29 02:16:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53220, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:16:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:39", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.59465, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 02:17:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:01:04", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.14709, "top1_err": 10.93750, "top5_err": 1.56250}
[04/29 02:17:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.55550, "top1_err": 12.50000, "top5_err": 3.12500}
[04/29 02:17:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:21", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.59606, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 02:17:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.55543, "top1_err": 7.81250, "top5_err": 1.56250}
[04/29 02:17:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:11", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.69746, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 02:17:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "17/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.48073, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 02:17:38][INFO] logging.py:  99: json_stats: {"RAM": "187.59/1007.34G", "_type": "val_epoch", "epoch": "17/30", "gpu_mem": "25.00G", "min_top1_err": 9.96127, "min_top5_err": 3.06583, "time_diff": 0.00011, "top1_err": 9.96127, "top5_err": 3.27022}
[04/29 02:19:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89018, "dt_data": 0.02635, "dt_net": 6.86382, "epoch": "18/30", "eta": "2:16:11", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.25067, "lr": 0.00007, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:20:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84165, "dt_data": 0.02634, "dt_net": 6.81531, "epoch": "18/30", "eta": "2:14:05", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.02327, "lr": 0.00007, "target_top1_err": 10.93750, "target_top5_err": 0.78125, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:21:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81764, "dt_data": 0.02541, "dt_net": 6.79223, "epoch": "18/30", "eta": "2:12:29", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.00816, "lr": 0.00007, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:22:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88444, "dt_data": 0.02680, "dt_net": 6.85763, "epoch": "18/30", "eta": "2:12:38", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.19029, "lr": 0.00007, "target_top1_err": 11.71875, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:23:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83859, "dt_data": 0.03025, "dt_net": 6.80833, "epoch": "18/30", "eta": "2:10:37", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.20637, "lr": 0.00007, "target_top1_err": 16.40625, "target_top5_err": 3.90625, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:24:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89467, "dt_data": 0.03087, "dt_net": 6.86380, "epoch": "18/30", "eta": "2:10:32", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.05228, "lr": 0.00007, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:25:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84787, "dt_data": 0.02592, "dt_net": 6.82195, "epoch": "18/30", "eta": "2:08:30", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.11090, "lr": 0.00007, "target_top1_err": 12.50000, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:27:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89923, "dt_data": 0.02563, "dt_net": 6.87360, "epoch": "18/30", "eta": "2:08:19", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.20863, "lr": 0.00007, "target_top1_err": 16.40625, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:28:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82359, "dt_data": 0.02505, "dt_net": 6.79854, "epoch": "18/30", "eta": "2:05:46", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.00075, "lr": 0.00007, "target_top1_err": 12.50000, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:28:22][INFO] logging.py:  99: json_stats: {"RAM": "191.69/1007.34G", "_type": "train_epoch", "dt": 0.00168, "dt_data": 0.00167, "dt_net": 6.80265, "epoch": "18/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.08586, "lr": 0.00007, "target_top1_err": 59.83356, "target_top5_err": 6.64062, "top1_err": 3.34579, "top5_err": 0.35666}
[04/29 02:28:22][INFO] train_net_bn_pseudo.py: 569: Epoch 17 takes 639.41s. Epochs from 2 to 17 take 656.97s in average and 650.56s in median.
[04/29 02:28:22][INFO] train_net_bn_pseudo.py: 575: For epoch 17, each iteraction takes 6.95s in average. From epoch 2 to 17, each iteraction takes 7.14s in average.
[04/29 02:28:32][INFO] logging.py:  99: json_stats: {"RAM": "192.10/1007.34G", "_type": "val_epoch", "epoch": "18/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00007, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 02:28:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:01:50", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 0.80895, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 02:28:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:02:00", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.95414, "top1_err": 10.93750, "top5_err": 5.46875}
[04/29 02:29:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:01:06", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.56983, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 02:29:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:01:07", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.63646, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:29:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:01:44", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 1.08609, "top1_err": 11.71875, "top5_err": 3.12500}
[04/29 02:29:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:43", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.50484, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:29:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53640, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 02:29:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.56601, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 02:29:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:01:08", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.22846, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:29:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:23", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.50256, "top1_err": 12.50000, "top5_err": 4.68750}
[04/29 02:29:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.53120, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 02:30:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:13", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.53146, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:30:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:08", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.56017, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 02:30:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "18/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.47645, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 02:30:21][INFO] logging.py:  99: json_stats: {"RAM": "192.71/1007.34G", "_type": "val_epoch", "epoch": "18/30", "gpu_mem": "25.00G", "min_top1_err": 9.96127, "min_top5_err": 3.06583, "time_diff": 0.00009, "top1_err": 10.17642, "top5_err": 4.15232}
[04/29 02:31:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84844, "dt_data": 0.03206, "dt_net": 6.81637, "epoch": "19/30", "eta": "2:04:52", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.08436, "lr": 0.00007, "target_top1_err": 11.71875, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:32:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86314, "dt_data": 0.03603, "dt_net": 6.82711, "epoch": "19/30", "eta": "2:03:59", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.18264, "lr": 0.00006, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:34:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81932, "dt_data": 0.02607, "dt_net": 6.79325, "epoch": "19/30", "eta": "2:02:03", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.03830, "lr": 0.00006, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 02:35:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86645, "dt_data": 0.02625, "dt_net": 6.84020, "epoch": "19/30", "eta": "2:01:45", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.05560, "lr": 0.00006, "target_top1_err": 15.62500, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:36:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82311, "dt_data": 0.02537, "dt_net": 6.79774, "epoch": "19/30", "eta": "1:59:51", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.10299, "lr": 0.00006, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:37:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81933, "dt_data": 0.02589, "dt_net": 6.79343, "epoch": "19/30", "eta": "1:58:39", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.19855, "lr": 0.00006, "target_top1_err": 14.06250, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:38:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82703, "dt_data": 0.02623, "dt_net": 6.80080, "epoch": "19/30", "eta": "1:57:39", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.24015, "lr": 0.00006, "target_top1_err": 16.40625, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:39:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.90812, "dt_data": 0.02856, "dt_net": 6.87956, "epoch": "19/30", "eta": "1:57:53", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.11764, "lr": 0.00006, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 02:40:53][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81786, "dt_data": 0.02541, "dt_net": 6.79245, "epoch": "19/30", "eta": "1:55:13", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.20511, "lr": 0.00006, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:41:07][INFO] logging.py:  99: json_stats: {"RAM": "190.12/1007.34G", "_type": "train_epoch", "dt": 0.00014, "dt_data": 0.00013, "dt_net": 6.81251, "epoch": "19/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.07154, "lr": 0.00006, "target_top1_err": 63.06046, "target_top5_err": 7.04823, "top1_err": 3.22690, "top5_err": 0.40761}
[04/29 02:41:07][INFO] train_net_bn_pseudo.py: 569: Epoch 18 takes 646.75s. Epochs from 2 to 18 take 656.37s in average and 650.31s in median.
[04/29 02:41:07][INFO] train_net_bn_pseudo.py: 575: For epoch 18, each iteraction takes 7.03s in average. From epoch 2 to 18, each iteraction takes 7.13s in average.
[04/29 02:41:17][INFO] logging.py:  99: json_stats: {"RAM": "191.72/1007.34G", "_type": "val_epoch", "epoch": "19/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00008, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 02:41:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:01:58", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 0.87026, "top1_err": 11.71875, "top5_err": 4.68750}
[04/29 02:41:40][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:02:19", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 1.10521, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 02:41:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:01:03", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.54317, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:41:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:55", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.52387, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:42:00][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:49", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.51379, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 02:42:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:45", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.53335, "top1_err": 8.59375, "top5_err": 1.56250}
[04/29 02:42:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:38", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.50539, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:42:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.54289, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 02:42:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.44720, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 02:42:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.77488, "top1_err": 14.06250, "top5_err": 3.90625}
[04/29 02:42:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.55213, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 02:42:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.56307, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 02:42:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:12", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.76242, "top1_err": 8.59375, "top5_err": 2.34375}
[04/29 02:43:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "19/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.48137, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:43:05][INFO] logging.py:  99: json_stats: {"RAM": "193.09/1007.34G", "_type": "val_epoch", "epoch": "19/30", "gpu_mem": "25.00G", "min_top1_err": 9.96127, "min_top5_err": 3.06583, "time_diff": 0.00009, "top1_err": 10.29475, "top5_err": 3.64673}
[04/29 02:44:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.93331, "dt_data": 0.03086, "dt_net": 6.90244, "epoch": "20/30", "eta": "1:55:47", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.16156, "lr": 0.00006, "target_top1_err": 11.71875, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:45:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85523, "dt_data": 0.02714, "dt_net": 6.82809, "epoch": "20/30", "eta": "1:53:20", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.11473, "lr": 0.00006, "target_top1_err": 11.71875, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:46:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82454, "dt_data": 0.02633, "dt_net": 6.79820, "epoch": "20/30", "eta": "1:51:41", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.20439, "lr": 0.00006, "target_top1_err": 12.50000, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:48:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82231, "dt_data": 0.02599, "dt_net": 6.79631, "epoch": "20/30", "eta": "1:50:31", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.13604, "lr": 0.00005, "target_top1_err": 11.71875, "target_top5_err": 0.00000, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:49:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82675, "dt_data": 0.02610, "dt_net": 6.80065, "epoch": "20/30", "eta": "1:49:27", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.02468, "lr": 0.00005, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 02:50:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85331, "dt_data": 0.02648, "dt_net": 6.82683, "epoch": "20/30", "eta": "1:48:44", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.16029, "lr": 0.00005, "target_top1_err": 12.50000, "target_top5_err": 4.68750, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:51:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87838, "dt_data": 0.02860, "dt_net": 6.84977, "epoch": "20/30", "eta": "1:47:59", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.01245, "lr": 0.00005, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 02:52:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82041, "dt_data": 0.02544, "dt_net": 6.79496, "epoch": "20/30", "eta": "1:45:56", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.00089, "lr": 0.00005, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 4.68750, "top5_err": 0.00000}
[04/29 02:53:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87710, "dt_data": 0.02538, "dt_net": 6.85172, "epoch": "20/30", "eta": "1:45:40", "gpu_mem": "25.00G", "iter": "90/92", "loss": 0.97298, "lr": 0.00005, "target_top1_err": 14.84375, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:53:57][INFO] logging.py:  99: json_stats: {"RAM": "190.68/1007.34G", "_type": "train_epoch", "dt": 0.00013, "dt_data": 0.00013, "dt_net": 6.83288, "epoch": "20/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.06970, "lr": 0.00005, "target_top1_err": 66.01562, "target_top5_err": 7.33696, "top1_err": 2.95516, "top5_err": 0.28872}
[04/29 02:53:57][INFO] train_net_bn_pseudo.py: 569: Epoch 19 takes 651.41s. Epochs from 2 to 19 take 656.09s in average and 650.56s in median.
[04/29 02:53:57][INFO] train_net_bn_pseudo.py: 575: For epoch 19, each iteraction takes 7.08s in average. From epoch 2 to 19, each iteraction takes 7.13s in average.
[04/29 02:54:05][INFO] logging.py:  99: json_stats: {"RAM": "192.12/1007.34G", "_type": "val_epoch", "epoch": "20/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00015, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 02:54:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:02:52", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.27094, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 02:54:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.46977, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 02:54:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:52", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.45355, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:54:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:49", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.46623, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 02:54:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:53", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.55434, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 02:54:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:44", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.51799, "top1_err": 8.59375, "top5_err": 1.56250}
[04/29 02:55:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53699, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 02:55:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:42", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.63660, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 02:55:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:01:13", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.31123, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 02:55:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:26", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.56819, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 02:55:29][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:20", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.56482, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 02:55:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:12", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.47134, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 02:55:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:39", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 2.45455, "top1_err": 7.03125, "top5_err": 3.12500}
[04/29 02:55:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "20/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.49597, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 02:55:52][INFO] logging.py:  99: json_stats: {"RAM": "190.51/1007.34G", "_type": "val_epoch", "epoch": "20/30", "gpu_mem": "25.00G", "min_top1_err": 9.69234, "min_top5_err": 3.06583, "time_diff": 0.00010, "top1_err": 9.69234, "top5_err": 3.65749}
[04/29 02:57:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82185, "dt_data": 0.02573, "dt_net": 6.79612, "epoch": "21/30", "eta": "1:43:27", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.24361, "lr": 0.00005, "target_top1_err": 9.37500, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:58:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83357, "dt_data": 0.02655, "dt_net": 6.80702, "epoch": "21/30", "eta": "1:42:30", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.04325, "lr": 0.00005, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 02:59:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86898, "dt_data": 0.02564, "dt_net": 6.84333, "epoch": "21/30", "eta": "1:41:53", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.05469, "lr": 0.00005, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:00:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.92714, "dt_data": 0.02523, "dt_net": 6.90192, "epoch": "21/30", "eta": "1:41:35", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.15097, "lr": 0.00005, "target_top1_err": 14.06250, "target_top5_err": 4.68750, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 03:01:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.94593, "dt_data": 0.02590, "dt_net": 6.92003, "epoch": "21/30", "eta": "1:40:42", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.15218, "lr": 0.00005, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:03:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89486, "dt_data": 0.02554, "dt_net": 6.86932, "epoch": "21/30", "eta": "1:38:49", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.07262, "lr": 0.00005, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:04:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81792, "dt_data": 0.02577, "dt_net": 6.79215, "epoch": "21/30", "eta": "1:36:35", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.11216, "lr": 0.00004, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:05:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82227, "dt_data": 0.02582, "dt_net": 6.79645, "epoch": "21/30", "eta": "1:35:30", "gpu_mem": "25.00G", "iter": "80/92", "loss": 0.95961, "lr": 0.00004, "target_top1_err": 13.28125, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:06:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82402, "dt_data": 0.02584, "dt_net": 6.79818, "epoch": "21/30", "eta": "1:34:23", "gpu_mem": "25.00G", "iter": "90/92", "loss": 0.99427, "lr": 0.00004, "target_top1_err": 10.93750, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:06:44][INFO] logging.py:  99: json_stats: {"RAM": "191.78/1007.34G", "_type": "train_epoch", "dt": 0.00209, "dt_data": 0.00209, "dt_net": 6.80482, "epoch": "21/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.07637, "lr": 0.00004, "target_top1_err": 68.95380, "target_top5_err": 7.62568, "top1_err": 2.93818, "top5_err": 0.28872}
[04/29 03:06:44][INFO] train_net_bn_pseudo.py: 569: Epoch 20 takes 645.96s. Epochs from 2 to 20 take 655.56s in average and 650.31s in median.
[04/29 03:06:44][INFO] train_net_bn_pseudo.py: 575: For epoch 20, each iteraction takes 7.02s in average. From epoch 2 to 20, each iteraction takes 7.13s in average.
[04/29 03:06:52][INFO] logging.py:  99: json_stats: {"RAM": "191.99/1007.34G", "_type": "val_epoch", "epoch": "21/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 03:07:08][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:02:53", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.27623, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 03:07:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:57", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.45284, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 03:07:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:01:00", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.52083, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 03:07:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.55106, "top1_err": 9.37500, "top5_err": 1.56250}
[04/29 03:07:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:51", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.53147, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 03:07:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:48", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.56217, "top1_err": 8.59375, "top5_err": 1.56250}
[04/29 03:07:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:43", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.57262, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 03:07:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.53812, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 03:08:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:30", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.54472, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 03:08:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.56062, "top1_err": 11.71875, "top5_err": 3.12500}
[04/29 03:08:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.55362, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 03:08:25][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:13", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.52213, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 03:08:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:23", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.47945, "top1_err": 7.03125, "top5_err": 3.12500}
[04/29 03:08:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "21/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.49418, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 03:08:41][INFO] logging.py:  99: json_stats: {"RAM": "191.94/1007.34G", "_type": "val_epoch", "epoch": "21/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00125, "top1_err": 9.60628, "top5_err": 3.47461}
[04/29 03:10:18][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.93097, "dt_data": 0.02973, "dt_net": 6.90123, "epoch": "22/30", "eta": "1:34:29", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.14774, "lr": 0.00004, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 5.46875, "top5_err": 0.00000}
[04/29 03:11:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82209, "dt_data": 0.02601, "dt_net": 6.79607, "epoch": "22/30", "eta": "1:31:52", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.16445, "lr": 0.00004, "target_top1_err": 14.06250, "target_top5_err": 2.34375, "top1_err": 3.90625, "top5_err": 0.00000}
[04/29 03:12:35][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87547, "dt_data": 0.02671, "dt_net": 6.84875, "epoch": "22/30", "eta": "1:31:26", "gpu_mem": "25.00G", "iter": "30/92", "loss": 0.90237, "lr": 0.00004, "target_top1_err": 9.37500, "target_top5_err": 0.00000, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:13:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81840, "dt_data": 0.02572, "dt_net": 6.79268, "epoch": "22/30", "eta": "1:29:32", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.02273, "lr": 0.00004, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:14:52][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84025, "dt_data": 0.02560, "dt_net": 6.81464, "epoch": "22/30", "eta": "1:28:41", "gpu_mem": "25.00G", "iter": "50/92", "loss": 0.89114, "lr": 0.00004, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:16:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86569, "dt_data": 0.02739, "dt_net": 6.83830, "epoch": "22/30", "eta": "1:27:52", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.20182, "lr": 0.00004, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:17:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.94122, "dt_data": 0.03269, "dt_net": 6.90852, "epoch": "22/30", "eta": "1:27:41", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.08605, "lr": 0.00004, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:18:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81752, "dt_data": 0.02507, "dt_net": 6.79245, "epoch": "22/30", "eta": "1:24:59", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.11591, "lr": 0.00004, "target_top1_err": 15.62500, "target_top5_err": 3.12500, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:19:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87716, "dt_data": 0.02538, "dt_net": 6.85177, "epoch": "22/30", "eta": "1:24:35", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.05855, "lr": 0.00004, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:19:40][INFO] logging.py:  99: json_stats: {"RAM": "193.29/1007.34G", "_type": "train_epoch", "dt": 0.00013, "dt_data": 0.00013, "dt_net": 6.82024, "epoch": "22/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.05031, "lr": 0.00004, "target_top1_err": 71.85802, "target_top5_err": 7.98234, "top1_err": 2.90421, "top5_err": 0.35666}
[04/29 03:19:40][INFO] train_net_bn_pseudo.py: 569: Epoch 21 takes 653.57s. Epochs from 2 to 21 take 655.46s in average and 650.56s in median.
[04/29 03:19:40][INFO] train_net_bn_pseudo.py: 575: For epoch 21, each iteraction takes 7.10s in average. From epoch 2 to 21, each iteraction takes 7.12s in average.
[04/29 03:19:48][INFO] logging.py:  99: json_stats: {"RAM": "193.23/1007.34G", "_type": "val_epoch", "epoch": "22/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00008, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 03:20:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:01:11", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 0.52670, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 03:20:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:01:36", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.76958, "top1_err": 10.15625, "top5_err": 5.46875}
[04/29 03:20:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.50201, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 03:20:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:55", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.52095, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 03:20:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:01:11", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.74461, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 03:20:36][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.55287, "top1_err": 9.37500, "top5_err": 1.56250}
[04/29 03:20:44][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53860, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:20:50][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:36", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.55343, "top1_err": 7.03125, "top5_err": 3.12500}
[04/29 03:20:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:46", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.83293, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 03:21:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:49", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 1.07768, "top1_err": 11.71875, "top5_err": 4.68750}
[04/29 03:21:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.72005, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:21:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:13", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.50441, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 03:21:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:26", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.67269, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:21:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "22/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.48202, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 03:21:34][INFO] logging.py:  99: json_stats: {"RAM": "192.51/1007.34G", "_type": "val_epoch", "epoch": "22/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00015, "top1_err": 9.92900, "top5_err": 3.60370}
[04/29 03:23:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82927, "dt_data": 0.02536, "dt_net": 6.80391, "epoch": "23/30", "eta": "1:22:38", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.21444, "lr": 0.00003, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:24:09][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.91401, "dt_data": 0.02497, "dt_net": 6.88903, "epoch": "23/30", "eta": "1:22:30", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.12075, "lr": 0.00003, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:25:17][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84293, "dt_data": 0.02756, "dt_net": 6.81537, "epoch": "23/30", "eta": "1:20:31", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.23090, "lr": 0.00003, "target_top1_err": 12.50000, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:26:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86045, "dt_data": 0.02650, "dt_net": 6.83395, "epoch": "23/30", "eta": "1:19:34", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.14969, "lr": 0.00003, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:27:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82130, "dt_data": 0.02604, "dt_net": 6.79526, "epoch": "23/30", "eta": "1:17:59", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.10871, "lr": 0.00003, "target_top1_err": 10.15625, "target_top5_err": 0.78125, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:28:43][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83243, "dt_data": 0.02570, "dt_net": 6.80672, "epoch": "23/30", "eta": "1:16:58", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.00397, "lr": 0.00003, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:29:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83146, "dt_data": 0.02488, "dt_net": 6.80657, "epoch": "23/30", "eta": "1:15:49", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.03594, "lr": 0.00003, "target_top1_err": 11.71875, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:31:00][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.91338, "dt_data": 0.02515, "dt_net": 6.88823, "epoch": "23/30", "eta": "1:15:35", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.07630, "lr": 0.00003, "target_top1_err": 14.84375, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:32:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82016, "dt_data": 0.02565, "dt_net": 6.79451, "epoch": "23/30", "eta": "1:13:25", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.18330, "lr": 0.00003, "target_top1_err": 14.06250, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:32:22][INFO] logging.py:  99: json_stats: {"RAM": "191.54/1007.34G", "_type": "train_epoch", "dt": 0.00027, "dt_data": 0.00027, "dt_net": 6.81889, "epoch": "23/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.07203, "lr": 0.00003, "target_top1_err": 74.49049, "target_top5_err": 8.15217, "top1_err": 2.63247, "top5_err": 0.16984}
[04/29 03:32:22][INFO] train_net_bn_pseudo.py: 569: Epoch 22 takes 647.95s. Epochs from 2 to 22 take 655.10s in average and 650.31s in median.
[04/29 03:32:22][INFO] train_net_bn_pseudo.py: 575: For epoch 22, each iteraction takes 7.04s in average. From epoch 2 to 22, each iteraction takes 7.12s in average.
[04/29 03:32:30][INFO] logging.py:  99: json_stats: {"RAM": "196.12/1007.34G", "_type": "val_epoch", "epoch": "23/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00014, "top1_err": 0.30120, "top5_err": 0.00000}
[04/29 03:32:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:03:42", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.63601, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 03:32:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:01:05", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.52365, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 03:32:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:51", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.44088, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 03:33:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.55430, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:33:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.60657, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 03:33:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:01:11", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.82603, "top1_err": 10.15625, "top5_err": 2.34375}
[04/29 03:33:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:39", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.52097, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 03:33:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.54013, "top1_err": 7.03125, "top5_err": 3.12500}
[04/29 03:33:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.04611, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 03:33:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:24", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.53720, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 03:33:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.55528, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 03:34:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.55449, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 03:34:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:26", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.66267, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:34:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "23/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.45120, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 03:34:18][INFO] logging.py:  99: json_stats: {"RAM": "193.93/1007.34G", "_type": "val_epoch", "epoch": "23/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00011, "top1_err": 9.71386, "top5_err": 3.94793}
[04/29 03:35:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82279, "dt_data": 0.02550, "dt_net": 6.79728, "epoch": "24/30", "eta": "1:12:05", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.12861, "lr": 0.00003, "target_top1_err": 9.37500, "target_top5_err": 0.00000, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:36:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.97493, "dt_data": 0.02571, "dt_net": 6.94921, "epoch": "24/30", "eta": "1:12:32", "gpu_mem": "25.00G", "iter": "20/92", "loss": 0.94266, "lr": 0.00003, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:38:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82940, "dt_data": 0.02659, "dt_net": 6.80281, "epoch": "24/30", "eta": "1:09:53", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.14827, "lr": 0.00003, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:39:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88050, "dt_data": 0.02559, "dt_net": 6.85491, "epoch": "24/30", "eta": "1:09:15", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.07563, "lr": 0.00003, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:40:21][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86290, "dt_data": 0.03244, "dt_net": 6.83046, "epoch": "24/30", "eta": "1:07:56", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.07143, "lr": 0.00002, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 0.78125, "top5_err": 0.00000}
[04/29 03:41:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82344, "dt_data": 0.02639, "dt_net": 6.79704, "epoch": "24/30", "eta": "1:06:24", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.17578, "lr": 0.00002, "target_top1_err": 16.40625, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:42:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84208, "dt_data": 0.02999, "dt_net": 6.81209, "epoch": "24/30", "eta": "1:05:27", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.02788, "lr": 0.00002, "target_top1_err": 6.25000, "target_top5_err": 0.78125, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:43:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.91397, "dt_data": 0.02539, "dt_net": 6.88858, "epoch": "24/30", "eta": "1:04:59", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.09600, "lr": 0.00002, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:44:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81958, "dt_data": 0.02580, "dt_net": 6.79377, "epoch": "24/30", "eta": "1:02:58", "gpu_mem": "25.00G", "iter": "90/92", "loss": 0.95935, "lr": 0.00002, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 3.90625, "top5_err": 0.78125}
[04/29 03:45:09][INFO] logging.py:  99: json_stats: {"RAM": "193.94/1007.34G", "_type": "train_epoch", "dt": 0.00014, "dt_data": 0.00014, "dt_net": 6.82822, "epoch": "24/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.04050, "lr": 0.00002, "target_top1_err": 77.12296, "target_top5_err": 8.44090, "top1_err": 2.63247, "top5_err": 0.28872}
[04/29 03:45:09][INFO] train_net_bn_pseudo.py: 569: Epoch 23 takes 651.64s. Epochs from 2 to 23 take 654.94s in average and 650.56s in median.
[04/29 03:45:09][INFO] train_net_bn_pseudo.py: 575: For epoch 23, each iteraction takes 7.08s in average. From epoch 2 to 23, each iteraction takes 7.12s in average.
[04/29 03:45:18][INFO] logging.py:  99: json_stats: {"RAM": "195.09/1007.34G", "_type": "val_epoch", "epoch": "24/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00013, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 03:45:32][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:03:29", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.54362, "top1_err": 10.93750, "top5_err": 5.46875}
[04/29 03:45:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:01:41", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.80591, "top1_err": 9.37500, "top5_err": 6.25000}
[04/29 03:45:47][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:01:04", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.55730, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 03:45:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:01:00", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.57000, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:46:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:01:11", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.74716, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 03:46:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.55357, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 03:46:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:48", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.63260, "top1_err": 9.37500, "top5_err": 4.68750}
[04/29 03:46:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.53666, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 03:46:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:01:29", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.59419, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 03:46:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:23", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.51439, "top1_err": 12.50000, "top5_err": 4.68750}
[04/29 03:46:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:18", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.52643, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 03:46:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.54647, "top1_err": 7.81250, "top5_err": 3.90625}
[04/29 03:46:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.22368, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:47:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "24/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.53484, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 03:47:06][INFO] logging.py:  99: json_stats: {"RAM": "189.25/1007.34G", "_type": "val_epoch", "epoch": "24/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00145, "top1_err": 9.84294, "top5_err": 4.62565}
[04/29 03:48:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82193, "dt_data": 0.02606, "dt_net": 6.79587, "epoch": "25/30", "eta": "1:01:37", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.11476, "lr": 0.00002, "target_top1_err": 14.84375, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:49:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83386, "dt_data": 0.02561, "dt_net": 6.80824, "epoch": "25/30", "eta": "1:00:35", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.03630, "lr": 0.00002, "target_top1_err": 11.71875, "target_top5_err": 0.00000, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:50:46][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82242, "dt_data": 0.02792, "dt_net": 6.79449, "epoch": "25/30", "eta": "0:59:21", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.00777, "lr": 0.00002, "target_top1_err": 7.81250, "target_top5_err": 0.78125, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:51:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.90521, "dt_data": 0.02593, "dt_net": 6.87928, "epoch": "25/30", "eta": "0:58:55", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.02643, "lr": 0.00002, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:53:03][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84774, "dt_data": 0.02730, "dt_net": 6.82043, "epoch": "25/30", "eta": "0:57:17", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.19779, "lr": 0.00002, "target_top1_err": 12.50000, "target_top5_err": 0.00000, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:54:12][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81813, "dt_data": 0.02535, "dt_net": 6.79278, "epoch": "25/30", "eta": "0:55:54", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.13550, "lr": 0.00002, "target_top1_err": 11.71875, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:55:20][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83156, "dt_data": 0.02604, "dt_net": 6.80553, "epoch": "25/30", "eta": "0:54:52", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.01962, "lr": 0.00002, "target_top1_err": 10.15625, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 03:56:29][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.90014, "dt_data": 0.02511, "dt_net": 6.87502, "epoch": "25/30", "eta": "0:54:16", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.11413, "lr": 0.00002, "target_top1_err": 13.28125, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 03:57:37][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84624, "dt_data": 0.02569, "dt_net": 6.82054, "epoch": "25/30", "eta": "0:52:42", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.18870, "lr": 0.00002, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 03:57:51][INFO] logging.py:  99: json_stats: {"RAM": "193.40/1007.34G", "_type": "train_epoch", "dt": 0.00012, "dt_data": 0.00012, "dt_net": 6.79806, "epoch": "25/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.06986, "lr": 0.00002, "target_top1_err": 79.67052, "target_top5_err": 8.71264, "top1_err": 2.54755, "top5_err": 0.27174}
[04/29 03:57:51][INFO] train_net_bn_pseudo.py: 569: Epoch 24 takes 645.21s. Epochs from 2 to 24 take 654.52s in average and 650.31s in median.
[04/29 03:57:51][INFO] train_net_bn_pseudo.py: 575: For epoch 24, each iteraction takes 7.01s in average. From epoch 2 to 24, each iteraction takes 7.11s in average.
[04/29 03:58:00][INFO] logging.py:  99: json_stats: {"RAM": "193.41/1007.34G", "_type": "val_epoch", "epoch": "25/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 03:58:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:01:11", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 0.52558, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 03:58:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:01:10", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.56184, "top1_err": 9.37500, "top5_err": 5.46875}
[04/29 03:58:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:01:05", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.56546, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 03:58:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:56", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.52839, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 03:58:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:01:21", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.85044, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 03:58:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:46", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.53630, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 03:58:56][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:34", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.45310, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 03:59:03][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.56186, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 03:59:11][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:30", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.54790, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 03:59:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:23", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.51104, "top1_err": 11.71875, "top5_err": 4.68750}
[04/29 03:59:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:16", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.45860, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 03:59:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.54529, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 03:59:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:12", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.75452, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 03:59:43][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "25/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.49171, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 03:59:46][INFO] logging.py:  99: json_stats: {"RAM": "192.15/1007.34G", "_type": "val_epoch", "epoch": "25/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00010, "top1_err": 9.81067, "top5_err": 4.32444}
[04/29 04:01:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83547, "dt_data": 0.02535, "dt_net": 6.81011, "epoch": "26/30", "eta": "0:51:15", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.16707, "lr": 0.00001, "target_top1_err": 10.15625, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:02:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87456, "dt_data": 0.02576, "dt_net": 6.84880, "epoch": "26/30", "eta": "0:50:24", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.08836, "lr": 0.00001, "target_top1_err": 7.81250, "target_top5_err": 0.78125, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:03:36][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.90938, "dt_data": 0.02687, "dt_net": 6.88251, "epoch": "26/30", "eta": "0:49:31", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.15352, "lr": 0.00001, "target_top1_err": 14.06250, "target_top5_err": 3.12500, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:04:45][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85861, "dt_data": 0.02636, "dt_net": 6.83225, "epoch": "26/30", "eta": "0:48:00", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.08217, "lr": 0.00001, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:05:54][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88145, "dt_data": 0.02599, "dt_net": 6.85546, "epoch": "26/30", "eta": "0:47:01", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.10723, "lr": 0.00001, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:07:02][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.92932, "dt_data": 0.02708, "dt_net": 6.90224, "epoch": "26/30", "eta": "0:46:11", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.14072, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:08:11][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82465, "dt_data": 0.02533, "dt_net": 6.79932, "epoch": "26/30", "eta": "0:44:21", "gpu_mem": "25.00G", "iter": "70/92", "loss": 0.95639, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:09:19][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81906, "dt_data": 0.02597, "dt_net": 6.79309, "epoch": "26/30", "eta": "0:43:11", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.03535, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:10:28][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81988, "dt_data": 0.02584, "dt_net": 6.79404, "epoch": "26/30", "eta": "0:42:03", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.13234, "lr": 0.00001, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:10:42][INFO] logging.py:  99: json_stats: {"RAM": "190.85/1007.34G", "_type": "train_epoch", "dt": 0.00303, "dt_data": 0.00303, "dt_net": 6.79632, "epoch": "26/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.07389, "lr": 0.00001, "target_top1_err": 82.35394, "target_top5_err": 8.98438, "top1_err": 2.68342, "top5_err": 0.27174}
[04/29 04:10:42][INFO] train_net_bn_pseudo.py: 569: Epoch 25 takes 655.69s. Epochs from 2 to 25 take 654.57s in average and 650.56s in median.
[04/29 04:10:42][INFO] train_net_bn_pseudo.py: 575: For epoch 25, each iteraction takes 7.13s in average. From epoch 2 to 25, each iteraction takes 7.11s in average.
[04/29 04:10:52][INFO] logging.py:  99: json_stats: {"RAM": "189.24/1007.34G", "_type": "val_epoch", "epoch": "26/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 04:11:06][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:01:52", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 0.82524, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 04:11:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:01:05", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.52330, "top1_err": 9.37500, "top5_err": 5.46875}
[04/29 04:11:20][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:01:02", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.53853, "top1_err": 8.59375, "top5_err": 4.68750}
[04/29 04:11:26][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:01:04", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.60727, "top1_err": 10.15625, "top5_err": 3.12500}
[04/29 04:11:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:01:18", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.81557, "top1_err": 11.71875, "top5_err": 3.90625}
[04/29 04:11:41][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:47", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.55570, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:11:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:42", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.56285, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 04:11:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.53872, "top1_err": 7.03125, "top5_err": 3.12500}
[04/29 04:12:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:35", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.62699, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 04:12:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.55286, "top1_err": 11.71875, "top5_err": 4.68750}
[04/29 04:12:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:42", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 1.17929, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 04:12:23][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.55801, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:12:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:15", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.94312, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 04:12:37][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "26/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.54789, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 04:12:39][INFO] logging.py:  99: json_stats: {"RAM": "189.97/1007.34G", "_type": "val_epoch", "epoch": "26/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00010, "top1_err": 9.81067, "top5_err": 4.43201}
[04/29 04:14:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85092, "dt_data": 0.02550, "dt_net": 6.82542, "epoch": "27/30", "eta": "0:40:52", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.08872, "lr": 0.00001, "target_top1_err": 10.15625, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:15:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.96771, "dt_data": 0.02615, "dt_net": 6.94156, "epoch": "27/30", "eta": "0:40:24", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.13390, "lr": 0.00001, "target_top1_err": 7.81250, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:16:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85131, "dt_data": 0.02541, "dt_net": 6.82589, "epoch": "27/30", "eta": "0:38:35", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.09519, "lr": 0.00001, "target_top1_err": 10.93750, "target_top5_err": 0.00000, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:17:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82229, "dt_data": 0.02587, "dt_net": 6.79641, "epoch": "27/30", "eta": "0:37:17", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.20582, "lr": 0.00001, "target_top1_err": 15.62500, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:18:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81782, "dt_data": 0.02666, "dt_net": 6.79115, "epoch": "27/30", "eta": "0:36:08", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.10071, "lr": 0.00001, "target_top1_err": 8.59375, "target_top5_err": 0.00000, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:19:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84788, "dt_data": 0.02735, "dt_net": 6.82053, "epoch": "27/30", "eta": "0:35:09", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.09145, "lr": 0.00001, "target_top1_err": 11.71875, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:20:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84274, "dt_data": 0.02572, "dt_net": 6.81702, "epoch": "27/30", "eta": "0:33:59", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.07068, "lr": 0.00001, "target_top1_err": 6.25000, "target_top5_err": 0.78125, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:22:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81942, "dt_data": 0.02516, "dt_net": 6.79426, "epoch": "27/30", "eta": "0:32:43", "gpu_mem": "25.00G", "iter": "80/92", "loss": 0.91873, "lr": 0.00001, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:23:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84924, "dt_data": 0.02597, "dt_net": 6.82326, "epoch": "27/30", "eta": "0:31:44", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.06788, "lr": 0.00001, "target_top1_err": 11.71875, "target_top5_err": 3.12500, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 04:23:26][INFO] logging.py:  99: json_stats: {"RAM": "193.83/1007.34G", "_type": "train_epoch", "dt": 0.00012, "dt_data": 0.00012, "dt_net": 6.82842, "epoch": "27/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.04457, "lr": 0.00001, "target_top1_err": 84.49389, "target_top5_err": 9.10326, "top1_err": 2.13995, "top5_err": 0.11889}
[04/29 04:23:26][INFO] train_net_bn_pseudo.py: 569: Epoch 26 takes 647.03s. Epochs from 2 to 26 take 654.27s in average and 650.31s in median.
[04/29 04:23:26][INFO] train_net_bn_pseudo.py: 575: For epoch 26, each iteraction takes 7.03s in average. From epoch 2 to 26, each iteraction takes 7.11s in average.
[04/29 04:23:36][INFO] logging.py:  99: json_stats: {"RAM": "191.91/1007.34G", "_type": "val_epoch", "epoch": "27/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 04:23:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:04:01", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.77782, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 04:23:57][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:01:03", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.50729, "top1_err": 10.15625, "top5_err": 5.46875}
[04/29 04:24:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:52", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.45398, "top1_err": 8.59375, "top5_err": 3.12500}
[04/29 04:24:10][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.55707, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:24:17][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:52", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.54997, "top1_err": 10.15625, "top5_err": 5.46875}
[04/29 04:24:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:44", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.51946, "top1_err": 9.37500, "top5_err": 2.34375}
[04/29 04:24:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:41", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.54735, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 04:24:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:36", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.55513, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 04:24:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:01:14", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 1.32621, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 04:24:51][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:38", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.82713, "top1_err": 11.71875, "top5_err": 5.46875}
[04/29 04:24:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:17", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.49664, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 04:25:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.55406, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:25:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:19", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.22776, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 04:25:19][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "27/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.45205, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 04:25:21][INFO] logging.py:  99: json_stats: {"RAM": "191.87/1007.34G", "_type": "val_epoch", "epoch": "27/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00009, "top1_err": 9.89673, "top5_err": 4.48580}
[04/29 04:26:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82558, "dt_data": 0.03219, "dt_net": 6.79339, "epoch": "28/30", "eta": "0:30:15", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.11195, "lr": 0.00001, "target_top1_err": 12.50000, "target_top5_err": 2.34375, "top1_err": 0.78125, "top5_err": 0.00000}
[04/29 04:28:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83927, "dt_data": 0.02609, "dt_net": 6.81318, "epoch": "28/30", "eta": "0:29:10", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.06845, "lr": 0.00001, "target_top1_err": 10.15625, "target_top5_err": 2.34375, "top1_err": 0.78125, "top5_err": 0.00000}
[04/29 04:29:13][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84882, "dt_data": 0.02573, "dt_net": 6.82309, "epoch": "28/30", "eta": "0:28:04", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.12571, "lr": 0.00001, "target_top1_err": 12.50000, "target_top5_err": 2.34375, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:30:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85573, "dt_data": 0.02684, "dt_net": 6.82889, "epoch": "28/30", "eta": "0:26:57", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.12036, "lr": 0.00000, "target_top1_err": 7.81250, "target_top5_err": 0.00000, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:31:30][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81885, "dt_data": 0.02531, "dt_net": 6.79353, "epoch": "28/30", "eta": "0:25:41", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.08963, "lr": 0.00000, "target_top1_err": 12.50000, "target_top5_err": 3.90625, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:32:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.81928, "dt_data": 0.02577, "dt_net": 6.79351, "epoch": "28/30", "eta": "0:24:32", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.18281, "lr": 0.00000, "target_top1_err": 9.37500, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:33:47][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82185, "dt_data": 0.02936, "dt_net": 6.79249, "epoch": "28/30", "eta": "0:23:25", "gpu_mem": "25.00G", "iter": "70/92", "loss": 0.96883, "lr": 0.00000, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:34:56][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86337, "dt_data": 0.02522, "dt_net": 6.83815, "epoch": "28/30", "eta": "0:22:25", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.06762, "lr": 0.00000, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:36:04][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82974, "dt_data": 0.02548, "dt_net": 6.80426, "epoch": "28/30", "eta": "0:21:10", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.04469, "lr": 0.00000, "target_top1_err": 14.06250, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:36:18][INFO] logging.py:  99: json_stats: {"RAM": "191.76/1007.34G", "_type": "train_epoch", "dt": 0.00013, "dt_data": 0.00013, "dt_net": 6.79256, "epoch": "28/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.03956, "lr": 0.00000, "target_top1_err": 86.39606, "target_top5_err": 9.32405, "top1_err": 1.90217, "top5_err": 0.22079}
[04/29 04:36:18][INFO] train_net_bn_pseudo.py: 569: Epoch 27 takes 656.97s. Epochs from 2 to 27 take 654.37s in average and 650.56s in median.
[04/29 04:36:18][INFO] train_net_bn_pseudo.py: 575: For epoch 27, each iteraction takes 7.14s in average. From epoch 2 to 27, each iteraction takes 7.11s in average.
[04/29 04:36:27][INFO] logging.py:  99: json_stats: {"RAM": "192.69/1007.34G", "_type": "val_epoch", "epoch": "28/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00009, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 04:36:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:03:16", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.44831, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 04:36:48][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:01:06", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.52707, "top1_err": 10.15625, "top5_err": 5.46875}
[04/29 04:36:54][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:58", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.50664, "top1_err": 8.59375, "top5_err": 3.90625}
[04/29 04:37:02][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.56145, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:37:09][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:57", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.59892, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 04:37:16][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:45", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.53220, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:37:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:41", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.55019, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 04:37:30][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:34", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.53015, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 04:37:38][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:30", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.54497, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 04:37:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:20", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.44082, "top1_err": 12.50000, "top5_err": 4.68750}
[04/29 04:37:52][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:25", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.69829, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 04:37:58][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.55612, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:38:05][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:08", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 0.56084, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:38:13][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "28/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.50768, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 04:38:15][INFO] logging.py:  99: json_stats: {"RAM": "192.37/1007.34G", "_type": "val_epoch", "epoch": "28/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00010, "top1_err": 9.85370, "top5_err": 4.27065}
[04/29 04:39:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.88798, "dt_data": 0.02559, "dt_net": 6.86239, "epoch": "29/30", "eta": "0:19:58", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.03271, "lr": 0.00000, "target_top1_err": 6.25000, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:40:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83751, "dt_data": 0.02536, "dt_net": 6.81215, "epoch": "29/30", "eta": "0:18:41", "gpu_mem": "25.00G", "iter": "20/92", "loss": 1.16866, "lr": 0.00000, "target_top1_err": 10.93750, "target_top5_err": 2.34375, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:41:57][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87986, "dt_data": 0.02522, "dt_net": 6.85464, "epoch": "29/30", "eta": "0:17:39", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.16473, "lr": 0.00000, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 04:43:05][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.85010, "dt_data": 0.02646, "dt_net": 6.82364, "epoch": "29/30", "eta": "0:16:26", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.00815, "lr": 0.00000, "target_top1_err": 9.37500, "target_top5_err": 0.78125, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:44:14][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.89687, "dt_data": 0.02683, "dt_net": 6.87004, "epoch": "29/30", "eta": "0:15:24", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.12252, "lr": 0.00000, "target_top1_err": 14.84375, "target_top5_err": 3.90625, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:45:22][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86824, "dt_data": 0.02612, "dt_net": 6.84211, "epoch": "29/30", "eta": "0:14:11", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.09746, "lr": 0.00000, "target_top1_err": 14.84375, "target_top5_err": 3.12500, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:46:31][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83184, "dt_data": 0.02727, "dt_net": 6.80457, "epoch": "29/30", "eta": "0:12:58", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.09867, "lr": 0.00000, "target_top1_err": 7.81250, "target_top5_err": 2.34375, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:47:39][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82302, "dt_data": 0.02566, "dt_net": 6.79736, "epoch": "29/30", "eta": "0:11:49", "gpu_mem": "25.00G", "iter": "80/92", "loss": 0.94739, "lr": 0.00000, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 3.12500, "top5_err": 0.00000}
[04/29 04:48:48][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.87713, "dt_data": 0.02742, "dt_net": 6.84971, "epoch": "29/30", "eta": "0:10:46", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.09512, "lr": 0.00000, "target_top1_err": 7.81250, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:49:02][INFO] logging.py:  99: json_stats: {"RAM": "189.55/1007.34G", "_type": "train_epoch", "dt": 0.00176, "dt_data": 0.00176, "dt_net": 6.80505, "epoch": "29/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.04925, "lr": 0.00000, "target_top1_err": 88.67188, "target_top5_err": 9.52785, "top1_err": 2.27582, "top5_err": 0.20380}
[04/29 04:49:02][INFO] train_net_bn_pseudo.py: 569: Epoch 28 takes 646.41s. Epochs from 2 to 28 take 654.08s in average and 650.31s in median.
[04/29 04:49:02][INFO] train_net_bn_pseudo.py: 575: For epoch 28, each iteraction takes 7.03s in average. From epoch 2 to 28, each iteraction takes 7.11s in average.
[04/29 04:49:11][INFO] logging.py:  99: json_stats: {"RAM": "194.43/1007.34G", "_type": "val_epoch", "epoch": "29/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00011, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 04:49:27][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:03:32", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.56175, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 04:49:33][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:56", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.45216, "top1_err": 10.15625, "top5_err": 5.46875}
[04/29 04:49:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:01:01", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.53361, "top1_err": 8.59375, "top5_err": 3.90625}
[04/29 04:49:46][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:52", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.49356, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:49:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:01:26", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.89909, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 04:50:01][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:42", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.49929, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:50:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:38", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.50959, "top1_err": 10.93750, "top5_err": 3.90625}
[04/29 04:50:15][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:28", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.43904, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 04:50:22][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:53", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.96407, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 04:50:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:28", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.61712, "top1_err": 12.50000, "top5_err": 4.68750}
[04/29 04:50:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:30", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.85709, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 04:50:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.53913, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:50:49][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:26", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.63790, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 04:50:55][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "29/30", "eta": "0:00:02", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.47049, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 04:50:58][INFO] logging.py:  99: json_stats: {"RAM": "192.98/1007.34G", "_type": "val_epoch", "epoch": "29/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00010, "top1_err": 9.97203, "top5_err": 4.28141}
[04/29 04:52:26][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86192, "dt_data": 0.02583, "dt_net": 6.83609, "epoch": "30/30", "eta": "0:09:22", "gpu_mem": "25.00G", "iter": "10/92", "loss": 1.12959, "lr": 0.00000, "target_top1_err": 11.71875, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:53:34][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86383, "dt_data": 0.02574, "dt_net": 6.83808, "epoch": "30/30", "eta": "0:08:14", "gpu_mem": "25.00G", "iter": "20/92", "loss": 0.99586, "lr": 0.00000, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:54:42][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82272, "dt_data": 0.02540, "dt_net": 6.79732, "epoch": "30/30", "eta": "0:07:03", "gpu_mem": "25.00G", "iter": "30/92", "loss": 1.09074, "lr": 0.00000, "target_top1_err": 8.59375, "target_top5_err": 2.34375, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:55:51][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82461, "dt_data": 0.02608, "dt_net": 6.79852, "epoch": "30/30", "eta": "0:05:54", "gpu_mem": "25.00G", "iter": "40/92", "loss": 1.09963, "lr": 0.00000, "target_top1_err": 10.93750, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 04:56:59][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.83213, "dt_data": 0.02596, "dt_net": 6.80617, "epoch": "30/30", "eta": "0:04:46", "gpu_mem": "25.00G", "iter": "50/92", "loss": 1.03828, "lr": 0.00000, "target_top1_err": 9.37500, "target_top5_err": 0.00000, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:58:08][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.92959, "dt_data": 0.03091, "dt_net": 6.89868, "epoch": "30/30", "eta": "0:03:41", "gpu_mem": "25.00G", "iter": "60/92", "loss": 1.12603, "lr": 0.00000, "target_top1_err": 12.50000, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 04:59:16][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.84862, "dt_data": 0.02761, "dt_net": 6.82101, "epoch": "30/30", "eta": "0:02:30", "gpu_mem": "25.00G", "iter": "70/92", "loss": 1.14636, "lr": 0.00000, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 2.34375, "top5_err": 0.00000}
[04/29 05:00:25][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.86283, "dt_data": 0.02524, "dt_net": 6.83759, "epoch": "30/30", "eta": "0:01:22", "gpu_mem": "25.00G", "iter": "80/92", "loss": 1.06620, "lr": 0.00000, "target_top1_err": 10.15625, "target_top5_err": 2.34375, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 05:01:33][INFO] logging.py:  99: json_stats: {"_type": "train_iter", "dt": 6.82044, "dt_data": 0.02572, "dt_net": 6.79472, "epoch": "30/30", "eta": "0:00:13", "gpu_mem": "25.00G", "iter": "90/92", "loss": 1.09745, "lr": 0.00000, "target_top1_err": 8.59375, "target_top5_err": 1.56250, "top1_err": 1.56250, "top5_err": 0.00000}
[04/29 05:01:47][INFO] logging.py:  99: json_stats: {"RAM": "194.34/1007.34G", "_type": "train_epoch", "dt": 0.00014, "dt_data": 0.00014, "dt_net": 6.83369, "epoch": "30/30", "eta": "0:00:00", "gpu_mem": "25.00G", "loss": 1.06016, "lr": 0.00000, "target_top1_err": 90.93071, "target_top5_err": 9.66372, "top1_err": 2.25883, "top5_err": 0.13587}
[04/29 05:01:47][INFO] train_net_bn_pseudo.py: 569: Epoch 29 takes 649.37s. Epochs from 2 to 29 take 653.91s in average and 650.26s in median.
[04/29 05:01:47][INFO] train_net_bn_pseudo.py: 575: For epoch 29, each iteraction takes 7.06s in average. From epoch 2 to 29, each iteraction takes 7.11s in average.
[04/29 05:01:57][INFO] logging.py:  99: json_stats: {"RAM": "194.42/1007.34G", "_type": "val_epoch", "epoch": "30/30", "gpu_mem": "25.00G", "min_top1_err": 0.00000, "min_top5_err": 0.00000, "time_diff": 0.00010, "top1_err": 0.00000, "top5_err": 0.00000}
[04/29 05:02:12][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:02:49", "gpu_mem": "25.00G", "iter": "10/146", "time_diff": 1.24552, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 05:02:18][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:01:02", "gpu_mem": "25.00G", "iter": "20/146", "time_diff": 0.49563, "top1_err": 10.15625, "top5_err": 5.46875}
[04/29 05:02:24][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:59", "gpu_mem": "25.00G", "iter": "30/146", "time_diff": 0.51306, "top1_err": 8.59375, "top5_err": 3.90625}
[04/29 05:02:31][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:57", "gpu_mem": "25.00G", "iter": "40/146", "time_diff": 0.54401, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 05:02:39][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:44", "gpu_mem": "25.00G", "iter": "50/146", "time_diff": 0.46131, "top1_err": 10.93750, "top5_err": 4.68750}
[04/29 05:02:45][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:48", "gpu_mem": "25.00G", "iter": "60/146", "time_diff": 0.56212, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 05:02:53][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:40", "gpu_mem": "25.00G", "iter": "70/146", "time_diff": 0.53455, "top1_err": 10.15625, "top5_err": 3.90625}
[04/29 05:02:59][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:37", "gpu_mem": "25.00G", "iter": "80/146", "time_diff": 0.56561, "top1_err": 7.81250, "top5_err": 3.12500}
[04/29 05:03:07][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:42", "gpu_mem": "25.00G", "iter": "90/146", "time_diff": 0.76349, "top1_err": 10.93750, "top5_err": 3.12500}
[04/29 05:03:14][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:24", "gpu_mem": "25.00G", "iter": "100/146", "time_diff": 0.53006, "top1_err": 12.50000, "top5_err": 4.68750}
[04/29 05:03:21][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:18", "gpu_mem": "25.00G", "iter": "110/146", "time_diff": 0.50484, "top1_err": 7.81250, "top5_err": 4.68750}
[04/29 05:03:28][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:14", "gpu_mem": "25.00G", "iter": "120/146", "time_diff": 0.55799, "top1_err": 9.37500, "top5_err": 3.90625}
[04/29 05:03:35][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:31", "gpu_mem": "25.00G", "iter": "130/146", "time_diff": 1.99828, "top1_err": 9.37500, "top5_err": 3.12500}
[04/29 05:03:42][INFO] logging.py:  99: json_stats: {"_type": "val_iter", "epoch": "30/30", "eta": "0:00:03", "gpu_mem": "25.00G", "iter": "140/146", "time_diff": 0.56118, "top1_err": 10.15625, "top5_err": 4.68750}
[04/29 05:03:44][INFO] logging.py:  99: json_stats: {"RAM": "193.14/1007.34G", "_type": "val_epoch", "epoch": "30/30", "gpu_mem": "25.00G", "min_top1_err": 9.60628, "min_top5_err": 3.06583, "time_diff": 0.00009, "top1_err": 9.91824, "top5_err": 4.33520}
[04/29 05:04:11][INFO] test_net_gamma.py: 157: Test with config:
[04/29 05:04:11][INFO] test_net_gamma.py: 158: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: True
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  FRAME_PATH: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: True
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  PSEUDO_CSV: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/pseudo/all_0.895_prob_stage4.csv
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 3
  SPECIAL_LABEL_LIST: [5, 9]
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
EVL:
  ADD_RESIDUAL: False
  AFTER_ME: False
  BACKBONE: vit_b16
  BEFORE_ME: False
  CLS_DROPOUT: 0.5
  FIRST_N: 0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  SHIFT_INIT: False
  SPATAIL_SIZE: 14
  USE_IMAGE_ATTNMAP: True
  USE_T_CONV: True
  USE_T_POS_EMBED: True
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: True
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  CHECKPOINT_NUM: [0, 0, 0, 0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 11
  PSEUDO_LOSS_FUNC: 
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'vip', 'swin', 'sf', 'evl']
  SOFT_T: 1
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: None
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]]
  QKV_BIAS: True
  SEP_POS_EMBED: True
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SF:
  DROPOUT_RATE: 0.2
  FROZEN_BN: False
  NONLOCAL:
    FROZEN_BN: False
  PRETRAIN_NAME: SlowFast-ResNet101-8x8
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRADIENT: 20
  CLIP_GRAD_L2NORM: 1.0
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 10.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.1
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 64
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  DATA_SELECT: real_unlabel
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 1
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 32
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage3/mvit_b32_k600_dp0.3_ce/dark/best.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  ENABLE: True
  EVAL_PERIOD: 1
  SAVE_LATEST: True
  THRESHOLD: -1
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  KS: 5
  MBCONV: False
  MLP_RATIO: 4
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[04/29 08:54:23][INFO] test_net_gamma.py: 157: Test with config:
[04/29 08:54:23][INFO] test_net_gamma.py: 158: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: True
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  FRAME_PATH: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: True
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  PSEUDO_CSV: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 3
  SPECIAL_LABEL_LIST: [5, 9]
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
EVL:
  ADD_RESIDUAL: False
  AFTER_ME: False
  BACKBONE: vit_b16
  BEFORE_ME: False
  CLS_DROPOUT: 0.5
  FIRST_N: 0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  SHIFT_INIT: False
  SPATAIL_SIZE: 14
  USE_IMAGE_ATTNMAP: True
  USE_T_CONV: True
  USE_T_POS_EMBED: True
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: True
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  CHECKPOINT_NUM: [0, 0, 0, 0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 11
  PSEUDO_LOSS_FUNC: 
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'vip', 'swin', 'sf', 'evl']
  SOFT_T: 1
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: None
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]]
  QKV_BIAS: True
  SEP_POS_EMBED: True
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 2
NUM_SHARDS: 1
OUTPUT_DIR: exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SF:
  DROPOUT_RATE: 0.3
  FROZEN_BN: False
  NONLOCAL:
    FROZEN_BN: False
  PRETRAIN_NAME: SlowFast-ResNet101-8x8
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRADIENT: 20
  CLIP_GRAD_L2NORM: 1.0
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 40
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 10.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.03
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 64
  CHECKPOINT_FILE_PATH: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  DATA_SELECT: real_unlabel
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 1
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
  THRESHOLD: 2
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  KS: 5
  MBCONV: False
  MLP_RATIO: 4
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[04/29 08:54:27][INFO] checkpoint.py: 223: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/29 08:54:54][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[04/29 08:54:54][INFO] ug2_sparse.py:  91: Number of clips 1
[04/29 08:54:54][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 9295) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 08:54:58][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 08:54:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 08:54:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 08:54:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 08:54:59][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f09082658c0>
[04/29 08:54:59][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 08:54:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0908311e60>
[04/29 08:54:59][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0a4032f4d0>
[04/29 08:55:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0908311c20>
[04/29 08:55:00][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 08:55:00][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 08:55:00][DEBUG] factory.py:  66: Loading s3:s3
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 08:55:00][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f09082658c0>
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 08:55:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0908311e60>
[04/29 08:55:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0901613050>
[04/29 08:55:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0908311c20>
[04/29 08:55:00][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 08:55:00][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 08:55:00][DEBUG] factory.py:  66: Loading s3:s3
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 08:55:00][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f09082658c0>
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 08:55:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0908311e60>
[04/29 08:55:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0900faf0e0>
[04/29 08:55:00][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0908311c20>
[04/29 08:55:00][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 08:55:00][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 08:55:00][DEBUG] factory.py:  66: Loading s3:s3
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 08:55:00][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 08:55:00][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 08:55:00][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f09082658c0>
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0908311e60>
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0901748170>
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0908311c20>
[04/29 08:55:01][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 08:55:01][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 08:55:01][DEBUG] factory.py:  66: Loading s3:s3
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 08:55:01][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f09082658c0>
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0908311e60>
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f09002860e0>
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0908311c20>
[04/29 08:55:01][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 08:55:01][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 08:55:01][DEBUG] factory.py:  66: Loading s3:s3
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 08:55:01][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 08:55:01][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f09082658c0>
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0908311e60>
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f08e9c15170>
[04/29 08:55:01][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0908311c20>
[04/29 08:55:01][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 08:55:01][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 08:55:01][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 08:55:01][DEBUG] factory.py:  66: Loading s3:s3
[04/29 08:55:01][INFO] test_net_gamma.py: 169: Testing model for 146 iterations
[04/29 08:56:40][INFO] logging.py:  99: json_stats: {"cur_iter": "1", "eta": "3:59:02", "split": "test_iter", "time_diff": 98.23951}
[04/29 08:56:41][INFO] logging.py:  99: json_stats: {"cur_iter": "2", "eta": "0:02:07", "split": "test_iter", "time_diff": 0.87832}
[04/29 08:56:42][INFO] logging.py:  99: json_stats: {"cur_iter": "3", "eta": "0:02:09", "split": "test_iter", "time_diff": 0.89748}
[04/29 08:56:42][INFO] logging.py:  99: json_stats: {"cur_iter": "4", "eta": "0:02:18", "split": "test_iter", "time_diff": 0.96514}
[04/29 08:56:43][INFO] logging.py:  99: json_stats: {"cur_iter": "5", "eta": "0:02:21", "split": "test_iter", "time_diff": 0.99922}
[04/29 08:56:45][INFO] logging.py:  99: json_stats: {"cur_iter": "6", "eta": "0:02:06", "split": "test_iter", "time_diff": 0.89736}
[04/29 08:56:46][INFO] logging.py:  99: json_stats: {"cur_iter": "7", "eta": "0:02:18", "split": "test_iter", "time_diff": 0.99036}
[04/29 08:56:47][INFO] logging.py:  99: json_stats: {"cur_iter": "8", "eta": "0:02:18", "split": "test_iter", "time_diff": 0.99917}
[04/29 08:56:48][INFO] logging.py:  99: json_stats: {"cur_iter": "9", "eta": "0:02:04", "split": "test_iter", "time_diff": 0.89972}
[04/29 08:56:48][INFO] logging.py:  99: json_stats: {"cur_iter": "10", "eta": "0:02:16", "split": "test_iter", "time_diff": 0.99463}
[04/29 08:56:49][INFO] logging.py:  99: json_stats: {"cur_iter": "11", "eta": "0:02:02", "split": "test_iter", "time_diff": 0.89792}
[04/29 08:56:50][INFO] logging.py:  99: json_stats: {"cur_iter": "12", "eta": "0:02:09", "split": "test_iter", "time_diff": 0.96069}
[04/29 08:56:51][INFO] logging.py:  99: json_stats: {"cur_iter": "13", "eta": "0:02:13", "split": "test_iter", "time_diff": 0.99354}
[04/29 08:56:52][INFO] logging.py:  99: json_stats: {"cur_iter": "14", "eta": "0:02:12", "split": "test_iter", "time_diff": 0.99898}
[04/29 08:56:53][INFO] logging.py:  99: json_stats: {"cur_iter": "15", "eta": "0:02:11", "split": "test_iter", "time_diff": 0.99575}
[04/29 08:56:54][INFO] logging.py:  99: json_stats: {"cur_iter": "16", "eta": "0:02:09", "split": "test_iter", "time_diff": 0.98652}
[04/29 08:56:56][INFO] logging.py:  99: json_stats: {"cur_iter": "17", "eta": "0:02:22", "split": "test_iter", "time_diff": 1.09640}
[04/29 08:56:56][INFO] logging.py:  99: json_stats: {"cur_iter": "18", "eta": "0:01:56", "split": "test_iter", "time_diff": 0.89966}
[04/29 08:56:58][INFO] logging.py:  99: json_stats: {"cur_iter": "19", "eta": "0:02:15", "split": "test_iter", "time_diff": 1.05873}
[04/29 08:56:58][INFO] logging.py:  99: json_stats: {"cur_iter": "20", "eta": "0:02:00", "split": "test_iter", "time_diff": 0.95212}
[04/29 08:56:59][INFO] logging.py:  99: json_stats: {"cur_iter": "21", "eta": "0:02:07", "split": "test_iter", "time_diff": 1.00987}
[04/29 08:57:01][INFO] logging.py:  99: json_stats: {"cur_iter": "22", "eta": "0:01:52", "split": "test_iter", "time_diff": 0.89872}
[04/29 08:57:01][INFO] logging.py:  99: json_stats: {"cur_iter": "23", "eta": "0:01:57", "split": "test_iter", "time_diff": 0.95141}
[04/29 08:57:02][INFO] logging.py:  99: json_stats: {"cur_iter": "24", "eta": "0:02:02", "split": "test_iter", "time_diff": 0.99329}
[04/29 08:57:03][INFO] logging.py:  99: json_stats: {"cur_iter": "25", "eta": "0:02:01", "split": "test_iter", "time_diff": 0.99326}
[04/29 08:57:04][INFO] logging.py:  99: json_stats: {"cur_iter": "26", "eta": "0:01:57", "split": "test_iter", "time_diff": 0.97105}
[04/29 08:57:05][INFO] logging.py:  99: json_stats: {"cur_iter": "27", "eta": "0:01:59", "split": "test_iter", "time_diff": 0.99760}
[04/29 08:57:06][INFO] logging.py:  99: json_stats: {"cur_iter": "28", "eta": "0:01:53", "split": "test_iter", "time_diff": 0.95754}
[04/29 08:57:07][INFO] logging.py:  99: json_stats: {"cur_iter": "29", "eta": "0:01:55", "split": "test_iter", "time_diff": 0.97467}
[04/29 08:57:08][INFO] logging.py:  99: json_stats: {"cur_iter": "30", "eta": "0:01:58", "split": "test_iter", "time_diff": 1.01545}
[04/29 08:57:09][INFO] logging.py:  99: json_stats: {"cur_iter": "31", "eta": "0:01:43", "split": "test_iter", "time_diff": 0.89538}
[04/29 08:57:10][INFO] logging.py:  99: json_stats: {"cur_iter": "32", "eta": "0:01:59", "split": "test_iter", "time_diff": 1.03712}
[04/29 08:57:11][INFO] logging.py:  99: json_stats: {"cur_iter": "33", "eta": "0:01:53", "split": "test_iter", "time_diff": 0.99904}
[04/29 08:57:12][INFO] logging.py:  99: json_stats: {"cur_iter": "34", "eta": "0:01:51", "split": "test_iter", "time_diff": 0.98615}
[04/29 08:57:13][INFO] logging.py:  99: json_stats: {"cur_iter": "35", "eta": "0:01:40", "split": "test_iter", "time_diff": 0.90129}
[04/29 08:57:14][INFO] logging.py:  99: json_stats: {"cur_iter": "36", "eta": "0:01:55", "split": "test_iter", "time_diff": 1.03627}
[04/29 08:57:15][INFO] logging.py:  99: json_stats: {"cur_iter": "37", "eta": "0:01:52", "split": "test_iter", "time_diff": 1.02250}
[04/29 08:57:16][INFO] logging.py:  99: json_stats: {"cur_iter": "38", "eta": "0:01:49", "split": "test_iter", "time_diff": 1.00073}
[04/29 08:57:17][INFO] logging.py:  99: json_stats: {"cur_iter": "39", "eta": "0:01:45", "split": "test_iter", "time_diff": 0.97596}
[04/29 08:57:18][INFO] logging.py:  99: json_stats: {"cur_iter": "40", "eta": "0:01:46", "split": "test_iter", "time_diff": 0.99618}
[04/29 08:57:20][INFO] logging.py:  99: json_stats: {"cur_iter": "41", "eta": "0:02:16", "split": "test_iter", "time_diff": 1.28922}
[04/29 08:57:21][INFO] logging.py:  99: json_stats: {"cur_iter": "42", "eta": "0:01:43", "split": "test_iter", "time_diff": 0.98394}
[04/29 08:57:22][INFO] logging.py:  99: json_stats: {"cur_iter": "43", "eta": "0:01:32", "split": "test_iter", "time_diff": 0.89016}
[04/29 08:57:23][INFO] logging.py:  99: json_stats: {"cur_iter": "44", "eta": "0:01:32", "split": "test_iter", "time_diff": 0.89809}
[04/29 08:57:24][INFO] logging.py:  99: json_stats: {"cur_iter": "45", "eta": "0:01:37", "split": "test_iter", "time_diff": 0.95421}
[04/29 08:57:25][INFO] logging.py:  99: json_stats: {"cur_iter": "46", "eta": "0:01:31", "split": "test_iter", "time_diff": 0.90164}
[04/29 08:57:25][INFO] logging.py:  99: json_stats: {"cur_iter": "47", "eta": "0:01:38", "split": "test_iter", "time_diff": 0.98039}
[04/29 08:57:27][INFO] logging.py:  99: json_stats: {"cur_iter": "48", "eta": "0:01:39", "split": "test_iter", "time_diff": 1.00769}
[04/29 08:57:28][INFO] logging.py:  99: json_stats: {"cur_iter": "49", "eta": "0:02:36", "split": "test_iter", "time_diff": 1.59520}
[04/29 08:57:29][INFO] logging.py:  99: json_stats: {"cur_iter": "50", "eta": "0:01:36", "split": "test_iter", "time_diff": 0.99988}
[04/29 08:57:30][INFO] logging.py:  99: json_stats: {"cur_iter": "51", "eta": "0:01:35", "split": "test_iter", "time_diff": 0.99377}
[04/29 08:57:31][INFO] logging.py:  99: json_stats: {"cur_iter": "52", "eta": "0:01:34", "split": "test_iter", "time_diff": 0.99228}
[04/29 08:57:32][INFO] logging.py:  99: json_stats: {"cur_iter": "53", "eta": "0:01:31", "split": "test_iter", "time_diff": 0.97419}
[04/29 08:57:33][INFO] logging.py:  99: json_stats: {"cur_iter": "54", "eta": "0:01:32", "split": "test_iter", "time_diff": 0.99236}
[04/29 08:57:34][INFO] logging.py:  99: json_stats: {"cur_iter": "55", "eta": "0:01:28", "split": "test_iter", "time_diff": 0.95974}
[04/29 08:57:35][INFO] logging.py:  99: json_stats: {"cur_iter": "56", "eta": "0:01:40", "split": "test_iter", "time_diff": 1.10336}
[04/29 08:57:37][INFO] logging.py:  99: json_stats: {"cur_iter": "57", "eta": "0:02:22", "split": "test_iter", "time_diff": 1.58550}
[04/29 08:57:38][INFO] logging.py:  99: json_stats: {"cur_iter": "58", "eta": "0:01:23", "split": "test_iter", "time_diff": 0.94003}
[04/29 08:57:39][INFO] logging.py:  99: json_stats: {"cur_iter": "59", "eta": "0:01:27", "split": "test_iter", "time_diff": 0.98907}
[04/29 08:57:40][INFO] logging.py:  99: json_stats: {"cur_iter": "60", "eta": "0:01:26", "split": "test_iter", "time_diff": 0.99493}
[04/29 08:57:41][INFO] logging.py:  99: json_stats: {"cur_iter": "61", "eta": "0:01:27", "split": "test_iter", "time_diff": 1.02162}
[04/29 08:57:42][INFO] logging.py:  99: json_stats: {"cur_iter": "62", "eta": "0:01:24", "split": "test_iter", "time_diff": 0.99743}
[04/29 08:57:43][INFO] logging.py:  99: json_stats: {"cur_iter": "63", "eta": "0:01:22", "split": "test_iter", "time_diff": 0.97876}
[04/29 08:57:44][INFO] logging.py:  99: json_stats: {"cur_iter": "64", "eta": "0:01:24", "split": "test_iter", "time_diff": 1.01599}
[04/29 08:57:45][INFO] logging.py:  99: json_stats: {"cur_iter": "65", "eta": "0:02:15", "split": "test_iter", "time_diff": 1.65028}
[04/29 08:57:46][INFO] logging.py:  99: json_stats: {"cur_iter": "66", "eta": "0:01:17", "split": "test_iter", "time_diff": 0.95999}
[04/29 08:57:47][INFO] logging.py:  99: json_stats: {"cur_iter": "67", "eta": "0:01:20", "split": "test_iter", "time_diff": 1.01134}
[04/29 08:57:48][INFO] logging.py:  99: json_stats: {"cur_iter": "68", "eta": "0:01:10", "split": "test_iter", "time_diff": 0.88680}
[04/29 08:57:50][INFO] logging.py:  99: json_stats: {"cur_iter": "69", "eta": "0:01:22", "split": "test_iter", "time_diff": 1.05822}
[04/29 08:57:50][INFO] logging.py:  99: json_stats: {"cur_iter": "70", "eta": "0:01:15", "split": "test_iter", "time_diff": 0.97981}
[04/29 08:57:52][INFO] logging.py:  99: json_stats: {"cur_iter": "71", "eta": "0:01:18", "split": "test_iter", "time_diff": 1.03722}
[04/29 08:57:53][INFO] logging.py:  99: json_stats: {"cur_iter": "72", "eta": "0:01:15", "split": "test_iter", "time_diff": 1.00285}
[04/29 08:57:54][INFO] logging.py:  99: json_stats: {"cur_iter": "73", "eta": "0:01:13", "split": "test_iter", "time_diff": 0.98860}
[04/29 08:57:55][INFO] logging.py:  99: json_stats: {"cur_iter": "74", "eta": "0:01:13", "split": "test_iter", "time_diff": 1.01023}
[04/29 08:57:56][INFO] logging.py:  99: json_stats: {"cur_iter": "75", "eta": "0:01:14", "split": "test_iter", "time_diff": 1.03776}
[04/29 08:57:57][INFO] logging.py:  99: json_stats: {"cur_iter": "76", "eta": "0:01:13", "split": "test_iter", "time_diff": 1.03753}
[04/29 08:57:58][INFO] logging.py:  99: json_stats: {"cur_iter": "77", "eta": "0:01:10", "split": "test_iter", "time_diff": 1.01066}
[04/29 08:57:59][INFO] logging.py:  99: json_stats: {"cur_iter": "78", "eta": "0:01:07", "split": "test_iter", "time_diff": 0.98020}
[04/29 08:58:00][INFO] logging.py:  99: json_stats: {"cur_iter": "79", "eta": "0:01:07", "split": "test_iter", "time_diff": 0.98800}
[04/29 08:58:01][INFO] logging.py:  99: json_stats: {"cur_iter": "80", "eta": "0:01:05", "split": "test_iter", "time_diff": 0.97889}
[04/29 08:58:02][INFO] logging.py:  99: json_stats: {"cur_iter": "81", "eta": "0:01:07", "split": "test_iter", "time_diff": 1.01899}
[04/29 08:58:03][INFO] logging.py:  99: json_stats: {"cur_iter": "82", "eta": "0:01:04", "split": "test_iter", "time_diff": 0.98806}
[04/29 08:58:04][INFO] logging.py:  99: json_stats: {"cur_iter": "83", "eta": "0:01:04", "split": "test_iter", "time_diff": 1.00425}
[04/29 08:58:05][INFO] logging.py:  99: json_stats: {"cur_iter": "84", "eta": "0:00:55", "split": "test_iter", "time_diff": 0.88039}
[04/29 08:58:06][INFO] logging.py:  99: json_stats: {"cur_iter": "85", "eta": "0:01:07", "split": "test_iter", "time_diff": 1.09085}
[04/29 08:58:07][INFO] logging.py:  99: json_stats: {"cur_iter": "86", "eta": "0:01:00", "split": "test_iter", "time_diff": 0.99630}
[04/29 08:58:08][INFO] logging.py:  99: json_stats: {"cur_iter": "87", "eta": "0:01:00", "split": "test_iter", "time_diff": 1.00243}
[04/29 08:58:09][INFO] logging.py:  99: json_stats: {"cur_iter": "88", "eta": "0:00:58", "split": "test_iter", "time_diff": 0.99708}
[04/29 08:58:10][INFO] logging.py:  99: json_stats: {"cur_iter": "89", "eta": "0:00:57", "split": "test_iter", "time_diff": 0.98333}
[04/29 08:58:11][INFO] logging.py:  99: json_stats: {"cur_iter": "90", "eta": "0:00:57", "split": "test_iter", "time_diff": 1.00775}
[04/29 08:58:12][INFO] logging.py:  99: json_stats: {"cur_iter": "91", "eta": "0:00:56", "split": "test_iter", "time_diff": 1.00864}
[04/29 08:58:13][INFO] logging.py:  99: json_stats: {"cur_iter": "92", "eta": "0:00:54", "split": "test_iter", "time_diff": 0.99306}
[04/29 08:58:14][INFO] logging.py:  99: json_stats: {"cur_iter": "93", "eta": "0:00:53", "split": "test_iter", "time_diff": 0.99997}
[04/29 08:58:15][INFO] logging.py:  99: json_stats: {"cur_iter": "94", "eta": "0:00:56", "split": "test_iter", "time_diff": 1.06107}
[04/29 08:58:16][INFO] logging.py:  99: json_stats: {"cur_iter": "95", "eta": "0:00:52", "split": "test_iter", "time_diff": 1.01373}
[04/29 08:58:17][INFO] logging.py:  99: json_stats: {"cur_iter": "96", "eta": "0:00:50", "split": "test_iter", "time_diff": 0.98207}
[04/29 08:58:18][INFO] logging.py:  99: json_stats: {"cur_iter": "97", "eta": "0:00:49", "split": "test_iter", "time_diff": 0.99208}
[04/29 08:58:19][INFO] logging.py:  99: json_stats: {"cur_iter": "98", "eta": "0:00:49", "split": "test_iter", "time_diff": 1.00673}
[04/29 08:58:20][INFO] logging.py:  99: json_stats: {"cur_iter": "99", "eta": "0:00:43", "split": "test_iter", "time_diff": 0.89964}
[04/29 08:58:21][INFO] logging.py:  99: json_stats: {"cur_iter": "100", "eta": "0:00:45", "split": "test_iter", "time_diff": 0.97719}
[04/29 08:58:22][INFO] logging.py:  99: json_stats: {"cur_iter": "101", "eta": "0:00:45", "split": "test_iter", "time_diff": 0.98209}
[04/29 08:58:23][INFO] logging.py:  99: json_stats: {"cur_iter": "102", "eta": "0:00:44", "split": "test_iter", "time_diff": 0.98091}
[04/29 08:58:24][INFO] logging.py:  99: json_stats: {"cur_iter": "103", "eta": "0:00:40", "split": "test_iter", "time_diff": 0.92639}
[04/29 08:58:25][INFO] logging.py:  99: json_stats: {"cur_iter": "104", "eta": "0:00:44", "split": "test_iter", "time_diff": 1.04050}
[04/29 08:58:26][INFO] logging.py:  99: json_stats: {"cur_iter": "105", "eta": "0:00:41", "split": "test_iter", "time_diff": 0.97949}
[04/29 08:58:27][INFO] logging.py:  99: json_stats: {"cur_iter": "106", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.01059}
[04/29 08:58:28][INFO] logging.py:  99: json_stats: {"cur_iter": "107", "eta": "0:00:40", "split": "test_iter", "time_diff": 1.01256}
[04/29 08:58:29][INFO] logging.py:  99: json_stats: {"cur_iter": "108", "eta": "0:00:38", "split": "test_iter", "time_diff": 0.99992}
[04/29 08:58:30][INFO] logging.py:  99: json_stats: {"cur_iter": "109", "eta": "0:00:38", "split": "test_iter", "time_diff": 1.01380}
[04/29 08:58:31][INFO] logging.py:  99: json_stats: {"cur_iter": "110", "eta": "0:00:37", "split": "test_iter", "time_diff": 1.01003}
[04/29 08:58:32][INFO] logging.py:  99: json_stats: {"cur_iter": "111", "eta": "0:00:35", "split": "test_iter", "time_diff": 0.99169}
[04/29 08:58:33][INFO] logging.py:  99: json_stats: {"cur_iter": "112", "eta": "0:00:34", "split": "test_iter", "time_diff": 0.98196}
[04/29 08:58:34][INFO] logging.py:  99: json_stats: {"cur_iter": "113", "eta": "0:00:33", "split": "test_iter", "time_diff": 0.99836}
[04/29 08:58:35][INFO] logging.py:  99: json_stats: {"cur_iter": "114", "eta": "0:00:44", "split": "test_iter", "time_diff": 1.33842}
[04/29 08:58:36][INFO] logging.py:  99: json_stats: {"cur_iter": "115", "eta": "0:00:31", "split": "test_iter", "time_diff": 0.98912}
[04/29 08:58:37][INFO] logging.py:  99: json_stats: {"cur_iter": "116", "eta": "0:00:31", "split": "test_iter", "time_diff": 1.00239}
[04/29 08:58:38][INFO] logging.py:  99: json_stats: {"cur_iter": "117", "eta": "0:00:29", "split": "test_iter", "time_diff": 0.99696}
[04/29 08:58:39][INFO] logging.py:  99: json_stats: {"cur_iter": "118", "eta": "0:00:28", "split": "test_iter", "time_diff": 0.98113}
[04/29 08:58:40][INFO] logging.py:  99: json_stats: {"cur_iter": "119", "eta": "0:00:27", "split": "test_iter", "time_diff": 0.99872}
[04/29 08:58:41][INFO] logging.py:  99: json_stats: {"cur_iter": "120", "eta": "0:00:27", "split": "test_iter", "time_diff": 1.02786}
[04/29 08:58:42][INFO] logging.py:  99: json_stats: {"cur_iter": "121", "eta": "0:00:25", "split": "test_iter", "time_diff": 0.96239}
[04/29 08:58:43][INFO] logging.py:  99: json_stats: {"cur_iter": "122", "eta": "0:00:22", "split": "test_iter", "time_diff": 0.89892}
[04/29 08:58:45][INFO] logging.py:  99: json_stats: {"cur_iter": "123", "eta": "0:00:32", "split": "test_iter", "time_diff": 1.33805}
[04/29 08:58:46][INFO] logging.py:  99: json_stats: {"cur_iter": "124", "eta": "0:00:22", "split": "test_iter", "time_diff": 0.97024}
[04/29 08:58:47][INFO] logging.py:  99: json_stats: {"cur_iter": "125", "eta": "0:00:22", "split": "test_iter", "time_diff": 1.00389}
[04/29 08:58:48][INFO] logging.py:  99: json_stats: {"cur_iter": "126", "eta": "0:00:21", "split": "test_iter", "time_diff": 1.03796}
[04/29 08:58:49][INFO] logging.py:  99: json_stats: {"cur_iter": "127", "eta": "0:00:19", "split": "test_iter", "time_diff": 0.98235}
[04/29 08:58:50][INFO] logging.py:  99: json_stats: {"cur_iter": "128", "eta": "0:00:18", "split": "test_iter", "time_diff": 0.99949}
[04/29 08:58:51][INFO] logging.py:  99: json_stats: {"cur_iter": "129", "eta": "0:00:23", "split": "test_iter", "time_diff": 1.30515}
[04/29 08:58:52][INFO] logging.py:  99: json_stats: {"cur_iter": "130", "eta": "0:00:17", "split": "test_iter", "time_diff": 1.00302}
[04/29 08:58:53][INFO] logging.py:  99: json_stats: {"cur_iter": "131", "eta": "0:00:15", "split": "test_iter", "time_diff": 0.97630}
[04/29 08:58:54][INFO] logging.py:  99: json_stats: {"cur_iter": "132", "eta": "0:00:14", "split": "test_iter", "time_diff": 0.98135}
[04/29 08:58:55][INFO] logging.py:  99: json_stats: {"cur_iter": "133", "eta": "0:00:13", "split": "test_iter", "time_diff": 0.93838}
[04/29 08:58:56][INFO] logging.py:  99: json_stats: {"cur_iter": "134", "eta": "0:00:13", "split": "test_iter", "time_diff": 1.01172}
[04/29 08:58:57][INFO] logging.py:  99: json_stats: {"cur_iter": "135", "eta": "0:00:11", "split": "test_iter", "time_diff": 0.99974}
[04/29 08:58:58][INFO] logging.py:  99: json_stats: {"cur_iter": "136", "eta": "0:00:10", "split": "test_iter", "time_diff": 0.99132}
[04/29 08:58:59][INFO] logging.py:  99: json_stats: {"cur_iter": "137", "eta": "0:00:10", "split": "test_iter", "time_diff": 1.02576}
[04/29 08:59:00][INFO] logging.py:  99: json_stats: {"cur_iter": "138", "eta": "0:00:11", "split": "test_iter", "time_diff": 1.23824}
[04/29 08:59:01][INFO] logging.py:  99: json_stats: {"cur_iter": "139", "eta": "0:00:08", "split": "test_iter", "time_diff": 1.02341}
[04/29 08:59:02][INFO] logging.py:  99: json_stats: {"cur_iter": "140", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.96287}
[04/29 08:59:03][INFO] logging.py:  99: json_stats: {"cur_iter": "141", "eta": "0:00:05", "split": "test_iter", "time_diff": 0.90141}
[04/29 08:59:04][INFO] logging.py:  99: json_stats: {"cur_iter": "142", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.97344}
[04/29 08:59:05][INFO] logging.py:  99: json_stats: {"cur_iter": "143", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.96485}
[04/29 08:59:06][INFO] logging.py:  99: json_stats: {"cur_iter": "144", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.90096}
[04/29 08:59:07][INFO] logging.py:  99: json_stats: {"cur_iter": "145", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.95994}
[04/29 08:59:07][INFO] logging.py:  99: json_stats: {"cur_iter": "146", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.23575}
[04/29 08:59:07][WARNING] meters.py: 381: clip count 0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 64: 1, 65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1, 76: 1, 77: 1, 78: 1, 79: 1, 80: 1, 81: 1, 82: 1, 83: 1, 84: 1, 85: 1, 86: 1, 87: 1, 88: 1, 89: 1, 90: 1, 91: 1, 92: 1, 93: 1, 94: 1, 95: 1, 96: 1, 97: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 1, 103: 1, 104: 1, 105: 1, 106: 1, 107: 1, 108: 1, 109: 1, 110: 1, 111: 1, 112: 1, 113: 1, 114: 1, 115: 1, 116: 1, 117: 1, 118: 1, 119: 1, 120: 1, 121: 1, 122: 1, 123: 1, 124: 1, 125: 1, 126: 1, 127: 1, 128: 1, 129: 1, 130: 1, 131: 1, 132: 1, 133: 1, 134: 1, 135: 1, 136: 1, 137: 1, 138: 1, 139: 1, 140: 1, 141: 1, 142: 1, 143: 1, 144: 1, 145: 1, 146: 1, 147: 1, 148: 1, 149: 1, 150: 1, 151: 1, 152: 1, 153: 1, 154: 1, 155: 1, 156: 1, 157: 1, 158: 1, 159: 1, 160: 1, 161: 1, 162: 1, 163: 1, 164: 1, 165: 1, 166: 1, 167: 1, 168: 1, 169: 1, 170: 1, 171: 1, 172: 1, 173: 1, 174: 1, 175: 1, 176: 1, 177: 1, 178: 1, 179: 1, 180: 1, 181: 1, 182: 1, 183: 1, 184: 1, 185: 1, 186: 1, 187: 1, 188: 1, 189: 1, 190: 1, 191: 1, 192: 1, 193: 1, 194: 1, 195: 1, 196: 1, 197: 1, 198: 1, 199: 1, 200: 1, 201: 1, 202: 1, 203: 1, 204: 1, 205: 1, 206: 1, 207: 1, 208: 1, 209: 1, 210: 1, 211: 1, 212: 1, 213: 1, 214: 1, 215: 1, 216: 1, 217: 1, 218: 1, 219: 1, 220: 1, 221: 1, 222: 1, 223: 1, 224: 1, 225: 1, 226: 1, 227: 1, 228: 1, 229: 1, 230: 1, 231: 1, 232: 1, 233: 1, 234: 1, 235: 1, 236: 1, 237: 1, 238: 1, 239: 1, 240: 1, 241: 1, 242: 1, 243: 1, 244: 1, 245: 1, 246: 1, 247: 1, 248: 1, 249: 1, 250: 1, 251: 1, 252: 1, 253: 1, 254: 1, 255: 1, 256: 1, 257: 1, 258: 1, 259: 1, 260: 1, 261: 1, 262: 1, 263: 1, 264: 1, 265: 1, 266: 1, 267: 1, 268: 1, 269: 1, 270: 1, 271: 1, 272: 1, 273: 1, 274: 1, 275: 1, 276: 1, 277: 1, 278: 1, 279: 1, 280: 1, 281: 1, 282: 1, 283: 1, 284: 1, 285: 1, 286: 1, 287: 1, 288: 1, 289: 1, 290: 1, 291: 1, 292: 1, 293: 1, 294: 1, 295: 1, 296: 1, 297: 1, 298: 1, 299: 1, 300: 1, 301: 1, 302: 1, 303: 1, 304: 1, 305: 1, 306: 1, 307: 1, 308: 1, 309: 1, 310: 1, 311: 1, 312: 1, 313: 1, 314: 1, 315: 1, 316: 1, 317: 1, 318: 1, 319: 1, 320: 1, 321: 1, 322: 1, 323: 1, 324: 1, 325: 1, 326: 1, 327: 1, 328: 1, 329: 1, 330: 1, 331: 1, 332: 1, 333: 1, 334: 1, 335: 1, 336: 1, 337: 1, 338: 1, 339: 1, 340: 1, 341: 1, 342: 1, 343: 1, 344: 1, 345: 1, 346: 1, 347: 1, 348: 1, 349: 1, 350: 1, 351: 1, 352: 1, 353: 1, 354: 1, 355: 1, 356: 1, 357: 1, 358: 1, 359: 1, 360: 1, 361: 1, 362: 1, 363: 1, 364: 1, 365: 1, 366: 1, 367: 1, 368: 1, 369: 1, 370: 1, 371: 1, 372: 1, 373: 1, 374: 1, 375: 1, 376: 1, 377: 1, 378: 1, 379: 1, 380: 1, 381: 1, 382: 1, 383: 1, 384: 1, 385: 1, 386: 1, 387: 1, 388: 1, 389: 1, 390: 1, 391: 1, 392: 1, 393: 1, 394: 1, 395: 1, 396: 1, 397: 1, 398: 1, 399: 1, 400: 1, 401: 1, 402: 1, 403: 1, 404: 1, 405: 1, 406: 1, 407: 1, 408: 1, 409: 1, 410: 1, 411: 1, 412: 1, 413: 1, 414: 1, 415: 1, 416: 1, 417: 1, 418: 1, 419: 1, 420: 1, 421: 1, 422: 1, 423: 1, 424: 1, 425: 1, 426: 1, 427: 1, 428: 1, 429: 1, 430: 1, 431: 1, 432: 1, 433: 1, 434: 1, 435: 1, 436: 1, 437: 1, 438: 1, 439: 1, 440: 1, 441: 1, 442: 1, 443: 1, 444: 1, 445: 1, 446: 1, 447: 1, 448: 1, 449: 1, 450: 1, 451: 1, 452: 1, 453: 1, 454: 1, 455: 1, 456: 1, 457: 1, 458: 1, 459: 1, 460: 1, 461: 1, 462: 1, 463: 1, 464: 1, 465: 1, 466: 1, 467: 1, 468: 1, 469: 1, 470: 1, 471: 1, 472: 1, 473: 1, 474: 1, 475: 1, 476: 1, 477: 1, 478: 1, 479: 1, 480: 1, 481: 1, 482: 1, 483: 1, 484: 1, 485: 1, 486: 1, 487: 1, 488: 1, 489: 1, 490: 1, 491: 1, 492: 1, 493: 1, 494: 1, 495: 1, 496: 1, 497: 1, 498: 1, 499: 1, 500: 1, 501: 1, 502: 1, 503: 1, 504: 1, 505: 1, 506: 1, 507: 1, 508: 1, 509: 1, 510: 1, 511: 1, 512: 1, 513: 1, 514: 1, 515: 1, 516: 1, 517: 1, 518: 1, 519: 1, 520: 1, 521: 1, 522: 1, 523: 1, 524: 1, 525: 1, 526: 1, 527: 1, 528: 1, 529: 1, 530: 1, 531: 1, 532: 1, 533: 1, 534: 1, 535: 1, 536: 1, 537: 1, 538: 1, 539: 1, 540: 1, 541: 1, 542: 1, 543: 1, 544: 1, 545: 1, 546: 1, 547: 1, 548: 1, 549: 1, 550: 1, 551: 1, 552: 1, 553: 1, 554: 1, 555: 1, 556: 1, 557: 1, 558: 1, 559: 1, 560: 1, 561: 1, 562: 1, 563: 1, 564: 1, 565: 1, 566: 1, 567: 1, 568: 1, 569: 1, 570: 1, 571: 1, 572: 1, 573: 1, 574: 1, 575: 1, 576: 1, 577: 1, 578: 1, 579: 1, 580: 1, 581: 1, 582: 1, 583: 1, 584: 1, 585: 1, 586: 1, 587: 1, 588: 1, 589: 1, 590: 1, 591: 1, 592: 1, 593: 1, 594: 1, 595: 1, 596: 1, 597: 1, 598: 1, 599: 1, 600: 1, 601: 1, 602: 1, 603: 1, 604: 1, 605: 1, 606: 1, 607: 1, 608: 1, 609: 1, 610: 1, 611: 1, 612: 1, 613: 1, 614: 1, 615: 1, 616: 1, 617: 1, 618: 1, 619: 1, 620: 1, 621: 1, 622: 1, 623: 1, 624: 1, 625: 1, 626: 1, 627: 1, 628: 1, 629: 1, 630: 1, 631: 1, 632: 1, 633: 1, 634: 1, 635: 1, 636: 1, 637: 1, 638: 1, 639: 1, 640: 1, 641: 1, 642: 1, 643: 1, 644: 1, 645: 1, 646: 1, 647: 1, 648: 1, 649: 1, 650: 1, 651: 1, 652: 1, 653: 1, 654: 1, 655: 1, 656: 1, 657: 1, 658: 1, 659: 1, 660: 1, 661: 1, 662: 1, 663: 1, 664: 1, 665: 1, 666: 1, 667: 1, 668: 1, 669: 1, 670: 1, 671: 1, 672: 1, 673: 1, 674: 1, 675: 1, 676: 1, 677: 1, 678: 1, 679: 1, 680: 1, 681: 1, 682: 1, 683: 1, 684: 1, 685: 1, 686: 1, 687: 1, 688: 1, 689: 1, 690: 1, 691: 1, 692: 1, 693: 1, 694: 1, 695: 1, 696: 1, 697: 1, 698: 1, 699: 1, 700: 1, 701: 1, 702: 1, 703: 1, 704: 1, 705: 1, 706: 1, 707: 1, 708: 1, 709: 1, 710: 1, 711: 1, 712: 1, 713: 1, 714: 1, 715: 1, 716: 1, 717: 1, 718: 1, 719: 1, 720: 1, 721: 1, 722: 1, 723: 1, 724: 1, 725: 1, 726: 1, 727: 1, 728: 1, 729: 1, 730: 1, 731: 1, 732: 1, 733: 1, 734: 1, 735: 1, 736: 1, 737: 1, 738: 1, 739: 1, 740: 1, 741: 1, 742: 1, 743: 1, 744: 1, 745: 1, 746: 1, 747: 1, 748: 1, 749: 1, 750: 1, 751: 1, 752: 1, 753: 1, 754: 1, 755: 1, 756: 1, 757: 1, 758: 1, 759: 1, 760: 1, 761: 1, 762: 1, 763: 1, 764: 1, 765: 1, 766: 1, 767: 1, 768: 1, 769: 1, 770: 1, 771: 1, 772: 1, 773: 1, 774: 1, 775: 1, 776: 1, 777: 1, 778: 1, 779: 1, 780: 1, 781: 1, 782: 1, 783: 1, 784: 1, 785: 1, 786: 1, 787: 1, 788: 1, 789: 1, 790: 1, 791: 1, 792: 1, 793: 1, 794: 1, 795: 1, 796: 1, 797: 1, 798: 1, 799: 1, 800: 1, 801: 1, 802: 1, 803: 1, 804: 1, 805: 1, 806: 1, 807: 1, 808: 1, 809: 1, 810: 1, 811: 1, 812: 1, 813: 1, 814: 1, 815: 1, 816: 1, 817: 1, 818: 1, 819: 1, 820: 1, 821: 1, 822: 1, 823: 1, 824: 1, 825: 1, 826: 1, 827: 1, 828: 1, 829: 1, 830: 1, 831: 1, 832: 1, 833: 1, 834: 1, 835: 1, 836: 1, 837: 1, 838: 1, 839: 1, 840: 1, 841: 1, 842: 1, 843: 1, 844: 1, 845: 1, 846: 1, 847: 1, 848: 1, 849: 1, 850: 1, 851: 1, 852: 1, 853: 1, 854: 1, 855: 1, 856: 1, 857: 1, 858: 1, 859: 1, 860: 1, 861: 1, 862: 1, 863: 1, 864: 1, 865: 1, 866: 1, 867: 1, 868: 1, 869: 1, 870: 1, 871: 1, 872: 1, 873: 1, 874: 1, 875: 1, 876: 1, 877: 1, 878: 1, 879: 1, 880: 1, 881: 1, 882: 1, 883: 1, 884: 1, 885: 1, 886: 1, 887: 1, 888: 1, 889: 1, 890: 1, 891: 1, 892: 1, 893: 1, 894: 1, 895: 1, 896: 1, 897: 1, 898: 1, 899: 1, 900: 1, 901: 1, 902: 1, 903: 1, 904: 1, 905: 1, 906: 1, 907: 1, 908: 1, 909: 1, 910: 1, 911: 1, 912: 1, 913: 1, 914: 1, 915: 1, 916: 1, 917: 1, 918: 1, 919: 1, 920: 1, 921: 1, 922: 1, 923: 1, 924: 1, 925: 1, 926: 1, 927: 1, 928: 1, 929: 1, 930: 1, 931: 1, 932: 1, 933: 1, 934: 1, 935: 1, 936: 1, 937: 1, 938: 1, 939: 1, 940: 1, 941: 1, 942: 1, 943: 1, 944: 1, 945: 1, 946: 1, 947: 1, 948: 1, 949: 1, 950: 1, 951: 1, 952: 1, 953: 1, 954: 1, 955: 1, 956: 1, 957: 1, 958: 1, 959: 1, 960: 1, 961: 1, 962: 1, 963: 1, 964: 1, 965: 1, 966: 1, 967: 1, 968: 1, 969: 1, 970: 1, 971: 1, 972: 1, 973: 1, 974: 1, 975: 1, 976: 1, 977: 1, 978: 1, 979: 1, 980: 1, 981: 1, 982: 1, 983: 1, 984: 1, 985: 1, 986: 1, 987: 1, 988: 1, 989: 1, 990: 1, 991: 1, 992: 1, 993: 1, 994: 1, 995: 1, 996: 1, 997: 1, 998: 1, 999: 1, 1000: 1, 1001: 1, 1002: 1, 1003: 1, 1004: 1, 1005: 1, 1006: 1, 1007: 1, 1008: 1, 1009: 1, 1010: 1, 1011: 1, 1012: 1, 1013: 1, 1014: 1, 1015: 1, 1016: 1, 1017: 1, 1018: 1, 1019: 1, 1020: 1, 1021: 1, 1022: 1, 1023: 1, 1024: 1, 1025: 1, 1026: 1, 1027: 1, 1028: 1, 1029: 1, 1030: 1, 1031: 1, 1032: 1, 1033: 1, 1034: 1, 1035: 1, 1036: 1, 1037: 1, 1038: 1, 1039: 1, 1040: 1, 1041: 1, 1042: 1, 1043: 1, 1044: 1, 1045: 1, 1046: 1, 1047: 1, 1048: 1, 1049: 1, 1050: 1, 1051: 1, 1052: 1, 1053: 1, 1054: 1, 1055: 1, 1056: 1, 1057: 1, 1058: 1, 1059: 1, 1060: 1, 1061: 1, 1062: 1, 1063: 1, 1064: 1, 1065: 1, 1066: 1, 1067: 1, 1068: 1, 1069: 1, 1070: 1, 1071: 1, 1072: 1, 1073: 1, 1074: 1, 1075: 1, 1076: 1, 1077: 1, 1078: 1, 1079: 1, 1080: 1, 1081: 1, 1082: 1, 1083: 1, 1084: 1, 1085: 1, 1086: 1, 1087: 1, 1088: 1, 1089: 1, 1090: 1, 1091: 1, 1092: 1, 1093: 1, 1094: 1, 1095: 1, 1096: 1, 1097: 1, 1098: 1, 1099: 1, 1100: 1, 1101: 1, 1102: 1, 1103: 1, 1104: 1, 1105: 1, 1106: 1, 1107: 1, 1108: 1, 1109: 1, 1110: 1, 1111: 1, 1112: 1, 1113: 1, 1114: 1, 1115: 1, 1116: 1, 1117: 1, 1118: 1, 1119: 1, 1120: 1, 1121: 1, 1122: 1, 1123: 1, 1124: 1, 1125: 1, 1126: 1, 1127: 1, 1128: 1, 1129: 1, 1130: 1, 1131: 1, 1132: 1, 1133: 1, 1134: 1, 1135: 1, 1136: 1, 1137: 1, 1138: 1, 1139: 1, 1140: 1, 1141: 1, 1142: 1, 1143: 1, 1144: 1, 1145: 1, 1146: 1, 1147: 1, 1148: 1, 1149: 1, 1150: 1, 1151: 1, 1152: 1, 1153: 1, 1154: 1, 1155: 1, 1156: 1, 1157: 1, 1158: 1, 1159: 1, 1160: 1, 1161: 1, 1162: 1, 1163: 1, 1164: 1, 1165: 1, 1166: 1, 1167: 1, 1168: 1, 1169: 1, 1170: 1, 1171: 1, 1172: 1, 1173: 1, 1174: 1, 1175: 1, 1176: 1, 1177: 1, 1178: 1, 1179: 1, 1180: 1, 1181: 1, 1182: 1, 1183: 1, 1184: 1, 1185: 1, 1186: 1, 1187: 1, 1188: 1, 1189: 1, 1190: 1, 1191: 1, 1192: 1, 1193: 1, 1194: 1, 1195: 1, 1196: 1, 1197: 1, 1198: 1, 1199: 1, 1200: 1, 1201: 1, 1202: 1, 1203: 1, 1204: 1, 1205: 1, 1206: 1, 1207: 1, 1208: 1, 1209: 1, 1210: 1, 1211: 1, 1212: 1, 1213: 1, 1214: 1, 1215: 1, 1216: 1, 1217: 1, 1218: 1, 1219: 1, 1220: 1, 1221: 1, 1222: 1, 1223: 1, 1224: 1, 1225: 1, 1226: 1, 1227: 1, 1228: 1, 1229: 1, 1230: 1, 1231: 1, 1232: 1, 1233: 1, 1234: 1, 1235: 1, 1236: 1, 1237: 1, 1238: 1, 1239: 1, 1240: 1, 1241: 1, 1242: 1, 1243: 1, 1244: 1, 1245: 1, 1246: 1, 1247: 1, 1248: 1, 1249: 1, 1250: 1, 1251: 1, 1252: 1, 1253: 1, 1254: 1, 1255: 1, 1256: 1, 1257: 1, 1258: 1, 1259: 1, 1260: 1, 1261: 1, 1262: 1, 1263: 1, 1264: 1, 1265: 1, 1266: 1, 1267: 1, 1268: 1, 1269: 1, 1270: 1, 1271: 1, 1272: 1, 1273: 1, 1274: 1, 1275: 1, 1276: 1, 1277: 1, 1278: 1, 1279: 1, 1280: 1, 1281: 1, 1282: 1, 1283: 1, 1284: 1, 1285: 1, 1286: 1, 1287: 1, 1288: 1, 1289: 1, 1290: 1, 1291: 1, 1292: 1, 1293: 1, 1294: 1, 1295: 1, 1296: 1, 1297: 1, 1298: 1, 1299: 1, 1300: 1, 1301: 1, 1302: 1, 1303: 1, 1304: 1, 1305: 1, 1306: 1, 1307: 1, 1308: 1, 1309: 1, 1310: 1, 1311: 1, 1312: 1, 1313: 1, 1314: 1, 1315: 1, 1316: 1, 1317: 1, 1318: 1, 1319: 1, 1320: 1, 1321: 1, 1322: 1, 1323: 1, 1324: 1, 1325: 1, 1326: 1, 1327: 1, 1328: 1, 1329: 1, 1330: 1, 1331: 1, 1332: 1, 1333: 1, 1334: 1, 1335: 1, 1336: 1, 1337: 1, 1338: 1, 1339: 1, 1340: 1, 1341: 1, 1342: 1, 1343: 1, 1344: 1, 1345: 1, 1346: 1, 1347: 1, 1348: 1, 1349: 1, 1350: 1, 1351: 1, 1352: 1, 1353: 1, 1354: 1, 1355: 1, 1356: 1, 1357: 1, 1358: 1, 1359: 1, 1360: 1, 1361: 1, 1362: 1, 1363: 1, 1364: 1, 1365: 1, 1366: 1, 1367: 1, 1368: 1, 1369: 1, 1370: 1, 1371: 1, 1372: 1, 1373: 1, 1374: 1, 1375: 1, 1376: 1, 1377: 1, 1378: 1, 1379: 1, 1380: 1, 1381: 1, 1382: 1, 1383: 1, 1384: 1, 1385: 1, 1386: 1, 1387: 1, 1388: 1, 1389: 1, 1390: 1, 1391: 1, 1392: 1, 1393: 1, 1394: 1, 1395: 1, 1396: 1, 1397: 1, 1398: 1, 1399: 1, 1400: 1, 1401: 1, 1402: 1, 1403: 1, 1404: 1, 1405: 1, 1406: 1, 1407: 1, 1408: 1, 1409: 1, 1410: 1, 1411: 1, 1412: 1, 1413: 1, 1414: 1, 1415: 1, 1416: 1, 1417: 1, 1418: 1, 1419: 1, 1420: 1, 1421: 1, 1422: 1, 1423: 1, 1424: 1, 1425: 1, 1426: 1, 1427: 1, 1428: 1, 1429: 1, 1430: 1, 1431: 1, 1432: 1, 1433: 1, 1434: 1, 1435: 1, 1436: 1, 1437: 1, 1438: 1, 1439: 1, 1440: 1, 1441: 1, 1442: 1, 1443: 1, 1444: 1, 1445: 1, 1446: 1, 1447: 1, 1448: 1, 1449: 1, 1450: 1, 1451: 1, 1452: 1, 1453: 1, 1454: 1, 1455: 1, 1456: 1, 1457: 1, 1458: 1, 1459: 1, 1460: 1, 1461: 1, 1462: 1, 1463: 1, 1464: 1, 1465: 1, 1466: 1, 1467: 1, 1468: 1, 1469: 1, 1470: 1, 1471: 1, 1472: 1, 1473: 1, 1474: 1, 1475: 1, 1476: 1, 1477: 1, 1478: 1, 1479: 1, 1480: 1, 1481: 1, 1482: 1, 1483: 1, 1484: 1, 1485: 1, 1486: 1, 1487: 1, 1488: 1, 1489: 1, 1490: 1, 1491: 1, 1492: 1, 1493: 1, 1494: 1, 1495: 1, 1496: 1, 1497: 1, 1498: 1, 1499: 1, 1500: 1, 1501: 1, 1502: 1, 1503: 1, 1504: 1, 1505: 1, 1506: 1, 1507: 1, 1508: 1, 1509: 1, 1510: 1, 1511: 1, 1512: 1, 1513: 1, 1514: 1, 1515: 1, 1516: 1, 1517: 1, 1518: 1, 1519: 1, 1520: 1, 1521: 1, 1522: 1, 1523: 1, 1524: 1, 1525: 1, 1526: 1, 1527: 1, 1528: 1, 1529: 1, 1530: 1, 1531: 1, 1532: 1, 1533: 1, 1534: 1, 1535: 1, 1536: 1, 1537: 1, 1538: 1, 1539: 1, 1540: 1, 1541: 1, 1542: 1, 1543: 1, 1544: 1, 1545: 1, 1546: 1, 1547: 1, 1548: 1, 1549: 1, 1550: 1, 1551: 1, 1552: 1, 1553: 1, 1554: 1, 1555: 1, 1556: 1, 1557: 1, 1558: 1, 1559: 1, 1560: 1, 1561: 1, 1562: 1, 1563: 1, 1564: 1, 1565: 1, 1566: 1, 1567: 1, 1568: 1, 1569: 1, 1570: 1, 1571: 1, 1572: 1, 1573: 1, 1574: 1, 1575: 1, 1576: 1, 1577: 1, 1578: 1, 1579: 1, 1580: 1, 1581: 1, 1582: 1, 1583: 1, 1584: 1, 1585: 1, 1586: 1, 1587: 1, 1588: 1, 1589: 1, 1590: 1, 1591: 1, 1592: 1, 1593: 1, 1594: 1, 1595: 1, 1596: 1, 1597: 1, 1598: 1, 1599: 1, 1600: 1, 1601: 1, 1602: 1, 1603: 1, 1604: 1, 1605: 1, 1606: 1, 1607: 1, 1608: 1, 1609: 1, 1610: 1, 1611: 1, 1612: 1, 1613: 1, 1614: 1, 1615: 1, 1616: 1, 1617: 1, 1618: 1, 1619: 1, 1620: 1, 1621: 1, 1622: 1, 1623: 1, 1624: 1, 1625: 1, 1626: 1, 1627: 1, 1628: 1, 1629: 1, 1630: 1, 1631: 1, 1632: 1, 1633: 1, 1634: 1, 1635: 1, 1636: 1, 1637: 1, 1638: 1, 1639: 1, 1640: 1, 1641: 1, 1642: 1, 1643: 1, 1644: 1, 1645: 1, 1646: 1, 1647: 1, 1648: 1, 1649: 1, 1650: 1, 1651: 1, 1652: 1, 1653: 1, 1654: 1, 1655: 1, 1656: 1, 1657: 1, 1658: 1, 1659: 1, 1660: 1, 1661: 1, 1662: 1, 1663: 1, 1664: 1, 1665: 1, 1666: 1, 1667: 1, 1668: 1, 1669: 1, 1670: 1, 1671: 1, 1672: 1, 1673: 1, 1674: 1, 1675: 1, 1676: 1, 1677: 1, 1678: 1, 1679: 1, 1680: 1, 1681: 1, 1682: 1, 1683: 1, 1684: 1, 1685: 1, 1686: 1, 1687: 1, 1688: 1, 1689: 1, 1690: 1, 1691: 1, 1692: 1, 1693: 1, 1694: 1, 1695: 1, 1696: 1, 1697: 1, 1698: 1, 1699: 1, 1700: 1, 1701: 1, 1702: 1, 1703: 1, 1704: 1, 1705: 1, 1706: 1, 1707: 1, 1708: 1, 1709: 1, 1710: 1, 1711: 1, 1712: 1, 1713: 1, 1714: 1, 1715: 1, 1716: 1, 1717: 1, 1718: 1, 1719: 1, 1720: 1, 1721: 1, 1722: 1, 1723: 1, 1724: 1, 1725: 1, 1726: 1, 1727: 1, 1728: 1, 1729: 1, 1730: 1, 1731: 1, 1732: 1, 1733: 1, 1734: 1, 1735: 1, 1736: 1, 1737: 1, 1738: 1, 1739: 1, 1740: 1, 1741: 1, 1742: 1, 1743: 1, 1744: 1, 1745: 1, 1746: 1, 1747: 1, 1748: 1, 1749: 1, 1750: 1, 1751: 1, 1752: 1, 1753: 1, 1754: 1, 1755: 1, 1756: 1, 1757: 1, 1758: 1, 1759: 1, 1760: 1, 1761: 1, 1762: 1, 1763: 1, 1764: 1, 1765: 1, 1766: 1, 1767: 1, 1768: 1, 1769: 1, 1770: 1, 1771: 1, 1772: 1, 1773: 1, 1774: 1, 1775: 1, 1776: 1, 1777: 1, 1778: 1, 1779: 1, 1780: 1, 1781: 1, 1782: 1, 1783: 1, 1784: 1, 1785: 1, 1786: 1, 1787: 1, 1788: 1, 1789: 1, 1790: 1, 1791: 1, 1792: 1, 1793: 1, 1794: 1, 1795: 1, 1796: 1, 1797: 1, 1798: 1, 1799: 1, 1800: 1, 1801: 1, 1802: 1, 1803: 1, 1804: 1, 1805: 1, 1806: 1, 1807: 1, 1808: 1, 1809: 1, 1810: 1, 1811: 1, 1812: 1, 1813: 1, 1814: 1, 1815: 1, 1816: 1, 1817: 1, 1818: 1, 1819: 1, 1820: 1, 1821: 1, 1822: 1, 1823: 1, 1824: 1, 1825: 1, 1826: 1, 1827: 1, 1828: 1, 1829: 1, 1830: 1, 1831: 1, 1832: 1, 1833: 1, 1834: 1, 1835: 1, 1836: 1, 1837: 1, 1838: 1, 1839: 1, 1840: 1, 1841: 1, 1842: 1, 1843: 1, 1844: 1, 1845: 1, 1846: 1, 1847: 1, 1848: 1, 1849: 1, 1850: 1, 1851: 1, 1852: 1, 1853: 1, 1854: 1, 1855: 1, 1856: 1, 1857: 1, 1858: 1, 1859: 1, 1860: 1, 1861: 1, 1862: 1, 1863: 1, 1864: 1, 1865: 1, 1866: 1, 1867: 1, 1868: 1, 1869: 1, 1870: 1, 1871: 1, 1872: 1, 1873: 1, 1874: 1, 1875: 1, 1876: 1, 1877: 1, 1878: 1, 1879: 1, 1880: 1, 1881: 1, 1882: 1, 1883: 1, 1884: 1, 1885: 1, 1886: 1, 1887: 1, 1888: 1, 1889: 1, 1890: 1, 1891: 1, 1892: 1, 1893: 1, 1894: 1, 1895: 1, 1896: 1, 1897: 1, 1898: 1, 1899: 1, 1900: 1, 1901: 1, 1902: 1, 1903: 1, 1904: 1, 1905: 1, 1906: 1, 1907: 1, 1908: 1, 1909: 1, 1910: 1, 1911: 1, 1912: 1, 1913: 1, 1914: 1, 1915: 1, 1916: 1, 1917: 1, 1918: 1, 1919: 1, 1920: 1, 1921: 1, 1922: 1, 1923: 1, 1924: 1, 1925: 1, 1926: 1, 1927: 1, 1928: 1, 1929: 1, 1930: 1, 1931: 1, 1932: 1, 1933: 1, 1934: 1, 1935: 1, 1936: 1, 1937: 1, 1938: 1, 1939: 1, 1940: 1, 1941: 1, 1942: 1, 1943: 1, 1944: 1, 1945: 1, 1946: 1, 1947: 1, 1948: 1, 1949: 1, 1950: 1, 1951: 1, 1952: 1, 1953: 1, 1954: 1, 1955: 1, 1956: 1, 1957: 1, 1958: 1, 1959: 1, 1960: 1, 1961: 1, 1962: 1, 1963: 1, 1964: 1, 1965: 1, 1966: 1, 1967: 1, 1968: 1, 1969: 1, 1970: 1, 1971: 1, 1972: 1, 1973: 1, 1974: 1, 1975: 1, 1976: 1, 1977: 1, 1978: 1, 1979: 1, 1980: 1, 1981: 1, 1982: 1, 1983: 1, 1984: 1, 1985: 1, 1986: 1, 1987: 1, 1988: 1, 1989: 1, 1990: 1, 1991: 1, 1992: 1, 1993: 1, 1994: 1, 1995: 1, 1996: 1, 1997: 1, 1998: 1, 1999: 1, 2000: 1, 2001: 1, 2002: 1, 2003: 1, 2004: 1, 2005: 1, 2006: 1, 2007: 1, 2008: 1, 2009: 1, 2010: 1, 2011: 1, 2012: 1, 2013: 1, 2014: 1, 2015: 1, 2016: 1, 2017: 1, 2018: 1, 2019: 1, 2020: 1, 2021: 1, 2022: 1, 2023: 1, 2024: 1, 2025: 1, 2026: 1, 2027: 1, 2028: 1, 2029: 1, 2030: 1, 2031: 1, 2032: 1, 2033: 1, 2034: 1, 2035: 1, 2036: 1, 2037: 1, 2038: 1, 2039: 1, 2040: 1, 2041: 1, 2042: 1, 2043: 1, 2044: 1, 2045: 1, 2046: 1, 2047: 1, 2048: 1, 2049: 1, 2050: 1, 2051: 1, 2052: 1, 2053: 1, 2054: 1, 2055: 1, 2056: 1, 2057: 1, 2058: 1, 2059: 1, 2060: 1, 2061: 1, 2062: 1, 2063: 1, 2064: 1, 2065: 1, 2066: 1, 2067: 1, 2068: 1, 2069: 1, 2070: 1, 2071: 1, 2072: 1, 2073: 1, 2074: 1, 2075: 1, 2076: 1, 2077: 1, 2078: 1, 2079: 1, 2080: 1, 2081: 1, 2082: 1, 2083: 1, 2084: 1, 2085: 1, 2086: 1, 2087: 1, 2088: 1, 2089: 1, 2090: 1, 2091: 1, 2092: 1, 2093: 1, 2094: 1, 2095: 1, 2096: 1, 2097: 1, 2098: 1, 2099: 1, 2100: 1, 2101: 1, 2102: 1, 2103: 1, 2104: 1, 2105: 1, 2106: 1, 2107: 1, 2108: 1, 2109: 1, 2110: 1, 2111: 1, 2112: 1, 2113: 1, 2114: 1, 2115: 1, 2116: 1, 2117: 1, 2118: 1, 2119: 1, 2120: 1, 2121: 1, 2122: 1, 2123: 1, 2124: 1, 2125: 1, 2126: 1, 2127: 1, 2128: 1, 2129: 1, 2130: 1, 2131: 1, 2132: 1, 2133: 1, 2134: 1, 2135: 1, 2136: 1, 2137: 1, 2138: 1, 2139: 1, 2140: 1, 2141: 1, 2142: 1, 2143: 1, 2144: 1, 2145: 1, 2146: 1, 2147: 1, 2148: 1, 2149: 1, 2150: 1, 2151: 1, 2152: 1, 2153: 1, 2154: 1, 2155: 1, 2156: 1, 2157: 1, 2158: 1, 2159: 1, 2160: 1, 2161: 1, 2162: 1, 2163: 1, 2164: 1, 2165: 1, 2166: 1, 2167: 1, 2168: 1, 2169: 1, 2170: 1, 2171: 1, 2172: 1, 2173: 1, 2174: 1, 2175: 1, 2176: 1, 2177: 1, 2178: 1, 2179: 1, 2180: 1, 2181: 1, 2182: 1, 2183: 1, 2184: 1, 2185: 1, 2186: 1, 2187: 1, 2188: 1, 2189: 1, 2190: 1, 2191: 1, 2192: 1, 2193: 1, 2194: 1, 2195: 1, 2196: 1, 2197: 1, 2198: 1, 2199: 1, 2200: 1, 2201: 1, 2202: 1, 2203: 1, 2204: 1, 2205: 1, 2206: 1, 2207: 1, 2208: 1, 2209: 1, 2210: 1, 2211: 1, 2212: 1, 2213: 1, 2214: 1, 2215: 1, 2216: 1, 2217: 1, 2218: 1, 2219: 1, 2220: 1, 2221: 1, 2222: 1, 2223: 1, 2224: 1, 2225: 1, 2226: 1, 2227: 1, 2228: 1, 2229: 1, 2230: 1, 2231: 1, 2232: 1, 2233: 1, 2234: 1, 2235: 1, 2236: 1, 2237: 1, 2238: 1, 2239: 1, 2240: 1, 2241: 1, 2242: 1, 2243: 1, 2244: 1, 2245: 1, 2246: 1, 2247: 1, 2248: 1, 2249: 1, 2250: 1, 2251: 1, 2252: 1, 2253: 1, 2254: 1, 2255: 1, 2256: 1, 2257: 1, 2258: 1, 2259: 1, 2260: 1, 2261: 1, 2262: 1, 2263: 1, 2264: 1, 2265: 1, 2266: 1, 2267: 1, 2268: 1, 2269: 1, 2270: 1, 2271: 1, 2272: 1, 2273: 1, 2274: 1, 2275: 1, 2276: 1, 2277: 1, 2278: 1, 2279: 1, 2280: 1, 2281: 1, 2282: 1, 2283: 1, 2284: 1, 2285: 1, 2286: 1, 2287: 1, 2288: 1, 2289: 1, 2290: 1, 2291: 1, 2292: 1, 2293: 1, 2294: 1, 2295: 1, 2296: 1, 2297: 1, 2298: 1, 2299: 1, 2300: 1, 2301: 1, 2302: 1, 2303: 1, 2304: 1, 2305: 1, 2306: 1, 2307: 1, 2308: 1, 2309: 1, 2310: 1, 2311: 1, 2312: 1, 2313: 1, 2314: 1, 2315: 1, 2316: 1, 2317: 1, 2318: 1, 2319: 1, 2320: 1, 2321: 1, 2322: 1, 2323: 1, 2324: 1, 2325: 1, 2326: 1, 2327: 1, 2328: 1, 2329: 1, 2330: 1, 2331: 1, 2332: 1, 2333: 1, 2334: 1, 2335: 1, 2336: 1, 2337: 1, 2338: 1, 2339: 1, 2340: 1, 2341: 1, 2342: 1, 2343: 1, 2344: 1, 2345: 1, 2346: 1, 2347: 1, 2348: 1, 2349: 1, 2350: 1, 2351: 1, 2352: 1, 2353: 1, 2354: 1, 2355: 1, 2356: 1, 2357: 1, 2358: 1, 2359: 1, 2360: 1, 2361: 1, 2362: 1, 2363: 1, 2364: 1, 2365: 1, 2366: 1, 2367: 1, 2368: 1, 2369: 1, 2370: 1, 2371: 1, 2372: 1, 2373: 1, 2374: 1, 2375: 1, 2376: 1, 2377: 1, 2378: 1, 2379: 1, 2380: 1, 2381: 1, 2382: 1, 2383: 1, 2384: 1, 2385: 1, 2386: 1, 2387: 1, 2388: 1, 2389: 1, 2390: 1, 2391: 1, 2392: 1, 2393: 1, 2394: 1, 2395: 1, 2396: 1, 2397: 1, 2398: 1, 2399: 1, 2400: 1, 2401: 1, 2402: 1, 2403: 1, 2404: 1, 2405: 1, 2406: 1, 2407: 1, 2408: 1, 2409: 1, 2410: 1, 2411: 1, 2412: 1, 2413: 1, 2414: 1, 2415: 1, 2416: 1, 2417: 1, 2418: 1, 2419: 1, 2420: 1, 2421: 1, 2422: 1, 2423: 1, 2424: 1, 2425: 1, 2426: 1, 2427: 1, 2428: 1, 2429: 1, 2430: 1, 2431: 1, 2432: 1, 2433: 1, 2434: 1, 2435: 1, 2436: 1, 2437: 1, 2438: 1, 2439: 1, 2440: 1, 2441: 1, 2442: 1, 2443: 1, 2444: 1, 2445: 1, 2446: 1, 2447: 1, 2448: 1, 2449: 1, 2450: 1, 2451: 1, 2452: 1, 2453: 1, 2454: 1, 2455: 1, 2456: 1, 2457: 1, 2458: 1, 2459: 1, 2460: 1, 2461: 1, 2462: 1, 2463: 1, 2464: 1, 2465: 1, 2466: 1, 2467: 1, 2468: 1, 2469: 1, 2470: 1, 2471: 1, 2472: 1, 2473: 1, 2474: 1, 2475: 1, 2476: 1, 2477: 1, 2478: 1, 2479: 1, 2480: 1, 2481: 1, 2482: 1, 2483: 1, 2484: 1, 2485: 1, 2486: 1, 2487: 1, 2488: 1, 2489: 1, 2490: 1, 2491: 1, 2492: 1, 2493: 1, 2494: 1, 2495: 1, 2496: 1, 2497: 1, 2498: 1, 2499: 1, 2500: 1, 2501: 1, 2502: 1, 2503: 1, 2504: 1, 2505: 1, 2506: 1, 2507: 1, 2508: 1, 2509: 1, 2510: 1, 2511: 1, 2512: 1, 2513: 1, 2514: 1, 2515: 1, 2516: 1, 2517: 1, 2518: 1, 2519: 1, 2520: 1, 2521: 1, 2522: 1, 2523: 1, 2524: 1, 2525: 1, 2526: 1, 2527: 1, 2528: 1, 2529: 1, 2530: 1, 2531: 1, 2532: 1, 2533: 1, 2534: 1, 2535: 1, 2536: 1, 2537: 1, 2538: 1, 2539: 1, 2540: 1, 2541: 1, 2542: 1, 2543: 1, 2544: 1, 2545: 1, 2546: 1, 2547: 1, 2548: 1, 2549: 1, 2550: 1, 2551: 1, 2552: 1, 2553: 1, 2554: 1, 2555: 1, 2556: 1, 2557: 1, 2558: 1, 2559: 1, 2560: 1, 2561: 1, 2562: 1, 2563: 1, 2564: 1, 2565: 1, 2566: 1, 2567: 1, 2568: 1, 2569: 1, 2570: 1, 2571: 1, 2572: 1, 2573: 1, 2574: 1, 2575: 1, 2576: 1, 2577: 1, 2578: 1, 2579: 1, 2580: 1, 2581: 1, 2582: 1, 2583: 1, 2584: 1, 2585: 1, 2586: 1, 2587: 1, 2588: 1, 2589: 1, 2590: 1, 2591: 1, 2592: 1, 2593: 1, 2594: 1, 2595: 1, 2596: 1, 2597: 1, 2598: 1, 2599: 1, 2600: 1, 2601: 1, 2602: 1, 2603: 1, 2604: 1, 2605: 1, 2606: 1, 2607: 1, 2608: 1, 2609: 1, 2610: 1, 2611: 1, 2612: 1, 2613: 1, 2614: 1, 2615: 1, 2616: 1, 2617: 1, 2618: 1, 2619: 1, 2620: 1, 2621: 1, 2622: 1, 2623: 1, 2624: 1, 2625: 1, 2626: 1, 2627: 1, 2628: 1, 2629: 1, 2630: 1, 2631: 1, 2632: 1, 2633: 1, 2634: 1, 2635: 1, 2636: 1, 2637: 1, 2638: 1, 2639: 1, 2640: 1, 2641: 1, 2642: 1, 2643: 1, 2644: 1, 2645: 1, 2646: 1, 2647: 1, 2648: 1, 2649: 1, 2650: 1, 2651: 1, 2652: 1, 2653: 1, 2654: 1, 2655: 1, 2656: 1, 2657: 1, 2658: 1, 2659: 1, 2660: 1, 2661: 1, 2662: 1, 2663: 1, 2664: 1, 2665: 1, 2666: 1, 2667: 1, 2668: 1, 2669: 1, 2670: 1, 2671: 1, 2672: 1, 2673: 1, 2674: 1, 2675: 1, 2676: 1, 2677: 1, 2678: 1, 2679: 1, 2680: 1, 2681: 1, 2682: 1, 2683: 1, 2684: 1, 2685: 1, 2686: 1, 2687: 1, 2688: 1, 2689: 1, 2690: 1, 2691: 1, 2692: 1, 2693: 1, 2694: 1, 2695: 1, 2696: 1, 2697: 1, 2698: 1, 2699: 1, 2700: 1, 2701: 1, 2702: 1, 2703: 1, 2704: 1, 2705: 1, 2706: 1, 2707: 1, 2708: 1, 2709: 1, 2710: 1, 2711: 1, 2712: 1, 2713: 1, 2714: 1, 2715: 1, 2716: 1, 2717: 1, 2718: 1, 2719: 1, 2720: 1, 2721: 1, 2722: 1, 2723: 1, 2724: 1, 2725: 1, 2726: 1, 2727: 1, 2728: 1, 2729: 1, 2730: 1, 2731: 1, 2732: 1, 2733: 1, 2734: 1, 2735: 1, 2736: 1, 2737: 1, 2738: 1, 2739: 1, 2740: 1, 2741: 1, 2742: 1, 2743: 1, 2744: 1, 2745: 1, 2746: 1, 2747: 1, 2748: 1, 2749: 1, 2750: 1, 2751: 1, 2752: 1, 2753: 1, 2754: 1, 2755: 1, 2756: 1, 2757: 1, 2758: 1, 2759: 1, 2760: 1, 2761: 1, 2762: 1, 2763: 1, 2764: 1, 2765: 1, 2766: 1, 2767: 1, 2768: 1, 2769: 1, 2770: 1, 2771: 1, 2772: 1, 2773: 1, 2774: 1, 2775: 1, 2776: 1, 2777: 1, 2778: 1, 2779: 1, 2780: 1, 2781: 1, 2782: 1, 2783: 1, 2784: 1, 2785: 1, 2786: 1, 2787: 1, 2788: 1, 2789: 1, 2790: 1, 2791: 1, 2792: 1, 2793: 1, 2794: 1, 2795: 1, 2796: 1, 2797: 1, 2798: 1, 2799: 1, 2800: 1, 2801: 1, 2802: 1, 2803: 1, 2804: 1, 2805: 1, 2806: 1, 2807: 1, 2808: 1, 2809: 1, 2810: 1, 2811: 1, 2812: 1, 2813: 1, 2814: 1, 2815: 1, 2816: 1, 2817: 1, 2818: 1, 2819: 1, 2820: 1, 2821: 1, 2822: 1, 2823: 1, 2824: 1, 2825: 1, 2826: 1, 2827: 1, 2828: 1, 2829: 1, 2830: 1, 2831: 1, 2832: 1, 2833: 1, 2834: 1, 2835: 1, 2836: 1, 2837: 1, 2838: 1, 2839: 1, 2840: 1, 2841: 1, 2842: 1, 2843: 1, 2844: 1, 2845: 1, 2846: 1, 2847: 1, 2848: 1, 2849: 1, 2850: 1, 2851: 1, 2852: 1, 2853: 1, 2854: 1, 2855: 1, 2856: 1, 2857: 1, 2858: 1, 2859: 1, 2860: 1, 2861: 1, 2862: 1, 2863: 1, 2864: 1, 2865: 1, 2866: 1, 2867: 1, 2868: 1, 2869: 1, 2870: 1, 2871: 1, 2872: 1, 2873: 1, 2874: 1, 2875: 1, 2876: 1, 2877: 1, 2878: 1, 2879: 1, 2880: 1, 2881: 1, 2882: 1, 2883: 1, 2884: 1, 2885: 1, 2886: 1, 2887: 1, 2888: 1, 2889: 1, 2890: 1, 2891: 1, 2892: 1, 2893: 1, 2894: 1, 2895: 1, 2896: 1, 2897: 1, 2898: 1, 2899: 1, 2900: 1, 2901: 1, 2902: 1, 2903: 1, 2904: 1, 2905: 1, 2906: 1, 2907: 1, 2908: 1, 2909: 1, 2910: 1, 2911: 1, 2912: 1, 2913: 1, 2914: 1, 2915: 1, 2916: 1, 2917: 1, 2918: 1, 2919: 1, 2920: 1, 2921: 1, 2922: 1, 2923: 1, 2924: 1, 2925: 1, 2926: 1, 2927: 1, 2928: 1, 2929: 1, 2930: 1, 2931: 1, 2932: 1, 2933: 1, 2934: 1, 2935: 1, 2936: 1, 2937: 1, 2938: 1, 2939: 1, 2940: 1, 2941: 1, 2942: 1, 2943: 1, 2944: 1, 2945: 1, 2946: 1, 2947: 1, 2948: 1, 2949: 1, 2950: 1, 2951: 1, 2952: 1, 2953: 1, 2954: 1, 2955: 1, 2956: 1, 2957: 1, 2958: 1, 2959: 1, 2960: 1, 2961: 1, 2962: 1, 2963: 1, 2964: 1, 2965: 1, 2966: 1, 2967: 1, 2968: 1, 2969: 1, 2970: 1, 2971: 1, 2972: 1, 2973: 1, 2974: 1, 2975: 1, 2976: 1, 2977: 1, 2978: 1, 2979: 1, 2980: 1, 2981: 1, 2982: 1, 2983: 1, 2984: 1, 2985: 1, 2986: 1, 2987: 1, 2988: 1, 2989: 1, 2990: 1, 2991: 1, 2992: 1, 2993: 1, 2994: 1, 2995: 1, 2996: 1, 2997: 1, 2998: 1, 2999: 1, 3000: 1, 3001: 1, 3002: 1, 3003: 1, 3004: 1, 3005: 1, 3006: 1, 3007: 1, 3008: 1, 3009: 1, 3010: 1, 3011: 1, 3012: 1, 3013: 1, 3014: 1, 3015: 1, 3016: 1, 3017: 1, 3018: 1, 3019: 1, 3020: 1, 3021: 1, 3022: 1, 3023: 1, 3024: 1, 3025: 1, 3026: 1, 3027: 1, 3028: 1, 3029: 1, 3030: 1, 3031: 1, 3032: 1, 3033: 1, 3034: 1, 3035: 1, 3036: 1, 3037: 1, 3038: 1, 3039: 1, 3040: 1, 3041: 1, 3042: 1, 3043: 1, 3044: 1, 3045: 1, 3046: 1, 3047: 1, 3048: 1, 3049: 1, 3050: 1, 3051: 1, 3052: 1, 3053: 1, 3054: 1, 3055: 1, 3056: 1, 3057: 1, 3058: 1, 3059: 1, 3060: 1, 3061: 1, 3062: 1, 3063: 1, 3064: 1, 3065: 1, 3066: 1, 3067: 1, 3068: 1, 3069: 1, 3070: 1, 3071: 1, 3072: 1, 3073: 1, 3074: 1, 3075: 1, 3076: 1, 3077: 1, 3078: 1, 3079: 1, 3080: 1, 3081: 1, 3082: 1, 3083: 1, 3084: 1, 3085: 1, 3086: 1, 3087: 1, 3088: 1, 3089: 1, 3090: 1, 3091: 1, 3092: 1, 3093: 1, 3094: 1, 3095: 1, 3096: 1, 3097: 1, 3098: 1, 3099: 1, 3100: 1, 3101: 1, 3102: 1, 3103: 1, 3104: 1, 3105: 1, 3106: 1, 3107: 1, 3108: 1, 3109: 1, 3110: 1, 3111: 1, 3112: 1, 3113: 1, 3114: 1, 3115: 1, 3116: 1, 3117: 1, 3118: 1, 3119: 1, 3120: 1, 3121: 1, 3122: 1, 3123: 1, 3124: 1, 3125: 1, 3126: 1, 3127: 1, 3128: 1, 3129: 1, 3130: 1, 3131: 1, 3132: 1, 3133: 1, 3134: 1, 3135: 1, 3136: 1, 3137: 1, 3138: 1, 3139: 1, 3140: 1, 3141: 1, 3142: 1, 3143: 1, 3144: 1, 3145: 1, 3146: 1, 3147: 1, 3148: 1, 3149: 1, 3150: 1, 3151: 1, 3152: 1, 3153: 1, 3154: 1, 3155: 1, 3156: 1, 3157: 1, 3158: 1, 3159: 1, 3160: 1, 3161: 1, 3162: 1, 3163: 1, 3164: 1, 3165: 1, 3166: 1, 3167: 1, 3168: 1, 3169: 1, 3170: 1, 3171: 1, 3172: 1, 3173: 1, 3174: 1, 3175: 1, 3176: 1, 3177: 1, 3178: 1, 3179: 1, 3180: 1, 3181: 1, 3182: 1, 3183: 1, 3184: 1, 3185: 1, 3186: 1, 3187: 1, 3188: 1, 3189: 1, 3190: 1, 3191: 1, 3192: 1, 3193: 1, 3194: 1, 3195: 1, 3196: 1, 3197: 1, 3198: 1, 3199: 1, 3200: 1, 3201: 1, 3202: 1, 3203: 1, 3204: 1, 3205: 1, 3206: 1, 3207: 1, 3208: 1, 3209: 1, 3210: 1, 3211: 1, 3212: 1, 3213: 1, 3214: 1, 3215: 1, 3216: 1, 3217: 1, 3218: 1, 3219: 1, 3220: 1, 3221: 1, 3222: 1, 3223: 1, 3224: 1, 3225: 1, 3226: 1, 3227: 1, 3228: 1, 3229: 1, 3230: 1, 3231: 1, 3232: 1, 3233: 1, 3234: 1, 3235: 1, 3236: 1, 3237: 1, 3238: 1, 3239: 1, 3240: 1, 3241: 1, 3242: 1, 3243: 1, 3244: 1, 3245: 1, 3246: 1, 3247: 1, 3248: 1, 3249: 1, 3250: 1, 3251: 1, 3252: 1, 3253: 1, 3254: 1, 3255: 1, 3256: 1, 3257: 1, 3258: 1, 3259: 1, 3260: 1, 3261: 1, 3262: 1, 3263: 1, 3264: 1, 3265: 1, 3266: 1, 3267: 1, 3268: 1, 3269: 1, 3270: 1, 3271: 1, 3272: 1, 3273: 1, 3274: 1, 3275: 1, 3276: 1, 3277: 1, 3278: 1, 3279: 1, 3280: 1, 3281: 1, 3282: 1, 3283: 1, 3284: 1, 3285: 1, 3286: 1, 3287: 1, 3288: 1, 3289: 1, 3290: 1, 3291: 1, 3292: 1, 3293: 1, 3294: 1, 3295: 1, 3296: 1, 3297: 1, 3298: 1, 3299: 1, 3300: 1, 3301: 1, 3302: 1, 3303: 1, 3304: 1, 3305: 1, 3306: 1, 3307: 1, 3308: 1, 3309: 1, 3310: 1, 3311: 1, 3312: 1, 3313: 1, 3314: 1, 3315: 1, 3316: 1, 3317: 1, 3318: 1, 3319: 1, 3320: 1, 3321: 1, 3322: 1, 3323: 1, 3324: 1, 3325: 1, 3326: 1, 3327: 1, 3328: 1, 3329: 1, 3330: 1, 3331: 1, 3332: 1, 3333: 1, 3334: 1, 3335: 1, 3336: 1, 3337: 1, 3338: 1, 3339: 1, 3340: 1, 3341: 1, 3342: 1, 3343: 1, 3344: 1, 3345: 1, 3346: 1, 3347: 1, 3348: 1, 3349: 1, 3350: 1, 3351: 1, 3352: 1, 3353: 1, 3354: 1, 3355: 1, 3356: 1, 3357: 1, 3358: 1, 3359: 1, 3360: 1, 3361: 1, 3362: 1, 3363: 1, 3364: 1, 3365: 1, 3366: 1, 3367: 1, 3368: 1, 3369: 1, 3370: 1, 3371: 1, 3372: 1, 3373: 1, 3374: 1, 3375: 1, 3376: 1, 3377: 1, 3378: 1, 3379: 1, 3380: 1, 3381: 1, 3382: 1, 3383: 1, 3384: 1, 3385: 1, 3386: 1, 3387: 1, 3388: 1, 3389: 1, 3390: 1, 3391: 1, 3392: 1, 3393: 1, 3394: 1, 3395: 1, 3396: 1, 3397: 1, 3398: 1, 3399: 1, 3400: 1, 3401: 1, 3402: 1, 3403: 1, 3404: 1, 3405: 1, 3406: 1, 3407: 1, 3408: 1, 3409: 1, 3410: 1, 3411: 1, 3412: 1, 3413: 1, 3414: 1, 3415: 1, 3416: 1, 3417: 1, 3418: 1, 3419: 1, 3420: 1, 3421: 1, 3422: 1, 3423: 1, 3424: 1, 3425: 1, 3426: 1, 3427: 1, 3428: 1, 3429: 1, 3430: 1, 3431: 1, 3432: 1, 3433: 1, 3434: 1, 3435: 1, 3436: 1, 3437: 1, 3438: 1, 3439: 1, 3440: 1, 3441: 1, 3442: 1, 3443: 1, 3444: 1, 3445: 1, 3446: 1, 3447: 1, 3448: 1, 3449: 1, 3450: 1, 3451: 1, 3452: 1, 3453: 1, 3454: 1, 3455: 1, 3456: 1, 3457: 1, 3458: 1, 3459: 1, 3460: 1, 3461: 1, 3462: 1, 3463: 1, 3464: 1, 3465: 1, 3466: 1, 3467: 1, 3468: 1, 3469: 1, 3470: 1, 3471: 1, 3472: 1, 3473: 1, 3474: 1, 3475: 1, 3476: 1, 3477: 1, 3478: 1, 3479: 1, 3480: 1, 3481: 1, 3482: 1, 3483: 1, 3484: 1, 3485: 1, 3486: 1, 3487: 1, 3488: 1, 3489: 1, 3490: 1, 3491: 1, 3492: 1, 3493: 1, 3494: 1, 3495: 1, 3496: 1, 3497: 1, 3498: 1, 3499: 1, 3500: 1, 3501: 1, 3502: 1, 3503: 1, 3504: 1, 3505: 1, 3506: 1, 3507: 1, 3508: 1, 3509: 1, 3510: 1, 3511: 1, 3512: 1, 3513: 1, 3514: 1, 3515: 1, 3516: 1, 3517: 1, 3518: 1, 3519: 1, 3520: 1, 3521: 1, 3522: 1, 3523: 1, 3524: 1, 3525: 1, 3526: 1, 3527: 1, 3528: 1, 3529: 1, 3530: 1, 3531: 1, 3532: 1, 3533: 1, 3534: 1, 3535: 1, 3536: 1, 3537: 1, 3538: 1, 3539: 1, 3540: 1, 3541: 1, 3542: 1, 3543: 1, 3544: 1, 3545: 1, 3546: 1, 3547: 1, 3548: 1, 3549: 1, 3550: 1, 3551: 1, 3552: 1, 3553: 1, 3554: 1, 3555: 1, 3556: 1, 3557: 1, 3558: 1, 3559: 1, 3560: 1, 3561: 1, 3562: 1, 3563: 1, 3564: 1, 3565: 1, 3566: 1, 3567: 1, 3568: 1, 3569: 1, 3570: 1, 3571: 1, 3572: 1, 3573: 1, 3574: 1, 3575: 1, 3576: 1, 3577: 1, 3578: 1, 3579: 1, 3580: 1, 3581: 1, 3582: 1, 3583: 1, 3584: 1, 3585: 1, 3586: 1, 3587: 1, 3588: 1, 3589: 1, 3590: 1, 3591: 1, 3592: 1, 3593: 1, 3594: 1, 3595: 1, 3596: 1, 3597: 1, 3598: 1, 3599: 1, 3600: 1, 3601: 1, 3602: 1, 3603: 1, 3604: 1, 3605: 1, 3606: 1, 3607: 1, 3608: 1, 3609: 1, 3610: 1, 3611: 1, 3612: 1, 3613: 1, 3614: 1, 3615: 1, 3616: 1, 3617: 1, 3618: 1, 3619: 1, 3620: 1, 3621: 1, 3622: 1, 3623: 1, 3624: 1, 3625: 1, 3626: 1, 3627: 1, 3628: 1, 3629: 1, 3630: 1, 3631: 1, 3632: 1, 3633: 1, 3634: 1, 3635: 1, 3636: 1, 3637: 1, 3638: 1, 3639: 1, 3640: 1, 3641: 1, 3642: 1, 3643: 1, 3644: 1, 3645: 1, 3646: 1, 3647: 1, 3648: 1, 3649: 1, 3650: 1, 3651: 1, 3652: 1, 3653: 1, 3654: 1, 3655: 1, 3656: 1, 3657: 1, 3658: 1, 3659: 1, 3660: 1, 3661: 1, 3662: 1, 3663: 1, 3664: 1, 3665: 1, 3666: 1, 3667: 1, 3668: 1, 3669: 1, 3670: 1, 3671: 1, 3672: 1, 3673: 1, 3674: 1, 3675: 1, 3676: 1, 3677: 1, 3678: 1, 3679: 1, 3680: 1, 3681: 1, 3682: 1, 3683: 1, 3684: 1, 3685: 1, 3686: 1, 3687: 1, 3688: 1, 3689: 1, 3690: 1, 3691: 1, 3692: 1, 3693: 1, 3694: 1, 3695: 1, 3696: 1, 3697: 1, 3698: 1, 3699: 1, 3700: 1, 3701: 1, 3702: 1, 3703: 1, 3704: 1, 3705: 1, 3706: 1, 3707: 1, 3708: 1, 3709: 1, 3710: 1, 3711: 1, 3712: 1, 3713: 1, 3714: 1, 3715: 1, 3716: 1, 3717: 1, 3718: 1, 3719: 1, 3720: 1, 3721: 1, 3722: 1, 3723: 1, 3724: 1, 3725: 1, 3726: 1, 3727: 1, 3728: 1, 3729: 1, 3730: 1, 3731: 1, 3732: 1, 3733: 1, 3734: 1, 3735: 1, 3736: 1, 3737: 1, 3738: 1, 3739: 1, 3740: 1, 3741: 1, 3742: 1, 3743: 1, 3744: 1, 3745: 1, 3746: 1, 3747: 1, 3748: 1, 3749: 1, 3750: 1, 3751: 1, 3752: 1, 3753: 1, 3754: 1, 3755: 1, 3756: 1, 3757: 1, 3758: 1, 3759: 1, 3760: 1, 3761: 1, 3762: 1, 3763: 1, 3764: 1, 3765: 1, 3766: 1, 3767: 1, 3768: 1, 3769: 1, 3770: 1, 3771: 1, 3772: 1, 3773: 1, 3774: 1, 3775: 1, 3776: 1, 3777: 1, 3778: 1, 3779: 1, 3780: 1, 3781: 1, 3782: 1, 3783: 1, 3784: 1, 3785: 1, 3786: 1, 3787: 1, 3788: 1, 3789: 1, 3790: 1, 3791: 1, 3792: 1, 3793: 1, 3794: 1, 3795: 1, 3796: 1, 3797: 1, 3798: 1, 3799: 1, 3800: 1, 3801: 1, 3802: 1, 3803: 1, 3804: 1, 3805: 1, 3806: 1, 3807: 1, 3808: 1, 3809: 1, 3810: 1, 3811: 1, 3812: 1, 3813: 1, 3814: 1, 3815: 1, 3816: 1, 3817: 1, 3818: 1, 3819: 1, 3820: 1, 3821: 1, 3822: 1, 3823: 1, 3824: 1, 3825: 1, 3826: 1, 3827: 1, 3828: 1, 3829: 1, 3830: 1, 3831: 1, 3832: 1, 3833: 1, 3834: 1, 3835: 1, 3836: 1, 3837: 1, 3838: 1, 3839: 1, 3840: 1, 3841: 1, 3842: 1, 3843: 1, 3844: 1, 3845: 1, 3846: 1, 3847: 1, 3848: 1, 3849: 1, 3850: 1, 3851: 1, 3852: 1, 3853: 1, 3854: 1, 3855: 1, 3856: 1, 3857: 1, 3858: 1, 3859: 1, 3860: 1, 3861: 1, 3862: 1, 3863: 1, 3864: 1, 3865: 1, 3866: 1, 3867: 1, 3868: 1, 3869: 1, 3870: 1, 3871: 1, 3872: 1, 3873: 1, 3874: 1, 3875: 1, 3876: 1, 3877: 1, 3878: 1, 3879: 1, 3880: 1, 3881: 1, 3882: 1, 3883: 1, 3884: 1, 3885: 1, 3886: 1, 3887: 1, 3888: 1, 3889: 1, 3890: 1, 3891: 1, 3892: 1, 3893: 1, 3894: 1, 3895: 1, 3896: 1, 3897: 1, 3898: 1, 3899: 1, 3900: 1, 3901: 1, 3902: 1, 3903: 1, 3904: 1, 3905: 1, 3906: 1, 3907: 1, 3908: 1, 3909: 1, 3910: 1, 3911: 1, 3912: 1, 3913: 1, 3914: 1, 3915: 1, 3916: 1, 3917: 1, 3918: 1, 3919: 1, 3920: 1, 3921: 1, 3922: 1, 3923: 1, 3924: 1, 3925: 1, 3926: 1, 3927: 1, 3928: 1, 3929: 1, 3930: 1, 3931: 1, 3932: 1, 3933: 1, 3934: 1, 3935: 1, 3936: 1, 3937: 1, 3938: 1, 3939: 1, 3940: 1, 3941: 1, 3942: 1, 3943: 1, 3944: 1, 3945: 1, 3946: 1, 3947: 1, 3948: 1, 3949: 1, 3950: 1, 3951: 1, 3952: 1, 3953: 1, 3954: 1, 3955: 1, 3956: 1, 3957: 1, 3958: 1, 3959: 1, 3960: 1, 3961: 1, 3962: 1, 3963: 1, 3964: 1, 3965: 1, 3966: 1, 3967: 1, 3968: 1, 3969: 1, 3970: 1, 3971: 1, 3972: 1, 3973: 1, 3974: 1, 3975: 1, 3976: 1, 3977: 1, 3978: 1, 3979: 1, 3980: 1, 3981: 1, 3982: 1, 3983: 1, 3984: 1, 3985: 1, 3986: 1, 3987: 1, 3988: 1, 3989: 1, 3990: 1, 3991: 1, 3992: 1, 3993: 1, 3994: 1, 3995: 1, 3996: 1, 3997: 1, 3998: 1, 3999: 1, 4000: 1, 4001: 1, 4002: 1, 4003: 1, 4004: 1, 4005: 1, 4006: 1, 4007: 1, 4008: 1, 4009: 1, 4010: 1, 4011: 1, 4012: 1, 4013: 1, 4014: 1, 4015: 1, 4016: 1, 4017: 1, 4018: 1, 4019: 1, 4020: 1, 4021: 1, 4022: 1, 4023: 1, 4024: 1, 4025: 1, 4026: 1, 4027: 1, 4028: 1, 4029: 1, 4030: 1, 4031: 1, 4032: 1, 4033: 1, 4034: 1, 4035: 1, 4036: 1, 4037: 1, 4038: 1, 4039: 1, 4040: 1, 4041: 1, 4042: 1, 4043: 1, 4044: 1, 4045: 1, 4046: 1, 4047: 1, 4048: 1, 4049: 1, 4050: 1, 4051: 1, 4052: 1, 4053: 1, 4054: 1, 4055: 1, 4056: 1, 4057: 1, 4058: 1, 4059: 1, 4060: 1, 4061: 1, 4062: 1, 4063: 1, 4064: 1, 4065: 1, 4066: 1, 4067: 1, 4068: 1, 4069: 1, 4070: 1, 4071: 1, 4072: 1, 4073: 1, 4074: 1, 4075: 1, 4076: 1, 4077: 1, 4078: 1, 4079: 1, 4080: 1, 4081: 1, 4082: 1, 4083: 1, 4084: 1, 4085: 1, 4086: 1, 4087: 1, 4088: 1, 4089: 1, 4090: 1, 4091: 1, 4092: 1, 4093: 1, 4094: 1, 4095: 1, 4096: 1, 4097: 1, 4098: 1, 4099: 1, 4100: 1, 4101: 1, 4102: 1, 4103: 1, 4104: 1, 4105: 1, 4106: 1, 4107: 1, 4108: 1, 4109: 1, 4110: 1, 4111: 1, 4112: 1, 4113: 1, 4114: 1, 4115: 1, 4116: 1, 4117: 1, 4118: 1, 4119: 1, 4120: 1, 4121: 1, 4122: 1, 4123: 1, 4124: 1, 4125: 1, 4126: 1, 4127: 1, 4128: 1, 4129: 1, 4130: 1, 4131: 1, 4132: 1, 4133: 1, 4134: 1, 4135: 1, 4136: 1, 4137: 1, 4138: 1, 4139: 1, 4140: 1, 4141: 1, 4142: 1, 4143: 1, 4144: 1, 4145: 1, 4146: 1, 4147: 1, 4148: 1, 4149: 1, 4150: 1, 4151: 1, 4152: 1, 4153: 1, 4154: 1, 4155: 1, 4156: 1, 4157: 1, 4158: 1, 4159: 1, 4160: 1, 4161: 1, 4162: 1, 4163: 1, 4164: 1, 4165: 1, 4166: 1, 4167: 1, 4168: 1, 4169: 1, 4170: 1, 4171: 1, 4172: 1, 4173: 1, 4174: 1, 4175: 1, 4176: 1, 4177: 1, 4178: 1, 4179: 1, 4180: 1, 4181: 1, 4182: 1, 4183: 1, 4184: 1, 4185: 1, 4186: 1, 4187: 1, 4188: 1, 4189: 1, 4190: 1, 4191: 1, 4192: 1, 4193: 1, 4194: 1, 4195: 1, 4196: 1, 4197: 1, 4198: 1, 4199: 1, 4200: 1, 4201: 1, 4202: 1, 4203: 1, 4204: 1, 4205: 1, 4206: 1, 4207: 1, 4208: 1, 4209: 1, 4210: 1, 4211: 1, 4212: 1, 4213: 1, 4214: 1, 4215: 1, 4216: 1, 4217: 1, 4218: 1, 4219: 1, 4220: 1, 4221: 1, 4222: 1, 4223: 1, 4224: 1, 4225: 1, 4226: 1, 4227: 1, 4228: 1, 4229: 1, 4230: 1, 4231: 1, 4232: 1, 4233: 1, 4234: 1, 4235: 1, 4236: 1, 4237: 1, 4238: 1, 4239: 1, 4240: 1, 4241: 1, 4242: 1, 4243: 1, 4244: 1, 4245: 1, 4246: 1, 4247: 1, 4248: 1, 4249: 1, 4250: 1, 4251: 1, 4252: 1, 4253: 1, 4254: 1, 4255: 1, 4256: 1, 4257: 1, 4258: 1, 4259: 1, 4260: 1, 4261: 1, 4262: 1, 4263: 1, 4264: 1, 4265: 1, 4266: 1, 4267: 1, 4268: 1, 4269: 1, 4270: 1, 4271: 1, 4272: 1, 4273: 1, 4274: 1, 4275: 1, 4276: 1, 4277: 1, 4278: 1, 4279: 1, 4280: 1, 4281: 1, 4282: 1, 4283: 1, 4284: 1, 4285: 1, 4286: 1, 4287: 1, 4288: 1, 4289: 1, 4290: 1, 4291: 1, 4292: 1, 4293: 1, 4294: 1, 4295: 1, 4296: 1, 4297: 1, 4298: 1, 4299: 1, 4300: 1, 4301: 1, 4302: 1, 4303: 1, 4304: 1, 4305: 1, 4306: 1, 4307: 1, 4308: 1, 4309: 1, 4310: 1, 4311: 1, 4312: 1, 4313: 1, 4314: 1, 4315: 1, 4316: 1, 4317: 1, 4318: 1, 4319: 1, 4320: 1, 4321: 1, 4322: 1, 4323: 1, 4324: 1, 4325: 1, 4326: 1, 4327: 1, 4328: 1, 4329: 1, 4330: 1, 4331: 1, 4332: 1, 4333: 1, 4334: 1, 4335: 1, 4336: 1, 4337: 1, 4338: 1, 4339: 1, 4340: 1, 4341: 1, 4342: 1, 4343: 1, 4344: 1, 4345: 1, 4346: 1, 4347: 1, 4348: 1, 4349: 1, 4350: 1, 4351: 1, 4352: 1, 4353: 1, 4354: 1, 4355: 1, 4356: 1, 4357: 1, 4358: 1, 4359: 1, 4360: 1, 4361: 1, 4362: 1, 4363: 1, 4364: 1, 4365: 1, 4366: 1, 4367: 1, 4368: 1, 4369: 1, 4370: 1, 4371: 1, 4372: 1, 4373: 1, 4374: 1, 4375: 1, 4376: 1, 4377: 1, 4378: 1, 4379: 1, 4380: 1, 4381: 1, 4382: 1, 4383: 1, 4384: 1, 4385: 1, 4386: 1, 4387: 1, 4388: 1, 4389: 1, 4390: 1, 4391: 1, 4392: 1, 4393: 1, 4394: 1, 4395: 1, 4396: 1, 4397: 1, 4398: 1, 4399: 1, 4400: 1, 4401: 1, 4402: 1, 4403: 1, 4404: 1, 4405: 1, 4406: 1, 4407: 1, 4408: 1, 4409: 1, 4410: 1, 4411: 1, 4412: 1, 4413: 1, 4414: 1, 4415: 1, 4416: 1, 4417: 1, 4418: 1, 4419: 1, 4420: 1, 4421: 1, 4422: 1, 4423: 1, 4424: 1, 4425: 1, 4426: 1, 4427: 1, 4428: 1, 4429: 1, 4430: 1, 4431: 1, 4432: 1, 4433: 1, 4434: 1, 4435: 1, 4436: 1, 4437: 1, 4438: 1, 4439: 1, 4440: 1, 4441: 1, 4442: 1, 4443: 1, 4444: 1, 4445: 1, 4446: 1, 4447: 1, 4448: 1, 4449: 1, 4450: 1, 4451: 1, 4452: 1, 4453: 1, 4454: 1, 4455: 1, 4456: 1, 4457: 1, 4458: 1, 4459: 1, 4460: 1, 4461: 1, 4462: 1, 4463: 1, 4464: 1, 4465: 1, 4466: 1, 4467: 1, 4468: 1, 4469: 1, 4470: 1, 4471: 1, 4472: 1, 4473: 1, 4474: 1, 4475: 1, 4476: 1, 4477: 1, 4478: 1, 4479: 1, 4480: 1, 4481: 1, 4482: 1, 4483: 1, 4484: 1, 4485: 1, 4486: 1, 4487: 1, 4488: 1, 4489: 1, 4490: 1, 4491: 1, 4492: 1, 4493: 1, 4494: 1, 4495: 1, 4496: 1, 4497: 1, 4498: 1, 4499: 1, 4500: 1, 4501: 1, 4502: 1, 4503: 1, 4504: 1, 4505: 1, 4506: 1, 4507: 1, 4508: 1, 4509: 1, 4510: 1, 4511: 1, 4512: 1, 4513: 1, 4514: 1, 4515: 1, 4516: 1, 4517: 1, 4518: 1, 4519: 1, 4520: 1, 4521: 1, 4522: 1, 4523: 1, 4524: 1, 4525: 1, 4526: 1, 4527: 1, 4528: 1, 4529: 1, 4530: 1, 4531: 1, 4532: 1, 4533: 1, 4534: 1, 4535: 1, 4536: 1, 4537: 1, 4538: 1, 4539: 1, 4540: 1, 4541: 1, 4542: 1, 4543: 1, 4544: 1, 4545: 1, 4546: 1, 4547: 1, 4548: 1, 4549: 1, 4550: 1, 4551: 1, 4552: 1, 4553: 1, 4554: 1, 4555: 1, 4556: 1, 4557: 1, 4558: 1, 4559: 1, 4560: 1, 4561: 1, 4562: 1, 4563: 1, 4564: 1, 4565: 1, 4566: 1, 4567: 1, 4568: 1, 4569: 1, 4570: 1, 4571: 1, 4572: 1, 4573: 1, 4574: 1, 4575: 1, 4576: 1, 4577: 1, 4578: 1, 4579: 1, 4580: 1, 4581: 1, 4582: 1, 4583: 1, 4584: 1, 4585: 1, 4586: 1, 4587: 1, 4588: 1, 4589: 1, 4590: 1, 4591: 1, 4592: 1, 4593: 1, 4594: 1, 4595: 1, 4596: 1, 4597: 1, 4598: 1, 4599: 1, 4600: 1, 4601: 1, 4602: 1, 4603: 1, 4604: 1, 4605: 1, 4606: 1, 4607: 1, 4608: 1, 4609: 1, 4610: 1, 4611: 1, 4612: 1, 4613: 1, 4614: 1, 4615: 1, 4616: 1, 4617: 1, 4618: 1, 4619: 1, 4620: 1, 4621: 1, 4622: 1, 4623: 1, 4624: 1, 4625: 1, 4626: 1, 4627: 1, 4628: 1, 4629: 1, 4630: 1, 4631: 1, 4632: 1, 4633: 1, 4634: 1, 4635: 1, 4636: 1, 4637: 1, 4638: 1, 4639: 1, 4640: 1, 4641: 1, 4642: 1, 4643: 1, 4644: 1, 4645: 1, 4646: 1, 4647: 1, 4648: 1, 4649: 1, 4650: 1, 4651: 1, 4652: 1, 4653: 1, 4654: 1, 4655: 1, 4656: 1, 4657: 1, 4658: 1, 4659: 1, 4660: 1, 4661: 1, 4662: 1, 4663: 1, 4664: 1, 4665: 1, 4666: 1, 4667: 1, 4668: 1, 4669: 1, 4670: 1, 4671: 1, 4672: 1, 4673: 1, 4674: 1, 4675: 1, 4676: 1, 4677: 1, 4678: 1, 4679: 1, 4680: 1, 4681: 1, 4682: 1, 4683: 1, 4684: 1, 4685: 1, 4686: 1, 4687: 1, 4688: 1, 4689: 1, 4690: 1, 4691: 1, 4692: 1, 4693: 1, 4694: 1, 4695: 1, 4696: 1, 4697: 1, 4698: 1, 4699: 1, 4700: 1, 4701: 1, 4702: 1, 4703: 1, 4704: 1, 4705: 1, 4706: 1, 4707: 1, 4708: 1, 4709: 1, 4710: 1, 4711: 1, 4712: 1, 4713: 1, 4714: 1, 4715: 1, 4716: 1, 4717: 1, 4718: 1, 4719: 1, 4720: 1, 4721: 1, 4722: 1, 4723: 1, 4724: 1, 4725: 1, 4726: 1, 4727: 1, 4728: 1, 4729: 1, 4730: 1, 4731: 1, 4732: 1, 4733: 1, 4734: 1, 4735: 1, 4736: 1, 4737: 1, 4738: 1, 4739: 1, 4740: 1, 4741: 1, 4742: 1, 4743: 1, 4744: 1, 4745: 1, 4746: 1, 4747: 1, 4748: 1, 4749: 1, 4750: 1, 4751: 1, 4752: 1, 4753: 1, 4754: 1, 4755: 1, 4756: 1, 4757: 1, 4758: 1, 4759: 1, 4760: 1, 4761: 1, 4762: 1, 4763: 1, 4764: 1, 4765: 1, 4766: 1, 4767: 1, 4768: 1, 4769: 1, 4770: 1, 4771: 1, 4772: 1, 4773: 1, 4774: 1, 4775: 1, 4776: 1, 4777: 1, 4778: 1, 4779: 1, 4780: 1, 4781: 1, 4782: 1, 4783: 1, 4784: 1, 4785: 1, 4786: 1, 4787: 1, 4788: 1, 4789: 1, 4790: 1, 4791: 1, 4792: 1, 4793: 1, 4794: 1, 4795: 1, 4796: 1, 4797: 1, 4798: 1, 4799: 1, 4800: 1, 4801: 1, 4802: 1, 4803: 1, 4804: 1, 4805: 1, 4806: 1, 4807: 1, 4808: 1, 4809: 1, 4810: 1, 4811: 1, 4812: 1, 4813: 1, 4814: 1, 4815: 1, 4816: 1, 4817: 1, 4818: 1, 4819: 1, 4820: 1, 4821: 1, 4822: 1, 4823: 1, 4824: 1, 4825: 1, 4826: 1, 4827: 1, 4828: 1, 4829: 1, 4830: 1, 4831: 1, 4832: 1, 4833: 1, 4834: 1, 4835: 1, 4836: 1, 4837: 1, 4838: 1, 4839: 1, 4840: 1, 4841: 1, 4842: 1, 4843: 1, 4844: 1, 4845: 1, 4846: 1, 4847: 1, 4848: 1, 4849: 1, 4850: 1, 4851: 1, 4852: 1, 4853: 1, 4854: 1, 4855: 1, 4856: 1, 4857: 1, 4858: 1, 4859: 1, 4860: 1, 4861: 1, 4862: 1, 4863: 1, 4864: 1, 4865: 1, 4866: 1, 4867: 1, 4868: 1, 4869: 1, 4870: 1, 4871: 1, 4872: 1, 4873: 1, 4874: 1, 4875: 1, 4876: 1, 4877: 1, 4878: 1, 4879: 1, 4880: 1, 4881: 1, 4882: 1, 4883: 1, 4884: 1, 4885: 1, 4886: 1, 4887: 1, 4888: 1, 4889: 1, 4890: 1, 4891: 1, 4892: 1, 4893: 1, 4894: 1, 4895: 1, 4896: 1, 4897: 1, 4898: 1, 4899: 1, 4900: 1, 4901: 1, 4902: 1, 4903: 1, 4904: 1, 4905: 1, 4906: 1, 4907: 1, 4908: 1, 4909: 1, 4910: 1, 4911: 1, 4912: 1, 4913: 1, 4914: 1, 4915: 1, 4916: 1, 4917: 1, 4918: 1, 4919: 1, 4920: 1, 4921: 1, 4922: 1, 4923: 1, 4924: 1, 4925: 1, 4926: 1, 4927: 1, 4928: 1, 4929: 1, 4930: 1, 4931: 1, 4932: 1, 4933: 1, 4934: 1, 4935: 1, 4936: 1, 4937: 1, 4938: 1, 4939: 1, 4940: 1, 4941: 1, 4942: 1, 4943: 1, 4944: 1, 4945: 1, 4946: 1, 4947: 1, 4948: 1, 4949: 1, 4950: 1, 4951: 1, 4952: 1, 4953: 1, 4954: 1, 4955: 1, 4956: 1, 4957: 1, 4958: 1, 4959: 1, 4960: 1, 4961: 1, 4962: 1, 4963: 1, 4964: 1, 4965: 1, 4966: 1, 4967: 1, 4968: 1, 4969: 1, 4970: 1, 4971: 1, 4972: 1, 4973: 1, 4974: 1, 4975: 1, 4976: 1, 4977: 1, 4978: 1, 4979: 1, 4980: 1, 4981: 1, 4982: 1, 4983: 1, 4984: 1, 4985: 1, 4986: 1, 4987: 1, 4988: 1, 4989: 1, 4990: 1, 4991: 1, 4992: 1, 4993: 1, 4994: 1, 4995: 1, 4996: 1, 4997: 1, 4998: 1, 4999: 1, 5000: 1, 5001: 1, 5002: 1, 5003: 1, 5004: 1, 5005: 1, 5006: 1, 5007: 1, 5008: 1, 5009: 1, 5010: 1, 5011: 1, 5012: 1, 5013: 1, 5014: 1, 5015: 1, 5016: 1, 5017: 1, 5018: 1, 5019: 1, 5020: 1, 5021: 1, 5022: 1, 5023: 1, 5024: 1, 5025: 1, 5026: 1, 5027: 1, 5028: 1, 5029: 1, 5030: 1, 5031: 1, 5032: 1, 5033: 1, 5034: 1, 5035: 1, 5036: 1, 5037: 1, 5038: 1, 5039: 1, 5040: 1, 5041: 1, 5042: 1, 5043: 1, 5044: 1, 5045: 1, 5046: 1, 5047: 1, 5048: 1, 5049: 1, 5050: 1, 5051: 1, 5052: 1, 5053: 1, 5054: 1, 5055: 1, 5056: 1, 5057: 1, 5058: 1, 5059: 1, 5060: 1, 5061: 1, 5062: 1, 5063: 1, 5064: 1, 5065: 1, 5066: 1, 5067: 1, 5068: 1, 5069: 1, 5070: 1, 5071: 1, 5072: 1, 5073: 1, 5074: 1, 5075: 1, 5076: 1, 5077: 1, 5078: 1, 5079: 1, 5080: 1, 5081: 1, 5082: 1, 5083: 1, 5084: 1, 5085: 1, 5086: 1, 5087: 1, 5088: 1, 5089: 1, 5090: 1, 5091: 1, 5092: 1, 5093: 1, 5094: 1, 5095: 1, 5096: 1, 5097: 1, 5098: 1, 5099: 1, 5100: 1, 5101: 1, 5102: 1, 5103: 1, 5104: 1, 5105: 1, 5106: 1, 5107: 1, 5108: 1, 5109: 1, 5110: 1, 5111: 1, 5112: 1, 5113: 1, 5114: 1, 5115: 1, 5116: 1, 5117: 1, 5118: 1, 5119: 1, 5120: 1, 5121: 1, 5122: 1, 5123: 1, 5124: 1, 5125: 1, 5126: 1, 5127: 1, 5128: 1, 5129: 1, 5130: 1, 5131: 1, 5132: 1, 5133: 1, 5134: 1, 5135: 1, 5136: 1, 5137: 1, 5138: 1, 5139: 1, 5140: 1, 5141: 1, 5142: 1, 5143: 1, 5144: 1, 5145: 1, 5146: 1, 5147: 1, 5148: 1, 5149: 1, 5150: 1, 5151: 1, 5152: 1, 5153: 1, 5154: 1, 5155: 1, 5156: 1, 5157: 1, 5158: 1, 5159: 1, 5160: 1, 5161: 1, 5162: 1, 5163: 1, 5164: 1, 5165: 1, 5166: 1, 5167: 1, 5168: 1, 5169: 1, 5170: 1, 5171: 1, 5172: 1, 5173: 1, 5174: 1, 5175: 1, 5176: 1, 5177: 1, 5178: 1, 5179: 1, 5180: 1, 5181: 1, 5182: 1, 5183: 1, 5184: 1, 5185: 1, 5186: 1, 5187: 1, 5188: 1, 5189: 1, 5190: 1, 5191: 1, 5192: 1, 5193: 1, 5194: 1, 5195: 1, 5196: 1, 5197: 1, 5198: 1, 5199: 1, 5200: 1, 5201: 1, 5202: 1, 5203: 1, 5204: 1, 5205: 1, 5206: 1, 5207: 1, 5208: 1, 5209: 1, 5210: 1, 5211: 1, 5212: 1, 5213: 1, 5214: 1, 5215: 1, 5216: 1, 5217: 1, 5218: 1, 5219: 1, 5220: 1, 5221: 1, 5222: 1, 5223: 1, 5224: 1, 5225: 1, 5226: 1, 5227: 1, 5228: 1, 5229: 1, 5230: 1, 5231: 1, 5232: 1, 5233: 1, 5234: 1, 5235: 1, 5236: 1, 5237: 1, 5238: 1, 5239: 1, 5240: 1, 5241: 1, 5242: 1, 5243: 1, 5244: 1, 5245: 1, 5246: 1, 5247: 1, 5248: 1, 5249: 1, 5250: 1, 5251: 1, 5252: 1, 5253: 1, 5254: 1, 5255: 1, 5256: 1, 5257: 1, 5258: 1, 5259: 1, 5260: 1, 5261: 1, 5262: 1, 5263: 1, 5264: 1, 5265: 1, 5266: 1, 5267: 1, 5268: 1, 5269: 1, 5270: 1, 5271: 1, 5272: 1, 5273: 1, 5274: 1, 5275: 1, 5276: 1, 5277: 1, 5278: 1, 5279: 1, 5280: 1, 5281: 1, 5282: 1, 5283: 1, 5284: 1, 5285: 1, 5286: 1, 5287: 1, 5288: 1, 5289: 1, 5290: 1, 5291: 1, 5292: 1, 5293: 1, 5294: 1, 5295: 1, 5296: 1, 5297: 1, 5298: 1, 5299: 1, 5300: 1, 5301: 1, 5302: 1, 5303: 1, 5304: 1, 5305: 1, 5306: 1, 5307: 1, 5308: 1, 5309: 1, 5310: 1, 5311: 1, 5312: 1, 5313: 1, 5314: 1, 5315: 1, 5316: 1, 5317: 1, 5318: 1, 5319: 1, 5320: 1, 5321: 1, 5322: 1, 5323: 1, 5324: 1, 5325: 1, 5326: 1, 5327: 1, 5328: 1, 5329: 1, 5330: 1, 5331: 1, 5332: 1, 5333: 1, 5334: 1, 5335: 1, 5336: 1, 5337: 1, 5338: 1, 5339: 1, 5340: 1, 5341: 1, 5342: 1, 5343: 1, 5344: 1, 5345: 1, 5346: 1, 5347: 1, 5348: 1, 5349: 1, 5350: 1, 5351: 1, 5352: 1, 5353: 1, 5354: 1, 5355: 1, 5356: 1, 5357: 1, 5358: 1, 5359: 1, 5360: 1, 5361: 1, 5362: 1, 5363: 1, 5364: 1, 5365: 1, 5366: 1, 5367: 1, 5368: 1, 5369: 1, 5370: 1, 5371: 1, 5372: 1, 5373: 1, 5374: 1, 5375: 1, 5376: 1, 5377: 1, 5378: 1, 5379: 1, 5380: 1, 5381: 1, 5382: 1, 5383: 1, 5384: 1, 5385: 1, 5386: 1, 5387: 1, 5388: 1, 5389: 1, 5390: 1, 5391: 1, 5392: 1, 5393: 1, 5394: 1, 5395: 1, 5396: 1, 5397: 1, 5398: 1, 5399: 1, 5400: 1, 5401: 1, 5402: 1, 5403: 1, 5404: 1, 5405: 1, 5406: 1, 5407: 1, 5408: 1, 5409: 1, 5410: 1, 5411: 1, 5412: 1, 5413: 1, 5414: 1, 5415: 1, 5416: 1, 5417: 1, 5418: 1, 5419: 1, 5420: 1, 5421: 1, 5422: 1, 5423: 1, 5424: 1, 5425: 1, 5426: 1, 5427: 1, 5428: 1, 5429: 1, 5430: 1, 5431: 1, 5432: 1, 5433: 1, 5434: 1, 5435: 1, 5436: 1, 5437: 1, 5438: 1, 5439: 1, 5440: 1, 5441: 1, 5442: 1, 5443: 1, 5444: 1, 5445: 1, 5446: 1, 5447: 1, 5448: 1, 5449: 1, 5450: 1, 5451: 1, 5452: 1, 5453: 1, 5454: 1, 5455: 1, 5456: 1, 5457: 1, 5458: 1, 5459: 1, 5460: 1, 5461: 1, 5462: 1, 5463: 1, 5464: 1, 5465: 1, 5466: 1, 5467: 1, 5468: 1, 5469: 1, 5470: 1, 5471: 1, 5472: 1, 5473: 1, 5474: 1, 5475: 1, 5476: 1, 5477: 1, 5478: 1, 5479: 1, 5480: 1, 5481: 1, 5482: 1, 5483: 1, 5484: 1, 5485: 1, 5486: 1, 5487: 1, 5488: 1, 5489: 1, 5490: 1, 5491: 1, 5492: 1, 5493: 1, 5494: 1, 5495: 1, 5496: 1, 5497: 1, 5498: 1, 5499: 1, 5500: 1, 5501: 1, 5502: 1, 5503: 1, 5504: 1, 5505: 1, 5506: 1, 5507: 1, 5508: 1, 5509: 1, 5510: 1, 5511: 1, 5512: 1, 5513: 1, 5514: 1, 5515: 1, 5516: 1, 5517: 1, 5518: 1, 5519: 1, 5520: 1, 5521: 1, 5522: 1, 5523: 1, 5524: 1, 5525: 1, 5526: 1, 5527: 1, 5528: 1, 5529: 1, 5530: 1, 5531: 1, 5532: 1, 5533: 1, 5534: 1, 5535: 1, 5536: 1, 5537: 1, 5538: 1, 5539: 1, 5540: 1, 5541: 1, 5542: 1, 5543: 1, 5544: 1, 5545: 1, 5546: 1, 5547: 1, 5548: 1, 5549: 1, 5550: 1, 5551: 1, 5552: 1, 5553: 1, 5554: 1, 5555: 1, 5556: 1, 5557: 1, 5558: 1, 5559: 1, 5560: 1, 5561: 1, 5562: 1, 5563: 1, 5564: 1, 5565: 1, 5566: 1, 5567: 1, 5568: 1, 5569: 1, 5570: 1, 5571: 1, 5572: 1, 5573: 1, 5574: 1, 5575: 1, 5576: 1, 5577: 1, 5578: 1, 5579: 1, 5580: 1, 5581: 1, 5582: 1, 5583: 1, 5584: 1, 5585: 1, 5586: 1, 5587: 1, 5588: 1, 5589: 1, 5590: 1, 5591: 1, 5592: 1, 5593: 1, 5594: 1, 5595: 1, 5596: 1, 5597: 1, 5598: 1, 5599: 1, 5600: 1, 5601: 1, 5602: 1, 5603: 1, 5604: 1, 5605: 1, 5606: 1, 5607: 1, 5608: 1, 5609: 1, 5610: 1, 5611: 1, 5612: 1, 5613: 1, 5614: 1, 5615: 1, 5616: 1, 5617: 1, 5618: 1, 5619: 1, 5620: 1, 5621: 1, 5622: 1, 5623: 1, 5624: 1, 5625: 1, 5626: 1, 5627: 1, 5628: 1, 5629: 1, 5630: 1, 5631: 1, 5632: 1, 5633: 1, 5634: 1, 5635: 1, 5636: 1, 5637: 1, 5638: 1, 5639: 1, 5640: 1, 5641: 1, 5642: 1, 5643: 1, 5644: 1, 5645: 1, 5646: 1, 5647: 1, 5648: 1, 5649: 1, 5650: 1, 5651: 1, 5652: 1, 5653: 1, 5654: 1, 5655: 1, 5656: 1, 5657: 1, 5658: 1, 5659: 1, 5660: 1, 5661: 1, 5662: 1, 5663: 1, 5664: 1, 5665: 1, 5666: 1, 5667: 1, 5668: 1, 5669: 1, 5670: 1, 5671: 1, 5672: 1, 5673: 1, 5674: 1, 5675: 1, 5676: 1, 5677: 1, 5678: 1, 5679: 1, 5680: 1, 5681: 1, 5682: 1, 5683: 1, 5684: 1, 5685: 1, 5686: 1, 5687: 1, 5688: 1, 5689: 1, 5690: 1, 5691: 1, 5692: 1, 5693: 1, 5694: 1, 5695: 1, 5696: 1, 5697: 1, 5698: 1, 5699: 1, 5700: 1, 5701: 1, 5702: 1, 5703: 1, 5704: 1, 5705: 1, 5706: 1, 5707: 1, 5708: 1, 5709: 1, 5710: 1, 5711: 1, 5712: 1, 5713: 1, 5714: 1, 5715: 1, 5716: 1, 5717: 1, 5718: 1, 5719: 1, 5720: 1, 5721: 1, 5722: 1, 5723: 1, 5724: 1, 5725: 1, 5726: 1, 5727: 1, 5728: 1, 5729: 1, 5730: 1, 5731: 1, 5732: 1, 5733: 1, 5734: 1, 5735: 1, 5736: 1, 5737: 1, 5738: 1, 5739: 1, 5740: 1, 5741: 1, 5742: 1, 5743: 1, 5744: 1, 5745: 1, 5746: 1, 5747: 1, 5748: 1, 5749: 1, 5750: 1, 5751: 1, 5752: 1, 5753: 1, 5754: 1, 5755: 1, 5756: 1, 5757: 1, 5758: 1, 5759: 1, 5760: 1, 5761: 1, 5762: 1, 5763: 1, 5764: 1, 5765: 1, 5766: 1, 5767: 1, 5768: 1, 5769: 1, 5770: 1, 5771: 1, 5772: 1, 5773: 1, 5774: 1, 5775: 1, 5776: 1, 5777: 1, 5778: 1, 5779: 1, 5780: 1, 5781: 1, 5782: 1, 5783: 1, 5784: 1, 5785: 1, 5786: 1, 5787: 1, 5788: 1, 5789: 1, 5790: 1, 5791: 1, 5792: 1, 5793: 1, 5794: 1, 5795: 1, 5796: 1, 5797: 1, 5798: 1, 5799: 1, 5800: 1, 5801: 1, 5802: 1, 5803: 1, 5804: 1, 5805: 1, 5806: 1, 5807: 1, 5808: 1, 5809: 1, 5810: 1, 5811: 1, 5812: 1, 5813: 1, 5814: 1, 5815: 1, 5816: 1, 5817: 1, 5818: 1, 5819: 1, 5820: 1, 5821: 1, 5822: 1, 5823: 1, 5824: 1, 5825: 1, 5826: 1, 5827: 1, 5828: 1, 5829: 1, 5830: 1, 5831: 1, 5832: 1, 5833: 1, 5834: 1, 5835: 1, 5836: 1, 5837: 1, 5838: 1, 5839: 1, 5840: 1, 5841: 1, 5842: 1, 5843: 1, 5844: 1, 5845: 1, 5846: 1, 5847: 1, 5848: 1, 5849: 1, 5850: 1, 5851: 1, 5852: 1, 5853: 1, 5854: 1, 5855: 1, 5856: 1, 5857: 1, 5858: 1, 5859: 1, 5860: 1, 5861: 1, 5862: 1, 5863: 1, 5864: 1, 5865: 1, 5866: 1, 5867: 1, 5868: 1, 5869: 1, 5870: 1, 5871: 1, 5872: 1, 5873: 1, 5874: 1, 5875: 1, 5876: 1, 5877: 1, 5878: 1, 5879: 1, 5880: 1, 5881: 1, 5882: 1, 5883: 1, 5884: 1, 5885: 1, 5886: 1, 5887: 1, 5888: 1, 5889: 1, 5890: 1, 5891: 1, 5892: 1, 5893: 1, 5894: 1, 5895: 1, 5896: 1, 5897: 1, 5898: 1, 5899: 1, 5900: 1, 5901: 1, 5902: 1, 5903: 1, 5904: 1, 5905: 1, 5906: 1, 5907: 1, 5908: 1, 5909: 1, 5910: 1, 5911: 1, 5912: 1, 5913: 1, 5914: 1, 5915: 1, 5916: 1, 5917: 1, 5918: 1, 5919: 1, 5920: 1, 5921: 1, 5922: 1, 5923: 1, 5924: 1, 5925: 1, 5926: 1, 5927: 1, 5928: 1, 5929: 1, 5930: 1, 5931: 1, 5932: 1, 5933: 1, 5934: 1, 5935: 1, 5936: 1, 5937: 1, 5938: 1, 5939: 1, 5940: 1, 5941: 1, 5942: 1, 5943: 1, 5944: 1, 5945: 1, 5946: 1, 5947: 1, 5948: 1, 5949: 1, 5950: 1, 5951: 1, 5952: 1, 5953: 1, 5954: 1, 5955: 1, 5956: 1, 5957: 1, 5958: 1, 5959: 1, 5960: 1, 5961: 1, 5962: 1, 5963: 1, 5964: 1, 5965: 1, 5966: 1, 5967: 1, 5968: 1, 5969: 1, 5970: 1, 5971: 1, 5972: 1, 5973: 1, 5974: 1, 5975: 1, 5976: 1, 5977: 1, 5978: 1, 5979: 1, 5980: 1, 5981: 1, 5982: 1, 5983: 1, 5984: 1, 5985: 1, 5986: 1, 5987: 1, 5988: 1, 5989: 1, 5990: 1, 5991: 1, 5992: 1, 5993: 1, 5994: 1, 5995: 1, 5996: 1, 5997: 1, 5998: 1, 5999: 1, 6000: 1, 6001: 1, 6002: 1, 6003: 1, 6004: 1, 6005: 1, 6006: 1, 6007: 1, 6008: 1, 6009: 1, 6010: 1, 6011: 1, 6012: 1, 6013: 1, 6014: 1, 6015: 1, 6016: 1, 6017: 1, 6018: 1, 6019: 1, 6020: 1, 6021: 1, 6022: 1, 6023: 1, 6024: 1, 6025: 1, 6026: 1, 6027: 1, 6028: 1, 6029: 1, 6030: 1, 6031: 1, 6032: 1, 6033: 1, 6034: 1, 6035: 1, 6036: 1, 6037: 1, 6038: 1, 6039: 1, 6040: 1, 6041: 1, 6042: 1, 6043: 1, 6044: 1, 6045: 1, 6046: 1, 6047: 1, 6048: 1, 6049: 1, 6050: 1, 6051: 1, 6052: 1, 6053: 1, 6054: 1, 6055: 1, 6056: 1, 6057: 1, 6058: 1, 6059: 1, 6060: 1, 6061: 1, 6062: 1, 6063: 1, 6064: 1, 6065: 1, 6066: 1, 6067: 1, 6068: 1, 6069: 1, 6070: 1, 6071: 1, 6072: 1, 6073: 1, 6074: 1, 6075: 1, 6076: 1, 6077: 1, 6078: 1, 6079: 1, 6080: 1, 6081: 1, 6082: 1, 6083: 1, 6084: 1, 6085: 1, 6086: 1, 6087: 1, 6088: 1, 6089: 1, 6090: 1, 6091: 1, 6092: 1, 6093: 1, 6094: 1, 6095: 1, 6096: 1, 6097: 1, 6098: 1, 6099: 1, 6100: 1, 6101: 1, 6102: 1, 6103: 1, 6104: 1, 6105: 1, 6106: 1, 6107: 1, 6108: 1, 6109: 1, 6110: 1, 6111: 1, 6112: 1, 6113: 1, 6114: 1, 6115: 1, 6116: 1, 6117: 1, 6118: 1, 6119: 1, 6120: 1, 6121: 1, 6122: 1, 6123: 1, 6124: 1, 6125: 1, 6126: 1, 6127: 1, 6128: 1, 6129: 1, 6130: 1, 6131: 1, 6132: 1, 6133: 1, 6134: 1, 6135: 1, 6136: 1, 6137: 1, 6138: 1, 6139: 1, 6140: 1, 6141: 1, 6142: 1, 6143: 1, 6144: 1, 6145: 1, 6146: 1, 6147: 1, 6148: 1, 6149: 1, 6150: 1, 6151: 1, 6152: 1, 6153: 1, 6154: 1, 6155: 1, 6156: 1, 6157: 1, 6158: 1, 6159: 1, 6160: 1, 6161: 1, 6162: 1, 6163: 1, 6164: 1, 6165: 1, 6166: 1, 6167: 1, 6168: 1, 6169: 1, 6170: 1, 6171: 1, 6172: 1, 6173: 1, 6174: 1, 6175: 1, 6176: 1, 6177: 1, 6178: 1, 6179: 1, 6180: 1, 6181: 1, 6182: 1, 6183: 1, 6184: 1, 6185: 1, 6186: 1, 6187: 1, 6188: 1, 6189: 1, 6190: 1, 6191: 1, 6192: 1, 6193: 1, 6194: 1, 6195: 1, 6196: 1, 6197: 1, 6198: 1, 6199: 1, 6200: 1, 6201: 1, 6202: 1, 6203: 1, 6204: 1, 6205: 1, 6206: 1, 6207: 1, 6208: 1, 6209: 1, 6210: 1, 6211: 1, 6212: 1, 6213: 1, 6214: 1, 6215: 1, 6216: 1, 6217: 1, 6218: 1, 6219: 1, 6220: 1, 6221: 1, 6222: 1, 6223: 1, 6224: 1, 6225: 1, 6226: 1, 6227: 1, 6228: 1, 6229: 1, 6230: 1, 6231: 1, 6232: 1, 6233: 1, 6234: 1, 6235: 1, 6236: 1, 6237: 1, 6238: 1, 6239: 1, 6240: 1, 6241: 1, 6242: 1, 6243: 1, 6244: 1, 6245: 1, 6246: 1, 6247: 1, 6248: 1, 6249: 1, 6250: 1, 6251: 1, 6252: 1, 6253: 1, 6254: 1, 6255: 1, 6256: 1, 6257: 1, 6258: 1, 6259: 1, 6260: 1, 6261: 1, 6262: 1, 6263: 1, 6264: 1, 6265: 1, 6266: 1, 6267: 1, 6268: 1, 6269: 1, 6270: 1, 6271: 1, 6272: 1, 6273: 1, 6274: 1, 6275: 1, 6276: 1, 6277: 1, 6278: 1, 6279: 1, 6280: 1, 6281: 1, 6282: 1, 6283: 1, 6284: 1, 6285: 1, 6286: 1, 6287: 1, 6288: 1, 6289: 1, 6290: 1, 6291: 1, 6292: 1, 6293: 1, 6294: 1, 6295: 1, 6296: 1, 6297: 1, 6298: 1, 6299: 1, 6300: 1, 6301: 1, 6302: 1, 6303: 1, 6304: 1, 6305: 1, 6306: 1, 6307: 1, 6308: 1, 6309: 1, 6310: 1, 6311: 1, 6312: 1, 6313: 1, 6314: 1, 6315: 1, 6316: 1, 6317: 1, 6318: 1, 6319: 1, 6320: 1, 6321: 1, 6322: 1, 6323: 1, 6324: 1, 6325: 1, 6326: 1, 6327: 1, 6328: 1, 6329: 1, 6330: 1, 6331: 1, 6332: 1, 6333: 1, 6334: 1, 6335: 1, 6336: 1, 6337: 1, 6338: 1, 6339: 1, 6340: 1, 6341: 1, 6342: 1, 6343: 1, 6344: 1, 6345: 1, 6346: 1, 6347: 1, 6348: 1, 6349: 1, 6350: 1, 6351: 1, 6352: 1, 6353: 1, 6354: 1, 6355: 1, 6356: 1, 6357: 1, 6358: 1, 6359: 1, 6360: 1, 6361: 1, 6362: 1, 6363: 1, 6364: 1, 6365: 1, 6366: 1, 6367: 1, 6368: 1, 6369: 1, 6370: 1, 6371: 1, 6372: 1, 6373: 1, 6374: 1, 6375: 1, 6376: 1, 6377: 1, 6378: 1, 6379: 1, 6380: 1, 6381: 1, 6382: 1, 6383: 1, 6384: 1, 6385: 1, 6386: 1, 6387: 1, 6388: 1, 6389: 1, 6390: 1, 6391: 1, 6392: 1, 6393: 1, 6394: 1, 6395: 1, 6396: 1, 6397: 1, 6398: 1, 6399: 1, 6400: 1, 6401: 1, 6402: 1, 6403: 1, 6404: 1, 6405: 1, 6406: 1, 6407: 1, 6408: 1, 6409: 1, 6410: 1, 6411: 1, 6412: 1, 6413: 1, 6414: 1, 6415: 1, 6416: 1, 6417: 1, 6418: 1, 6419: 1, 6420: 1, 6421: 1, 6422: 1, 6423: 1, 6424: 1, 6425: 1, 6426: 1, 6427: 1, 6428: 1, 6429: 1, 6430: 1, 6431: 1, 6432: 1, 6433: 1, 6434: 1, 6435: 1, 6436: 1, 6437: 1, 6438: 1, 6439: 1, 6440: 1, 6441: 1, 6442: 1, 6443: 1, 6444: 1, 6445: 1, 6446: 1, 6447: 1, 6448: 1, 6449: 1, 6450: 1, 6451: 1, 6452: 1, 6453: 1, 6454: 1, 6455: 1, 6456: 1, 6457: 1, 6458: 1, 6459: 1, 6460: 1, 6461: 1, 6462: 1, 6463: 1, 6464: 1, 6465: 1, 6466: 1, 6467: 1, 6468: 1, 6469: 1, 6470: 1, 6471: 1, 6472: 1, 6473: 1, 6474: 1, 6475: 1, 6476: 1, 6477: 1, 6478: 1, 6479: 1, 6480: 1, 6481: 1, 6482: 1, 6483: 1, 6484: 1, 6485: 1, 6486: 1, 6487: 1, 6488: 1, 6489: 1, 6490: 1, 6491: 1, 6492: 1, 6493: 1, 6494: 1, 6495: 1, 6496: 1, 6497: 1, 6498: 1, 6499: 1, 6500: 1, 6501: 1, 6502: 1, 6503: 1, 6504: 1, 6505: 1, 6506: 1, 6507: 1, 6508: 1, 6509: 1, 6510: 1, 6511: 1, 6512: 1, 6513: 1, 6514: 1, 6515: 1, 6516: 1, 6517: 1, 6518: 1, 6519: 1, 6520: 1, 6521: 1, 6522: 1, 6523: 1, 6524: 1, 6525: 1, 6526: 1, 6527: 1, 6528: 1, 6529: 1, 6530: 1, 6531: 1, 6532: 1, 6533: 1, 6534: 1, 6535: 1, 6536: 1, 6537: 1, 6538: 1, 6539: 1, 6540: 1, 6541: 1, 6542: 1, 6543: 1, 6544: 1, 6545: 1, 6546: 1, 6547: 1, 6548: 1, 6549: 1, 6550: 1, 6551: 1, 6552: 1, 6553: 1, 6554: 1, 6555: 1, 6556: 1, 6557: 1, 6558: 1, 6559: 1, 6560: 1, 6561: 1, 6562: 1, 6563: 1, 6564: 1, 6565: 1, 6566: 1, 6567: 1, 6568: 1, 6569: 1, 6570: 1, 6571: 1, 6572: 1, 6573: 1, 6574: 1, 6575: 1, 6576: 1, 6577: 1, 6578: 1, 6579: 1, 6580: 1, 6581: 1, 6582: 1, 6583: 1, 6584: 1, 6585: 1, 6586: 1, 6587: 1, 6588: 1, 6589: 1, 6590: 1, 6591: 1, 6592: 1, 6593: 1, 6594: 1, 6595: 1, 6596: 1, 6597: 1, 6598: 1, 6599: 1, 6600: 1, 6601: 1, 6602: 1, 6603: 1, 6604: 1, 6605: 1, 6606: 1, 6607: 1, 6608: 1, 6609: 1, 6610: 1, 6611: 1, 6612: 1, 6613: 1, 6614: 1, 6615: 1, 6616: 1, 6617: 1, 6618: 1, 6619: 1, 6620: 1, 6621: 1, 6622: 1, 6623: 1, 6624: 1, 6625: 1, 6626: 1, 6627: 1, 6628: 1, 6629: 1, 6630: 1, 6631: 1, 6632: 1, 6633: 1, 6634: 1, 6635: 1, 6636: 1, 6637: 1, 6638: 1, 6639: 1, 6640: 1, 6641: 1, 6642: 1, 6643: 1, 6644: 1, 6645: 1, 6646: 1, 6647: 1, 6648: 1, 6649: 1, 6650: 1, 6651: 1, 6652: 1, 6653: 1, 6654: 1, 6655: 1, 6656: 1, 6657: 1, 6658: 1, 6659: 1, 6660: 1, 6661: 1, 6662: 1, 6663: 1, 6664: 1, 6665: 1, 6666: 1, 6667: 1, 6668: 1, 6669: 1, 6670: 1, 6671: 1, 6672: 1, 6673: 1, 6674: 1, 6675: 1, 6676: 1, 6677: 1, 6678: 1, 6679: 1, 6680: 1, 6681: 1, 6682: 1, 6683: 1, 6684: 1, 6685: 1, 6686: 1, 6687: 1, 6688: 1, 6689: 1, 6690: 1, 6691: 1, 6692: 1, 6693: 1, 6694: 1, 6695: 1, 6696: 1, 6697: 1, 6698: 1, 6699: 1, 6700: 1, 6701: 1, 6702: 1, 6703: 1, 6704: 1, 6705: 1, 6706: 1, 6707: 1, 6708: 1, 6709: 1, 6710: 1, 6711: 1, 6712: 1, 6713: 1, 6714: 1, 6715: 1, 6716: 1, 6717: 1, 6718: 1, 6719: 1, 6720: 1, 6721: 1, 6722: 1, 6723: 1, 6724: 1, 6725: 1, 6726: 1, 6727: 1, 6728: 1, 6729: 1, 6730: 1, 6731: 1, 6732: 1, 6733: 1, 6734: 1, 6735: 1, 6736: 1, 6737: 1, 6738: 1, 6739: 1, 6740: 1, 6741: 1, 6742: 1, 6743: 1, 6744: 1, 6745: 1, 6746: 1, 6747: 1, 6748: 1, 6749: 1, 6750: 1, 6751: 1, 6752: 1, 6753: 1, 6754: 1, 6755: 1, 6756: 1, 6757: 1, 6758: 1, 6759: 1, 6760: 1, 6761: 1, 6762: 1, 6763: 1, 6764: 1, 6765: 1, 6766: 1, 6767: 1, 6768: 1, 6769: 1, 6770: 1, 6771: 1, 6772: 1, 6773: 1, 6774: 1, 6775: 1, 6776: 1, 6777: 1, 6778: 1, 6779: 1, 6780: 1, 6781: 1, 6782: 1, 6783: 1, 6784: 1, 6785: 1, 6786: 1, 6787: 1, 6788: 1, 6789: 1, 6790: 1, 6791: 1, 6792: 1, 6793: 1, 6794: 1, 6795: 1, 6796: 1, 6797: 1, 6798: 1, 6799: 1, 6800: 1, 6801: 1, 6802: 1, 6803: 1, 6804: 1, 6805: 1, 6806: 1, 6807: 1, 6808: 1, 6809: 1, 6810: 1, 6811: 1, 6812: 1, 6813: 1, 6814: 1, 6815: 1, 6816: 1, 6817: 1, 6818: 1, 6819: 1, 6820: 1, 6821: 1, 6822: 1, 6823: 1, 6824: 1, 6825: 1, 6826: 1, 6827: 1, 6828: 1, 6829: 1, 6830: 1, 6831: 1, 6832: 1, 6833: 1, 6834: 1, 6835: 1, 6836: 1, 6837: 1, 6838: 1, 6839: 1, 6840: 1, 6841: 1, 6842: 1, 6843: 1, 6844: 1, 6845: 1, 6846: 1, 6847: 1, 6848: 1, 6849: 1, 6850: 1, 6851: 1, 6852: 1, 6853: 1, 6854: 1, 6855: 1, 6856: 1, 6857: 1, 6858: 1, 6859: 1, 6860: 1, 6861: 1, 6862: 1, 6863: 1, 6864: 1, 6865: 1, 6866: 1, 6867: 1, 6868: 1, 6869: 1, 6870: 1, 6871: 1, 6872: 1, 6873: 1, 6874: 1, 6875: 1, 6876: 1, 6877: 1, 6878: 1, 6879: 1, 6880: 1, 6881: 1, 6882: 1, 6883: 1, 6884: 1, 6885: 1, 6886: 1, 6887: 1, 6888: 1, 6889: 1, 6890: 1, 6891: 1, 6892: 1, 6893: 1, 6894: 1, 6895: 1, 6896: 1, 6897: 1, 6898: 1, 6899: 1, 6900: 1, 6901: 1, 6902: 1, 6903: 1, 6904: 1, 6905: 1, 6906: 1, 6907: 1, 6908: 1, 6909: 1, 6910: 1, 6911: 1, 6912: 1, 6913: 1, 6914: 1, 6915: 1, 6916: 1, 6917: 1, 6918: 1, 6919: 1, 6920: 1, 6921: 1, 6922: 1, 6923: 1, 6924: 1, 6925: 1, 6926: 1, 6927: 1, 6928: 1, 6929: 1, 6930: 1, 6931: 1, 6932: 1, 6933: 1, 6934: 1, 6935: 1, 6936: 1, 6937: 1, 6938: 1, 6939: 1, 6940: 1, 6941: 1, 6942: 1, 6943: 1, 6944: 1, 6945: 1, 6946: 1, 6947: 1, 6948: 1, 6949: 1, 6950: 1, 6951: 1, 6952: 1, 6953: 1, 6954: 1, 6955: 1, 6956: 1, 6957: 1, 6958: 1, 6959: 1, 6960: 1, 6961: 1, 6962: 1, 6963: 1, 6964: 1, 6965: 1, 6966: 1, 6967: 1, 6968: 1, 6969: 1, 6970: 1, 6971: 1, 6972: 1, 6973: 1, 6974: 1, 6975: 1, 6976: 1, 6977: 1, 6978: 1, 6979: 1, 6980: 1, 6981: 1, 6982: 1, 6983: 1, 6984: 1, 6985: 1, 6986: 1, 6987: 1, 6988: 1, 6989: 1, 6990: 1, 6991: 1, 6992: 1, 6993: 1, 6994: 1, 6995: 1, 6996: 1, 6997: 1, 6998: 1, 6999: 1, 7000: 1, 7001: 1, 7002: 1, 7003: 1, 7004: 1, 7005: 1, 7006: 1, 7007: 1, 7008: 1, 7009: 1, 7010: 1, 7011: 1, 7012: 1, 7013: 1, 7014: 1, 7015: 1, 7016: 1, 7017: 1, 7018: 1, 7019: 1, 7020: 1, 7021: 1, 7022: 1, 7023: 1, 7024: 1, 7025: 1, 7026: 1, 7027: 1, 7028: 1, 7029: 1, 7030: 1, 7031: 1, 7032: 1, 7033: 1, 7034: 1, 7035: 1, 7036: 1, 7037: 1, 7038: 1, 7039: 1, 7040: 1, 7041: 1, 7042: 1, 7043: 1, 7044: 1, 7045: 1, 7046: 1, 7047: 1, 7048: 1, 7049: 1, 7050: 1, 7051: 1, 7052: 1, 7053: 1, 7054: 1, 7055: 1, 7056: 1, 7057: 1, 7058: 1, 7059: 1, 7060: 1, 7061: 1, 7062: 1, 7063: 1, 7064: 1, 7065: 1, 7066: 1, 7067: 1, 7068: 1, 7069: 1, 7070: 1, 7071: 1, 7072: 1, 7073: 1, 7074: 1, 7075: 1, 7076: 1, 7077: 1, 7078: 1, 7079: 1, 7080: 1, 7081: 1, 7082: 1, 7083: 1, 7084: 1, 7085: 1, 7086: 1, 7087: 1, 7088: 1, 7089: 1, 7090: 1, 7091: 1, 7092: 1, 7093: 1, 7094: 1, 7095: 1, 7096: 1, 7097: 1, 7098: 1, 7099: 1, 7100: 1, 7101: 1, 7102: 1, 7103: 1, 7104: 1, 7105: 1, 7106: 1, 7107: 1, 7108: 1, 7109: 1, 7110: 1, 7111: 1, 7112: 1, 7113: 1, 7114: 1, 7115: 1, 7116: 1, 7117: 1, 7118: 1, 7119: 1, 7120: 1, 7121: 1, 7122: 1, 7123: 1, 7124: 1, 7125: 1, 7126: 1, 7127: 1, 7128: 1, 7129: 1, 7130: 1, 7131: 1, 7132: 1, 7133: 1, 7134: 1, 7135: 1, 7136: 1, 7137: 1, 7138: 1, 7139: 1, 7140: 1, 7141: 1, 7142: 1, 7143: 1, 7144: 1, 7145: 1, 7146: 1, 7147: 1, 7148: 1, 7149: 1, 7150: 1, 7151: 1, 7152: 1, 7153: 1, 7154: 1, 7155: 1, 7156: 1, 7157: 1, 7158: 1, 7159: 1, 7160: 1, 7161: 1, 7162: 1, 7163: 1, 7164: 1, 7165: 1, 7166: 1, 7167: 1, 7168: 1, 7169: 1, 7170: 1, 7171: 1, 7172: 1, 7173: 1, 7174: 1, 7175: 1, 7176: 1, 7177: 1, 7178: 1, 7179: 1, 7180: 1, 7181: 1, 7182: 1, 7183: 1, 7184: 1, 7185: 1, 7186: 1, 7187: 1, 7188: 1, 7189: 1, 7190: 1, 7191: 1, 7192: 1, 7193: 1, 7194: 1, 7195: 1, 7196: 1, 7197: 1, 7198: 1, 7199: 1, 7200: 1, 7201: 1, 7202: 1, 7203: 1, 7204: 1, 7205: 1, 7206: 1, 7207: 1, 7208: 1, 7209: 1, 7210: 1, 7211: 1, 7212: 1, 7213: 1, 7214: 1, 7215: 1, 7216: 1, 7217: 1, 7218: 1, 7219: 1, 7220: 1, 7221: 1, 7222: 1, 7223: 1, 7224: 1, 7225: 1, 7226: 1, 7227: 1, 7228: 1, 7229: 1, 7230: 1, 7231: 1, 7232: 1, 7233: 1, 7234: 1, 7235: 1, 7236: 1, 7237: 1, 7238: 1, 7239: 1, 7240: 1, 7241: 1, 7242: 1, 7243: 1, 7244: 1, 7245: 1, 7246: 1, 7247: 1, 7248: 1, 7249: 1, 7250: 1, 7251: 1, 7252: 1, 7253: 1, 7254: 1, 7255: 1, 7256: 1, 7257: 1, 7258: 1, 7259: 1, 7260: 1, 7261: 1, 7262: 1, 7263: 1, 7264: 1, 7265: 1, 7266: 1, 7267: 1, 7268: 1, 7269: 1, 7270: 1, 7271: 1, 7272: 1, 7273: 1, 7274: 1, 7275: 1, 7276: 1, 7277: 1, 7278: 1, 7279: 1, 7280: 1, 7281: 1, 7282: 1, 7283: 1, 7284: 1, 7285: 1, 7286: 1, 7287: 1, 7288: 1, 7289: 1, 7290: 1, 7291: 1, 7292: 1, 7293: 1, 7294: 1, 7295: 1, 7296: 1, 7297: 1, 7298: 1, 7299: 1, 7300: 1, 7301: 1, 7302: 1, 7303: 1, 7304: 1, 7305: 1, 7306: 1, 7307: 1, 7308: 1, 7309: 1, 7310: 1, 7311: 1, 7312: 1, 7313: 1, 7314: 1, 7315: 1, 7316: 1, 7317: 1, 7318: 1, 7319: 1, 7320: 1, 7321: 1, 7322: 1, 7323: 1, 7324: 1, 7325: 1, 7326: 1, 7327: 1, 7328: 1, 7329: 1, 7330: 1, 7331: 1, 7332: 1, 7333: 1, 7334: 1, 7335: 1, 7336: 1, 7337: 1, 7338: 1, 7339: 1, 7340: 1, 7341: 1, 7342: 1, 7343: 1, 7344: 1, 7345: 1, 7346: 1, 7347: 1, 7348: 1, 7349: 1, 7350: 1, 7351: 1, 7352: 1, 7353: 1, 7354: 1, 7355: 1, 7356: 1, 7357: 1, 7358: 1, 7359: 1, 7360: 1, 7361: 1, 7362: 1, 7363: 1, 7364: 1, 7365: 1, 7366: 1, 7367: 1, 7368: 1, 7369: 1, 7370: 1, 7371: 1, 7372: 1, 7373: 1, 7374: 1, 7375: 1, 7376: 1, 7377: 1, 7378: 1, 7379: 1, 7380: 1, 7381: 1, 7382: 1, 7383: 1, 7384: 1, 7385: 1, 7386: 1, 7387: 1, 7388: 1, 7389: 1, 7390: 1, 7391: 1, 7392: 1, 7393: 1, 7394: 1, 7395: 1, 7396: 1, 7397: 1, 7398: 1, 7399: 1, 7400: 1, 7401: 1, 7402: 1, 7403: 1, 7404: 1, 7405: 1, 7406: 1, 7407: 1, 7408: 1, 7409: 1, 7410: 1, 7411: 1, 7412: 1, 7413: 1, 7414: 1, 7415: 1, 7416: 1, 7417: 1, 7418: 1, 7419: 1, 7420: 1, 7421: 1, 7422: 1, 7423: 1, 7424: 1, 7425: 1, 7426: 1, 7427: 1, 7428: 1, 7429: 1, 7430: 1, 7431: 1, 7432: 1, 7433: 1, 7434: 1, 7435: 1, 7436: 1, 7437: 1, 7438: 1, 7439: 1, 7440: 1, 7441: 1, 7442: 1, 7443: 1, 7444: 1, 7445: 1, 7446: 1, 7447: 1, 7448: 1, 7449: 1, 7450: 1, 7451: 1, 7452: 1, 7453: 1, 7454: 1, 7455: 1, 7456: 1, 7457: 1, 7458: 1, 7459: 1, 7460: 1, 7461: 1, 7462: 1, 7463: 1, 7464: 1, 7465: 1, 7466: 1, 7467: 1, 7468: 1, 7469: 1, 7470: 1, 7471: 1, 7472: 1, 7473: 1, 7474: 1, 7475: 1, 7476: 1, 7477: 1, 7478: 1, 7479: 1, 7480: 1, 7481: 1, 7482: 1, 7483: 1, 7484: 1, 7485: 1, 7486: 1, 7487: 1, 7488: 1, 7489: 1, 7490: 1, 7491: 1, 7492: 1, 7493: 1, 7494: 1, 7495: 1, 7496: 1, 7497: 1, 7498: 1, 7499: 1, 7500: 1, 7501: 1, 7502: 1, 7503: 1, 7504: 1, 7505: 1, 7506: 1, 7507: 1, 7508: 1, 7509: 1, 7510: 1, 7511: 1, 7512: 1, 7513: 1, 7514: 1, 7515: 1, 7516: 1, 7517: 1, 7518: 1, 7519: 1, 7520: 1, 7521: 1, 7522: 1, 7523: 1, 7524: 1, 7525: 1, 7526: 1, 7527: 1, 7528: 1, 7529: 1, 7530: 1, 7531: 1, 7532: 1, 7533: 1, 7534: 1, 7535: 1, 7536: 1, 7537: 1, 7538: 1, 7539: 1, 7540: 1, 7541: 1, 7542: 1, 7543: 1, 7544: 1, 7545: 1, 7546: 1, 7547: 1, 7548: 1, 7549: 1, 7550: 1, 7551: 1, 7552: 1, 7553: 1, 7554: 1, 7555: 1, 7556: 1, 7557: 1, 7558: 1, 7559: 1, 7560: 1, 7561: 1, 7562: 1, 7563: 1, 7564: 1, 7565: 1, 7566: 1, 7567: 1, 7568: 1, 7569: 1, 7570: 1, 7571: 1, 7572: 1, 7573: 1, 7574: 1, 7575: 1, 7576: 1, 7577: 1, 7578: 1, 7579: 1, 7580: 1, 7581: 1, 7582: 1, 7583: 1, 7584: 1, 7585: 1, 7586: 1, 7587: 1, 7588: 1, 7589: 1, 7590: 1, 7591: 1, 7592: 1, 7593: 1, 7594: 1, 7595: 1, 7596: 1, 7597: 1, 7598: 1, 7599: 1, 7600: 1, 7601: 1, 7602: 1, 7603: 1, 7604: 1, 7605: 1, 7606: 1, 7607: 1, 7608: 1, 7609: 1, 7610: 1, 7611: 1, 7612: 1, 7613: 1, 7614: 1, 7615: 1, 7616: 1, 7617: 1, 7618: 1, 7619: 1, 7620: 1, 7621: 1, 7622: 1, 7623: 1, 7624: 1, 7625: 1, 7626: 1, 7627: 1, 7628: 1, 7629: 1, 7630: 1, 7631: 1, 7632: 1, 7633: 1, 7634: 1, 7635: 1, 7636: 1, 7637: 1, 7638: 1, 7639: 1, 7640: 1, 7641: 1, 7642: 1, 7643: 1, 7644: 1, 7645: 1, 7646: 1, 7647: 1, 7648: 1, 7649: 1, 7650: 1, 7651: 1, 7652: 1, 7653: 1, 7654: 1, 7655: 1, 7656: 1, 7657: 1, 7658: 1, 7659: 1, 7660: 1, 7661: 1, 7662: 1, 7663: 1, 7664: 1, 7665: 1, 7666: 1, 7667: 1, 7668: 1, 7669: 1, 7670: 1, 7671: 1, 7672: 1, 7673: 1, 7674: 1, 7675: 1, 7676: 1, 7677: 1, 7678: 1, 7679: 1, 7680: 1, 7681: 1, 7682: 1, 7683: 1, 7684: 1, 7685: 1, 7686: 1, 7687: 1, 7688: 1, 7689: 1, 7690: 1, 7691: 1, 7692: 1, 7693: 1, 7694: 1, 7695: 1, 7696: 1, 7697: 1, 7698: 1, 7699: 2, 7700: 1, 7701: 1, 7702: 1, 7703: 1, 7704: 1, 7705: 1, 7706: 1, 7707: 1, 7708: 1, 7709: 1, 7710: 1, 7711: 1, 7712: 1, 7713: 1, 7714: 1, 7715: 1, 7716: 1, 7717: 1, 7718: 1, 7719: 1, 7720: 1, 7721: 1, 7722: 1, 7723: 1, 7724: 1, 7725: 1, 7726: 1, 7727: 1, 7728: 1, 7729: 1, 7730: 1, 7731: 1, 7732: 1, 7733: 1, 7734: 1, 7735: 1, 7736: 1, 7737: 1, 7738: 1, 7739: 1, 7740: 1, 7741: 1, 7742: 1, 7743: 1, 7744: 1, 7745: 1, 7746: 1, 7747: 1, 7748: 1, 7749: 1, 7750: 1, 7751: 1, 7752: 1, 7753: 1, 7754: 1, 7755: 1, 7756: 1, 7757: 1, 7758: 1, 7759: 1, 7760: 1, 7761: 1, 7762: 1, 7763: 1, 7764: 1, 7765: 1, 7766: 1, 7767: 1, 7768: 1, 7769: 1, 7770: 1, 7771: 1, 7772: 1, 7773: 1, 7774: 1, 7775: 1, 7776: 1, 7777: 1, 7778: 1, 7779: 1, 7780: 1, 7781: 1, 7782: 1, 7783: 1, 7784: 1, 7785: 1, 7786: 1, 7787: 1, 7788: 1, 7789: 1, 7790: 1, 7791: 1, 7792: 1, 7793: 1, 7794: 1, 7795: 1, 7796: 1, 7797: 1, 7798: 1, 7799: 1, 7800: 1, 7801: 1, 7802: 1, 7803: 1, 7804: 1, 7805: 1, 7806: 1, 7807: 1, 7808: 1, 7809: 1, 7810: 1, 7811: 1, 7812: 1, 7813: 1, 7814: 1, 7815: 1, 7816: 1, 7817: 1, 7818: 1, 7819: 1, 7820: 1, 7821: 1, 7822: 1, 7823: 1, 7824: 1, 7825: 1, 7826: 1, 7827: 1, 7828: 1, 7829: 1, 7830: 1, 7831: 1, 7832: 1, 7833: 1, 7834: 1, 7835: 1, 7836: 1, 7837: 1, 7838: 1, 7839: 1, 7840: 1, 7841: 1, 7842: 1, 7843: 1, 7844: 1, 7845: 1, 7846: 1, 7847: 1, 7848: 1, 7849: 1, 7850: 1, 7851: 1, 7852: 1, 7853: 1, 7854: 1, 7855: 1, 7856: 1, 7857: 1, 7858: 1, 7859: 1, 7860: 1, 7861: 1, 7862: 1, 7863: 1, 7864: 1, 7865: 1, 7866: 1, 7867: 1, 7868: 1, 7869: 1, 7870: 1, 7871: 1, 7872: 1, 7873: 1, 7874: 1, 7875: 1, 7876: 1, 7877: 1, 7878: 1, 7879: 1, 7880: 1, 7881: 1, 7882: 1, 7883: 1, 7884: 1, 7885: 1, 7886: 1, 7887: 1, 7888: 1, 7889: 1, 7890: 1, 7891: 1, 7892: 1, 7893: 1, 7894: 1, 7895: 1, 7896: 1, 7897: 1, 7898: 1, 7899: 1, 7900: 1, 7901: 1, 7902: 1, 7903: 1, 7904: 1, 7905: 1, 7906: 1, 7907: 1, 7908: 1, 7909: 1, 7910: 1, 7911: 1, 7912: 1, 7913: 1, 7914: 1, 7915: 1, 7916: 1, 7917: 1, 7918: 1, 7919: 1, 7920: 1, 7921: 1, 7922: 1, 7923: 1, 7924: 1, 7925: 1, 7926: 1, 7927: 1, 7928: 1, 7929: 1, 7930: 1, 7931: 1, 7932: 1, 7933: 1, 7934: 1, 7935: 1, 7936: 1, 7937: 1, 7938: 1, 7939: 1, 7940: 1, 7941: 1, 7942: 1, 7943: 1, 7944: 1, 7945: 1, 7946: 1, 7947: 1, 7948: 1, 7949: 1, 7950: 1, 7951: 1, 7952: 1, 7953: 1, 7954: 1, 7955: 1, 7956: 1, 7957: 1, 7958: 1, 7959: 1, 7960: 1, 7961: 1, 7962: 1, 7963: 1, 7964: 1, 7965: 1, 7966: 1, 7967: 1, 7968: 1, 7969: 1, 7970: 1, 7971: 1, 7972: 1, 7973: 1, 7974: 1, 7975: 1, 7976: 1, 7977: 1, 7978: 1, 7979: 1, 7980: 1, 7981: 1, 7982: 1, 7983: 1, 7984: 1, 7985: 1, 7986: 1, 7987: 1, 7988: 1, 7989: 1, 7990: 1, 7991: 1, 7992: 1, 7993: 1, 7994: 1, 7995: 1, 7996: 1, 7997: 1, 7998: 1, 7999: 1, 8000: 1, 8001: 1, 8002: 1, 8003: 1, 8004: 1, 8005: 1, 8006: 1, 8007: 1, 8008: 1, 8009: 1, 8010: 1, 8011: 1, 8012: 1, 8013: 1, 8014: 1, 8015: 1, 8016: 1, 8017: 1, 8018: 1, 8019: 1, 8020: 1, 8021: 1, 8022: 1, 8023: 1, 8024: 1, 8025: 1, 8026: 1, 8027: 1, 8028: 1, 8029: 1, 8030: 1, 8031: 1, 8032: 1, 8033: 1, 8034: 1, 8035: 1, 8036: 1, 8037: 1, 8038: 1, 8039: 1, 8040: 1, 8041: 1, 8042: 1, 8043: 1, 8044: 1, 8045: 1, 8046: 1, 8047: 1, 8048: 1, 8049: 1, 8050: 1, 8051: 1, 8052: 1, 8053: 1, 8054: 1, 8055: 1, 8056: 1, 8057: 1, 8058: 1, 8059: 1, 8060: 1, 8061: 1, 8062: 1, 8063: 1, 8064: 1, 8065: 1, 8066: 1, 8067: 1, 8068: 1, 8069: 1, 8070: 1, 8071: 1, 8072: 1, 8073: 1, 8074: 1, 8075: 1, 8076: 1, 8077: 1, 8078: 1, 8079: 1, 8080: 1, 8081: 1, 8082: 1, 8083: 1, 8084: 1, 8085: 1, 8086: 1, 8087: 1, 8088: 1, 8089: 1, 8090: 1, 8091: 1, 8092: 1, 8093: 1, 8094: 1, 8095: 1, 8096: 1, 8097: 1, 8098: 1, 8099: 1, 8100: 1, 8101: 1, 8102: 1, 8103: 1, 8104: 1, 8105: 1, 8106: 1, 8107: 1, 8108: 1, 8109: 1, 8110: 1, 8111: 1, 8112: 1, 8113: 1, 8114: 1, 8115: 1, 8116: 1, 8117: 1, 8118: 1, 8119: 1, 8120: 1, 8121: 1, 8122: 1, 8123: 1, 8124: 1, 8125: 1, 8126: 1, 8127: 1, 8128: 1, 8129: 1, 8130: 1, 8131: 1, 8132: 1, 8133: 1, 8134: 1, 8135: 1, 8136: 1, 8137: 1, 8138: 1, 8139: 1, 8140: 1, 8141: 1, 8142: 1, 8143: 1, 8144: 1, 8145: 1, 8146: 1, 8147: 1, 8148: 1, 8149: 1, 8150: 1, 8151: 1, 8152: 1, 8153: 1, 8154: 1, 8155: 1, 8156: 1, 8157: 1, 8158: 1, 8159: 1, 8160: 1, 8161: 1, 8162: 1, 8163: 1, 8164: 1, 8165: 1, 8166: 1, 8167: 1, 8168: 1, 8169: 1, 8170: 1, 8171: 1, 8172: 1, 8173: 1, 8174: 1, 8175: 1, 8176: 1, 8177: 1, 8178: 1, 8179: 1, 8180: 1, 8181: 1, 8182: 1, 8183: 1, 8184: 1, 8185: 1, 8186: 1, 8187: 1, 8188: 1, 8189: 1, 8190: 1, 8191: 1, 8192: 1, 8193: 1, 8194: 1, 8195: 1, 8196: 1, 8197: 1, 8198: 1, 8199: 1, 8200: 1, 8201: 1, 8202: 1, 8203: 1, 8204: 1, 8205: 1, 8206: 1, 8207: 1, 8208: 1, 8209: 1, 8210: 1, 8211: 1, 8212: 1, 8213: 1, 8214: 1, 8215: 1, 8216: 1, 8217: 1, 8218: 1, 8219: 1, 8220: 1, 8221: 1, 8222: 1, 8223: 1, 8224: 1, 8225: 1, 8226: 1, 8227: 1, 8228: 1, 8229: 1, 8230: 1, 8231: 1, 8232: 1, 8233: 1, 8234: 1, 8235: 1, 8236: 1, 8237: 1, 8238: 1, 8239: 1, 8240: 1, 8241: 1, 8242: 1, 8243: 1, 8244: 1, 8245: 1, 8246: 1, 8247: 1, 8248: 1, 8249: 1, 8250: 1, 8251: 1, 8252: 1, 8253: 1, 8254: 1, 8255: 1, 8256: 1, 8257: 1, 8258: 1, 8259: 1, 8260: 1, 8261: 1, 8262: 1, 8263: 1, 8264: 1, 8265: 1, 8266: 1, 8267: 1, 8268: 1, 8269: 1, 8270: 1, 8271: 1, 8272: 1, 8273: 1, 8274: 1, 8275: 1, 8276: 1, 8277: 1, 8278: 1, 8279: 1, 8280: 1, 8281: 1, 8282: 1, 8283: 1, 8284: 1, 8285: 1, 8286: 1, 8287: 1, 8288: 1, 8289: 1, 8290: 1, 8291: 1, 8292: 1, 8293: 1, 8294: 1, 8295: 1, 8296: 1, 8297: 1, 8298: 1, 8299: 1, 8300: 1, 8301: 1, 8302: 1, 8303: 1, 8304: 1, 8305: 1, 8306: 1, 8307: 1, 8308: 1, 8309: 1, 8310: 1, 8311: 1, 8312: 1, 8313: 1, 8314: 1, 8315: 1, 8316: 1, 8317: 1, 8318: 1, 8319: 1, 8320: 1, 8321: 1, 8322: 1, 8323: 1, 8324: 1, 8325: 1, 8326: 1, 8327: 1, 8328: 1, 8329: 1, 8330: 1, 8331: 1, 8332: 1, 8333: 1, 8334: 1, 8335: 1, 8336: 1, 8337: 1, 8338: 1, 8339: 1, 8340: 1, 8341: 1, 8342: 1, 8343: 1, 8344: 1, 8345: 1, 8346: 1, 8347: 1, 8348: 1, 8349: 1, 8350: 1, 8351: 1, 8352: 1, 8353: 1, 8354: 1, 8355: 1, 8356: 1, 8357: 1, 8358: 1, 8359: 1, 8360: 1, 8361: 1, 8362: 1, 8363: 1, 8364: 1, 8365: 1, 8366: 1, 8367: 1, 8368: 1, 8369: 1, 8370: 1, 8371: 1, 8372: 1, 8373: 1, 8374: 1, 8375: 1, 8376: 1, 8377: 1, 8378: 1, 8379: 1, 8380: 1, 8381: 1, 8382: 1, 8383: 1, 8384: 1, 8385: 1, 8386: 1, 8387: 1, 8388: 1, 8389: 1, 8390: 1, 8391: 1, 8392: 1, 8393: 1, 8394: 1, 8395: 1, 8396: 1, 8397: 1, 8398: 1, 8399: 1, 8400: 1, 8401: 1, 8402: 1, 8403: 1, 8404: 1, 8405: 1, 8406: 1, 8407: 1, 8408: 1, 8409: 1, 8410: 1, 8411: 1, 8412: 1, 8413: 1, 8414: 1, 8415: 1, 8416: 1, 8417: 1, 8418: 1, 8419: 1, 8420: 1, 8421: 1, 8422: 1, 8423: 1, 8424: 1, 8425: 1, 8426: 1, 8427: 1, 8428: 1, 8429: 1, 8430: 1, 8431: 1, 8432: 1, 8433: 1, 8434: 1, 8435: 1, 8436: 1, 8437: 1, 8438: 1, 8439: 1, 8440: 1, 8441: 1, 8442: 1, 8443: 1, 8444: 1, 8445: 1, 8446: 1, 8447: 1, 8448: 1, 8449: 1, 8450: 1, 8451: 1, 8452: 1, 8453: 1, 8454: 1, 8455: 1, 8456: 1, 8457: 1, 8458: 1, 8459: 1, 8460: 1, 8461: 1, 8462: 1, 8463: 1, 8464: 1, 8465: 1, 8466: 1, 8467: 1, 8468: 1, 8469: 1, 8470: 1, 8471: 1, 8472: 1, 8473: 1, 8474: 1, 8475: 1, 8476: 1, 8477: 1, 8478: 1, 8479: 1, 8480: 1, 8481: 1, 8482: 1, 8483: 1, 8484: 1, 8485: 1, 8486: 1, 8487: 1, 8488: 1, 8489: 1, 8490: 1, 8491: 1, 8492: 1, 8493: 1, 8494: 1, 8495: 1, 8496: 1, 8497: 1, 8498: 1, 8499: 1, 8500: 1, 8501: 1, 8502: 1, 8503: 1, 8504: 1, 8505: 1, 8506: 1, 8507: 1, 8508: 1, 8509: 1, 8510: 1, 8511: 1, 8512: 1, 8513: 1, 8514: 1, 8515: 1, 8516: 1, 8517: 1, 8518: 1, 8519: 1, 8520: 1, 8521: 1, 8522: 1, 8523: 1, 8524: 1, 8525: 1, 8526: 1, 8527: 1, 8528: 1, 8529: 1, 8530: 1, 8531: 1, 8532: 1, 8533: 1, 8534: 1, 8535: 1, 8536: 1, 8537: 1, 8538: 1, 8539: 1, 8540: 1, 8541: 1, 8542: 1, 8543: 1, 8544: 1, 8545: 1, 8546: 1, 8547: 1, 8548: 1, 8549: 1, 8550: 1, 8551: 1, 8552: 1, 8553: 1, 8554: 1, 8555: 1, 8556: 1, 8557: 1, 8558: 1, 8559: 1, 8560: 1, 8561: 1, 8562: 1, 8563: 1, 8564: 1, 8565: 1, 8566: 1, 8567: 1, 8568: 1, 8569: 1, 8570: 1, 8571: 1, 8572: 1, 8573: 1, 8574: 1, 8575: 1, 8576: 1, 8577: 1, 8578: 1, 8579: 1, 8580: 1, 8581: 1, 8582: 1, 8583: 1, 8584: 1, 8585: 1, 8586: 1, 8587: 1, 8588: 1, 8589: 1, 8590: 1, 8591: 1, 8592: 1, 8593: 1, 8594: 1, 8595: 1, 8596: 1, 8597: 1, 8598: 1, 8599: 1, 8600: 1, 8601: 1, 8602: 1, 8603: 1, 8604: 1, 8605: 1, 8606: 1, 8607: 1, 8608: 1, 8609: 1, 8610: 1, 8611: 1, 8612: 1, 8613: 1, 8614: 1, 8615: 1, 8616: 1, 8617: 1, 8618: 1, 8619: 1, 8620: 1, 8621: 1, 8622: 1, 8623: 1, 8624: 1, 8625: 1, 8626: 1, 8627: 1, 8628: 1, 8629: 1, 8630: 1, 8631: 1, 8632: 1, 8633: 1, 8634: 1, 8635: 1, 8636: 1, 8637: 1, 8638: 1, 8639: 1, 8640: 1, 8641: 1, 8642: 1, 8643: 1, 8644: 1, 8645: 1, 8646: 1, 8647: 1, 8648: 1, 8649: 1, 8650: 1, 8651: 1, 8652: 1, 8653: 1, 8654: 1, 8655: 1, 8656: 1, 8657: 1, 8658: 1, 8659: 1, 8660: 1, 8661: 1, 8662: 1, 8663: 1, 8664: 1, 8665: 1, 8666: 1, 8667: 1, 8668: 1, 8669: 1, 8670: 1, 8671: 1, 8672: 1, 8673: 1, 8674: 1, 8675: 1, 8676: 1, 8677: 1, 8678: 1, 8679: 1, 8680: 1, 8681: 1, 8682: 1, 8683: 1, 8684: 1, 8685: 1, 8686: 1, 8687: 1, 8688: 1, 8689: 1, 8690: 1, 8691: 1, 8692: 1, 8693: 1, 8694: 1, 8695: 1, 8696: 1, 8697: 1, 8698: 1, 8699: 1, 8700: 1, 8701: 1, 8702: 1, 8703: 1, 8704: 1, 8705: 1, 8706: 1, 8707: 1, 8708: 1, 8709: 1, 8710: 1, 8711: 1, 8712: 1, 8713: 1, 8714: 1, 8715: 1, 8716: 1, 8717: 1, 8718: 1, 8719: 1, 8720: 1, 8721: 1, 8722: 1, 8723: 1, 8724: 1, 8725: 1, 8726: 1, 8727: 1, 8728: 1, 8729: 1, 8730: 1, 8731: 1, 8732: 1, 8733: 1, 8734: 1, 8735: 1, 8736: 1, 8737: 1, 8738: 1, 8739: 1, 8740: 1, 8741: 1, 8742: 1, 8743: 1, 8744: 1, 8745: 1, 8746: 1, 8747: 1, 8748: 1, 8749: 1, 8750: 1, 8751: 1, 8752: 1, 8753: 1, 8754: 1, 8755: 1, 8756: 1, 8757: 1, 8758: 1, 8759: 1, 8760: 1, 8761: 1, 8762: 1, 8763: 1, 8764: 1, 8765: 1, 8766: 1, 8767: 1, 8768: 1, 8769: 1, 8770: 1, 8771: 1, 8772: 1, 8773: 1, 8774: 1, 8775: 1, 8776: 1, 8777: 1, 8778: 1, 8779: 1, 8780: 1, 8781: 1, 8782: 1, 8783: 1, 8784: 1, 8785: 1, 8786: 1, 8787: 1, 8788: 1, 8789: 1, 8790: 1, 8791: 1, 8792: 1, 8793: 1, 8794: 1, 8795: 1, 8796: 1, 8797: 1, 8798: 1, 8799: 1, 8800: 1, 8801: 1, 8802: 1, 8803: 1, 8804: 1, 8805: 1, 8806: 1, 8807: 1, 8808: 1, 8809: 1, 8810: 1, 8811: 1, 8812: 1, 8813: 1, 8814: 1, 8815: 1, 8816: 1, 8817: 1, 8818: 1, 8819: 1, 8820: 1, 8821: 1, 8822: 1, 8823: 1, 8824: 1, 8825: 1, 8826: 1, 8827: 1, 8828: 1, 8829: 1, 8830: 1, 8831: 1, 8832: 1, 8833: 1, 8834: 1, 8835: 1, 8836: 1, 8837: 1, 8838: 1, 8839: 1, 8840: 1, 8841: 1, 8842: 1, 8843: 1, 8844: 1, 8845: 1, 8846: 1, 8847: 1, 8848: 1, 8849: 1, 8850: 1, 8851: 1, 8852: 1, 8853: 1, 8854: 1, 8855: 1, 8856: 1, 8857: 1, 8858: 1, 8859: 1, 8860: 1, 8861: 1, 8862: 1, 8863: 1, 8864: 1, 8865: 1, 8866: 1, 8867: 1, 8868: 1, 8869: 1, 8870: 1, 8871: 1, 8872: 1, 8873: 1, 8874: 1, 8875: 1, 8876: 1, 8877: 1, 8878: 1, 8879: 1, 8880: 1, 8881: 1, 8882: 1, 8883: 1, 8884: 1, 8885: 1, 8886: 1, 8887: 1, 8888: 1, 8889: 1, 8890: 1, 8891: 1, 8892: 1, 8893: 1, 8894: 1, 8895: 1, 8896: 1, 8897: 1, 8898: 1, 8899: 1, 8900: 1, 8901: 1, 8902: 1, 8903: 1, 8904: 1, 8905: 1, 8906: 1, 8907: 1, 8908: 1, 8909: 1, 8910: 1, 8911: 1, 8912: 1, 8913: 1, 8914: 1, 8915: 1, 8916: 1, 8917: 1, 8918: 1, 8919: 1, 8920: 1, 8921: 1, 8922: 1, 8923: 1, 8924: 1, 8925: 1, 8926: 1, 8927: 1, 8928: 1, 8929: 1, 8930: 1, 8931: 1, 8932: 1, 8933: 1, 8934: 1, 8935: 1, 8936: 1, 8937: 1, 8938: 1, 8939: 1, 8940: 1, 8941: 1, 8942: 1, 8943: 1, 8944: 1, 8945: 1, 8946: 1, 8947: 1, 8948: 1, 8949: 1, 8950: 1, 8951: 1, 8952: 1, 8953: 1, 8954: 1, 8955: 1, 8956: 1, 8957: 1, 8958: 1, 8959: 1, 8960: 1, 8961: 1, 8962: 1, 8963: 1, 8964: 1, 8965: 1, 8966: 1, 8967: 1, 8968: 1, 8969: 1, 8970: 1, 8971: 1, 8972: 1, 8973: 1, 8974: 1, 8975: 1, 8976: 1, 8977: 1, 8978: 1, 8979: 1, 8980: 1, 8981: 1, 8982: 1, 8983: 1, 8984: 1, 8985: 1, 8986: 1, 8987: 1, 8988: 1, 8989: 1, 8990: 1, 8991: 1, 8992: 1, 8993: 1, 8994: 1, 8995: 1, 8996: 1, 8997: 1, 8998: 1, 8999: 1, 9000: 1, 9001: 1, 9002: 1, 9003: 1, 9004: 1, 9005: 1, 9006: 1, 9007: 1, 9008: 1, 9009: 1, 9010: 1, 9011: 1, 9012: 1, 9013: 1, 9014: 1, 9015: 1, 9016: 1, 9017: 1, 9018: 1, 9019: 1, 9020: 1, 9021: 1, 9022: 1, 9023: 1, 9024: 1, 9025: 1, 9026: 1, 9027: 1, 9028: 1, 9029: 1, 9030: 1, 9031: 1, 9032: 1, 9033: 1, 9034: 1, 9035: 1, 9036: 1, 9037: 1, 9038: 1, 9039: 1, 9040: 1, 9041: 1, 9042: 1, 9043: 1, 9044: 1, 9045: 1, 9046: 1, 9047: 1, 9048: 1, 9049: 1, 9050: 1, 9051: 1, 9052: 1, 9053: 1, 9054: 1, 9055: 1, 9056: 1, 9057: 1, 9058: 1, 9059: 1, 9060: 1, 9061: 1, 9062: 1, 9063: 1, 9064: 1, 9065: 1, 9066: 1, 9067: 1, 9068: 1, 9069: 1, 9070: 1, 9071: 1, 9072: 1, 9073: 1, 9074: 1, 9075: 1, 9076: 1, 9077: 1, 9078: 1, 9079: 1, 9080: 1, 9081: 1, 9082: 1, 9083: 1, 9084: 1, 9085: 1, 9086: 1, 9087: 1, 9088: 1, 9089: 1, 9090: 1, 9091: 1, 9092: 1, 9093: 1, 9094: 1, 9095: 1, 9096: 1, 9097: 1, 9098: 1, 9099: 1, 9100: 1, 9101: 1, 9102: 1, 9103: 1, 9104: 1, 9105: 1, 9106: 1, 9107: 1, 9108: 1, 9109: 1, 9110: 1, 9111: 1, 9112: 1, 9113: 1, 9114: 1, 9115: 1, 9116: 1, 9117: 1, 9118: 1, 9119: 1, 9120: 1, 9121: 1, 9122: 1, 9123: 1, 9124: 1, 9125: 1, 9126: 1, 9127: 1, 9128: 1, 9129: 1, 9130: 1, 9131: 1, 9132: 1, 9133: 1, 9134: 1, 9135: 1, 9136: 1, 9137: 1, 9138: 1, 9139: 1, 9140: 1, 9141: 1, 9142: 1, 9143: 1, 9144: 1, 9145: 1, 9146: 1, 9147: 1, 9148: 1, 9149: 1, 9150: 1, 9151: 1, 9152: 1, 9153: 1, 9154: 1, 9155: 1, 9156: 1, 9157: 1, 9158: 1, 9159: 1, 9160: 1, 9161: 1, 9162: 1, 9163: 1, 9164: 1, 9165: 1, 9166: 1, 9167: 1, 9168: 1, 9169: 1, 9170: 1, 9171: 1, 9172: 1, 9173: 1, 9174: 1, 9175: 1, 9176: 1, 9177: 1, 9178: 1, 9179: 1, 9180: 1, 9181: 1, 9182: 1, 9183: 1, 9184: 1, 9185: 1, 9186: 1, 9187: 1, 9188: 1, 9189: 1, 9190: 1, 9191: 1, 9192: 1, 9193: 1, 9194: 1, 9195: 1, 9196: 1, 9197: 1, 9198: 1, 9199: 1, 9200: 1, 9201: 1, 9202: 1, 9203: 1, 9204: 1, 9205: 1, 9206: 1, 9207: 1, 9208: 1, 9209: 1, 9210: 1, 9211: 1, 9212: 1, 9213: 1, 9214: 1, 9215: 1, 9216: 1, 9217: 1, 9218: 1, 9219: 1, 9220: 1, 9221: 1, 9222: 1, 9223: 1, 9224: 1, 9225: 1, 9226: 1, 9227: 1, 9228: 1, 9229: 1, 9230: 1, 9231: 1, 9232: 1, 9233: 1, 9234: 1, 9235: 1, 9236: 1, 9237: 1, 9238: 1, 9239: 1, 9240: 1, 9241: 1, 9242: 1, 9243: 1, 9244: 1, 9245: 1, 9246: 1, 9247: 1, 9248: 1, 9249: 1, 9250: 1, 9251: 1, 9252: 1, 9253: 1, 9254: 1, 9255: 1, 9256: 1, 9257: 1, 9258: 1, 9259: 1, 9260: 1, 9261: 1, 9262: 1, 9263: 1, 9264: 1, 9265: 1, 9266: 1, 9267: 1, 9268: 1, 9269: 1, 9270: 1, 9271: 1, 9272: 1, 9273: 1, 9274: 1, 9275: 1, 9276: 1, 9277: 1, 9278: 1, 9279: 1, 9280: 1, 9281: 1, 9282: 1, 9283: 1, 9284: 1, 9285: 1, 9286: 1, 9287: 1, 9288: 1, 9289: 1, 9290: 1, 9291: 1, 9292: 1, 9293: 1, 9294: 1 ~= num clips 1
[04/29 08:59:07][INFO] logging.py:  99: json_stats: {"split": "test_final", "top1_acc": "90.39", "top5_acc": "96.53"}
[04/29 09:03:43][INFO] test_net_gamma.py: 157: Test with config:
[04/29 09:03:43][INFO] test_net_gamma.py: 158: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: True
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  FRAME_PATH: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: True
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  PSEUDO_CSV: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 3
  SPECIAL_LABEL_LIST: [5, 9]
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
EVL:
  ADD_RESIDUAL: False
  AFTER_ME: False
  BACKBONE: vit_b16
  BEFORE_ME: False
  CLS_DROPOUT: 0.5
  FIRST_N: 0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  SHIFT_INIT: False
  SPATAIL_SIZE: 14
  USE_IMAGE_ATTNMAP: True
  USE_T_CONV: True
  USE_T_POS_EMBED: True
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: True
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  CHECKPOINT_NUM: [0, 0, 0, 0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 11
  PSEUDO_LOSS_FUNC: 
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'vip', 'swin', 'sf', 'evl']
  SOFT_T: 1
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: None
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]]
  QKV_BIAS: True
  SEP_POS_EMBED: True
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 2
NUM_SHARDS: 1
OUTPUT_DIR: exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SF:
  DROPOUT_RATE: 0.3
  FROZEN_BN: False
  NONLOCAL:
    FROZEN_BN: False
  PRETRAIN_NAME: SlowFast-ResNet101-8x8
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRADIENT: 20
  CLIP_GRAD_L2NORM: 1.0
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 40
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 10.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.03
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 64
  CHECKPOINT_FILE_PATH: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  DATA_SELECT: real_unlabel_pre
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 1
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
  THRESHOLD: 2
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  KS: 5
  MBCONV: False
  MLP_RATIO: 4
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[04/29 09:03:45][INFO] checkpoint.py: 223: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/29 09:03:52][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel_pre...
[04/29 09:03:52][INFO] ug2_sparse.py:  91: Number of clips 1
[04/29 09:03:52][INFO] ug2_sparse.py: 200: Constructing Ug2 dataloader (size: 3088) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real_unlabel.csv
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 09:03:53][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 09:03:54][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f652eb41710>
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 09:03:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f652eb6bcb0>
[04/29 09:03:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f656817c680>
[04/29 09:03:54][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f652eb6ba70>
[04/29 09:03:54][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 09:03:54][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 09:03:54][DEBUG] factory.py:  66: Loading s3:s3
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 09:03:54][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 09:03:54][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 09:03:54][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f652eb41710>
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f652eb6bcb0>
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f64bea46e60>
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f652eb6ba70>
[04/29 09:03:55][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 09:03:55][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 09:03:55][DEBUG] factory.py:  66: Loading s3:s3
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 09:03:55][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f652eb41710>
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f652eb6bcb0>
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f64be37cef0>
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f652eb6ba70>
[04/29 09:03:55][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 09:03:55][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 09:03:55][DEBUG] factory.py:  66: Loading s3:s3
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 09:03:55][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f652eb41710>
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f652eb6bcb0>
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f64bdca6f80>
[04/29 09:03:55][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f652eb6ba70>
[04/29 09:03:55][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 09:03:55][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 09:03:55][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 09:03:55][DEBUG] factory.py:  66: Loading s3:s3
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 09:03:55][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 09:03:56][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f652eb41710>
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 09:03:56][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f652eb6bcb0>
[04/29 09:03:56][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f64bc044cb0>
[04/29 09:03:56][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f652eb6ba70>
[04/29 09:03:56][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 09:03:56][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 09:03:56][DEBUG] factory.py:  66: Loading s3:s3
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/29 09:03:56][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/29 09:03:56][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f652eb41710>
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/29 09:03:56][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f652eb6bcb0>
[04/29 09:03:56][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f64b5958d40>
[04/29 09:03:56][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f652eb6ba70>
[04/29 09:03:56][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/29 09:03:56][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/29 09:03:56][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/29 09:03:56][DEBUG] factory.py:  66: Loading s3:s3
[04/29 09:03:56][INFO] test_net_gamma.py: 169: Testing model for 49 iterations
[04/29 09:04:52][INFO] logging.py:  99: json_stats: {"cur_iter": "1", "eta": "0:45:46", "split": "test_iter", "time_diff": 56.04619}
[04/29 09:04:53][INFO] logging.py:  99: json_stats: {"cur_iter": "2", "eta": "0:00:42", "split": "test_iter", "time_diff": 0.87617}
[04/29 09:04:54][INFO] logging.py:  99: json_stats: {"cur_iter": "3", "eta": "0:00:41", "split": "test_iter", "time_diff": 0.87657}
[04/29 09:04:55][INFO] logging.py:  99: json_stats: {"cur_iter": "4", "eta": "0:00:40", "split": "test_iter", "time_diff": 0.87733}
[04/29 09:04:56][INFO] logging.py:  99: json_stats: {"cur_iter": "5", "eta": "0:00:39", "split": "test_iter", "time_diff": 0.87609}
[04/29 09:04:57][INFO] logging.py:  99: json_stats: {"cur_iter": "6", "eta": "0:00:38", "split": "test_iter", "time_diff": 0.87346}
[04/29 09:04:58][INFO] logging.py:  99: json_stats: {"cur_iter": "7", "eta": "0:00:41", "split": "test_iter", "time_diff": 0.97053}
[04/29 09:04:59][INFO] logging.py:  99: json_stats: {"cur_iter": "8", "eta": "0:00:35", "split": "test_iter", "time_diff": 0.85706}
[04/29 09:05:01][INFO] logging.py:  99: json_stats: {"cur_iter": "9", "eta": "0:01:30", "split": "test_iter", "time_diff": 2.20025}
[04/29 09:05:02][INFO] logging.py:  99: json_stats: {"cur_iter": "10", "eta": "0:00:34", "split": "test_iter", "time_diff": 0.85423}
[04/29 09:05:03][INFO] logging.py:  99: json_stats: {"cur_iter": "11", "eta": "0:00:33", "split": "test_iter", "time_diff": 0.85352}
[04/29 09:05:04][INFO] logging.py:  99: json_stats: {"cur_iter": "12", "eta": "0:00:35", "split": "test_iter", "time_diff": 0.92936}
[04/29 09:05:05][INFO] logging.py:  99: json_stats: {"cur_iter": "13", "eta": "0:00:38", "split": "test_iter", "time_diff": 1.03120}
[04/29 09:05:06][INFO] logging.py:  99: json_stats: {"cur_iter": "14", "eta": "0:00:36", "split": "test_iter", "time_diff": 1.02586}
[04/29 09:05:07][INFO] logging.py:  99: json_stats: {"cur_iter": "15", "eta": "0:00:34", "split": "test_iter", "time_diff": 0.98663}
[04/29 09:05:08][INFO] logging.py:  99: json_stats: {"cur_iter": "16", "eta": "0:00:33", "split": "test_iter", "time_diff": 0.97092}
[04/29 09:05:09][INFO] logging.py:  99: json_stats: {"cur_iter": "17", "eta": "0:00:29", "split": "test_iter", "time_diff": 0.88021}
[04/29 09:05:10][INFO] logging.py:  99: json_stats: {"cur_iter": "18", "eta": "0:00:27", "split": "test_iter", "time_diff": 0.85444}
[04/29 09:05:11][INFO] logging.py:  99: json_stats: {"cur_iter": "19", "eta": "0:00:26", "split": "test_iter", "time_diff": 0.86472}
[04/29 09:05:12][INFO] logging.py:  99: json_stats: {"cur_iter": "20", "eta": "0:00:28", "split": "test_iter", "time_diff": 0.95784}
[04/29 09:05:13][INFO] logging.py:  99: json_stats: {"cur_iter": "21", "eta": "0:00:24", "split": "test_iter", "time_diff": 0.86101}
[04/29 09:05:14][INFO] logging.py:  99: json_stats: {"cur_iter": "22", "eta": "0:00:23", "split": "test_iter", "time_diff": 0.85474}
[04/29 09:05:15][INFO] logging.py:  99: json_stats: {"cur_iter": "23", "eta": "0:00:25", "split": "test_iter", "time_diff": 0.93767}
[04/29 09:05:16][INFO] logging.py:  99: json_stats: {"cur_iter": "24", "eta": "0:00:22", "split": "test_iter", "time_diff": 0.86635}
[04/29 09:05:17][INFO] logging.py:  99: json_stats: {"cur_iter": "25", "eta": "0:00:21", "split": "test_iter", "time_diff": 0.87892}
[04/29 09:05:18][INFO] logging.py:  99: json_stats: {"cur_iter": "26", "eta": "0:00:24", "split": "test_iter", "time_diff": 1.01784}
[04/29 09:05:19][INFO] logging.py:  99: json_stats: {"cur_iter": "27", "eta": "0:00:27", "split": "test_iter", "time_diff": 1.18664}
[04/29 09:05:20][INFO] logging.py:  99: json_stats: {"cur_iter": "28", "eta": "0:00:21", "split": "test_iter", "time_diff": 0.99338}
[04/29 09:05:21][INFO] logging.py:  99: json_stats: {"cur_iter": "29", "eta": "0:00:18", "split": "test_iter", "time_diff": 0.88011}
[04/29 09:05:22][INFO] logging.py:  99: json_stats: {"cur_iter": "30", "eta": "0:00:20", "split": "test_iter", "time_diff": 1.02953}
[04/29 09:05:23][INFO] logging.py:  99: json_stats: {"cur_iter": "31", "eta": "0:00:16", "split": "test_iter", "time_diff": 0.85191}
[04/29 09:05:24][INFO] logging.py:  99: json_stats: {"cur_iter": "32", "eta": "0:00:17", "split": "test_iter", "time_diff": 0.95345}
[04/29 09:05:25][INFO] logging.py:  99: json_stats: {"cur_iter": "33", "eta": "0:00:17", "split": "test_iter", "time_diff": 1.04329}
[04/29 09:05:26][INFO] logging.py:  99: json_stats: {"cur_iter": "34", "eta": "0:00:15", "split": "test_iter", "time_diff": 0.95070}
[04/29 09:05:28][INFO] logging.py:  99: json_stats: {"cur_iter": "35", "eta": "0:00:22", "split": "test_iter", "time_diff": 1.47015}
[04/29 09:05:29][INFO] logging.py:  99: json_stats: {"cur_iter": "36", "eta": "0:00:14", "split": "test_iter", "time_diff": 1.00069}
[04/29 09:05:30][INFO] logging.py:  99: json_stats: {"cur_iter": "37", "eta": "0:00:11", "split": "test_iter", "time_diff": 0.90699}
[04/29 09:05:31][INFO] logging.py:  99: json_stats: {"cur_iter": "38", "eta": "0:00:10", "split": "test_iter", "time_diff": 0.85532}
[04/29 09:05:32][INFO] logging.py:  99: json_stats: {"cur_iter": "39", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.85633}
[04/29 09:05:33][INFO] logging.py:  99: json_stats: {"cur_iter": "40", "eta": "0:00:08", "split": "test_iter", "time_diff": 0.88166}
[04/29 09:05:34][INFO] logging.py:  99: json_stats: {"cur_iter": "41", "eta": "0:00:08", "split": "test_iter", "time_diff": 0.95283}
[04/29 09:05:35][INFO] logging.py:  99: json_stats: {"cur_iter": "42", "eta": "0:00:07", "split": "test_iter", "time_diff": 0.88012}
[04/29 09:05:36][INFO] logging.py:  99: json_stats: {"cur_iter": "43", "eta": "0:00:10", "split": "test_iter", "time_diff": 1.54504}
[04/29 09:05:37][INFO] logging.py:  99: json_stats: {"cur_iter": "44", "eta": "0:00:05", "split": "test_iter", "time_diff": 0.94974}
[04/29 09:05:38][INFO] logging.py:  99: json_stats: {"cur_iter": "45", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.88188}
[04/29 09:05:39][INFO] logging.py:  99: json_stats: {"cur_iter": "46", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.87970}
[04/29 09:05:40][INFO] logging.py:  99: json_stats: {"cur_iter": "47", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.88091}
[04/29 09:05:41][INFO] logging.py:  99: json_stats: {"cur_iter": "48", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.88424}
[04/29 09:05:41][INFO] logging.py:  99: json_stats: {"cur_iter": "49", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.22960}
[04/29 09:05:41][INFO] logging.py:  99: json_stats: {"split": "test_final", "top1_acc": "90.58", "top5_acc": "96.47"}
[04/30 13:24:40][INFO] test_net_gamma.py: 157: Test with config:
[04/30 13:24:40][INFO] test_net_gamma.py: 158: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: True
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  FRAME_PATH: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: True
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  PSEUDO_CSV: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 3
  SPECIAL_LABEL_LIST: [5, 9]
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
EVL:
  ADD_RESIDUAL: False
  AFTER_ME: False
  BACKBONE: vit_b16
  BEFORE_ME: False
  CLS_DROPOUT: 0.5
  FIRST_N: 0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  SHIFT_INIT: False
  SPATAIL_SIZE: 14
  USE_IMAGE_ATTNMAP: True
  USE_T_CONV: True
  USE_T_POS_EMBED: True
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: True
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  CHECKPOINT_NUM: [0, 0, 0, 0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 11
  PSEUDO_LOSS_FUNC: 
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'vip', 'swin', 'sf', 'evl']
  SOFT_T: 1
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: None
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]]
  QKV_BIAS: True
  SEP_POS_EMBED: True
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 2
NUM_SHARDS: 1
OUTPUT_DIR: ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SF:
  DROPOUT_RATE: 0.3
  FROZEN_BN: False
  NONLOCAL:
    FROZEN_BN: False
  PRETRAIN_NAME: SlowFast-ResNet101-8x8
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRADIENT: 20
  CLIP_GRAD_L2NORM: 1.0
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 40
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 10.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.03
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 64
  CHECKPOINT_FILE_PATH: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  DATA_SELECT: test
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
  THRESHOLD: 2
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  KS: 5
  MBCONV: False
  MLP_RATIO: 4
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[04/30 13:24:56][INFO] checkpoint.py: 223: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[04/30 13:25:00][INFO] ug2_sparse.py:  90: Constructing Ug2 test...
[04/30 13:25:00][INFO] ug2_sparse.py:  91: Number of clips 3
[04/30 13:25:00][INFO] ug2_sparse.py: 203: Constructing Ug2 dataloader (size: 9309) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/test.csv
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/30 13:25:02][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/30 13:25:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/30 13:25:02][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/30 13:25:03][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fb05c070560>
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/30 13:25:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fb05c099b00>
[04/30 13:25:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fb1900d7170>
[04/30 13:25:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fb05c0998c0>
[04/30 13:25:03][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/30 13:25:03][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/30 13:25:03][DEBUG] factory.py:  66: Loading s3:s3
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/30 13:25:03][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fb05c070560>
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/30 13:25:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fb05c099b00>
[04/30 13:25:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fb020c20cb0>
[04/30 13:25:03][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fb05c0998c0>
[04/30 13:25:03][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/30 13:25:03][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/30 13:25:03][DEBUG] factory.py:  66: Loading s3:s3
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/30 13:25:03][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/30 13:25:03][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/30 13:25:03][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fb05c070560>
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fb05c099b00>
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fb020556d40>
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fb05c0998c0>
[04/30 13:25:04][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/30 13:25:04][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/30 13:25:04][DEBUG] factory.py:  66: Loading s3:s3
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/30 13:25:04][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fb05c070560>
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fb05c099b00>
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fb01fe7ddd0>
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fb05c0998c0>
[04/30 13:25:04][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/30 13:25:04][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/30 13:25:04][DEBUG] factory.py:  66: Loading s3:s3
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/30 13:25:04][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fb05c070560>
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fb05c099b00>
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fb01f82cd40>
[04/30 13:25:04][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fb05c0998c0>
[04/30 13:25:04][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/30 13:25:04][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/30 13:25:04][DEBUG] factory.py:  66: Loading s3:s3
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[04/30 13:25:04][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[04/30 13:25:04][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[04/30 13:25:04][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7fb05c070560>
[04/30 13:25:05][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[04/30 13:25:05][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7fb05c099b00>
[04/30 13:25:05][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7fb01f153dd0>
[04/30 13:25:05][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7fb05c0998c0>
[04/30 13:25:05][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[04/30 13:25:05][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[04/30 13:25:05][DEBUG] client.py: 207: Registering retry handlers for service: s3
[04/30 13:25:05][DEBUG] factory.py:  66: Loading s3:s3
[04/30 13:25:05][INFO] test_net_gamma.py: 169: Testing model for 146 iterations
[04/30 13:25:58][INFO] logging.py:  99: json_stats: {"cur_iter": "1", "eta": "2:10:49", "split": "test_iter", "time_diff": 53.76564}
[04/30 13:25:59][INFO] logging.py:  99: json_stats: {"cur_iter": "2", "eta": "0:02:21", "split": "test_iter", "time_diff": 0.97757}
[04/30 13:26:00][INFO] logging.py:  99: json_stats: {"cur_iter": "3", "eta": "0:02:21", "split": "test_iter", "time_diff": 0.98414}
[04/30 13:26:01][INFO] logging.py:  99: json_stats: {"cur_iter": "4", "eta": "0:02:08", "split": "test_iter", "time_diff": 0.89573}
[04/30 13:26:02][INFO] logging.py:  99: json_stats: {"cur_iter": "5", "eta": "0:02:07", "split": "test_iter", "time_diff": 0.89762}
[04/30 13:26:03][INFO] logging.py:  99: json_stats: {"cur_iter": "6", "eta": "0:02:19", "split": "test_iter", "time_diff": 0.98644}
[04/30 13:26:04][INFO] logging.py:  99: json_stats: {"cur_iter": "7", "eta": "0:02:05", "split": "test_iter", "time_diff": 0.89682}
[04/30 13:26:05][INFO] logging.py:  99: json_stats: {"cur_iter": "8", "eta": "0:02:04", "split": "test_iter", "time_diff": 0.89805}
[04/30 13:26:06][INFO] logging.py:  99: json_stats: {"cur_iter": "9", "eta": "0:02:19", "split": "test_iter", "time_diff": 1.00825}
[04/30 13:26:07][INFO] logging.py:  99: json_stats: {"cur_iter": "10", "eta": "0:02:17", "split": "test_iter", "time_diff": 1.00513}
[04/30 13:26:08][INFO] logging.py:  99: json_stats: {"cur_iter": "11", "eta": "0:02:14", "split": "test_iter", "time_diff": 0.99107}
[04/30 13:26:09][INFO] logging.py:  99: json_stats: {"cur_iter": "12", "eta": "0:02:18", "split": "test_iter", "time_diff": 1.02536}
[04/30 13:26:10][INFO] logging.py:  99: json_stats: {"cur_iter": "13", "eta": "0:02:15", "split": "test_iter", "time_diff": 1.00873}
[04/30 13:26:11][INFO] logging.py:  99: json_stats: {"cur_iter": "14", "eta": "0:02:16", "split": "test_iter", "time_diff": 1.02309}
[04/30 13:26:12][INFO] logging.py:  99: json_stats: {"cur_iter": "15", "eta": "0:02:12", "split": "test_iter", "time_diff": 1.00721}
[04/30 13:26:13][INFO] logging.py:  99: json_stats: {"cur_iter": "16", "eta": "0:01:57", "split": "test_iter", "time_diff": 0.89830}
[04/30 13:26:14][INFO] logging.py:  99: json_stats: {"cur_iter": "17", "eta": "0:02:12", "split": "test_iter", "time_diff": 1.01839}
[04/30 13:26:15][INFO] logging.py:  99: json_stats: {"cur_iter": "18", "eta": "0:01:55", "split": "test_iter", "time_diff": 0.89824}
[04/30 13:26:16][INFO] logging.py:  99: json_stats: {"cur_iter": "19", "eta": "0:02:16", "split": "test_iter", "time_diff": 1.06256}
[04/30 13:26:17][INFO] logging.py:  99: json_stats: {"cur_iter": "20", "eta": "0:02:08", "split": "test_iter", "time_diff": 1.01177}
[04/30 13:26:18][INFO] logging.py:  99: json_stats: {"cur_iter": "21", "eta": "0:01:53", "split": "test_iter", "time_diff": 0.89835}
[04/30 13:26:19][INFO] logging.py:  99: json_stats: {"cur_iter": "22", "eta": "0:02:01", "split": "test_iter", "time_diff": 0.97057}
[04/30 13:26:21][INFO] logging.py:  99: json_stats: {"cur_iter": "23", "eta": "0:01:55", "split": "test_iter", "time_diff": 0.92789}
[04/30 13:26:22][INFO] logging.py:  99: json_stats: {"cur_iter": "24", "eta": "0:01:50", "split": "test_iter", "time_diff": 0.89525}
[04/30 13:26:23][INFO] logging.py:  99: json_stats: {"cur_iter": "25", "eta": "0:02:02", "split": "test_iter", "time_diff": 1.00176}
[04/30 13:26:24][INFO] logging.py:  99: json_stats: {"cur_iter": "26", "eta": "0:02:02", "split": "test_iter", "time_diff": 1.00993}
[04/30 13:26:25][INFO] logging.py:  99: json_stats: {"cur_iter": "27", "eta": "0:01:59", "split": "test_iter", "time_diff": 0.99196}
[04/30 13:26:26][INFO] logging.py:  99: json_stats: {"cur_iter": "28", "eta": "0:02:01", "split": "test_iter", "time_diff": 1.02302}
[04/30 13:26:27][INFO] logging.py:  99: json_stats: {"cur_iter": "29", "eta": "0:01:56", "split": "test_iter", "time_diff": 0.98581}
[04/30 13:26:28][INFO] logging.py:  99: json_stats: {"cur_iter": "30", "eta": "0:01:53", "split": "test_iter", "time_diff": 0.96943}
[04/30 13:26:29][INFO] logging.py:  99: json_stats: {"cur_iter": "31", "eta": "0:01:57", "split": "test_iter", "time_diff": 1.01238}
[04/30 13:26:30][INFO] logging.py:  99: json_stats: {"cur_iter": "32", "eta": "0:01:51", "split": "test_iter", "time_diff": 0.96666}
[04/30 13:26:31][INFO] logging.py:  99: json_stats: {"cur_iter": "33", "eta": "0:02:03", "split": "test_iter", "time_diff": 1.08156}
[04/30 13:26:32][INFO] logging.py:  99: json_stats: {"cur_iter": "34", "eta": "0:01:55", "split": "test_iter", "time_diff": 1.01772}
[04/30 13:26:33][INFO] logging.py:  99: json_stats: {"cur_iter": "35", "eta": "0:01:57", "split": "test_iter", "time_diff": 1.04555}
[04/30 13:26:34][INFO] logging.py:  99: json_stats: {"cur_iter": "36", "eta": "0:01:48", "split": "test_iter", "time_diff": 0.97850}
[04/30 13:26:35][INFO] logging.py:  99: json_stats: {"cur_iter": "37", "eta": "0:01:48", "split": "test_iter", "time_diff": 0.98716}
[04/30 13:26:36][INFO] logging.py:  99: json_stats: {"cur_iter": "38", "eta": "0:01:52", "split": "test_iter", "time_diff": 1.02753}
[04/30 13:26:37][INFO] logging.py:  99: json_stats: {"cur_iter": "39", "eta": "0:01:44", "split": "test_iter", "time_diff": 0.97190}
[04/30 13:26:38][INFO] logging.py:  99: json_stats: {"cur_iter": "40", "eta": "0:01:36", "split": "test_iter", "time_diff": 0.90155}
[04/30 13:26:39][INFO] logging.py:  99: json_stats: {"cur_iter": "41", "eta": "0:01:42", "split": "test_iter", "time_diff": 0.96716}
[04/30 13:26:40][INFO] logging.py:  99: json_stats: {"cur_iter": "42", "eta": "0:01:47", "split": "test_iter", "time_diff": 1.02207}
[04/30 13:26:41][INFO] logging.py:  99: json_stats: {"cur_iter": "43", "eta": "0:01:44", "split": "test_iter", "time_diff": 1.00402}
[04/30 13:26:42][INFO] logging.py:  99: json_stats: {"cur_iter": "44", "eta": "0:01:41", "split": "test_iter", "time_diff": 0.98459}
[04/30 13:26:43][INFO] logging.py:  99: json_stats: {"cur_iter": "45", "eta": "0:01:49", "split": "test_iter", "time_diff": 1.07597}
[04/30 13:26:44][INFO] logging.py:  99: json_stats: {"cur_iter": "46", "eta": "0:01:40", "split": "test_iter", "time_diff": 0.99459}
[04/30 13:26:45][INFO] logging.py:  99: json_stats: {"cur_iter": "47", "eta": "0:01:37", "split": "test_iter", "time_diff": 0.97136}
[04/30 13:26:46][INFO] logging.py:  99: json_stats: {"cur_iter": "48", "eta": "0:01:38", "split": "test_iter", "time_diff": 0.99810}
[04/30 13:26:47][INFO] logging.py:  99: json_stats: {"cur_iter": "49", "eta": "0:01:39", "split": "test_iter", "time_diff": 1.01517}
[04/30 13:26:48][INFO] logging.py:  99: json_stats: {"cur_iter": "50", "eta": "0:01:35", "split": "test_iter", "time_diff": 0.98332}
[04/30 13:26:49][INFO] logging.py:  99: json_stats: {"cur_iter": "51", "eta": "0:01:37", "split": "test_iter", "time_diff": 1.01610}
[04/30 13:26:50][INFO] logging.py:  99: json_stats: {"cur_iter": "52", "eta": "0:01:32", "split": "test_iter", "time_diff": 0.97643}
[04/30 13:26:51][INFO] logging.py:  99: json_stats: {"cur_iter": "53", "eta": "0:01:37", "split": "test_iter", "time_diff": 1.03246}
[04/30 13:26:52][INFO] logging.py:  99: json_stats: {"cur_iter": "54", "eta": "0:01:40", "split": "test_iter", "time_diff": 1.07535}
[04/30 13:26:53][INFO] logging.py:  99: json_stats: {"cur_iter": "55", "eta": "0:01:30", "split": "test_iter", "time_diff": 0.97885}
[04/30 13:26:54][INFO] logging.py:  99: json_stats: {"cur_iter": "56", "eta": "0:01:30", "split": "test_iter", "time_diff": 0.99826}
[04/30 13:26:55][INFO] logging.py:  99: json_stats: {"cur_iter": "57", "eta": "0:01:31", "split": "test_iter", "time_diff": 1.01193}
[04/30 13:26:56][INFO] logging.py:  99: json_stats: {"cur_iter": "58", "eta": "0:01:26", "split": "test_iter", "time_diff": 0.97221}
[04/30 13:26:57][INFO] logging.py:  99: json_stats: {"cur_iter": "59", "eta": "0:01:19", "split": "test_iter", "time_diff": 0.90431}
[04/30 13:26:58][INFO] logging.py:  99: json_stats: {"cur_iter": "60", "eta": "0:01:27", "split": "test_iter", "time_diff": 1.00440}
[04/30 13:26:59][INFO] logging.py:  99: json_stats: {"cur_iter": "61", "eta": "0:01:26", "split": "test_iter", "time_diff": 1.00811}
[04/30 13:27:00][INFO] logging.py:  99: json_stats: {"cur_iter": "62", "eta": "0:01:23", "split": "test_iter", "time_diff": 0.98412}
[04/30 13:27:01][INFO] logging.py:  99: json_stats: {"cur_iter": "63", "eta": "0:01:23", "split": "test_iter", "time_diff": 0.99975}
[04/30 13:27:02][INFO] logging.py:  99: json_stats: {"cur_iter": "64", "eta": "0:01:29", "split": "test_iter", "time_diff": 1.07500}
[04/30 13:27:03][INFO] logging.py:  99: json_stats: {"cur_iter": "65", "eta": "0:01:22", "split": "test_iter", "time_diff": 1.00360}
[04/30 13:27:04][INFO] logging.py:  99: json_stats: {"cur_iter": "66", "eta": "0:01:23", "split": "test_iter", "time_diff": 1.03500}
[04/30 13:27:05][INFO] logging.py:  99: json_stats: {"cur_iter": "67", "eta": "0:01:20", "split": "test_iter", "time_diff": 1.00556}
[04/30 13:27:06][INFO] logging.py:  99: json_stats: {"cur_iter": "68", "eta": "0:01:18", "split": "test_iter", "time_diff": 0.98932}
[04/30 13:27:07][INFO] logging.py:  99: json_stats: {"cur_iter": "69", "eta": "0:01:18", "split": "test_iter", "time_diff": 1.00395}
[04/30 13:27:08][INFO] logging.py:  99: json_stats: {"cur_iter": "70", "eta": "0:01:16", "split": "test_iter", "time_diff": 0.99300}
[04/30 13:27:09][INFO] logging.py:  99: json_stats: {"cur_iter": "71", "eta": "0:01:15", "split": "test_iter", "time_diff": 0.99677}
[04/30 13:27:10][INFO] logging.py:  99: json_stats: {"cur_iter": "72", "eta": "0:01:15", "split": "test_iter", "time_diff": 1.00399}
[04/30 13:27:11][INFO] logging.py:  99: json_stats: {"cur_iter": "73", "eta": "0:01:14", "split": "test_iter", "time_diff": 1.00788}
[04/30 13:27:12][INFO] logging.py:  99: json_stats: {"cur_iter": "74", "eta": "0:01:15", "split": "test_iter", "time_diff": 1.03915}
[04/30 13:27:13][INFO] logging.py:  99: json_stats: {"cur_iter": "75", "eta": "0:01:17", "split": "test_iter", "time_diff": 1.08325}
[04/30 13:27:14][INFO] logging.py:  99: json_stats: {"cur_iter": "76", "eta": "0:01:11", "split": "test_iter", "time_diff": 1.00169}
[04/30 13:27:15][INFO] logging.py:  99: json_stats: {"cur_iter": "77", "eta": "0:01:10", "split": "test_iter", "time_diff": 1.01322}
[04/30 13:27:16][INFO] logging.py:  99: json_stats: {"cur_iter": "78", "eta": "0:01:08", "split": "test_iter", "time_diff": 0.98937}
[04/30 13:27:17][INFO] logging.py:  99: json_stats: {"cur_iter": "79", "eta": "0:01:08", "split": "test_iter", "time_diff": 1.01364}
[04/30 13:27:18][INFO] logging.py:  99: json_stats: {"cur_iter": "80", "eta": "0:01:05", "split": "test_iter", "time_diff": 0.97374}
[04/30 13:27:19][INFO] logging.py:  99: json_stats: {"cur_iter": "81", "eta": "0:01:06", "split": "test_iter", "time_diff": 1.01166}
[04/30 13:27:20][INFO] logging.py:  99: json_stats: {"cur_iter": "82", "eta": "0:01:05", "split": "test_iter", "time_diff": 1.00085}
[04/30 13:27:21][INFO] logging.py:  99: json_stats: {"cur_iter": "83", "eta": "0:01:05", "split": "test_iter", "time_diff": 1.02920}
[04/30 13:27:22][INFO] logging.py:  99: json_stats: {"cur_iter": "84", "eta": "0:01:02", "split": "test_iter", "time_diff": 0.99201}
[04/30 13:27:23][INFO] logging.py:  99: json_stats: {"cur_iter": "85", "eta": "0:01:05", "split": "test_iter", "time_diff": 1.05967}
[04/30 13:27:24][INFO] logging.py:  99: json_stats: {"cur_iter": "86", "eta": "0:01:00", "split": "test_iter", "time_diff": 0.99160}
[04/30 13:27:25][INFO] logging.py:  99: json_stats: {"cur_iter": "87", "eta": "0:00:59", "split": "test_iter", "time_diff": 0.99575}
[04/30 13:27:26][INFO] logging.py:  99: json_stats: {"cur_iter": "88", "eta": "0:01:00", "split": "test_iter", "time_diff": 1.02140}
[04/30 13:27:27][INFO] logging.py:  99: json_stats: {"cur_iter": "89", "eta": "0:00:57", "split": "test_iter", "time_diff": 0.99024}
[04/30 13:27:28][INFO] logging.py:  99: json_stats: {"cur_iter": "90", "eta": "0:00:57", "split": "test_iter", "time_diff": 1.00359}
[04/30 13:27:29][INFO] logging.py:  99: json_stats: {"cur_iter": "91", "eta": "0:00:56", "split": "test_iter", "time_diff": 1.01658}
[04/30 13:27:30][INFO] logging.py:  99: json_stats: {"cur_iter": "92", "eta": "0:00:54", "split": "test_iter", "time_diff": 0.99746}
[04/30 13:27:31][INFO] logging.py:  99: json_stats: {"cur_iter": "93", "eta": "0:00:55", "split": "test_iter", "time_diff": 1.01877}
[04/30 13:27:32][INFO] logging.py:  99: json_stats: {"cur_iter": "94", "eta": "0:00:53", "split": "test_iter", "time_diff": 1.01644}
[04/30 13:27:33][INFO] logging.py:  99: json_stats: {"cur_iter": "95", "eta": "0:00:53", "split": "test_iter", "time_diff": 1.02245}
[04/30 13:27:35][INFO] logging.py:  99: json_stats: {"cur_iter": "96", "eta": "0:00:55", "split": "test_iter", "time_diff": 1.08705}
[04/30 13:27:36][INFO] logging.py:  99: json_stats: {"cur_iter": "97", "eta": "0:00:50", "split": "test_iter", "time_diff": 1.00225}
[04/30 13:27:37][INFO] logging.py:  99: json_stats: {"cur_iter": "98", "eta": "0:00:50", "split": "test_iter", "time_diff": 1.03034}
[04/30 13:27:38][INFO] logging.py:  99: json_stats: {"cur_iter": "99", "eta": "0:00:48", "split": "test_iter", "time_diff": 1.00268}
[04/30 13:27:39][INFO] logging.py:  99: json_stats: {"cur_iter": "100", "eta": "0:00:46", "split": "test_iter", "time_diff": 0.99946}
[04/30 13:27:40][INFO] logging.py:  99: json_stats: {"cur_iter": "101", "eta": "0:00:46", "split": "test_iter", "time_diff": 1.00447}
[04/30 13:27:41][INFO] logging.py:  99: json_stats: {"cur_iter": "102", "eta": "0:00:45", "split": "test_iter", "time_diff": 1.00700}
[04/30 13:27:42][INFO] logging.py:  99: json_stats: {"cur_iter": "103", "eta": "0:00:39", "split": "test_iter", "time_diff": 0.90742}
[04/30 13:27:43][INFO] logging.py:  99: json_stats: {"cur_iter": "104", "eta": "0:00:43", "split": "test_iter", "time_diff": 1.00762}
[04/30 13:27:44][INFO] logging.py:  99: json_stats: {"cur_iter": "105", "eta": "0:00:44", "split": "test_iter", "time_diff": 1.05302}
[04/30 13:27:45][INFO] logging.py:  99: json_stats: {"cur_iter": "106", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.02078}
[04/30 13:27:46][INFO] logging.py:  99: json_stats: {"cur_iter": "107", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.04360}
[04/30 13:27:47][INFO] logging.py:  99: json_stats: {"cur_iter": "108", "eta": "0:00:37", "split": "test_iter", "time_diff": 0.97377}
[04/30 13:27:48][INFO] logging.py:  99: json_stats: {"cur_iter": "109", "eta": "0:00:39", "split": "test_iter", "time_diff": 1.02931}
[04/30 13:27:49][INFO] logging.py:  99: json_stats: {"cur_iter": "110", "eta": "0:00:38", "split": "test_iter", "time_diff": 1.02914}
[04/30 13:27:50][INFO] logging.py:  99: json_stats: {"cur_iter": "111", "eta": "0:00:35", "split": "test_iter", "time_diff": 0.97850}
[04/30 13:27:51][INFO] logging.py:  99: json_stats: {"cur_iter": "112", "eta": "0:00:34", "split": "test_iter", "time_diff": 0.99496}
[04/30 13:27:52][INFO] logging.py:  99: json_stats: {"cur_iter": "113", "eta": "0:00:34", "split": "test_iter", "time_diff": 1.01756}
[04/30 13:27:53][INFO] logging.py:  99: json_stats: {"cur_iter": "114", "eta": "0:00:29", "split": "test_iter", "time_diff": 0.89413}
[04/30 13:27:54][INFO] logging.py:  99: json_stats: {"cur_iter": "115", "eta": "0:00:32", "split": "test_iter", "time_diff": 1.02099}
[04/30 13:27:55][INFO] logging.py:  99: json_stats: {"cur_iter": "116", "eta": "0:00:31", "split": "test_iter", "time_diff": 1.02469}
[04/30 13:27:56][INFO] logging.py:  99: json_stats: {"cur_iter": "117", "eta": "0:00:30", "split": "test_iter", "time_diff": 1.00784}
[04/30 13:27:57][INFO] logging.py:  99: json_stats: {"cur_iter": "118", "eta": "0:00:30", "split": "test_iter", "time_diff": 1.05591}
[04/30 13:27:58][INFO] logging.py:  99: json_stats: {"cur_iter": "119", "eta": "0:00:27", "split": "test_iter", "time_diff": 0.98097}
[04/30 13:27:59][INFO] logging.py:  99: json_stats: {"cur_iter": "120", "eta": "0:00:27", "split": "test_iter", "time_diff": 1.01105}
[04/30 13:28:00][INFO] logging.py:  99: json_stats: {"cur_iter": "121", "eta": "0:00:25", "split": "test_iter", "time_diff": 0.99393}
[04/30 13:28:01][INFO] logging.py:  99: json_stats: {"cur_iter": "122", "eta": "0:00:24", "split": "test_iter", "time_diff": 0.99052}
[04/30 13:28:02][INFO] logging.py:  99: json_stats: {"cur_iter": "123", "eta": "0:00:23", "split": "test_iter", "time_diff": 0.99350}
[04/30 13:28:03][INFO] logging.py:  99: json_stats: {"cur_iter": "124", "eta": "0:00:22", "split": "test_iter", "time_diff": 0.99164}
[04/30 13:28:04][INFO] logging.py:  99: json_stats: {"cur_iter": "125", "eta": "0:00:21", "split": "test_iter", "time_diff": 0.99848}
[04/30 13:28:05][INFO] logging.py:  99: json_stats: {"cur_iter": "126", "eta": "0:00:21", "split": "test_iter", "time_diff": 1.03819}
[04/30 13:28:06][INFO] logging.py:  99: json_stats: {"cur_iter": "127", "eta": "0:00:19", "split": "test_iter", "time_diff": 0.99458}
[04/30 13:28:07][INFO] logging.py:  99: json_stats: {"cur_iter": "128", "eta": "0:00:19", "split": "test_iter", "time_diff": 1.01313}
[04/30 13:28:08][INFO] logging.py:  99: json_stats: {"cur_iter": "129", "eta": "0:00:17", "split": "test_iter", "time_diff": 0.97736}
[04/30 13:28:09][INFO] logging.py:  99: json_stats: {"cur_iter": "130", "eta": "0:00:17", "split": "test_iter", "time_diff": 1.00084}
[04/30 13:28:10][INFO] logging.py:  99: json_stats: {"cur_iter": "131", "eta": "0:00:16", "split": "test_iter", "time_diff": 1.03849}
[04/30 13:28:11][INFO] logging.py:  99: json_stats: {"cur_iter": "132", "eta": "0:00:15", "split": "test_iter", "time_diff": 1.00089}
[04/30 13:28:12][INFO] logging.py:  99: json_stats: {"cur_iter": "133", "eta": "0:00:14", "split": "test_iter", "time_diff": 1.02572}
[04/30 13:28:13][INFO] logging.py:  99: json_stats: {"cur_iter": "134", "eta": "0:00:12", "split": "test_iter", "time_diff": 0.98600}
[04/30 13:28:14][INFO] logging.py:  99: json_stats: {"cur_iter": "135", "eta": "0:00:11", "split": "test_iter", "time_diff": 0.98410}
[04/30 13:28:15][INFO] logging.py:  99: json_stats: {"cur_iter": "136", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.88481}
[04/30 13:28:16][INFO] logging.py:  99: json_stats: {"cur_iter": "137", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.99717}
[04/30 13:28:17][INFO] logging.py:  99: json_stats: {"cur_iter": "138", "eta": "0:00:08", "split": "test_iter", "time_diff": 0.98699}
[04/30 13:28:18][INFO] logging.py:  99: json_stats: {"cur_iter": "139", "eta": "0:00:07", "split": "test_iter", "time_diff": 0.96501}
[04/30 13:28:19][INFO] logging.py:  99: json_stats: {"cur_iter": "140", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.94791}
[04/30 13:28:20][INFO] logging.py:  99: json_stats: {"cur_iter": "141", "eta": "0:00:05", "split": "test_iter", "time_diff": 0.88370}
[04/30 13:28:21][INFO] logging.py:  99: json_stats: {"cur_iter": "142", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.92033}
[04/30 13:28:22][INFO] logging.py:  99: json_stats: {"cur_iter": "143", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.90607}
[04/30 13:28:23][INFO] logging.py:  99: json_stats: {"cur_iter": "144", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.90586}
[04/30 13:28:24][INFO] logging.py:  99: json_stats: {"cur_iter": "145", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.90592}
[04/30 13:28:24][INFO] logging.py:  99: json_stats: {"cur_iter": "146", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.43043}
[04/30 13:28:24][WARNING] meters.py: 381: clip count 0: 3, 1: 3, 2: 3, 3: 3, 4: 3, 5: 3, 6: 3, 7: 3, 8: 3, 9: 3, 10: 3, 11: 3, 12: 3, 13: 3, 14: 3, 15: 3, 16: 3, 17: 3, 18: 3, 19: 3, 20: 3, 21: 3, 22: 3, 23: 3, 24: 3, 25: 3, 26: 3, 27: 3, 28: 3, 29: 3, 30: 3, 31: 3, 32: 3, 33: 3, 34: 3, 35: 3, 36: 3, 37: 3, 38: 3, 39: 3, 40: 3, 41: 3, 42: 3, 43: 3, 44: 3, 45: 3, 46: 3, 47: 3, 48: 3, 49: 3, 50: 3, 51: 3, 52: 3, 53: 3, 54: 3, 55: 3, 56: 3, 57: 3, 58: 3, 59: 3, 60: 3, 61: 3, 62: 3, 63: 3, 64: 3, 65: 3, 66: 3, 67: 3, 68: 3, 69: 3, 70: 3, 71: 3, 72: 3, 73: 3, 74: 3, 75: 3, 76: 3, 77: 3, 78: 3, 79: 3, 80: 3, 81: 3, 82: 3, 83: 3, 84: 3, 85: 3, 86: 3, 87: 3, 88: 3, 89: 3, 90: 3, 91: 3, 92: 3, 93: 3, 94: 3, 95: 3, 96: 3, 97: 3, 98: 3, 99: 3, 100: 3, 101: 3, 102: 3, 103: 3, 104: 3, 105: 3, 106: 3, 107: 3, 108: 3, 109: 3, 110: 3, 111: 3, 112: 3, 113: 3, 114: 3, 115: 3, 116: 3, 117: 3, 118: 3, 119: 3, 120: 3, 121: 3, 122: 3, 123: 3, 124: 3, 125: 3, 126: 3, 127: 3, 128: 3, 129: 3, 130: 3, 131: 3, 132: 3, 133: 3, 134: 3, 135: 3, 136: 3, 137: 3, 138: 3, 139: 3, 140: 3, 141: 3, 142: 3, 143: 3, 144: 3, 145: 3, 146: 3, 147: 3, 148: 3, 149: 3, 150: 3, 151: 3, 152: 3, 153: 3, 154: 3, 155: 3, 156: 3, 157: 3, 158: 3, 159: 3, 160: 3, 161: 3, 162: 3, 163: 3, 164: 3, 165: 3, 166: 3, 167: 3, 168: 3, 169: 3, 170: 3, 171: 3, 172: 3, 173: 3, 174: 3, 175: 3, 176: 3, 177: 3, 178: 3, 179: 3, 180: 3, 181: 3, 182: 3, 183: 3, 184: 3, 185: 3, 186: 3, 187: 3, 188: 3, 189: 3, 190: 3, 191: 3, 192: 3, 193: 3, 194: 3, 195: 3, 196: 3, 197: 3, 198: 3, 199: 3, 200: 3, 201: 3, 202: 3, 203: 3, 204: 3, 205: 3, 206: 3, 207: 3, 208: 3, 209: 3, 210: 3, 211: 3, 212: 3, 213: 3, 214: 3, 215: 3, 216: 3, 217: 3, 218: 3, 219: 3, 220: 3, 221: 3, 222: 3, 223: 3, 224: 3, 225: 3, 226: 3, 227: 3, 228: 3, 229: 3, 230: 3, 231: 3, 232: 3, 233: 3, 234: 3, 235: 3, 236: 3, 237: 3, 238: 3, 239: 3, 240: 3, 241: 3, 242: 3, 243: 3, 244: 3, 245: 3, 246: 3, 247: 3, 248: 3, 249: 3, 250: 3, 251: 3, 252: 3, 253: 3, 254: 3, 255: 3, 256: 3, 257: 3, 258: 3, 259: 3, 260: 3, 261: 3, 262: 3, 263: 3, 264: 3, 265: 3, 266: 3, 267: 3, 268: 3, 269: 3, 270: 3, 271: 3, 272: 3, 273: 3, 274: 3, 275: 3, 276: 3, 277: 3, 278: 3, 279: 3, 280: 3, 281: 3, 282: 3, 283: 3, 284: 3, 285: 3, 286: 3, 287: 3, 288: 3, 289: 3, 290: 3, 291: 3, 292: 3, 293: 3, 294: 3, 295: 3, 296: 3, 297: 3, 298: 3, 299: 3, 300: 3, 301: 3, 302: 3, 303: 3, 304: 3, 305: 3, 306: 3, 307: 3, 308: 3, 309: 3, 310: 3, 311: 3, 312: 3, 313: 3, 314: 3, 315: 3, 316: 3, 317: 3, 318: 3, 319: 3, 320: 3, 321: 3, 322: 3, 323: 3, 324: 3, 325: 3, 326: 3, 327: 3, 328: 3, 329: 3, 330: 3, 331: 3, 332: 3, 333: 3, 334: 3, 335: 3, 336: 3, 337: 3, 338: 3, 339: 3, 340: 3, 341: 3, 342: 3, 343: 3, 344: 3, 345: 3, 346: 3, 347: 3, 348: 3, 349: 3, 350: 3, 351: 3, 352: 3, 353: 3, 354: 3, 355: 3, 356: 3, 357: 3, 358: 3, 359: 3, 360: 3, 361: 3, 362: 3, 363: 3, 364: 3, 365: 3, 366: 3, 367: 3, 368: 3, 369: 3, 370: 3, 371: 3, 372: 3, 373: 3, 374: 3, 375: 3, 376: 3, 377: 3, 378: 3, 379: 3, 380: 3, 381: 3, 382: 3, 383: 3, 384: 3, 385: 3, 386: 3, 387: 3, 388: 3, 389: 3, 390: 3, 391: 3, 392: 3, 393: 3, 394: 3, 395: 3, 396: 3, 397: 3, 398: 3, 399: 3, 400: 3, 401: 3, 402: 3, 403: 3, 404: 3, 405: 3, 406: 3, 407: 3, 408: 3, 409: 3, 410: 3, 411: 3, 412: 3, 413: 3, 414: 3, 415: 3, 416: 3, 417: 3, 418: 3, 419: 3, 420: 3, 421: 3, 422: 3, 423: 3, 424: 3, 425: 3, 426: 3, 427: 3, 428: 3, 429: 3, 430: 3, 431: 3, 432: 3, 433: 3, 434: 3, 435: 3, 436: 3, 437: 3, 438: 3, 439: 3, 440: 3, 441: 3, 442: 3, 443: 3, 444: 3, 445: 3, 446: 3, 447: 3, 448: 3, 449: 3, 450: 3, 451: 3, 452: 3, 453: 3, 454: 3, 455: 3, 456: 3, 457: 3, 458: 3, 459: 3, 460: 3, 461: 3, 462: 3, 463: 3, 464: 3, 465: 3, 466: 3, 467: 3, 468: 3, 469: 3, 470: 3, 471: 3, 472: 3, 473: 3, 474: 3, 475: 3, 476: 3, 477: 3, 478: 3, 479: 3, 480: 3, 481: 3, 482: 3, 483: 3, 484: 3, 485: 3, 486: 3, 487: 3, 488: 3, 489: 3, 490: 3, 491: 3, 492: 3, 493: 3, 494: 3, 495: 3, 496: 3, 497: 3, 498: 3, 499: 3, 500: 3, 501: 3, 502: 3, 503: 3, 504: 3, 505: 3, 506: 3, 507: 3, 508: 3, 509: 3, 510: 3, 511: 3, 512: 3, 513: 3, 514: 3, 515: 3, 516: 3, 517: 3, 518: 3, 519: 3, 520: 3, 521: 3, 522: 3, 523: 3, 524: 3, 525: 3, 526: 3, 527: 3, 528: 3, 529: 3, 530: 3, 531: 3, 532: 3, 533: 3, 534: 3, 535: 3, 536: 3, 537: 3, 538: 3, 539: 3, 540: 3, 541: 3, 542: 3, 543: 3, 544: 3, 545: 3, 546: 3, 547: 3, 548: 3, 549: 3, 550: 3, 551: 3, 552: 3, 553: 3, 554: 3, 555: 3, 556: 3, 557: 3, 558: 3, 559: 3, 560: 3, 561: 3, 562: 3, 563: 3, 564: 3, 565: 3, 566: 3, 567: 3, 568: 3, 569: 3, 570: 3, 571: 3, 572: 3, 573: 3, 574: 3, 575: 3, 576: 3, 577: 3, 578: 3, 579: 3, 580: 3, 581: 3, 582: 3, 583: 3, 584: 3, 585: 3, 586: 3, 587: 3, 588: 3, 589: 3, 590: 3, 591: 3, 592: 3, 593: 3, 594: 3, 595: 3, 596: 3, 597: 3, 598: 3, 599: 3, 600: 3, 601: 3, 602: 3, 603: 3, 604: 3, 605: 3, 606: 3, 607: 3, 608: 3, 609: 3, 610: 3, 611: 3, 612: 3, 613: 3, 614: 3, 615: 3, 616: 3, 617: 3, 618: 3, 619: 3, 620: 3, 621: 3, 622: 3, 623: 3, 624: 3, 625: 3, 626: 3, 627: 3, 628: 3, 629: 3, 630: 3, 631: 3, 632: 3, 633: 3, 634: 3, 635: 3, 636: 3, 637: 3, 638: 3, 639: 3, 640: 3, 641: 3, 642: 3, 643: 3, 644: 3, 645: 3, 646: 3, 647: 3, 648: 3, 649: 3, 650: 3, 651: 3, 652: 3, 653: 3, 654: 3, 655: 3, 656: 3, 657: 3, 658: 3, 659: 3, 660: 3, 661: 3, 662: 3, 663: 3, 664: 3, 665: 3, 666: 3, 667: 3, 668: 3, 669: 3, 670: 3, 671: 3, 672: 3, 673: 3, 674: 3, 675: 3, 676: 3, 677: 3, 678: 3, 679: 3, 680: 3, 681: 3, 682: 3, 683: 3, 684: 3, 685: 3, 686: 3, 687: 3, 688: 3, 689: 3, 690: 3, 691: 3, 692: 3, 693: 3, 694: 3, 695: 3, 696: 3, 697: 3, 698: 3, 699: 3, 700: 3, 701: 3, 702: 3, 703: 3, 704: 3, 705: 3, 706: 3, 707: 3, 708: 3, 709: 3, 710: 3, 711: 3, 712: 3, 713: 3, 714: 3, 715: 3, 716: 3, 717: 3, 718: 3, 719: 3, 720: 3, 721: 3, 722: 3, 723: 3, 724: 3, 725: 3, 726: 3, 727: 3, 728: 3, 729: 3, 730: 3, 731: 3, 732: 3, 733: 3, 734: 3, 735: 3, 736: 3, 737: 3, 738: 3, 739: 3, 740: 3, 741: 3, 742: 3, 743: 3, 744: 3, 745: 3, 746: 3, 747: 3, 748: 3, 749: 3, 750: 3, 751: 3, 752: 3, 753: 3, 754: 3, 755: 3, 756: 3, 757: 3, 758: 3, 759: 3, 760: 3, 761: 3, 762: 3, 763: 3, 764: 3, 765: 3, 766: 3, 767: 3, 768: 3, 769: 3, 770: 3, 771: 3, 772: 3, 773: 3, 774: 3, 775: 3, 776: 3, 777: 3, 778: 3, 779: 3, 780: 3, 781: 3, 782: 3, 783: 3, 784: 3, 785: 3, 786: 3, 787: 3, 788: 3, 789: 3, 790: 3, 791: 3, 792: 3, 793: 3, 794: 3, 795: 3, 796: 3, 797: 3, 798: 3, 799: 3, 800: 3, 801: 3, 802: 3, 803: 3, 804: 3, 805: 3, 806: 3, 807: 3, 808: 3, 809: 3, 810: 3, 811: 3, 812: 3, 813: 3, 814: 3, 815: 3, 816: 3, 817: 3, 818: 3, 819: 3, 820: 3, 821: 3, 822: 3, 823: 3, 824: 3, 825: 3, 826: 3, 827: 3, 828: 3, 829: 3, 830: 3, 831: 3, 832: 3, 833: 3, 834: 3, 835: 3, 836: 3, 837: 3, 838: 3, 839: 3, 840: 3, 841: 3, 842: 3, 843: 3, 844: 3, 845: 3, 846: 3, 847: 3, 848: 3, 849: 3, 850: 3, 851: 3, 852: 3, 853: 3, 854: 3, 855: 3, 856: 3, 857: 3, 858: 3, 859: 3, 860: 3, 861: 3, 862: 3, 863: 3, 864: 3, 865: 3, 866: 3, 867: 3, 868: 3, 869: 3, 870: 3, 871: 3, 872: 3, 873: 3, 874: 3, 875: 3, 876: 3, 877: 3, 878: 3, 879: 3, 880: 3, 881: 3, 882: 3, 883: 3, 884: 3, 885: 3, 886: 3, 887: 3, 888: 3, 889: 3, 890: 3, 891: 3, 892: 3, 893: 3, 894: 3, 895: 3, 896: 3, 897: 3, 898: 3, 899: 3, 900: 3, 901: 3, 902: 3, 903: 3, 904: 3, 905: 3, 906: 3, 907: 3, 908: 3, 909: 3, 910: 3, 911: 3, 912: 3, 913: 3, 914: 3, 915: 3, 916: 3, 917: 3, 918: 3, 919: 3, 920: 3, 921: 3, 922: 3, 923: 3, 924: 3, 925: 3, 926: 3, 927: 3, 928: 3, 929: 3, 930: 3, 931: 3, 932: 3, 933: 3, 934: 3, 935: 3, 936: 3, 937: 3, 938: 3, 939: 3, 940: 3, 941: 3, 942: 3, 943: 3, 944: 3, 945: 3, 946: 3, 947: 3, 948: 3, 949: 3, 950: 3, 951: 3, 952: 3, 953: 3, 954: 3, 955: 3, 956: 3, 957: 3, 958: 3, 959: 3, 960: 3, 961: 3, 962: 3, 963: 3, 964: 3, 965: 3, 966: 3, 967: 3, 968: 3, 969: 3, 970: 3, 971: 3, 972: 3, 973: 3, 974: 3, 975: 3, 976: 3, 977: 3, 978: 3, 979: 3, 980: 3, 981: 3, 982: 3, 983: 3, 984: 3, 985: 3, 986: 3, 987: 3, 988: 3, 989: 3, 990: 3, 991: 3, 992: 3, 993: 3, 994: 3, 995: 3, 996: 3, 997: 3, 998: 3, 999: 3, 1000: 3, 1001: 3, 1002: 3, 1003: 3, 1004: 3, 1005: 3, 1006: 3, 1007: 3, 1008: 3, 1009: 3, 1010: 3, 1011: 3, 1012: 3, 1013: 3, 1014: 3, 1015: 3, 1016: 3, 1017: 3, 1018: 3, 1019: 3, 1020: 3, 1021: 3, 1022: 3, 1023: 3, 1024: 3, 1025: 3, 1026: 3, 1027: 3, 1028: 3, 1029: 3, 1030: 3, 1031: 3, 1032: 3, 1033: 3, 1034: 3, 1035: 3, 1036: 3, 1037: 3, 1038: 3, 1039: 3, 1040: 3, 1041: 3, 1042: 3, 1043: 3, 1044: 3, 1045: 3, 1046: 3, 1047: 3, 1048: 3, 1049: 3, 1050: 3, 1051: 3, 1052: 3, 1053: 3, 1054: 3, 1055: 3, 1056: 3, 1057: 3, 1058: 3, 1059: 3, 1060: 3, 1061: 3, 1062: 3, 1063: 3, 1064: 3, 1065: 3, 1066: 3, 1067: 3, 1068: 3, 1069: 3, 1070: 3, 1071: 3, 1072: 3, 1073: 3, 1074: 3, 1075: 3, 1076: 3, 1077: 3, 1078: 3, 1079: 3, 1080: 3, 1081: 3, 1082: 3, 1083: 3, 1084: 3, 1085: 3, 1086: 3, 1087: 3, 1088: 3, 1089: 3, 1090: 3, 1091: 3, 1092: 3, 1093: 3, 1094: 3, 1095: 3, 1096: 3, 1097: 3, 1098: 3, 1099: 3, 1100: 3, 1101: 3, 1102: 3, 1103: 3, 1104: 3, 1105: 3, 1106: 3, 1107: 3, 1108: 3, 1109: 3, 1110: 3, 1111: 3, 1112: 3, 1113: 3, 1114: 3, 1115: 3, 1116: 3, 1117: 3, 1118: 3, 1119: 3, 1120: 3, 1121: 3, 1122: 3, 1123: 3, 1124: 3, 1125: 3, 1126: 3, 1127: 3, 1128: 3, 1129: 3, 1130: 3, 1131: 3, 1132: 3, 1133: 3, 1134: 3, 1135: 3, 1136: 3, 1137: 3, 1138: 3, 1139: 3, 1140: 3, 1141: 3, 1142: 3, 1143: 3, 1144: 3, 1145: 3, 1146: 3, 1147: 3, 1148: 3, 1149: 3, 1150: 3, 1151: 3, 1152: 3, 1153: 3, 1154: 3, 1155: 3, 1156: 3, 1157: 3, 1158: 3, 1159: 3, 1160: 3, 1161: 3, 1162: 3, 1163: 3, 1164: 3, 1165: 3, 1166: 3, 1167: 3, 1168: 3, 1169: 3, 1170: 3, 1171: 3, 1172: 3, 1173: 3, 1174: 3, 1175: 3, 1176: 3, 1177: 3, 1178: 3, 1179: 3, 1180: 3, 1181: 3, 1182: 3, 1183: 3, 1184: 3, 1185: 3, 1186: 3, 1187: 3, 1188: 3, 1189: 3, 1190: 3, 1191: 3, 1192: 3, 1193: 3, 1194: 3, 1195: 3, 1196: 3, 1197: 3, 1198: 3, 1199: 3, 1200: 3, 1201: 3, 1202: 3, 1203: 3, 1204: 3, 1205: 3, 1206: 3, 1207: 3, 1208: 3, 1209: 3, 1210: 3, 1211: 3, 1212: 3, 1213: 3, 1214: 3, 1215: 3, 1216: 3, 1217: 3, 1218: 3, 1219: 3, 1220: 3, 1221: 3, 1222: 3, 1223: 3, 1224: 3, 1225: 3, 1226: 3, 1227: 3, 1228: 3, 1229: 3, 1230: 3, 1231: 3, 1232: 3, 1233: 3, 1234: 3, 1235: 3, 1236: 3, 1237: 3, 1238: 3, 1239: 3, 1240: 3, 1241: 3, 1242: 3, 1243: 3, 1244: 3, 1245: 3, 1246: 3, 1247: 3, 1248: 3, 1249: 3, 1250: 3, 1251: 3, 1252: 3, 1253: 3, 1254: 3, 1255: 3, 1256: 3, 1257: 3, 1258: 3, 1259: 3, 1260: 3, 1261: 3, 1262: 3, 1263: 3, 1264: 3, 1265: 3, 1266: 3, 1267: 3, 1268: 3, 1269: 3, 1270: 3, 1271: 3, 1272: 3, 1273: 3, 1274: 3, 1275: 3, 1276: 3, 1277: 3, 1278: 3, 1279: 3, 1280: 3, 1281: 3, 1282: 3, 1283: 3, 1284: 3, 1285: 3, 1286: 3, 1287: 3, 1288: 3, 1289: 3, 1290: 3, 1291: 3, 1292: 3, 1293: 3, 1294: 3, 1295: 3, 1296: 3, 1297: 3, 1298: 3, 1299: 3, 1300: 3, 1301: 3, 1302: 3, 1303: 3, 1304: 3, 1305: 3, 1306: 3, 1307: 3, 1308: 3, 1309: 3, 1310: 3, 1311: 3, 1312: 3, 1313: 3, 1314: 3, 1315: 3, 1316: 3, 1317: 3, 1318: 3, 1319: 3, 1320: 3, 1321: 3, 1322: 3, 1323: 3, 1324: 3, 1325: 3, 1326: 3, 1327: 3, 1328: 3, 1329: 3, 1330: 3, 1331: 3, 1332: 3, 1333: 3, 1334: 3, 1335: 3, 1336: 3, 1337: 3, 1338: 3, 1339: 3, 1340: 3, 1341: 3, 1342: 3, 1343: 3, 1344: 3, 1345: 3, 1346: 3, 1347: 3, 1348: 3, 1349: 3, 1350: 3, 1351: 3, 1352: 3, 1353: 3, 1354: 3, 1355: 3, 1356: 3, 1357: 3, 1358: 3, 1359: 3, 1360: 3, 1361: 3, 1362: 3, 1363: 3, 1364: 3, 1365: 3, 1366: 3, 1367: 3, 1368: 3, 1369: 3, 1370: 3, 1371: 3, 1372: 3, 1373: 3, 1374: 3, 1375: 3, 1376: 3, 1377: 3, 1378: 3, 1379: 3, 1380: 3, 1381: 3, 1382: 3, 1383: 3, 1384: 4, 1385: 3, 1386: 3, 1387: 3, 1388: 3, 1389: 3, 1390: 3, 1391: 3, 1392: 3, 1393: 3, 1394: 3, 1395: 3, 1396: 3, 1397: 3, 1398: 3, 1399: 3, 1400: 3, 1401: 3, 1402: 3, 1403: 3, 1404: 3, 1405: 3, 1406: 3, 1407: 3, 1408: 3, 1409: 3, 1410: 3, 1411: 3, 1412: 3, 1413: 3, 1414: 3, 1415: 3, 1416: 3, 1417: 3, 1418: 3, 1419: 3, 1420: 3, 1421: 3, 1422: 3, 1423: 3, 1424: 3, 1425: 3, 1426: 3, 1427: 3, 1428: 3, 1429: 3, 1430: 3, 1431: 3, 1432: 3, 1433: 3, 1434: 3, 1435: 3, 1436: 3, 1437: 3, 1438: 3, 1439: 3, 1440: 3, 1441: 3, 1442: 3, 1443: 3, 1444: 3, 1445: 3, 1446: 3, 1447: 3, 1448: 3, 1449: 3, 1450: 3, 1451: 3, 1452: 3, 1453: 3, 1454: 3, 1455: 3, 1456: 3, 1457: 3, 1458: 3, 1459: 3, 1460: 3, 1461: 3, 1462: 3, 1463: 3, 1464: 3, 1465: 3, 1466: 3, 1467: 3, 1468: 3, 1469: 3, 1470: 3, 1471: 3, 1472: 3, 1473: 3, 1474: 3, 1475: 3, 1476: 3, 1477: 3, 1478: 3, 1479: 3, 1480: 3, 1481: 3, 1482: 3, 1483: 3, 1484: 3, 1485: 3, 1486: 3, 1487: 3, 1488: 3, 1489: 3, 1490: 3, 1491: 3, 1492: 3, 1493: 3, 1494: 3, 1495: 3, 1496: 3, 1497: 3, 1498: 3, 1499: 3, 1500: 3, 1501: 3, 1502: 3, 1503: 3, 1504: 3, 1505: 3, 1506: 3, 1507: 3, 1508: 3, 1509: 3, 1510: 3, 1511: 3, 1512: 3, 1513: 3, 1514: 3, 1515: 3, 1516: 3, 1517: 3, 1518: 3, 1519: 3, 1520: 3, 1521: 3, 1522: 3, 1523: 3, 1524: 3, 1525: 3, 1526: 3, 1527: 3, 1528: 3, 1529: 3, 1530: 3, 1531: 3, 1532: 3, 1533: 3, 1534: 3, 1535: 3, 1536: 3, 1537: 3, 1538: 3, 1539: 3, 1540: 3, 1541: 3, 1542: 3, 1543: 3, 1544: 3, 1545: 3, 1546: 3, 1547: 3, 1548: 3, 1549: 3, 1550: 3, 1551: 3, 1552: 3, 1553: 3, 1554: 3, 1555: 3, 1556: 3, 1557: 3, 1558: 3, 1559: 3, 1560: 3, 1561: 3, 1562: 3, 1563: 3, 1564: 3, 1565: 3, 1566: 3, 1567: 3, 1568: 3, 1569: 3, 1570: 3, 1571: 3, 1572: 3, 1573: 3, 1574: 3, 1575: 3, 1576: 3, 1577: 3, 1578: 3, 1579: 3, 1580: 3, 1581: 3, 1582: 3, 1583: 3, 1584: 3, 1585: 3, 1586: 3, 1587: 3, 1588: 3, 1589: 3, 1590: 3, 1591: 3, 1592: 3, 1593: 3, 1594: 3, 1595: 3, 1596: 3, 1597: 3, 1598: 3, 1599: 3, 1600: 3, 1601: 3, 1602: 3, 1603: 3, 1604: 3, 1605: 3, 1606: 3, 1607: 3, 1608: 3, 1609: 3, 1610: 3, 1611: 3, 1612: 3, 1613: 3, 1614: 3, 1615: 3, 1616: 3, 1617: 3, 1618: 3, 1619: 3, 1620: 3, 1621: 3, 1622: 3, 1623: 3, 1624: 3, 1625: 3, 1626: 3, 1627: 3, 1628: 3, 1629: 3, 1630: 3, 1631: 3, 1632: 3, 1633: 3, 1634: 3, 1635: 3, 1636: 3, 1637: 3, 1638: 3, 1639: 3, 1640: 3, 1641: 3, 1642: 3, 1643: 3, 1644: 3, 1645: 3, 1646: 3, 1647: 3, 1648: 3, 1649: 3, 1650: 3, 1651: 3, 1652: 3, 1653: 3, 1654: 3, 1655: 3, 1656: 3, 1657: 3, 1658: 3, 1659: 3, 1660: 3, 1661: 3, 1662: 3, 1663: 3, 1664: 3, 1665: 3, 1666: 3, 1667: 3, 1668: 3, 1669: 3, 1670: 3, 1671: 3, 1672: 3, 1673: 3, 1674: 3, 1675: 3, 1676: 3, 1677: 3, 1678: 3, 1679: 3, 1680: 3, 1681: 3, 1682: 3, 1683: 3, 1684: 3, 1685: 3, 1686: 3, 1687: 3, 1688: 3, 1689: 3, 1690: 3, 1691: 3, 1692: 3, 1693: 3, 1694: 3, 1695: 3, 1696: 3, 1697: 3, 1698: 3, 1699: 3, 1700: 3, 1701: 3, 1702: 3, 1703: 3, 1704: 3, 1705: 3, 1706: 3, 1707: 3, 1708: 3, 1709: 3, 1710: 3, 1711: 3, 1712: 3, 1713: 3, 1714: 3, 1715: 3, 1716: 3, 1717: 3, 1718: 3, 1719: 3, 1720: 3, 1721: 3, 1722: 3, 1723: 3, 1724: 3, 1725: 3, 1726: 3, 1727: 3, 1728: 3, 1729: 3, 1730: 3, 1731: 3, 1732: 3, 1733: 3, 1734: 3, 1735: 3, 1736: 3, 1737: 3, 1738: 3, 1739: 3, 1740: 3, 1741: 3, 1742: 3, 1743: 3, 1744: 3, 1745: 3, 1746: 3, 1747: 3, 1748: 3, 1749: 3, 1750: 3, 1751: 3, 1752: 3, 1753: 3, 1754: 3, 1755: 3, 1756: 3, 1757: 3, 1758: 3, 1759: 3, 1760: 3, 1761: 3, 1762: 3, 1763: 3, 1764: 3, 1765: 3, 1766: 3, 1767: 3, 1768: 3, 1769: 3, 1770: 3, 1771: 3, 1772: 3, 1773: 3, 1774: 3, 1775: 3, 1776: 3, 1777: 3, 1778: 3, 1779: 3, 1780: 3, 1781: 3, 1782: 3, 1783: 3, 1784: 3, 1785: 3, 1786: 3, 1787: 3, 1788: 3, 1789: 3, 1790: 3, 1791: 3, 1792: 3, 1793: 3, 1794: 3, 1795: 3, 1796: 3, 1797: 3, 1798: 3, 1799: 3, 1800: 3, 1801: 3, 1802: 3, 1803: 3, 1804: 3, 1805: 3, 1806: 3, 1807: 3, 1808: 3, 1809: 3, 1810: 3, 1811: 3, 1812: 3, 1813: 3, 1814: 3, 1815: 3, 1816: 3, 1817: 3, 1818: 3, 1819: 3, 1820: 3, 1821: 3, 1822: 3, 1823: 3, 1824: 3, 1825: 3, 1826: 3, 1827: 3, 1828: 3, 1829: 3, 1830: 3, 1831: 3, 1832: 3, 1833: 3, 1834: 3, 1835: 3, 1836: 3, 1837: 3, 1838: 3, 1839: 3, 1840: 3, 1841: 3, 1842: 3, 1843: 3, 1844: 3, 1845: 3, 1846: 3, 1847: 3, 1848: 3, 1849: 3, 1850: 3, 1851: 3, 1852: 3, 1853: 3, 1854: 3, 1855: 3, 1856: 3, 1857: 3, 1858: 3, 1859: 3, 1860: 3, 1861: 3, 1862: 3, 1863: 3, 1864: 3, 1865: 3, 1866: 3, 1867: 3, 1868: 3, 1869: 3, 1870: 3, 1871: 3, 1872: 3, 1873: 3, 1874: 3, 1875: 3, 1876: 3, 1877: 3, 1878: 3, 1879: 3, 1880: 3, 1881: 3, 1882: 3, 1883: 3, 1884: 3, 1885: 3, 1886: 3, 1887: 3, 1888: 3, 1889: 3, 1890: 3, 1891: 3, 1892: 3, 1893: 3, 1894: 3, 1895: 3, 1896: 3, 1897: 3, 1898: 3, 1899: 3, 1900: 3, 1901: 3, 1902: 3, 1903: 3, 1904: 3, 1905: 3, 1906: 3, 1907: 3, 1908: 3, 1909: 3, 1910: 3, 1911: 3, 1912: 3, 1913: 3, 1914: 3, 1915: 3, 1916: 3, 1917: 3, 1918: 3, 1919: 3, 1920: 3, 1921: 3, 1922: 3, 1923: 3, 1924: 3, 1925: 3, 1926: 3, 1927: 3, 1928: 3, 1929: 3, 1930: 3, 1931: 3, 1932: 3, 1933: 3, 1934: 3, 1935: 3, 1936: 3, 1937: 3, 1938: 3, 1939: 3, 1940: 3, 1941: 3, 1942: 3, 1943: 3, 1944: 3, 1945: 3, 1946: 3, 1947: 3, 1948: 3, 1949: 3, 1950: 3, 1951: 3, 1952: 3, 1953: 3, 1954: 3, 1955: 3, 1956: 3, 1957: 3, 1958: 3, 1959: 3, 1960: 3, 1961: 3, 1962: 3, 1963: 3, 1964: 3, 1965: 3, 1966: 3, 1967: 3, 1968: 3, 1969: 3, 1970: 3, 1971: 3, 1972: 3, 1973: 3, 1974: 3, 1975: 3, 1976: 3, 1977: 3, 1978: 3, 1979: 3, 1980: 3, 1981: 3, 1982: 3, 1983: 3, 1984: 3, 1985: 3, 1986: 3, 1987: 3, 1988: 3, 1989: 3, 1990: 3, 1991: 3, 1992: 3, 1993: 3, 1994: 3, 1995: 3, 1996: 3, 1997: 3, 1998: 3, 1999: 3, 2000: 3, 2001: 3, 2002: 3, 2003: 3, 2004: 3, 2005: 3, 2006: 3, 2007: 3, 2008: 3, 2009: 3, 2010: 3, 2011: 3, 2012: 3, 2013: 3, 2014: 3, 2015: 3, 2016: 3, 2017: 3, 2018: 3, 2019: 3, 2020: 3, 2021: 3, 2022: 3, 2023: 3, 2024: 3, 2025: 3, 2026: 3, 2027: 3, 2028: 3, 2029: 3, 2030: 3, 2031: 3, 2032: 3, 2033: 3, 2034: 3, 2035: 3, 2036: 3, 2037: 3, 2038: 3, 2039: 3, 2040: 3, 2041: 3, 2042: 3, 2043: 3, 2044: 3, 2045: 3, 2046: 3, 2047: 3, 2048: 3, 2049: 3, 2050: 3, 2051: 3, 2052: 3, 2053: 3, 2054: 3, 2055: 3, 2056: 3, 2057: 3, 2058: 3, 2059: 3, 2060: 3, 2061: 3, 2062: 3, 2063: 3, 2064: 3, 2065: 3, 2066: 3, 2067: 3, 2068: 3, 2069: 3, 2070: 3, 2071: 3, 2072: 3, 2073: 3, 2074: 3, 2075: 3, 2076: 3, 2077: 3, 2078: 3, 2079: 3, 2080: 3, 2081: 3, 2082: 3, 2083: 3, 2084: 3, 2085: 3, 2086: 3, 2087: 3, 2088: 3, 2089: 3, 2090: 3, 2091: 3, 2092: 3, 2093: 3, 2094: 3, 2095: 3, 2096: 3, 2097: 3, 2098: 3, 2099: 3, 2100: 3, 2101: 3, 2102: 3, 2103: 3, 2104: 3, 2105: 3, 2106: 3, 2107: 3, 2108: 3, 2109: 3, 2110: 3, 2111: 3, 2112: 3, 2113: 3, 2114: 3, 2115: 3, 2116: 3, 2117: 3, 2118: 3, 2119: 3, 2120: 3, 2121: 3, 2122: 3, 2123: 3, 2124: 3, 2125: 3, 2126: 3, 2127: 3, 2128: 3, 2129: 3, 2130: 3, 2131: 3, 2132: 3, 2133: 3, 2134: 3, 2135: 3, 2136: 3, 2137: 3, 2138: 3, 2139: 3, 2140: 3, 2141: 3, 2142: 3, 2143: 3, 2144: 3, 2145: 3, 2146: 3, 2147: 3, 2148: 3, 2149: 3, 2150: 3, 2151: 3, 2152: 3, 2153: 3, 2154: 3, 2155: 3, 2156: 3, 2157: 3, 2158: 3, 2159: 3, 2160: 3, 2161: 3, 2162: 3, 2163: 3, 2164: 3, 2165: 3, 2166: 3, 2167: 3, 2168: 3, 2169: 3, 2170: 3, 2171: 3, 2172: 3, 2173: 3, 2174: 3, 2175: 3, 2176: 3, 2177: 3, 2178: 3, 2179: 3, 2180: 3, 2181: 3, 2182: 3, 2183: 3, 2184: 3, 2185: 3, 2186: 3, 2187: 3, 2188: 3, 2189: 3, 2190: 3, 2191: 3, 2192: 3, 2193: 3, 2194: 3, 2195: 3, 2196: 3, 2197: 3, 2198: 3, 2199: 3, 2200: 3, 2201: 3, 2202: 3, 2203: 3, 2204: 3, 2205: 3, 2206: 3, 2207: 3, 2208: 3, 2209: 3, 2210: 3, 2211: 3, 2212: 3, 2213: 3, 2214: 3, 2215: 3, 2216: 3, 2217: 3, 2218: 3, 2219: 3, 2220: 3, 2221: 3, 2222: 3, 2223: 3, 2224: 3, 2225: 3, 2226: 3, 2227: 3, 2228: 3, 2229: 3, 2230: 3, 2231: 3, 2232: 3, 2233: 3, 2234: 3, 2235: 3, 2236: 3, 2237: 3, 2238: 3, 2239: 3, 2240: 3, 2241: 3, 2242: 3, 2243: 3, 2244: 3, 2245: 3, 2246: 3, 2247: 3, 2248: 3, 2249: 3, 2250: 3, 2251: 3, 2252: 3, 2253: 3, 2254: 3, 2255: 3, 2256: 3, 2257: 3, 2258: 3, 2259: 3, 2260: 3, 2261: 3, 2262: 3, 2263: 3, 2264: 3, 2265: 3, 2266: 3, 2267: 3, 2268: 3, 2269: 3, 2270: 3, 2271: 3, 2272: 3, 2273: 3, 2274: 3, 2275: 3, 2276: 3, 2277: 3, 2278: 3, 2279: 3, 2280: 3, 2281: 3, 2282: 3, 2283: 3, 2284: 3, 2285: 3, 2286: 3, 2287: 3, 2288: 3, 2289: 3, 2290: 3, 2291: 3, 2292: 3, 2293: 3, 2294: 3, 2295: 3, 2296: 3, 2297: 3, 2298: 3, 2299: 3, 2300: 3, 2301: 3, 2302: 3, 2303: 3, 2304: 3, 2305: 3, 2306: 3, 2307: 3, 2308: 3, 2309: 3, 2310: 3, 2311: 3, 2312: 3, 2313: 3, 2314: 3, 2315: 3, 2316: 3, 2317: 3, 2318: 3, 2319: 3, 2320: 3, 2321: 3, 2322: 3, 2323: 3, 2324: 3, 2325: 3, 2326: 3, 2327: 3, 2328: 3, 2329: 3, 2330: 3, 2331: 3, 2332: 3, 2333: 3, 2334: 3, 2335: 3, 2336: 3, 2337: 3, 2338: 3, 2339: 3, 2340: 3, 2341: 3, 2342: 3, 2343: 3, 2344: 3, 2345: 3, 2346: 3, 2347: 3, 2348: 3, 2349: 3, 2350: 3, 2351: 3, 2352: 3, 2353: 3, 2354: 3, 2355: 3, 2356: 3, 2357: 3, 2358: 3, 2359: 3, 2360: 3, 2361: 3, 2362: 3, 2363: 3, 2364: 3, 2365: 3, 2366: 3, 2367: 3, 2368: 3, 2369: 3, 2370: 3, 2371: 3, 2372: 3, 2373: 3, 2374: 3, 2375: 3, 2376: 3, 2377: 3, 2378: 3, 2379: 3, 2380: 3, 2381: 3, 2382: 3, 2383: 3, 2384: 3, 2385: 3, 2386: 3, 2387: 3, 2388: 3, 2389: 3, 2390: 3, 2391: 3, 2392: 3, 2393: 3, 2394: 3, 2395: 3, 2396: 3, 2397: 3, 2398: 3, 2399: 3, 2400: 3, 2401: 3, 2402: 3, 2403: 3, 2404: 3, 2405: 3, 2406: 3, 2407: 3, 2408: 3, 2409: 3, 2410: 3, 2411: 3, 2412: 3, 2413: 3, 2414: 3, 2415: 3, 2416: 3, 2417: 3, 2418: 3, 2419: 3, 2420: 3, 2421: 3, 2422: 3, 2423: 3, 2424: 3, 2425: 3, 2426: 3, 2427: 3, 2428: 3, 2429: 3, 2430: 3, 2431: 3, 2432: 3, 2433: 3, 2434: 3, 2435: 3, 2436: 3, 2437: 3, 2438: 3, 2439: 3, 2440: 3, 2441: 3, 2442: 3, 2443: 3, 2444: 3, 2445: 3, 2446: 3, 2447: 3, 2448: 3, 2449: 3, 2450: 3, 2451: 3, 2452: 3, 2453: 3, 2454: 3, 2455: 3, 2456: 3, 2457: 3, 2458: 3, 2459: 3, 2460: 3, 2461: 3, 2462: 3, 2463: 3, 2464: 3, 2465: 3, 2466: 3, 2467: 3, 2468: 3, 2469: 3, 2470: 3, 2471: 3, 2472: 3, 2473: 3, 2474: 3, 2475: 3, 2476: 3, 2477: 3, 2478: 3, 2479: 3, 2480: 3, 2481: 3, 2482: 3, 2483: 3, 2484: 3, 2485: 3, 2486: 3, 2487: 3, 2488: 3, 2489: 3, 2490: 3, 2491: 3, 2492: 3, 2493: 3, 2494: 3, 2495: 3, 2496: 3, 2497: 3, 2498: 3, 2499: 3, 2500: 3, 2501: 3, 2502: 3, 2503: 3, 2504: 3, 2505: 3, 2506: 3, 2507: 3, 2508: 3, 2509: 3, 2510: 3, 2511: 3, 2512: 3, 2513: 3, 2514: 3, 2515: 3, 2516: 3, 2517: 3, 2518: 3, 2519: 3, 2520: 3, 2521: 3, 2522: 3, 2523: 3, 2524: 3, 2525: 3, 2526: 3, 2527: 3, 2528: 3, 2529: 3, 2530: 3, 2531: 3, 2532: 3, 2533: 3, 2534: 3, 2535: 3, 2536: 3, 2537: 3, 2538: 3, 2539: 3, 2540: 3, 2541: 3, 2542: 3, 2543: 3, 2544: 3, 2545: 3, 2546: 3, 2547: 3, 2548: 3, 2549: 3, 2550: 3, 2551: 3, 2552: 3, 2553: 3, 2554: 3, 2555: 3, 2556: 3, 2557: 3, 2558: 3, 2559: 3, 2560: 3, 2561: 3, 2562: 3, 2563: 3, 2564: 3, 2565: 3, 2566: 3, 2567: 3, 2568: 3, 2569: 3, 2570: 3, 2571: 3, 2572: 3, 2573: 3, 2574: 3, 2575: 3, 2576: 3, 2577: 3, 2578: 3, 2579: 3, 2580: 3, 2581: 3, 2582: 3, 2583: 3, 2584: 3, 2585: 3, 2586: 3, 2587: 3, 2588: 3, 2589: 3, 2590: 3, 2591: 3, 2592: 3, 2593: 3, 2594: 3, 2595: 3, 2596: 3, 2597: 3, 2598: 3, 2599: 3, 2600: 3, 2601: 3, 2602: 3, 2603: 3, 2604: 3, 2605: 3, 2606: 3, 2607: 3, 2608: 3, 2609: 3, 2610: 3, 2611: 3, 2612: 3, 2613: 3, 2614: 3, 2615: 3, 2616: 3, 2617: 3, 2618: 3, 2619: 3, 2620: 3, 2621: 3, 2622: 3, 2623: 3, 2624: 3, 2625: 3, 2626: 3, 2627: 3, 2628: 3, 2629: 3, 2630: 3, 2631: 3, 2632: 3, 2633: 3, 2634: 3, 2635: 3, 2636: 3, 2637: 3, 2638: 3, 2639: 3, 2640: 3, 2641: 3, 2642: 3, 2643: 3, 2644: 3, 2645: 3, 2646: 3, 2647: 3, 2648: 3, 2649: 3, 2650: 3, 2651: 3, 2652: 3, 2653: 3, 2654: 3, 2655: 3, 2656: 3, 2657: 3, 2658: 3, 2659: 3, 2660: 3, 2661: 3, 2662: 3, 2663: 3, 2664: 3, 2665: 3, 2666: 3, 2667: 3, 2668: 3, 2669: 3, 2670: 3, 2671: 3, 2672: 3, 2673: 3, 2674: 3, 2675: 3, 2676: 3, 2677: 3, 2678: 3, 2679: 3, 2680: 3, 2681: 3, 2682: 3, 2683: 3, 2684: 3, 2685: 3, 2686: 3, 2687: 3, 2688: 3, 2689: 3, 2690: 3, 2691: 3, 2692: 3, 2693: 3, 2694: 3, 2695: 3, 2696: 3, 2697: 3, 2698: 3, 2699: 3, 2700: 3, 2701: 3, 2702: 3, 2703: 3, 2704: 3, 2705: 3, 2706: 3, 2707: 3, 2708: 3, 2709: 3, 2710: 3, 2711: 3, 2712: 3, 2713: 3, 2714: 3, 2715: 3, 2716: 3, 2717: 3, 2718: 3, 2719: 3, 2720: 3, 2721: 3, 2722: 3, 2723: 3, 2724: 3, 2725: 3, 2726: 3, 2727: 3, 2728: 3, 2729: 3, 2730: 3, 2731: 3, 2732: 3, 2733: 3, 2734: 3, 2735: 3, 2736: 3, 2737: 3, 2738: 3, 2739: 3, 2740: 3, 2741: 3, 2742: 3, 2743: 3, 2744: 3, 2745: 3, 2746: 3, 2747: 3, 2748: 3, 2749: 3, 2750: 3, 2751: 3, 2752: 3, 2753: 3, 2754: 3, 2755: 3, 2756: 3, 2757: 3, 2758: 3, 2759: 3, 2760: 3, 2761: 3, 2762: 3, 2763: 3, 2764: 3, 2765: 3, 2766: 3, 2767: 3, 2768: 3, 2769: 3, 2770: 3, 2771: 3, 2772: 3, 2773: 3, 2774: 3, 2775: 3, 2776: 3, 2777: 3, 2778: 3, 2779: 3, 2780: 3, 2781: 3, 2782: 3, 2783: 3, 2784: 3, 2785: 3, 2786: 3, 2787: 3, 2788: 3, 2789: 3, 2790: 3, 2791: 3, 2792: 3, 2793: 3, 2794: 3, 2795: 3, 2796: 3, 2797: 3, 2798: 3, 2799: 3, 2800: 3, 2801: 3, 2802: 3, 2803: 3, 2804: 3, 2805: 3, 2806: 3, 2807: 3, 2808: 3, 2809: 3, 2810: 3, 2811: 3, 2812: 3, 2813: 3, 2814: 3, 2815: 3, 2816: 3, 2817: 3, 2818: 3, 2819: 3, 2820: 3, 2821: 3, 2822: 3, 2823: 3, 2824: 3, 2825: 3, 2826: 3, 2827: 3, 2828: 3, 2829: 3, 2830: 3, 2831: 3, 2832: 3, 2833: 3, 2834: 3, 2835: 3, 2836: 3, 2837: 3, 2838: 3, 2839: 3, 2840: 3, 2841: 3, 2842: 3, 2843: 3, 2844: 3, 2845: 3, 2846: 3, 2847: 3, 2848: 3, 2849: 3, 2850: 3, 2851: 3, 2852: 3, 2853: 3, 2854: 3, 2855: 3, 2856: 3, 2857: 3, 2858: 3, 2859: 3, 2860: 3, 2861: 3, 2862: 3, 2863: 3, 2864: 3, 2865: 3, 2866: 3, 2867: 3, 2868: 3, 2869: 3, 2870: 3, 2871: 3, 2872: 3, 2873: 3, 2874: 3, 2875: 3, 2876: 3, 2877: 3, 2878: 3, 2879: 3, 2880: 3, 2881: 3, 2882: 3, 2883: 3, 2884: 3, 2885: 3, 2886: 3, 2887: 3, 2888: 3, 2889: 3, 2890: 3, 2891: 3, 2892: 3, 2893: 3, 2894: 3, 2895: 3, 2896: 3, 2897: 3, 2898: 3, 2899: 3, 2900: 3, 2901: 3, 2902: 3, 2903: 3, 2904: 3, 2905: 3, 2906: 3, 2907: 3, 2908: 3, 2909: 3, 2910: 3, 2911: 3, 2912: 3, 2913: 3, 2914: 3, 2915: 3, 2916: 3, 2917: 3, 2918: 3, 2919: 3, 2920: 3, 2921: 3, 2922: 3, 2923: 3, 2924: 3, 2925: 3, 2926: 3, 2927: 3, 2928: 3, 2929: 3, 2930: 3, 2931: 3, 2932: 3, 2933: 3, 2934: 3, 2935: 3, 2936: 3, 2937: 3, 2938: 3, 2939: 3, 2940: 3, 2941: 3, 2942: 3, 2943: 3, 2944: 3, 2945: 3, 2946: 3, 2947: 3, 2948: 3, 2949: 3, 2950: 3, 2951: 3, 2952: 3, 2953: 3, 2954: 3, 2955: 3, 2956: 3, 2957: 3, 2958: 3, 2959: 3, 2960: 3, 2961: 3, 2962: 3, 2963: 3, 2964: 3, 2965: 3, 2966: 3, 2967: 3, 2968: 3, 2969: 3, 2970: 3, 2971: 3, 2972: 3, 2973: 3, 2974: 3, 2975: 3, 2976: 3, 2977: 3, 2978: 3, 2979: 3, 2980: 3, 2981: 3, 2982: 3, 2983: 3, 2984: 3, 2985: 3, 2986: 3, 2987: 3, 2988: 3, 2989: 3, 2990: 3, 2991: 3, 2992: 3, 2993: 3, 2994: 3, 2995: 3, 2996: 3, 2997: 3, 2998: 3, 2999: 3, 3000: 3, 3001: 3, 3002: 3, 3003: 3, 3004: 3, 3005: 3, 3006: 3, 3007: 3, 3008: 3, 3009: 3, 3010: 3, 3011: 3, 3012: 3, 3013: 3, 3014: 3, 3015: 3, 3016: 3, 3017: 3, 3018: 3, 3019: 3, 3020: 3, 3021: 3, 3022: 3, 3023: 3, 3024: 3, 3025: 3, 3026: 3, 3027: 3, 3028: 3, 3029: 3, 3030: 3, 3031: 3, 3032: 3, 3033: 3, 3034: 3, 3035: 3, 3036: 3, 3037: 3, 3038: 3, 3039: 3, 3040: 3, 3041: 3, 3042: 3, 3043: 3, 3044: 3, 3045: 3, 3046: 3, 3047: 3, 3048: 3, 3049: 3, 3050: 3, 3051: 3, 3052: 3, 3053: 3, 3054: 3, 3055: 3, 3056: 3, 3057: 3, 3058: 3, 3059: 3, 3060: 3, 3061: 3, 3062: 3, 3063: 3, 3064: 3, 3065: 3, 3066: 3, 3067: 3, 3068: 3, 3069: 3, 3070: 3, 3071: 3, 3072: 3, 3073: 3, 3074: 3, 3075: 3, 3076: 3, 3077: 3, 3078: 3, 3079: 3, 3080: 3, 3081: 3, 3082: 3, 3083: 3, 3084: 3, 3085: 3, 3086: 3, 3087: 3, 3088: 3, 3089: 3, 3090: 3, 3091: 3, 3092: 3, 3093: 3, 3094: 3, 3095: 3, 3096: 3, 3097: 3, 3098: 3, 3099: 3, 3100: 3, 3101: 3, 3102: 3 ~= num clips 3
[04/30 13:28:24][INFO] logging.py:  99: json_stats: {"split": "test_final", "top1_acc": "0.00", "top5_acc": "0.00"}
[05/01 09:03:27][INFO] test_net_gamma.py: 157: Test with config:
[05/01 09:03:27][INFO] test_net_gamma.py: 158: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: True
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  FRAME_PATH: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: True
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  PSEUDO_CSV: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 3
  SPECIAL_LABEL_LIST: [5, 9]
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
EVL:
  ADD_RESIDUAL: False
  AFTER_ME: False
  BACKBONE: vit_b16
  BEFORE_ME: False
  CLS_DROPOUT: 0.5
  FIRST_N: 0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  SHIFT_INIT: False
  SPATAIL_SIZE: 14
  USE_IMAGE_ATTNMAP: True
  USE_T_CONV: True
  USE_T_POS_EMBED: True
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: True
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  CHECKPOINT_NUM: [0, 0, 0, 0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 11
  PSEUDO_LOSS_FUNC: 
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'vip', 'swin', 'sf', 'evl']
  SOFT_T: 1
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: None
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]]
  QKV_BIAS: True
  SEP_POS_EMBED: True
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 2
NUM_SHARDS: 1
OUTPUT_DIR: ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SF:
  DROPOUT_RATE: 0.3
  FROZEN_BN: False
  NONLOCAL:
    FROZEN_BN: False
  PRETRAIN_NAME: SlowFast-ResNet101-8x8
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRADIENT: 20
  CLIP_GRAD_L2NORM: 1.0
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 40
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 10.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.03
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 64
  CHECKPOINT_FILE_PATH: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  DATA_SELECT: test
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 3
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
  THRESHOLD: 2
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  KS: 5
  MBCONV: False
  MLP_RATIO: 4
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/01 09:03:30][INFO] checkpoint.py: 223: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[05/01 09:03:35][INFO] ug2_sparse.py:  90: Constructing Ug2 test...
[05/01 09:03:35][INFO] ug2_sparse.py:  91: Number of clips 9
[05/01 09:03:35][INFO] ug2_sparse.py: 203: Constructing Ug2 dataloader (size: 27927) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/test.csv
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:03:37][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:03:38][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:03:38][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:03:38][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:03:38][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f7d496ad680>
[05/01 09:03:38][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:03:38][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f7d496d6c20>
[05/01 09:03:38][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f7da8385320>
[05/01 09:03:38][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f7d496d69e0>
[05/01 09:03:38][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:03:38][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:03:38][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:03:38][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:03:38][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:03:39][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f7d496ad680>
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:03:39][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f7d496d6c20>
[05/01 09:03:39][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f7d48e77dd0>
[05/01 09:03:39][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f7d496d69e0>
[05/01 09:03:39][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:03:39][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:03:39][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:03:39][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f7d496ad680>
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:03:39][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f7d496d6c20>
[05/01 09:03:39][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f7d487aea70>
[05/01 09:03:39][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f7d496d69e0>
[05/01 09:03:39][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:03:39][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:03:39][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:03:39][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:03:39][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:03:40][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f7d496ad680>
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f7d496d6c20>
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f7d480d5b90>
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f7d496d69e0>
[05/01 09:03:40][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:03:40][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:03:40][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:03:40][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f7d496ad680>
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f7d496d6c20>
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f7d41125c20>
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f7d496d69e0>
[05/01 09:03:40][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:03:40][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:03:40][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:03:40][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:03:40][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f7d496ad680>
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f7d496d6c20>
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f7d40a4ecb0>
[05/01 09:03:40][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f7d496d69e0>
[05/01 09:03:40][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:03:40][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:03:40][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:03:40][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:03:40][INFO] test_net_gamma.py: 169: Testing model for 437 iterations
[05/01 09:04:42][INFO] logging.py:  99: json_stats: {"cur_iter": "1", "eta": "7:25:57", "split": "test_iter", "time_diff": 61.22948}
[05/01 09:04:43][INFO] logging.py:  99: json_stats: {"cur_iter": "2", "eta": "0:06:24", "split": "test_iter", "time_diff": 0.88168}
[05/01 09:04:44][INFO] logging.py:  99: json_stats: {"cur_iter": "3", "eta": "0:06:30", "split": "test_iter", "time_diff": 0.89859}
[05/01 09:04:45][INFO] logging.py:  99: json_stats: {"cur_iter": "4", "eta": "0:07:02", "split": "test_iter", "time_diff": 0.97384}
[05/01 09:04:46][INFO] logging.py:  99: json_stats: {"cur_iter": "5", "eta": "0:06:56", "split": "test_iter", "time_diff": 0.96149}
[05/01 09:04:47][INFO] logging.py:  99: json_stats: {"cur_iter": "6", "eta": "0:07:08", "split": "test_iter", "time_diff": 0.99204}
[05/01 09:04:48][INFO] logging.py:  99: json_stats: {"cur_iter": "7", "eta": "0:06:32", "split": "test_iter", "time_diff": 0.91115}
[05/01 09:04:49][INFO] logging.py:  99: json_stats: {"cur_iter": "8", "eta": "0:06:25", "split": "test_iter", "time_diff": 0.89682}
[05/01 09:04:50][INFO] logging.py:  99: json_stats: {"cur_iter": "9", "eta": "0:07:18", "split": "test_iter", "time_diff": 1.02165}
[05/01 09:04:51][INFO] logging.py:  99: json_stats: {"cur_iter": "10", "eta": "0:07:27", "split": "test_iter", "time_diff": 1.04474}
[05/01 09:04:52][INFO] logging.py:  99: json_stats: {"cur_iter": "11", "eta": "0:07:56", "split": "test_iter", "time_diff": 1.11533}
[05/01 09:04:53][INFO] logging.py:  99: json_stats: {"cur_iter": "12", "eta": "0:06:28", "split": "test_iter", "time_diff": 0.91175}
[05/01 09:04:54][INFO] logging.py:  99: json_stats: {"cur_iter": "13", "eta": "0:07:10", "split": "test_iter", "time_diff": 1.01225}
[05/01 09:04:55][INFO] logging.py:  99: json_stats: {"cur_iter": "14", "eta": "0:07:12", "split": "test_iter", "time_diff": 1.02094}
[05/01 09:04:56][INFO] logging.py:  99: json_stats: {"cur_iter": "15", "eta": "0:07:17", "split": "test_iter", "time_diff": 1.03511}
[05/01 09:04:57][INFO] logging.py:  99: json_stats: {"cur_iter": "16", "eta": "0:07:18", "split": "test_iter", "time_diff": 1.03903}
[05/01 09:04:58][INFO] logging.py:  99: json_stats: {"cur_iter": "17", "eta": "0:06:18", "split": "test_iter", "time_diff": 0.89943}
[05/01 09:04:59][INFO] logging.py:  99: json_stats: {"cur_iter": "18", "eta": "0:07:17", "split": "test_iter", "time_diff": 1.04158}
[05/01 09:05:00][INFO] logging.py:  99: json_stats: {"cur_iter": "19", "eta": "0:07:20", "split": "test_iter", "time_diff": 1.05074}
[05/01 09:05:01][INFO] logging.py:  99: json_stats: {"cur_iter": "20", "eta": "0:07:06", "split": "test_iter", "time_diff": 1.02151}
[05/01 09:05:02][INFO] logging.py:  99: json_stats: {"cur_iter": "21", "eta": "0:07:08", "split": "test_iter", "time_diff": 1.02856}
[05/01 09:05:03][INFO] logging.py:  99: json_stats: {"cur_iter": "22", "eta": "0:07:33", "split": "test_iter", "time_diff": 1.09047}
[05/01 09:05:04][INFO] logging.py:  99: json_stats: {"cur_iter": "23", "eta": "0:07:14", "split": "test_iter", "time_diff": 1.04748}
[05/01 09:05:05][INFO] logging.py:  99: json_stats: {"cur_iter": "24", "eta": "0:07:13", "split": "test_iter", "time_diff": 1.04809}
[05/01 09:05:06][INFO] logging.py:  99: json_stats: {"cur_iter": "25", "eta": "0:06:06", "split": "test_iter", "time_diff": 0.88767}
[05/01 09:05:07][INFO] logging.py:  99: json_stats: {"cur_iter": "26", "eta": "0:08:13", "split": "test_iter", "time_diff": 1.19706}
[05/01 09:05:08][INFO] logging.py:  99: json_stats: {"cur_iter": "27", "eta": "0:06:09", "split": "test_iter", "time_diff": 0.89843}
[05/01 09:05:09][INFO] logging.py:  99: json_stats: {"cur_iter": "28", "eta": "0:07:46", "split": "test_iter", "time_diff": 1.13777}
[05/01 09:05:11][INFO] logging.py:  99: json_stats: {"cur_iter": "29", "eta": "0:06:58", "split": "test_iter", "time_diff": 1.02368}
[05/01 09:05:12][INFO] logging.py:  99: json_stats: {"cur_iter": "30", "eta": "0:07:13", "split": "test_iter", "time_diff": 1.06186}
[05/01 09:05:13][INFO] logging.py:  99: json_stats: {"cur_iter": "31", "eta": "0:06:37", "split": "test_iter", "time_diff": 0.97691}
[05/01 09:05:14][INFO] logging.py:  99: json_stats: {"cur_iter": "32", "eta": "0:06:41", "split": "test_iter", "time_diff": 0.98944}
[05/01 09:05:15][INFO] logging.py:  99: json_stats: {"cur_iter": "33", "eta": "0:06:03", "split": "test_iter", "time_diff": 0.89779}
[05/01 09:05:16][INFO] logging.py:  99: json_stats: {"cur_iter": "34", "eta": "0:06:46", "split": "test_iter", "time_diff": 1.00581}
[05/01 09:05:17][INFO] logging.py:  99: json_stats: {"cur_iter": "35", "eta": "0:06:46", "split": "test_iter", "time_diff": 1.00863}
[05/01 09:05:18][INFO] logging.py:  99: json_stats: {"cur_iter": "36", "eta": "0:07:05", "split": "test_iter", "time_diff": 1.05785}
[05/01 09:05:19][INFO] logging.py:  99: json_stats: {"cur_iter": "37", "eta": "0:06:49", "split": "test_iter", "time_diff": 1.02182}
[05/01 09:05:20][INFO] logging.py:  99: json_stats: {"cur_iter": "38", "eta": "0:05:51", "split": "test_iter", "time_diff": 0.87951}
[05/01 09:05:21][INFO] logging.py:  99: json_stats: {"cur_iter": "39", "eta": "0:06:59", "split": "test_iter", "time_diff": 1.05250}
[05/01 09:05:22][INFO] logging.py:  99: json_stats: {"cur_iter": "40", "eta": "0:06:58", "split": "test_iter", "time_diff": 1.05159}
[05/01 09:05:23][INFO] logging.py:  99: json_stats: {"cur_iter": "41", "eta": "0:09:40", "split": "test_iter", "time_diff": 1.46219}
[05/01 09:05:24][INFO] logging.py:  99: json_stats: {"cur_iter": "42", "eta": "0:06:53", "split": "test_iter", "time_diff": 1.04502}
[05/01 09:05:25][INFO] logging.py:  99: json_stats: {"cur_iter": "43", "eta": "0:06:51", "split": "test_iter", "time_diff": 1.04228}
[05/01 09:05:26][INFO] logging.py:  99: json_stats: {"cur_iter": "44", "eta": "0:06:53", "split": "test_iter", "time_diff": 1.04998}
[05/01 09:05:27][INFO] logging.py:  99: json_stats: {"cur_iter": "45", "eta": "0:06:57", "split": "test_iter", "time_diff": 1.06241}
[05/01 09:05:28][INFO] logging.py:  99: json_stats: {"cur_iter": "46", "eta": "0:06:50", "split": "test_iter", "time_diff": 1.04796}
[05/01 09:05:29][INFO] logging.py:  99: json_stats: {"cur_iter": "47", "eta": "0:05:45", "split": "test_iter", "time_diff": 0.88478}
[05/01 09:05:30][INFO] logging.py:  99: json_stats: {"cur_iter": "48", "eta": "0:06:50", "split": "test_iter", "time_diff": 1.05292}
[05/01 09:05:32][INFO] logging.py:  99: json_stats: {"cur_iter": "49", "eta": "0:12:49", "split": "test_iter", "time_diff": 1.97764}
[05/01 09:05:34][INFO] logging.py:  99: json_stats: {"cur_iter": "50", "eta": "0:09:40", "split": "test_iter", "time_diff": 1.49660}
[05/01 09:05:35][INFO] logging.py:  99: json_stats: {"cur_iter": "51", "eta": "0:06:44", "split": "test_iter", "time_diff": 1.04578}
[05/01 09:05:36][INFO] logging.py:  99: json_stats: {"cur_iter": "52", "eta": "0:06:28", "split": "test_iter", "time_diff": 1.00672}
[05/01 09:05:37][INFO] logging.py:  99: json_stats: {"cur_iter": "53", "eta": "0:06:34", "split": "test_iter", "time_diff": 1.02580}
[05/01 09:05:38][INFO] logging.py:  99: json_stats: {"cur_iter": "54", "eta": "0:06:30", "split": "test_iter", "time_diff": 1.01717}
[05/01 09:05:39][INFO] logging.py:  99: json_stats: {"cur_iter": "55", "eta": "0:05:38", "split": "test_iter", "time_diff": 0.88265}
[05/01 09:05:40][INFO] logging.py:  99: json_stats: {"cur_iter": "56", "eta": "0:06:37", "split": "test_iter", "time_diff": 1.04021}
[05/01 09:05:42][INFO] logging.py:  99: json_stats: {"cur_iter": "57", "eta": "0:10:29", "split": "test_iter", "time_diff": 1.65187}
[05/01 09:05:43][INFO] logging.py:  99: json_stats: {"cur_iter": "58", "eta": "0:12:04", "split": "test_iter", "time_diff": 1.90751}
[05/01 09:05:44][INFO] logging.py:  99: json_stats: {"cur_iter": "59", "eta": "0:06:32", "split": "test_iter", "time_diff": 1.03447}
[05/01 09:05:46][INFO] logging.py:  99: json_stats: {"cur_iter": "60", "eta": "0:08:51", "split": "test_iter", "time_diff": 1.40528}
[05/01 09:05:47][INFO] logging.py:  99: json_stats: {"cur_iter": "61", "eta": "0:05:58", "split": "test_iter", "time_diff": 0.95212}
[05/01 09:05:48][INFO] logging.py:  99: json_stats: {"cur_iter": "62", "eta": "0:06:24", "split": "test_iter", "time_diff": 1.02297}
[05/01 09:05:49][INFO] logging.py:  99: json_stats: {"cur_iter": "63", "eta": "0:05:31", "split": "test_iter", "time_diff": 0.88403}
[05/01 09:05:50][INFO] logging.py:  99: json_stats: {"cur_iter": "64", "eta": "0:05:38", "split": "test_iter", "time_diff": 0.90483}
[05/01 09:05:52][INFO] logging.py:  99: json_stats: {"cur_iter": "65", "eta": "0:11:51", "split": "test_iter", "time_diff": 1.90785}
[05/01 09:05:54][INFO] logging.py:  99: json_stats: {"cur_iter": "66", "eta": "0:11:10", "split": "test_iter", "time_diff": 1.80322}
[05/01 09:05:55][INFO] logging.py:  99: json_stats: {"cur_iter": "67", "eta": "0:05:34", "split": "test_iter", "time_diff": 0.90119}
[05/01 09:05:56][INFO] logging.py:  99: json_stats: {"cur_iter": "68", "eta": "0:08:47", "split": "test_iter", "time_diff": 1.42560}
[05/01 09:05:57][INFO] logging.py:  99: json_stats: {"cur_iter": "69", "eta": "0:07:39", "split": "test_iter", "time_diff": 1.24467}
[05/01 09:05:58][INFO] logging.py:  99: json_stats: {"cur_iter": "70", "eta": "0:06:25", "split": "test_iter", "time_diff": 1.04831}
[05/01 09:05:59][INFO] logging.py:  99: json_stats: {"cur_iter": "71", "eta": "0:06:11", "split": "test_iter", "time_diff": 1.01272}
[05/01 09:06:00][INFO] logging.py:  99: json_stats: {"cur_iter": "72", "eta": "0:06:15", "split": "test_iter", "time_diff": 1.02670}
[05/01 09:06:02][INFO] logging.py:  99: json_stats: {"cur_iter": "73", "eta": "0:11:38", "split": "test_iter", "time_diff": 1.91480}
[05/01 09:06:04][INFO] logging.py:  99: json_stats: {"cur_iter": "74", "eta": "0:11:09", "split": "test_iter", "time_diff": 1.83990}
[05/01 09:06:05][INFO] logging.py:  99: json_stats: {"cur_iter": "75", "eta": "0:05:33", "split": "test_iter", "time_diff": 0.91940}
[05/01 09:06:06][INFO] logging.py:  99: json_stats: {"cur_iter": "76", "eta": "0:07:20", "split": "test_iter", "time_diff": 1.21647}
[05/01 09:06:07][INFO] logging.py:  99: json_stats: {"cur_iter": "77", "eta": "0:05:25", "split": "test_iter", "time_diff": 0.90178}
[05/01 09:06:08][INFO] logging.py:  99: json_stats: {"cur_iter": "78", "eta": "0:06:13", "split": "test_iter", "time_diff": 1.03849}
[05/01 09:06:09][INFO] logging.py:  99: json_stats: {"cur_iter": "79", "eta": "0:05:24", "split": "test_iter", "time_diff": 0.90291}
[05/01 09:06:11][INFO] logging.py:  99: json_stats: {"cur_iter": "80", "eta": "0:07:23", "split": "test_iter", "time_diff": 1.23894}
[05/01 09:06:12][INFO] logging.py:  99: json_stats: {"cur_iter": "81", "eta": "0:08:30", "split": "test_iter", "time_diff": 1.43075}
[05/01 09:06:14][INFO] logging.py:  99: json_stats: {"cur_iter": "82", "eta": "0:10:02", "split": "test_iter", "time_diff": 1.69374}
[05/01 09:06:15][INFO] logging.py:  99: json_stats: {"cur_iter": "83", "eta": "0:06:13", "split": "test_iter", "time_diff": 1.05277}
[05/01 09:06:16][INFO] logging.py:  99: json_stats: {"cur_iter": "84", "eta": "0:05:19", "split": "test_iter", "time_diff": 0.90203}
[05/01 09:06:17][INFO] logging.py:  99: json_stats: {"cur_iter": "85", "eta": "0:06:47", "split": "test_iter", "time_diff": 1.15496}
[05/01 09:06:18][INFO] logging.py:  99: json_stats: {"cur_iter": "86", "eta": "0:05:59", "split": "test_iter", "time_diff": 1.02131}
[05/01 09:06:19][INFO] logging.py:  99: json_stats: {"cur_iter": "87", "eta": "0:08:38", "split": "test_iter", "time_diff": 1.47595}
[05/01 09:06:20][INFO] logging.py:  99: json_stats: {"cur_iter": "88", "eta": "0:06:07", "split": "test_iter", "time_diff": 1.05095}
[05/01 09:06:22][INFO] logging.py:  99: json_stats: {"cur_iter": "89", "eta": "0:10:09", "split": "test_iter", "time_diff": 1.74768}
[05/01 09:06:24][INFO] logging.py:  99: json_stats: {"cur_iter": "90", "eta": "0:08:17", "split": "test_iter", "time_diff": 1.42976}
[05/01 09:06:25][INFO] logging.py:  99: json_stats: {"cur_iter": "91", "eta": "0:06:10", "split": "test_iter", "time_diff": 1.06862}
[05/01 09:06:25][INFO] logging.py:  99: json_stats: {"cur_iter": "92", "eta": "0:05:12", "split": "test_iter", "time_diff": 0.90205}
[05/01 09:06:27][INFO] logging.py:  99: json_stats: {"cur_iter": "93", "eta": "0:06:41", "split": "test_iter", "time_diff": 1.16337}
[05/01 09:06:28][INFO] logging.py:  99: json_stats: {"cur_iter": "94", "eta": "0:05:04", "split": "test_iter", "time_diff": 0.88506}
[05/01 09:06:29][INFO] logging.py:  99: json_stats: {"cur_iter": "95", "eta": "0:05:56", "split": "test_iter", "time_diff": 1.03905}
[05/01 09:06:30][INFO] logging.py:  99: json_stats: {"cur_iter": "96", "eta": "0:05:02", "split": "test_iter", "time_diff": 0.88420}
[05/01 09:06:33][INFO] logging.py:  99: json_stats: {"cur_iter": "97", "eta": "0:16:40", "split": "test_iter", "time_diff": 2.93296}
[05/01 09:06:35][INFO] logging.py:  99: json_stats: {"cur_iter": "98", "eta": "0:11:54", "split": "test_iter", "time_diff": 2.10236}
[05/01 09:06:36][INFO] logging.py:  99: json_stats: {"cur_iter": "99", "eta": "0:05:02", "split": "test_iter", "time_diff": 0.89121}
[05/01 09:06:37][INFO] logging.py:  99: json_stats: {"cur_iter": "100", "eta": "0:06:37", "split": "test_iter", "time_diff": 1.17496}
[05/01 09:06:38][INFO] logging.py:  99: json_stats: {"cur_iter": "101", "eta": "0:05:44", "split": "test_iter", "time_diff": 1.02277}
[05/01 09:06:39][INFO] logging.py:  99: json_stats: {"cur_iter": "102", "eta": "0:05:39", "split": "test_iter", "time_diff": 1.01037}
[05/01 09:06:40][INFO] logging.py:  99: json_stats: {"cur_iter": "103", "eta": "0:05:19", "split": "test_iter", "time_diff": 0.95495}
[05/01 09:06:41][INFO] logging.py:  99: json_stats: {"cur_iter": "104", "eta": "0:06:38", "split": "test_iter", "time_diff": 1.19394}
[05/01 09:06:42][INFO] logging.py:  99: json_stats: {"cur_iter": "105", "eta": "0:08:02", "split": "test_iter", "time_diff": 1.45021}
[05/01 09:06:43][INFO] logging.py:  99: json_stats: {"cur_iter": "106", "eta": "0:05:41", "split": "test_iter", "time_diff": 1.02841}
[05/01 09:06:44][INFO] logging.py:  99: json_stats: {"cur_iter": "107", "eta": "0:05:22", "split": "test_iter", "time_diff": 0.97433}
[05/01 09:06:46][INFO] logging.py:  99: json_stats: {"cur_iter": "108", "eta": "0:06:06", "split": "test_iter", "time_diff": 1.10986}
[05/01 09:06:47][INFO] logging.py:  99: json_stats: {"cur_iter": "109", "eta": "0:05:47", "split": "test_iter", "time_diff": 1.05592}
[05/01 09:06:48][INFO] logging.py:  99: json_stats: {"cur_iter": "110", "eta": "0:04:53", "split": "test_iter", "time_diff": 0.89549}
[05/01 09:06:49][INFO] logging.py:  99: json_stats: {"cur_iter": "111", "eta": "0:07:04", "split": "test_iter", "time_diff": 1.29912}
[05/01 09:06:50][INFO] logging.py:  99: json_stats: {"cur_iter": "112", "eta": "0:05:32", "split": "test_iter", "time_diff": 1.02081}
[05/01 09:06:53][INFO] logging.py:  99: json_stats: {"cur_iter": "113", "eta": "0:15:02", "split": "test_iter", "time_diff": 2.77551}
[05/01 09:06:55][INFO] logging.py:  99: json_stats: {"cur_iter": "114", "eta": "0:09:56", "split": "test_iter", "time_diff": 1.84009}
[05/01 09:06:56][INFO] logging.py:  99: json_stats: {"cur_iter": "115", "eta": "0:05:39", "split": "test_iter", "time_diff": 1.05068}
[05/01 09:06:57][INFO] logging.py:  99: json_stats: {"cur_iter": "116", "eta": "0:05:45", "split": "test_iter", "time_diff": 1.07303}
[05/01 09:06:58][INFO] logging.py:  99: json_stats: {"cur_iter": "117", "eta": "0:05:41", "split": "test_iter", "time_diff": 1.06301}
[05/01 09:06:59][INFO] logging.py:  99: json_stats: {"cur_iter": "118", "eta": "0:05:30", "split": "test_iter", "time_diff": 1.03246}
[05/01 09:07:00][INFO] logging.py:  99: json_stats: {"cur_iter": "119", "eta": "0:05:00", "split": "test_iter", "time_diff": 0.94263}
[05/01 09:07:01][INFO] logging.py:  99: json_stats: {"cur_iter": "120", "eta": "0:05:26", "split": "test_iter", "time_diff": 1.02773}
[05/01 09:07:03][INFO] logging.py:  99: json_stats: {"cur_iter": "121", "eta": "0:10:41", "split": "test_iter", "time_diff": 2.02494}
[05/01 09:07:05][INFO] logging.py:  99: json_stats: {"cur_iter": "122", "eta": "0:07:30", "split": "test_iter", "time_diff": 1.42656}
[05/01 09:07:06][INFO] logging.py:  99: json_stats: {"cur_iter": "123", "eta": "0:05:38", "split": "test_iter", "time_diff": 1.07592}
[05/01 09:07:07][INFO] logging.py:  99: json_stats: {"cur_iter": "124", "eta": "0:05:37", "split": "test_iter", "time_diff": 1.07367}
[05/01 09:07:08][INFO] logging.py:  99: json_stats: {"cur_iter": "125", "eta": "0:04:57", "split": "test_iter", "time_diff": 0.95203}
[05/01 09:07:09][INFO] logging.py:  99: json_stats: {"cur_iter": "126", "eta": "0:05:21", "split": "test_iter", "time_diff": 1.02890}
[05/01 09:07:10][INFO] logging.py:  99: json_stats: {"cur_iter": "127", "eta": "0:04:43", "split": "test_iter", "time_diff": 0.91097}
[05/01 09:07:11][INFO] logging.py:  99: json_stats: {"cur_iter": "128", "eta": "0:06:17", "split": "test_iter", "time_diff": 1.21694}
[05/01 09:07:14][INFO] logging.py:  99: json_stats: {"cur_iter": "129", "eta": "0:15:20", "split": "test_iter", "time_diff": 2.97811}
[05/01 09:07:15][INFO] logging.py:  99: json_stats: {"cur_iter": "130", "eta": "0:07:32", "split": "test_iter", "time_diff": 1.47045}
[05/01 09:07:16][INFO] logging.py:  99: json_stats: {"cur_iter": "131", "eta": "0:05:14", "split": "test_iter", "time_diff": 1.02520}
[05/01 09:07:17][INFO] logging.py:  99: json_stats: {"cur_iter": "132", "eta": "0:05:16", "split": "test_iter", "time_diff": 1.03307}
[05/01 09:07:18][INFO] logging.py:  99: json_stats: {"cur_iter": "133", "eta": "0:05:20", "split": "test_iter", "time_diff": 1.05109}
[05/01 09:07:20][INFO] logging.py:  99: json_stats: {"cur_iter": "134", "eta": "0:04:32", "split": "test_iter", "time_diff": 0.89724}
[05/01 09:07:21][INFO] logging.py:  99: json_stats: {"cur_iter": "135", "eta": "0:04:29", "split": "test_iter", "time_diff": 0.88924}
[05/01 09:07:22][INFO] logging.py:  99: json_stats: {"cur_iter": "136", "eta": "0:05:29", "split": "test_iter", "time_diff": 1.09169}
[05/01 09:07:24][INFO] logging.py:  99: json_stats: {"cur_iter": "137", "eta": "0:12:05", "split": "test_iter", "time_diff": 2.41056}
[05/01 09:07:25][INFO] logging.py:  99: json_stats: {"cur_iter": "138", "eta": "0:04:25", "split": "test_iter", "time_diff": 0.88637}
[05/01 09:07:26][INFO] logging.py:  99: json_stats: {"cur_iter": "139", "eta": "0:05:05", "split": "test_iter", "time_diff": 1.02120}
[05/01 09:07:27][INFO] logging.py:  99: json_stats: {"cur_iter": "140", "eta": "0:05:00", "split": "test_iter", "time_diff": 1.00900}
[05/01 09:07:28][INFO] logging.py:  99: json_stats: {"cur_iter": "141", "eta": "0:05:11", "split": "test_iter", "time_diff": 1.04774}
[05/01 09:07:29][INFO] logging.py:  99: json_stats: {"cur_iter": "142", "eta": "0:05:16", "split": "test_iter", "time_diff": 1.06852}
[05/01 09:07:30][INFO] logging.py:  99: json_stats: {"cur_iter": "143", "eta": "0:05:06", "split": "test_iter", "time_diff": 1.03810}
[05/01 09:07:32][INFO] logging.py:  99: json_stats: {"cur_iter": "144", "eta": "0:05:06", "split": "test_iter", "time_diff": 1.04199}
[05/01 09:07:35][INFO] logging.py:  99: json_stats: {"cur_iter": "145", "eta": "0:15:24", "split": "test_iter", "time_diff": 3.15421}
[05/01 09:07:36][INFO] logging.py:  99: json_stats: {"cur_iter": "146", "eta": "0:06:13", "split": "test_iter", "time_diff": 1.27811}
[05/01 09:07:37][INFO] logging.py:  99: json_stats: {"cur_iter": "147", "eta": "0:04:52", "split": "test_iter", "time_diff": 1.00541}
[05/01 09:07:38][INFO] logging.py:  99: json_stats: {"cur_iter": "148", "eta": "0:04:53", "split": "test_iter", "time_diff": 1.01290}
[05/01 09:07:39][INFO] logging.py:  99: json_stats: {"cur_iter": "149", "eta": "0:04:15", "split": "test_iter", "time_diff": 0.88423}
[05/01 09:07:40][INFO] logging.py:  99: json_stats: {"cur_iter": "150", "eta": "0:04:51", "split": "test_iter", "time_diff": 1.01358}
[05/01 09:07:41][INFO] logging.py:  99: json_stats: {"cur_iter": "151", "eta": "0:04:57", "split": "test_iter", "time_diff": 1.03659}
[05/01 09:07:42][INFO] logging.py:  99: json_stats: {"cur_iter": "152", "eta": "0:05:04", "split": "test_iter", "time_diff": 1.06379}
[05/01 09:07:45][INFO] logging.py:  99: json_stats: {"cur_iter": "153", "eta": "0:12:57", "split": "test_iter", "time_diff": 2.72904}
[05/01 09:07:47][INFO] logging.py:  99: json_stats: {"cur_iter": "154", "eta": "0:07:12", "split": "test_iter", "time_diff": 1.52458}
[05/01 09:07:48][INFO] logging.py:  99: json_stats: {"cur_iter": "155", "eta": "0:04:53", "split": "test_iter", "time_diff": 1.03716}
[05/01 09:07:49][INFO] logging.py:  99: json_stats: {"cur_iter": "156", "eta": "0:04:43", "split": "test_iter", "time_diff": 1.00655}
[05/01 09:07:50][INFO] logging.py:  99: json_stats: {"cur_iter": "157", "eta": "0:04:52", "split": "test_iter", "time_diff": 1.04195}
[05/01 09:07:51][INFO] logging.py:  99: json_stats: {"cur_iter": "158", "eta": "0:04:07", "split": "test_iter", "time_diff": 0.88352}
[05/01 09:07:52][INFO] logging.py:  99: json_stats: {"cur_iter": "159", "eta": "0:04:55", "split": "test_iter", "time_diff": 1.05847}
[05/01 09:07:53][INFO] logging.py:  99: json_stats: {"cur_iter": "160", "eta": "0:04:56", "split": "test_iter", "time_diff": 1.06525}
[05/01 09:07:56][INFO] logging.py:  99: json_stats: {"cur_iter": "161", "eta": "0:12:57", "split": "test_iter", "time_diff": 2.80563}
[05/01 09:07:57][INFO] logging.py:  99: json_stats: {"cur_iter": "162", "eta": "0:04:33", "split": "test_iter", "time_diff": 0.99142}
[05/01 09:07:58][INFO] logging.py:  99: json_stats: {"cur_iter": "163", "eta": "0:04:43", "split": "test_iter", "time_diff": 1.03257}
[05/01 09:07:59][INFO] logging.py:  99: json_stats: {"cur_iter": "164", "eta": "0:05:04", "split": "test_iter", "time_diff": 1.11270}
[05/01 09:08:00][INFO] logging.py:  99: json_stats: {"cur_iter": "165", "eta": "0:04:28", "split": "test_iter", "time_diff": 0.98481}
[05/01 09:08:01][INFO] logging.py:  99: json_stats: {"cur_iter": "166", "eta": "0:04:43", "split": "test_iter", "time_diff": 1.04188}
[05/01 09:08:02][INFO] logging.py:  99: json_stats: {"cur_iter": "167", "eta": "0:06:19", "split": "test_iter", "time_diff": 1.39872}
[05/01 09:08:03][INFO] logging.py:  99: json_stats: {"cur_iter": "168", "eta": "0:04:59", "split": "test_iter", "time_diff": 1.10946}
[05/01 09:08:06][INFO] logging.py:  99: json_stats: {"cur_iter": "169", "eta": "0:10:25", "split": "test_iter", "time_diff": 2.32683}
[05/01 09:08:07][INFO] logging.py:  99: json_stats: {"cur_iter": "170", "eta": "0:04:26", "split": "test_iter", "time_diff": 0.99381}
[05/01 09:08:08][INFO] logging.py:  99: json_stats: {"cur_iter": "171", "eta": "0:04:44", "split": "test_iter", "time_diff": 1.06595}
[05/01 09:08:09][INFO] logging.py:  99: json_stats: {"cur_iter": "172", "eta": "0:03:59", "split": "test_iter", "time_diff": 0.90077}
[05/01 09:08:10][INFO] logging.py:  99: json_stats: {"cur_iter": "173", "eta": "0:04:31", "split": "test_iter", "time_diff": 1.02506}
[05/01 09:08:11][INFO] logging.py:  99: json_stats: {"cur_iter": "174", "eta": "0:03:53", "split": "test_iter", "time_diff": 0.88296}
[05/01 09:08:13][INFO] logging.py:  99: json_stats: {"cur_iter": "175", "eta": "0:06:51", "split": "test_iter", "time_diff": 1.56550}
[05/01 09:08:14][INFO] logging.py:  99: json_stats: {"cur_iter": "176", "eta": "0:04:43", "split": "test_iter", "time_diff": 1.08107}
[05/01 09:08:16][INFO] logging.py:  99: json_stats: {"cur_iter": "177", "eta": "0:09:47", "split": "test_iter", "time_diff": 2.24907}
[05/01 09:08:17][INFO] logging.py:  99: json_stats: {"cur_iter": "178", "eta": "0:03:49", "split": "test_iter", "time_diff": 0.88097}
[05/01 09:08:18][INFO] logging.py:  99: json_stats: {"cur_iter": "179", "eta": "0:03:48", "split": "test_iter", "time_diff": 0.88086}
[05/01 09:08:19][INFO] logging.py:  99: json_stats: {"cur_iter": "180", "eta": "0:04:27", "split": "test_iter", "time_diff": 1.03847}
[05/01 09:08:20][INFO] logging.py:  99: json_stats: {"cur_iter": "181", "eta": "0:04:23", "split": "test_iter", "time_diff": 1.02720}
[05/01 09:08:21][INFO] logging.py:  99: json_stats: {"cur_iter": "182", "eta": "0:04:28", "split": "test_iter", "time_diff": 1.04716}
[05/01 09:08:23][INFO] logging.py:  99: json_stats: {"cur_iter": "183", "eta": "0:07:06", "split": "test_iter", "time_diff": 1.67107}
[05/01 09:08:24][INFO] logging.py:  99: json_stats: {"cur_iter": "184", "eta": "0:04:20", "split": "test_iter", "time_diff": 1.02514}
[05/01 09:08:26][INFO] logging.py:  99: json_stats: {"cur_iter": "185", "eta": "0:08:52", "split": "test_iter", "time_diff": 2.10464}
[05/01 09:08:27][INFO] logging.py:  99: json_stats: {"cur_iter": "186", "eta": "0:04:17", "split": "test_iter", "time_diff": 1.02121}
[05/01 09:08:28][INFO] logging.py:  99: json_stats: {"cur_iter": "187", "eta": "0:04:15", "split": "test_iter", "time_diff": 1.01926}
[05/01 09:08:29][INFO] logging.py:  99: json_stats: {"cur_iter": "188", "eta": "0:04:17", "split": "test_iter", "time_diff": 1.02929}
[05/01 09:08:30][INFO] logging.py:  99: json_stats: {"cur_iter": "189", "eta": "0:04:29", "split": "test_iter", "time_diff": 1.08112}
[05/01 09:08:31][INFO] logging.py:  99: json_stats: {"cur_iter": "190", "eta": "0:03:45", "split": "test_iter", "time_diff": 0.90760}
[05/01 09:08:33][INFO] logging.py:  99: json_stats: {"cur_iter": "191", "eta": "0:07:51", "split": "test_iter", "time_diff": 1.90872}
[05/01 09:08:34][INFO] logging.py:  99: json_stats: {"cur_iter": "192", "eta": "0:04:11", "split": "test_iter", "time_diff": 1.02397}
[05/01 09:08:36][INFO] logging.py:  99: json_stats: {"cur_iter": "193", "eta": "0:08:42", "split": "test_iter", "time_diff": 2.13294}
[05/01 09:08:37][INFO] logging.py:  99: json_stats: {"cur_iter": "194", "eta": "0:04:05", "split": "test_iter", "time_diff": 1.00420}
[05/01 09:08:38][INFO] logging.py:  99: json_stats: {"cur_iter": "195", "eta": "0:04:08", "split": "test_iter", "time_diff": 1.02185}
[05/01 09:08:39][INFO] logging.py:  99: json_stats: {"cur_iter": "196", "eta": "0:04:16", "split": "test_iter", "time_diff": 1.05895}
[05/01 09:08:41][INFO] logging.py:  99: json_stats: {"cur_iter": "197", "eta": "0:04:18", "split": "test_iter", "time_diff": 1.07352}
[05/01 09:08:42][INFO] logging.py:  99: json_stats: {"cur_iter": "198", "eta": "0:04:06", "split": "test_iter", "time_diff": 1.02753}
[05/01 09:08:43][INFO] logging.py:  99: json_stats: {"cur_iter": "199", "eta": "0:06:06", "split": "test_iter", "time_diff": 1.53337}
[05/01 09:08:44][INFO] logging.py:  99: json_stats: {"cur_iter": "200", "eta": "0:04:00", "split": "test_iter", "time_diff": 1.01217}
[05/01 09:08:46][INFO] logging.py:  99: json_stats: {"cur_iter": "201", "eta": "0:07:57", "split": "test_iter", "time_diff": 2.01600}
[05/01 09:08:47][INFO] logging.py:  99: json_stats: {"cur_iter": "202", "eta": "0:04:05", "split": "test_iter", "time_diff": 1.03976}
[05/01 09:08:48][INFO] logging.py:  99: json_stats: {"cur_iter": "203", "eta": "0:03:57", "split": "test_iter", "time_diff": 1.01258}
[05/01 09:08:49][INFO] logging.py:  99: json_stats: {"cur_iter": "204", "eta": "0:04:03", "split": "test_iter", "time_diff": 1.04258}
[05/01 09:08:50][INFO] logging.py:  99: json_stats: {"cur_iter": "205", "eta": "0:04:10", "split": "test_iter", "time_diff": 1.07532}
[05/01 09:08:51][INFO] logging.py:  99: json_stats: {"cur_iter": "206", "eta": "0:03:26", "split": "test_iter", "time_diff": 0.88919}
[05/01 09:08:53][INFO] logging.py:  99: json_stats: {"cur_iter": "207", "eta": "0:07:19", "split": "test_iter", "time_diff": 1.90463}
[05/01 09:08:54][INFO] logging.py:  99: json_stats: {"cur_iter": "208", "eta": "0:03:26", "split": "test_iter", "time_diff": 0.89926}
[05/01 09:08:57][INFO] logging.py:  99: json_stats: {"cur_iter": "209", "eta": "0:08:32", "split": "test_iter", "time_diff": 2.23777}
[05/01 09:08:58][INFO] logging.py:  99: json_stats: {"cur_iter": "210", "eta": "0:03:48", "split": "test_iter", "time_diff": 1.00347}
[05/01 09:08:59][INFO] logging.py:  99: json_stats: {"cur_iter": "211", "eta": "0:03:50", "split": "test_iter", "time_diff": 1.01583}
[05/01 09:09:00][INFO] logging.py:  99: json_stats: {"cur_iter": "212", "eta": "0:03:51", "split": "test_iter", "time_diff": 1.02488}
[05/01 09:09:01][INFO] logging.py:  99: json_stats: {"cur_iter": "213", "eta": "0:03:57", "split": "test_iter", "time_diff": 1.05740}
[05/01 09:09:02][INFO] logging.py:  99: json_stats: {"cur_iter": "214", "eta": "0:03:51", "split": "test_iter", "time_diff": 1.03527}
[05/01 09:09:03][INFO] logging.py:  99: json_stats: {"cur_iter": "215", "eta": "0:04:46", "split": "test_iter", "time_diff": 1.28536}
[05/01 09:09:04][INFO] logging.py:  99: json_stats: {"cur_iter": "216", "eta": "0:03:49", "split": "test_iter", "time_diff": 1.03188}
[05/01 09:09:06][INFO] logging.py:  99: json_stats: {"cur_iter": "217", "eta": "0:06:50", "split": "test_iter", "time_diff": 1.85822}
[05/01 09:09:07][INFO] logging.py:  99: json_stats: {"cur_iter": "218", "eta": "0:03:44", "split": "test_iter", "time_diff": 1.02102}
[05/01 09:09:08][INFO] logging.py:  99: json_stats: {"cur_iter": "219", "eta": "0:03:44", "split": "test_iter", "time_diff": 1.02375}
[05/01 09:09:09][INFO] logging.py:  99: json_stats: {"cur_iter": "220", "eta": "0:03:43", "split": "test_iter", "time_diff": 1.02692}
[05/01 09:09:10][INFO] logging.py:  99: json_stats: {"cur_iter": "221", "eta": "0:03:51", "split": "test_iter", "time_diff": 1.06769}
[05/01 09:09:11][INFO] logging.py:  99: json_stats: {"cur_iter": "222", "eta": "0:03:47", "split": "test_iter", "time_diff": 1.05179}
[05/01 09:09:14][INFO] logging.py:  99: json_stats: {"cur_iter": "223", "eta": "0:08:22", "split": "test_iter", "time_diff": 2.33623}
[05/01 09:09:15][INFO] logging.py:  99: json_stats: {"cur_iter": "224", "eta": "0:03:43", "split": "test_iter", "time_diff": 1.04573}
[05/01 09:09:16][INFO] logging.py:  99: json_stats: {"cur_iter": "225", "eta": "0:06:02", "split": "test_iter", "time_diff": 1.70324}
[05/01 09:09:18][INFO] logging.py:  99: json_stats: {"cur_iter": "226", "eta": "0:03:37", "split": "test_iter", "time_diff": 1.02548}
[05/01 09:09:19][INFO] logging.py:  99: json_stats: {"cur_iter": "227", "eta": "0:03:37", "split": "test_iter", "time_diff": 1.02881}
[05/01 09:09:20][INFO] logging.py:  99: json_stats: {"cur_iter": "228", "eta": "0:03:31", "split": "test_iter", "time_diff": 1.00563}
[05/01 09:09:21][INFO] logging.py:  99: json_stats: {"cur_iter": "229", "eta": "0:03:37", "split": "test_iter", "time_diff": 1.04287}
[05/01 09:09:22][INFO] logging.py:  99: json_stats: {"cur_iter": "230", "eta": "0:03:43", "split": "test_iter", "time_diff": 1.07237}
[05/01 09:09:23][INFO] logging.py:  99: json_stats: {"cur_iter": "231", "eta": "0:05:19", "split": "test_iter", "time_diff": 1.54508}
[05/01 09:09:24][INFO] logging.py:  99: json_stats: {"cur_iter": "232", "eta": "0:03:36", "split": "test_iter", "time_diff": 1.04994}
[05/01 09:09:26][INFO] logging.py:  99: json_stats: {"cur_iter": "233", "eta": "0:07:09", "split": "test_iter", "time_diff": 2.09293}
[05/01 09:09:28][INFO] logging.py:  99: json_stats: {"cur_iter": "234", "eta": "0:02:59", "split": "test_iter", "time_diff": 0.88152}
[05/01 09:09:29][INFO] logging.py:  99: json_stats: {"cur_iter": "235", "eta": "0:02:59", "split": "test_iter", "time_diff": 0.88228}
[05/01 09:09:30][INFO] logging.py:  99: json_stats: {"cur_iter": "236", "eta": "0:03:29", "split": "test_iter", "time_diff": 1.03879}
[05/01 09:09:31][INFO] logging.py:  99: json_stats: {"cur_iter": "237", "eta": "0:03:27", "split": "test_iter", "time_diff": 1.03104}
[05/01 09:09:32][INFO] logging.py:  99: json_stats: {"cur_iter": "238", "eta": "0:03:29", "split": "test_iter", "time_diff": 1.04610}
[05/01 09:09:34][INFO] logging.py:  99: json_stats: {"cur_iter": "239", "eta": "0:05:34", "split": "test_iter", "time_diff": 1.67908}
[05/01 09:09:35][INFO] logging.py:  99: json_stats: {"cur_iter": "240", "eta": "0:03:28", "split": "test_iter", "time_diff": 1.05304}
[05/01 09:09:37][INFO] logging.py:  99: json_stats: {"cur_iter": "241", "eta": "0:07:29", "split": "test_iter", "time_diff": 2.28198}
[05/01 09:09:38][INFO] logging.py:  99: json_stats: {"cur_iter": "242", "eta": "0:03:18", "split": "test_iter", "time_diff": 1.01473}
[05/01 09:09:39][INFO] logging.py:  99: json_stats: {"cur_iter": "243", "eta": "0:03:18", "split": "test_iter", "time_diff": 1.01915}
[05/01 09:09:40][INFO] logging.py:  99: json_stats: {"cur_iter": "244", "eta": "0:02:51", "split": "test_iter", "time_diff": 0.88202}
[05/01 09:09:41][INFO] logging.py:  99: json_stats: {"cur_iter": "245", "eta": "0:03:14", "split": "test_iter", "time_diff": 1.00868}
[05/01 09:09:42][INFO] logging.py:  99: json_stats: {"cur_iter": "246", "eta": "0:03:23", "split": "test_iter", "time_diff": 1.06040}
[05/01 09:09:44][INFO] logging.py:  99: json_stats: {"cur_iter": "247", "eta": "0:07:15", "split": "test_iter", "time_diff": 2.27979}
[05/01 09:09:45][INFO] logging.py:  99: json_stats: {"cur_iter": "248", "eta": "0:03:14", "split": "test_iter", "time_diff": 1.02519}
[05/01 09:09:47][INFO] logging.py:  99: json_stats: {"cur_iter": "249", "eta": "0:05:11", "split": "test_iter", "time_diff": 1.64920}
[05/01 09:09:48][INFO] logging.py:  99: json_stats: {"cur_iter": "250", "eta": "0:03:10", "split": "test_iter", "time_diff": 1.01160}
[05/01 09:09:49][INFO] logging.py:  99: json_stats: {"cur_iter": "251", "eta": "0:03:08", "split": "test_iter", "time_diff": 1.00690}
[05/01 09:09:50][INFO] logging.py:  99: json_stats: {"cur_iter": "252", "eta": "0:03:10", "split": "test_iter", "time_diff": 1.02279}
[05/01 09:09:51][INFO] logging.py:  99: json_stats: {"cur_iter": "253", "eta": "0:03:22", "split": "test_iter", "time_diff": 1.09462}
[05/01 09:09:52][INFO] logging.py:  99: json_stats: {"cur_iter": "254", "eta": "0:02:51", "split": "test_iter", "time_diff": 0.93387}
[05/01 09:09:54][INFO] logging.py:  99: json_stats: {"cur_iter": "255", "eta": "0:05:41", "split": "test_iter", "time_diff": 1.86666}
[05/01 09:09:55][INFO] logging.py:  99: json_stats: {"cur_iter": "256", "eta": "0:02:40", "split": "test_iter", "time_diff": 0.88119}
[05/01 09:09:58][INFO] logging.py:  99: json_stats: {"cur_iter": "257", "eta": "0:07:14", "split": "test_iter", "time_diff": 2.39906}
[05/01 09:09:59][INFO] logging.py:  99: json_stats: {"cur_iter": "258", "eta": "0:03:01", "split": "test_iter", "time_diff": 1.00919}
[05/01 09:10:00][INFO] logging.py:  99: json_stats: {"cur_iter": "259", "eta": "0:03:08", "split": "test_iter", "time_diff": 1.05481}
[05/01 09:10:01][INFO] logging.py:  99: json_stats: {"cur_iter": "260", "eta": "0:02:37", "split": "test_iter", "time_diff": 0.88253}
[05/01 09:10:02][INFO] logging.py:  99: json_stats: {"cur_iter": "261", "eta": "0:03:03", "split": "test_iter", "time_diff": 1.03684}
[05/01 09:10:03][INFO] logging.py:  99: json_stats: {"cur_iter": "262", "eta": "0:03:03", "split": "test_iter", "time_diff": 1.04333}
[05/01 09:10:05][INFO] logging.py:  99: json_stats: {"cur_iter": "263", "eta": "0:05:40", "split": "test_iter", "time_diff": 1.94592}
[05/01 09:10:06][INFO] logging.py:  99: json_stats: {"cur_iter": "264", "eta": "0:02:48", "split": "test_iter", "time_diff": 0.96894}
[05/01 09:10:09][INFO] logging.py:  99: json_stats: {"cur_iter": "265", "eta": "0:08:37", "split": "test_iter", "time_diff": 2.99369}
[05/01 09:10:10][INFO] logging.py:  99: json_stats: {"cur_iter": "266", "eta": "0:02:57", "split": "test_iter", "time_diff": 1.03256}
[05/01 09:10:11][INFO] logging.py:  99: json_stats: {"cur_iter": "267", "eta": "0:02:55", "split": "test_iter", "time_diff": 1.02473}
[05/01 09:10:12][INFO] logging.py:  99: json_stats: {"cur_iter": "268", "eta": "0:02:55", "split": "test_iter", "time_diff": 1.03276}
[05/01 09:10:13][INFO] logging.py:  99: json_stats: {"cur_iter": "269", "eta": "0:03:00", "split": "test_iter", "time_diff": 1.07025}
[05/01 09:10:14][INFO] logging.py:  99: json_stats: {"cur_iter": "270", "eta": "0:03:00", "split": "test_iter", "time_diff": 1.07305}
[05/01 09:10:15][INFO] logging.py:  99: json_stats: {"cur_iter": "271", "eta": "0:02:52", "split": "test_iter", "time_diff": 1.03327}
[05/01 09:10:16][INFO] logging.py:  99: json_stats: {"cur_iter": "272", "eta": "0:02:55", "split": "test_iter", "time_diff": 1.05867}
[05/01 09:10:19][INFO] logging.py:  99: json_stats: {"cur_iter": "273", "eta": "0:07:50", "split": "test_iter", "time_diff": 2.85271}
[05/01 09:10:20][INFO] logging.py:  99: json_stats: {"cur_iter": "274", "eta": "0:02:24", "split": "test_iter", "time_diff": 0.88189}
[05/01 09:10:21][INFO] logging.py:  99: json_stats: {"cur_iter": "275", "eta": "0:02:24", "split": "test_iter", "time_diff": 0.88569}
[05/01 09:10:22][INFO] logging.py:  99: json_stats: {"cur_iter": "276", "eta": "0:02:50", "split": "test_iter", "time_diff": 1.05198}
[05/01 09:10:23][INFO] logging.py:  99: json_stats: {"cur_iter": "277", "eta": "0:02:54", "split": "test_iter", "time_diff": 1.08083}
[05/01 09:10:24][INFO] logging.py:  99: json_stats: {"cur_iter": "278", "eta": "0:02:43", "split": "test_iter", "time_diff": 1.02086}
[05/01 09:10:26][INFO] logging.py:  99: json_stats: {"cur_iter": "279", "eta": "0:02:53", "split": "test_iter", "time_diff": 1.09022}
[05/01 09:10:27][INFO] logging.py:  99: json_stats: {"cur_iter": "280", "eta": "0:02:45", "split": "test_iter", "time_diff": 1.04751}
[05/01 09:10:29][INFO] logging.py:  99: json_stats: {"cur_iter": "281", "eta": "0:05:12", "split": "test_iter", "time_diff": 1.99343}
[05/01 09:10:30][INFO] logging.py:  99: json_stats: {"cur_iter": "282", "eta": "0:02:37", "split": "test_iter", "time_diff": 1.01225}
[05/01 09:10:31][INFO] logging.py:  99: json_stats: {"cur_iter": "283", "eta": "0:02:34", "split": "test_iter", "time_diff": 0.99461}
[05/01 09:10:32][INFO] logging.py:  99: json_stats: {"cur_iter": "284", "eta": "0:02:39", "split": "test_iter", "time_diff": 1.03473}
[05/01 09:10:33][INFO] logging.py:  99: json_stats: {"cur_iter": "285", "eta": "0:02:40", "split": "test_iter", "time_diff": 1.05082}
[05/01 09:10:34][INFO] logging.py:  99: json_stats: {"cur_iter": "286", "eta": "0:02:43", "split": "test_iter", "time_diff": 1.07767}
[05/01 09:10:35][INFO] logging.py:  99: json_stats: {"cur_iter": "287", "eta": "0:03:38", "split": "test_iter", "time_diff": 1.44454}
[05/01 09:10:36][INFO] logging.py:  99: json_stats: {"cur_iter": "288", "eta": "0:02:14", "split": "test_iter", "time_diff": 0.89805}
[05/01 09:10:39][INFO] logging.py:  99: json_stats: {"cur_iter": "289", "eta": "0:06:07", "split": "test_iter", "time_diff": 2.46475}
[05/01 09:10:40][INFO] logging.py:  99: json_stats: {"cur_iter": "290", "eta": "0:02:10", "split": "test_iter", "time_diff": 0.88499}
[05/01 09:10:41][INFO] logging.py:  99: json_stats: {"cur_iter": "291", "eta": "0:02:10", "split": "test_iter", "time_diff": 0.88575}
[05/01 09:10:42][INFO] logging.py:  99: json_stats: {"cur_iter": "292", "eta": "0:02:28", "split": "test_iter", "time_diff": 1.01777}
[05/01 09:10:43][INFO] logging.py:  99: json_stats: {"cur_iter": "293", "eta": "0:02:35", "split": "test_iter", "time_diff": 1.07456}
[05/01 09:10:44][INFO] logging.py:  99: json_stats: {"cur_iter": "294", "eta": "0:02:29", "split": "test_iter", "time_diff": 1.03557}
[05/01 09:10:45][INFO] logging.py:  99: json_stats: {"cur_iter": "295", "eta": "0:03:37", "split": "test_iter", "time_diff": 1.52249}
[05/01 09:10:46][INFO] logging.py:  99: json_stats: {"cur_iter": "296", "eta": "0:02:06", "split": "test_iter", "time_diff": 0.88877}
[05/01 09:10:49][INFO] logging.py:  99: json_stats: {"cur_iter": "297", "eta": "0:04:49", "split": "test_iter", "time_diff": 2.05430}
[05/01 09:10:50][INFO] logging.py:  99: json_stats: {"cur_iter": "298", "eta": "0:02:19", "split": "test_iter", "time_diff": 0.99774}
[05/01 09:10:51][INFO] logging.py:  99: json_stats: {"cur_iter": "299", "eta": "0:02:24", "split": "test_iter", "time_diff": 1.04254}
[05/01 09:10:52][INFO] logging.py:  99: json_stats: {"cur_iter": "300", "eta": "0:02:23", "split": "test_iter", "time_diff": 1.04094}
[05/01 09:10:53][INFO] logging.py:  99: json_stats: {"cur_iter": "301", "eta": "0:02:23", "split": "test_iter", "time_diff": 1.04719}
[05/01 09:10:54][INFO] logging.py:  99: json_stats: {"cur_iter": "302", "eta": "0:02:23", "split": "test_iter", "time_diff": 1.05840}
[05/01 09:10:55][INFO] logging.py:  99: json_stats: {"cur_iter": "303", "eta": "0:03:26", "split": "test_iter", "time_diff": 1.53224}
[05/01 09:10:56][INFO] logging.py:  99: json_stats: {"cur_iter": "304", "eta": "0:02:24", "split": "test_iter", "time_diff": 1.07877}
[05/01 09:10:59][INFO] logging.py:  99: json_stats: {"cur_iter": "305", "eta": "0:06:16", "split": "test_iter", "time_diff": 2.82942}
[05/01 09:11:00][INFO] logging.py:  99: json_stats: {"cur_iter": "306", "eta": "0:02:11", "split": "test_iter", "time_diff": 0.99911}
[05/01 09:11:01][INFO] logging.py:  99: json_stats: {"cur_iter": "307", "eta": "0:02:16", "split": "test_iter", "time_diff": 1.04414}
[05/01 09:11:02][INFO] logging.py:  99: json_stats: {"cur_iter": "308", "eta": "0:02:10", "split": "test_iter", "time_diff": 1.00435}
[05/01 09:11:03][INFO] logging.py:  99: json_stats: {"cur_iter": "309", "eta": "0:02:15", "split": "test_iter", "time_diff": 1.05238}
[05/01 09:11:04][INFO] logging.py:  99: json_stats: {"cur_iter": "310", "eta": "0:02:14", "split": "test_iter", "time_diff": 1.05407}
[05/01 09:11:05][INFO] logging.py:  99: json_stats: {"cur_iter": "311", "eta": "0:02:12", "split": "test_iter", "time_diff": 1.04465}
[05/01 09:11:06][INFO] logging.py:  99: json_stats: {"cur_iter": "312", "eta": "0:02:11", "split": "test_iter", "time_diff": 1.04274}
[05/01 09:11:10][INFO] logging.py:  99: json_stats: {"cur_iter": "313", "eta": "0:06:29", "split": "test_iter", "time_diff": 3.11251}
[05/01 09:11:11][INFO] logging.py:  99: json_stats: {"cur_iter": "314", "eta": "0:02:08", "split": "test_iter", "time_diff": 1.03947}
[05/01 09:11:12][INFO] logging.py:  99: json_stats: {"cur_iter": "315", "eta": "0:02:09", "split": "test_iter", "time_diff": 1.05218}
[05/01 09:11:13][INFO] logging.py:  99: json_stats: {"cur_iter": "316", "eta": "0:02:05", "split": "test_iter", "time_diff": 1.03064}
[05/01 09:11:14][INFO] logging.py:  99: json_stats: {"cur_iter": "317", "eta": "0:02:08", "split": "test_iter", "time_diff": 1.06014}
[05/01 09:11:15][INFO] logging.py:  99: json_stats: {"cur_iter": "318", "eta": "0:02:07", "split": "test_iter", "time_diff": 1.06459}
[05/01 09:11:16][INFO] logging.py:  99: json_stats: {"cur_iter": "319", "eta": "0:02:01", "split": "test_iter", "time_diff": 1.02203}
[05/01 09:11:17][INFO] logging.py:  99: json_stats: {"cur_iter": "320", "eta": "0:02:04", "split": "test_iter", "time_diff": 1.05870}
[05/01 09:11:20][INFO] logging.py:  99: json_stats: {"cur_iter": "321", "eta": "0:06:10", "split": "test_iter", "time_diff": 3.16537}
[05/01 09:11:21][INFO] logging.py:  99: json_stats: {"cur_iter": "322", "eta": "0:01:55", "split": "test_iter", "time_diff": 0.99579}
[05/01 09:11:22][INFO] logging.py:  99: json_stats: {"cur_iter": "323", "eta": "0:01:41", "split": "test_iter", "time_diff": 0.88117}
[05/01 09:11:23][INFO] logging.py:  99: json_stats: {"cur_iter": "324", "eta": "0:02:01", "split": "test_iter", "time_diff": 1.06407}
[05/01 09:11:24][INFO] logging.py:  99: json_stats: {"cur_iter": "325", "eta": "0:01:53", "split": "test_iter", "time_diff": 1.00769}
[05/01 09:11:25][INFO] logging.py:  99: json_stats: {"cur_iter": "326", "eta": "0:01:54", "split": "test_iter", "time_diff": 1.02647}
[05/01 09:11:26][INFO] logging.py:  99: json_stats: {"cur_iter": "327", "eta": "0:01:38", "split": "test_iter", "time_diff": 0.89022}
[05/01 09:11:27][INFO] logging.py:  99: json_stats: {"cur_iter": "328", "eta": "0:01:55", "split": "test_iter", "time_diff": 1.05225}
[05/01 09:11:30][INFO] logging.py:  99: json_stats: {"cur_iter": "329", "eta": "0:03:55", "split": "test_iter", "time_diff": 2.15843}
[05/01 09:11:31][INFO] logging.py:  99: json_stats: {"cur_iter": "330", "eta": "0:01:51", "split": "test_iter", "time_diff": 1.03238}
[05/01 09:11:32][INFO] logging.py:  99: json_stats: {"cur_iter": "331", "eta": "0:01:51", "split": "test_iter", "time_diff": 1.03978}
[05/01 09:11:33][INFO] logging.py:  99: json_stats: {"cur_iter": "332", "eta": "0:01:50", "split": "test_iter", "time_diff": 1.04406}
[05/01 09:11:34][INFO] logging.py:  99: json_stats: {"cur_iter": "333", "eta": "0:01:53", "split": "test_iter", "time_diff": 1.08248}
[05/01 09:11:35][INFO] logging.py:  99: json_stats: {"cur_iter": "334", "eta": "0:01:43", "split": "test_iter", "time_diff": 0.99244}
[05/01 09:11:36][INFO] logging.py:  99: json_stats: {"cur_iter": "335", "eta": "0:01:53", "split": "test_iter", "time_diff": 1.10438}
[05/01 09:11:37][INFO] logging.py:  99: json_stats: {"cur_iter": "336", "eta": "0:01:46", "split": "test_iter", "time_diff": 1.04725}
[05/01 09:11:40][INFO] logging.py:  99: json_stats: {"cur_iter": "337", "eta": "0:04:30", "split": "test_iter", "time_diff": 2.67610}
[05/01 09:11:41][INFO] logging.py:  99: json_stats: {"cur_iter": "338", "eta": "0:01:42", "split": "test_iter", "time_diff": 1.02789}
[05/01 09:11:42][INFO] logging.py:  99: json_stats: {"cur_iter": "339", "eta": "0:01:39", "split": "test_iter", "time_diff": 1.00581}
[05/01 09:11:43][INFO] logging.py:  99: json_stats: {"cur_iter": "340", "eta": "0:01:26", "split": "test_iter", "time_diff": 0.88213}
[05/01 09:11:44][INFO] logging.py:  99: json_stats: {"cur_iter": "341", "eta": "0:01:26", "split": "test_iter", "time_diff": 0.89680}
[05/01 09:11:45][INFO] logging.py:  99: json_stats: {"cur_iter": "342", "eta": "0:01:36", "split": "test_iter", "time_diff": 1.00015}
[05/01 09:11:46][INFO] logging.py:  99: json_stats: {"cur_iter": "343", "eta": "0:01:36", "split": "test_iter", "time_diff": 1.01784}
[05/01 09:11:47][INFO] logging.py:  99: json_stats: {"cur_iter": "344", "eta": "0:01:37", "split": "test_iter", "time_diff": 1.03760}
[05/01 09:11:49][INFO] logging.py:  99: json_stats: {"cur_iter": "345", "eta": "0:03:49", "split": "test_iter", "time_diff": 2.46936}
[05/01 09:11:50][INFO] logging.py:  99: json_stats: {"cur_iter": "346", "eta": "0:01:33", "split": "test_iter", "time_diff": 1.02040}
[05/01 09:11:51][INFO] logging.py:  99: json_stats: {"cur_iter": "347", "eta": "0:01:20", "split": "test_iter", "time_diff": 0.88920}
[05/01 09:11:52][INFO] logging.py:  99: json_stats: {"cur_iter": "348", "eta": "0:01:31", "split": "test_iter", "time_diff": 1.01269}
[05/01 09:11:53][INFO] logging.py:  99: json_stats: {"cur_iter": "349", "eta": "0:01:35", "split": "test_iter", "time_diff": 1.06769}
[05/01 09:11:55][INFO] logging.py:  99: json_stats: {"cur_iter": "350", "eta": "0:01:34", "split": "test_iter", "time_diff": 1.07549}
[05/01 09:11:56][INFO] logging.py:  99: json_stats: {"cur_iter": "351", "eta": "0:01:31", "split": "test_iter", "time_diff": 1.05031}
[05/01 09:11:57][INFO] logging.py:  99: json_stats: {"cur_iter": "352", "eta": "0:01:28", "split": "test_iter", "time_diff": 1.02409}
[05/01 09:11:59][INFO] logging.py:  99: json_stats: {"cur_iter": "353", "eta": "0:03:45", "split": "test_iter", "time_diff": 2.65114}
[05/01 09:12:00][INFO] logging.py:  99: json_stats: {"cur_iter": "354", "eta": "0:01:26", "split": "test_iter", "time_diff": 1.02911}
[05/01 09:12:01][INFO] logging.py:  99: json_stats: {"cur_iter": "355", "eta": "0:01:26", "split": "test_iter", "time_diff": 1.04210}
[05/01 09:12:02][INFO] logging.py:  99: json_stats: {"cur_iter": "356", "eta": "0:01:26", "split": "test_iter", "time_diff": 1.05090}
[05/01 09:12:03][INFO] logging.py:  99: json_stats: {"cur_iter": "357", "eta": "0:01:22", "split": "test_iter", "time_diff": 1.01705}
[05/01 09:12:04][INFO] logging.py:  99: json_stats: {"cur_iter": "358", "eta": "0:01:24", "split": "test_iter", "time_diff": 1.05959}
[05/01 09:12:06][INFO] logging.py:  99: json_stats: {"cur_iter": "359", "eta": "0:01:10", "split": "test_iter", "time_diff": 0.89569}
[05/01 09:12:07][INFO] logging.py:  99: json_stats: {"cur_iter": "360", "eta": "0:01:21", "split": "test_iter", "time_diff": 1.05116}
[05/01 09:12:09][INFO] logging.py:  99: json_stats: {"cur_iter": "361", "eta": "0:03:05", "split": "test_iter", "time_diff": 2.40321}
[05/01 09:12:10][INFO] logging.py:  99: json_stats: {"cur_iter": "362", "eta": "0:01:06", "split": "test_iter", "time_diff": 0.87873}
[05/01 09:12:11][INFO] logging.py:  99: json_stats: {"cur_iter": "363", "eta": "0:01:06", "split": "test_iter", "time_diff": 0.88170}
[05/01 09:12:12][INFO] logging.py:  99: json_stats: {"cur_iter": "364", "eta": "0:01:19", "split": "test_iter", "time_diff": 1.06940}
[05/01 09:12:13][INFO] logging.py:  99: json_stats: {"cur_iter": "365", "eta": "0:01:19", "split": "test_iter", "time_diff": 1.08513}
[05/01 09:12:14][INFO] logging.py:  99: json_stats: {"cur_iter": "366", "eta": "0:01:15", "split": "test_iter", "time_diff": 1.04626}
[05/01 09:12:15][INFO] logging.py:  99: json_stats: {"cur_iter": "367", "eta": "0:01:16", "split": "test_iter", "time_diff": 1.08069}
[05/01 09:12:16][INFO] logging.py:  99: json_stats: {"cur_iter": "368", "eta": "0:01:01", "split": "test_iter", "time_diff": 0.88370}
[05/01 09:12:19][INFO] logging.py:  99: json_stats: {"cur_iter": "369", "eta": "0:02:35", "split": "test_iter", "time_diff": 2.25849}
[05/01 09:12:20][INFO] logging.py:  99: json_stats: {"cur_iter": "370", "eta": "0:01:08", "split": "test_iter", "time_diff": 1.01355}
[05/01 09:12:21][INFO] logging.py:  99: json_stats: {"cur_iter": "371", "eta": "0:01:10", "split": "test_iter", "time_diff": 1.05678}
[05/01 09:12:22][INFO] logging.py:  99: json_stats: {"cur_iter": "372", "eta": "0:01:08", "split": "test_iter", "time_diff": 1.04028}
[05/01 09:12:23][INFO] logging.py:  99: json_stats: {"cur_iter": "373", "eta": "0:01:09", "split": "test_iter", "time_diff": 1.06972}
[05/01 09:12:24][INFO] logging.py:  99: json_stats: {"cur_iter": "374", "eta": "0:01:02", "split": "test_iter", "time_diff": 0.97645}
[05/01 09:12:26][INFO] logging.py:  99: json_stats: {"cur_iter": "375", "eta": "0:01:42", "split": "test_iter", "time_diff": 1.63180}
[05/01 09:12:27][INFO] logging.py:  99: json_stats: {"cur_iter": "376", "eta": "0:01:04", "split": "test_iter", "time_diff": 1.03309}
[05/01 09:12:29][INFO] logging.py:  99: json_stats: {"cur_iter": "377", "eta": "0:02:16", "split": "test_iter", "time_diff": 2.23381}
[05/01 09:12:30][INFO] logging.py:  99: json_stats: {"cur_iter": "378", "eta": "0:00:59", "split": "test_iter", "time_diff": 0.99905}
[05/01 09:12:31][INFO] logging.py:  99: json_stats: {"cur_iter": "379", "eta": "0:00:52", "split": "test_iter", "time_diff": 0.88201}
[05/01 09:12:32][INFO] logging.py:  99: json_stats: {"cur_iter": "380", "eta": "0:01:00", "split": "test_iter", "time_diff": 1.04481}
[05/01 09:12:33][INFO] logging.py:  99: json_stats: {"cur_iter": "381", "eta": "0:00:58", "split": "test_iter", "time_diff": 1.03437}
[05/01 09:12:34][INFO] logging.py:  99: json_stats: {"cur_iter": "382", "eta": "0:00:59", "split": "test_iter", "time_diff": 1.07103}
[05/01 09:12:35][INFO] logging.py:  99: json_stats: {"cur_iter": "383", "eta": "0:00:59", "split": "test_iter", "time_diff": 1.07680}
[05/01 09:12:36][INFO] logging.py:  99: json_stats: {"cur_iter": "384", "eta": "0:00:48", "split": "test_iter", "time_diff": 0.89592}
[05/01 09:12:38][INFO] logging.py:  99: json_stats: {"cur_iter": "385", "eta": "0:02:04", "split": "test_iter", "time_diff": 2.34349}
[05/01 09:12:40][INFO] logging.py:  99: json_stats: {"cur_iter": "386", "eta": "0:00:52", "split": "test_iter", "time_diff": 1.01466}
[05/01 09:12:41][INFO] logging.py:  99: json_stats: {"cur_iter": "387", "eta": "0:00:54", "split": "test_iter", "time_diff": 1.06120}
[05/01 09:12:42][INFO] logging.py:  99: json_stats: {"cur_iter": "388", "eta": "0:00:52", "split": "test_iter", "time_diff": 1.05562}
[05/01 09:12:43][INFO] logging.py:  99: json_stats: {"cur_iter": "389", "eta": "0:00:50", "split": "test_iter", "time_diff": 1.03176}
[05/01 09:12:44][INFO] logging.py:  99: json_stats: {"cur_iter": "390", "eta": "0:00:50", "split": "test_iter", "time_diff": 1.06203}
[05/01 09:12:45][INFO] logging.py:  99: json_stats: {"cur_iter": "391", "eta": "0:00:50", "split": "test_iter", "time_diff": 1.07955}
[05/01 09:12:46][INFO] logging.py:  99: json_stats: {"cur_iter": "392", "eta": "0:00:47", "split": "test_iter", "time_diff": 1.04010}
[05/01 09:12:49][INFO] logging.py:  99: json_stats: {"cur_iter": "393", "eta": "0:02:27", "split": "test_iter", "time_diff": 3.26732}
[05/01 09:12:50][INFO] logging.py:  99: json_stats: {"cur_iter": "394", "eta": "0:00:38", "split": "test_iter", "time_diff": 0.88553}
[05/01 09:12:51][INFO] logging.py:  99: json_stats: {"cur_iter": "395", "eta": "0:00:49", "split": "test_iter", "time_diff": 1.14270}
[05/01 09:12:52][INFO] logging.py:  99: json_stats: {"cur_iter": "396", "eta": "0:00:43", "split": "test_iter", "time_diff": 1.04268}
[05/01 09:12:53][INFO] logging.py:  99: json_stats: {"cur_iter": "397", "eta": "0:00:37", "split": "test_iter", "time_diff": 0.90810}
[05/01 09:12:55][INFO] logging.py:  99: json_stats: {"cur_iter": "398", "eta": "0:00:42", "split": "test_iter", "time_diff": 1.06717}
[05/01 09:12:56][INFO] logging.py:  99: json_stats: {"cur_iter": "399", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.05379}
[05/01 09:12:57][INFO] logging.py:  99: json_stats: {"cur_iter": "400", "eta": "0:00:39", "split": "test_iter", "time_diff": 1.03868}
[05/01 09:12:59][INFO] logging.py:  99: json_stats: {"cur_iter": "401", "eta": "0:01:33", "split": "test_iter", "time_diff": 2.51620}
[05/01 09:13:00][INFO] logging.py:  99: json_stats: {"cur_iter": "402", "eta": "0:00:36", "split": "test_iter", "time_diff": 1.02284}
[05/01 09:13:01][INFO] logging.py:  99: json_stats: {"cur_iter": "403", "eta": "0:00:39", "split": "test_iter", "time_diff": 1.11789}
[05/01 09:13:02][INFO] logging.py:  99: json_stats: {"cur_iter": "404", "eta": "0:00:35", "split": "test_iter", "time_diff": 1.05194}
[05/01 09:13:03][INFO] logging.py:  99: json_stats: {"cur_iter": "405", "eta": "0:00:34", "split": "test_iter", "time_diff": 1.05846}
[05/01 09:13:04][INFO] logging.py:  99: json_stats: {"cur_iter": "406", "eta": "0:00:32", "split": "test_iter", "time_diff": 1.03060}
[05/01 09:13:05][INFO] logging.py:  99: json_stats: {"cur_iter": "407", "eta": "0:00:31", "split": "test_iter", "time_diff": 1.02161}
[05/01 09:13:07][INFO] logging.py:  99: json_stats: {"cur_iter": "408", "eta": "0:00:31", "split": "test_iter", "time_diff": 1.05815}
[05/01 09:13:09][INFO] logging.py:  99: json_stats: {"cur_iter": "409", "eta": "0:01:06", "split": "test_iter", "time_diff": 2.27863}
[05/01 09:13:10][INFO] logging.py:  99: json_stats: {"cur_iter": "410", "eta": "0:00:29", "split": "test_iter", "time_diff": 1.05666}
[05/01 09:13:11][INFO] logging.py:  99: json_stats: {"cur_iter": "411", "eta": "0:00:29", "split": "test_iter", "time_diff": 1.08075}
[05/01 09:13:12][INFO] logging.py:  99: json_stats: {"cur_iter": "412", "eta": "0:00:28", "split": "test_iter", "time_diff": 1.09596}
[05/01 09:13:13][INFO] logging.py:  99: json_stats: {"cur_iter": "413", "eta": "0:00:24", "split": "test_iter", "time_diff": 0.96443}
[05/01 09:13:14][INFO] logging.py:  99: json_stats: {"cur_iter": "414", "eta": "0:00:23", "split": "test_iter", "time_diff": 0.98096}
[05/01 09:13:15][INFO] logging.py:  99: json_stats: {"cur_iter": "415", "eta": "0:00:26", "split": "test_iter", "time_diff": 1.13236}
[05/01 09:13:16][INFO] logging.py:  99: json_stats: {"cur_iter": "416", "eta": "0:00:22", "split": "test_iter", "time_diff": 1.00850}
[05/01 09:13:18][INFO] logging.py:  99: json_stats: {"cur_iter": "417", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.96242}
[05/01 09:13:19][INFO] logging.py:  99: json_stats: {"cur_iter": "418", "eta": "0:00:21", "split": "test_iter", "time_diff": 1.06123}
[05/01 09:13:20][INFO] logging.py:  99: json_stats: {"cur_iter": "419", "eta": "0:00:19", "split": "test_iter", "time_diff": 1.04373}
[05/01 09:13:21][INFO] logging.py:  99: json_stats: {"cur_iter": "420", "eta": "0:00:17", "split": "test_iter", "time_diff": 0.96973}
[05/01 09:13:23][INFO] logging.py:  99: json_stats: {"cur_iter": "421", "eta": "0:00:15", "split": "test_iter", "time_diff": 0.92300}
[05/01 09:13:24][INFO] logging.py:  99: json_stats: {"cur_iter": "422", "eta": "0:00:15", "split": "test_iter", "time_diff": 0.97754}
[05/01 09:13:25][INFO] logging.py:  99: json_stats: {"cur_iter": "423", "eta": "0:00:16", "split": "test_iter", "time_diff": 1.06838}
[05/01 09:13:26][INFO] logging.py:  99: json_stats: {"cur_iter": "424", "eta": "0:00:14", "split": "test_iter", "time_diff": 1.05727}
[05/01 09:13:29][INFO] logging.py:  99: json_stats: {"cur_iter": "425", "eta": "0:00:41", "split": "test_iter", "time_diff": 3.16370}
[05/01 09:13:30][INFO] logging.py:  99: json_stats: {"cur_iter": "426", "eta": "0:00:10", "split": "test_iter", "time_diff": 0.90122}
[05/01 09:13:31][INFO] logging.py:  99: json_stats: {"cur_iter": "427", "eta": "0:00:10", "split": "test_iter", "time_diff": 0.91251}
[05/01 09:13:32][INFO] logging.py:  99: json_stats: {"cur_iter": "428", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.93022}
[05/01 09:13:33][INFO] logging.py:  99: json_stats: {"cur_iter": "429", "eta": "0:00:09", "split": "test_iter", "time_diff": 1.00376}
[05/01 09:13:34][INFO] logging.py:  99: json_stats: {"cur_iter": "430", "eta": "0:00:07", "split": "test_iter", "time_diff": 0.99072}
[05/01 09:13:35][INFO] logging.py:  99: json_stats: {"cur_iter": "431", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.98555}
[05/01 09:13:36][INFO] logging.py:  99: json_stats: {"cur_iter": "432", "eta": "0:00:05", "split": "test_iter", "time_diff": 0.95821}
[05/01 09:13:37][INFO] logging.py:  99: json_stats: {"cur_iter": "433", "eta": "0:00:05", "split": "test_iter", "time_diff": 1.13362}
[05/01 09:13:38][INFO] logging.py:  99: json_stats: {"cur_iter": "434", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.88081}
[05/01 09:13:39][INFO] logging.py:  99: json_stats: {"cur_iter": "435", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.90026}
[05/01 09:13:40][INFO] logging.py:  99: json_stats: {"cur_iter": "436", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.90211}
[05/01 09:13:40][INFO] logging.py:  99: json_stats: {"cur_iter": "437", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.73935}
[05/01 09:13:41][WARNING] meters.py: 381: clip count 0: 9, 1: 9, 2: 9, 3: 9, 4: 9, 5: 9, 6: 9, 7: 9, 8: 9, 9: 9, 10: 9, 11: 9, 12: 9, 13: 9, 14: 9, 15: 9, 16: 9, 17: 9, 18: 9, 19: 9, 20: 9, 21: 9, 22: 9, 23: 9, 24: 9, 25: 9, 26: 9, 27: 9, 28: 9, 29: 9, 30: 9, 31: 9, 32: 9, 33: 9, 34: 9, 35: 9, 36: 9, 37: 9, 38: 9, 39: 9, 40: 9, 41: 9, 42: 9, 43: 9, 44: 9, 45: 9, 46: 9, 47: 9, 48: 9, 49: 9, 50: 9, 51: 9, 52: 9, 53: 9, 54: 9, 55: 9, 56: 9, 57: 9, 58: 9, 59: 9, 60: 9, 61: 9, 62: 9, 63: 9, 64: 9, 65: 9, 66: 9, 67: 9, 68: 9, 69: 9, 70: 9, 71: 9, 72: 9, 73: 9, 74: 9, 75: 9, 76: 9, 77: 9, 78: 9, 79: 9, 80: 9, 81: 9, 82: 9, 83: 9, 84: 9, 85: 9, 86: 9, 87: 9, 88: 9, 89: 9, 90: 9, 91: 9, 92: 9, 93: 9, 94: 9, 95: 9, 96: 9, 97: 9, 98: 9, 99: 9, 100: 9, 101: 9, 102: 9, 103: 9, 104: 9, 105: 9, 106: 9, 107: 9, 108: 9, 109: 9, 110: 9, 111: 9, 112: 9, 113: 9, 114: 9, 115: 9, 116: 9, 117: 9, 118: 9, 119: 9, 120: 9, 121: 9, 122: 9, 123: 9, 124: 9, 125: 9, 126: 9, 127: 9, 128: 9, 129: 9, 130: 9, 131: 9, 132: 9, 133: 9, 134: 9, 135: 9, 136: 9, 137: 9, 138: 9, 139: 9, 140: 9, 141: 9, 142: 9, 143: 9, 144: 9, 145: 9, 146: 9, 147: 9, 148: 9, 149: 9, 150: 9, 151: 9, 152: 9, 153: 9, 154: 9, 155: 9, 156: 9, 157: 9, 158: 9, 159: 9, 160: 9, 161: 9, 162: 9, 163: 9, 164: 9, 165: 9, 166: 9, 167: 9, 168: 9, 169: 9, 170: 9, 171: 9, 172: 9, 173: 9, 174: 9, 175: 9, 176: 9, 177: 9, 178: 9, 179: 9, 180: 9, 181: 9, 182: 9, 183: 9, 184: 9, 185: 9, 186: 9, 187: 9, 188: 9, 189: 9, 190: 9, 191: 9, 192: 9, 193: 9, 194: 9, 195: 9, 196: 9, 197: 9, 198: 9, 199: 9, 200: 9, 201: 9, 202: 9, 203: 9, 204: 9, 205: 9, 206: 9, 207: 9, 208: 9, 209: 9, 210: 9, 211: 9, 212: 9, 213: 9, 214: 9, 215: 9, 216: 9, 217: 9, 218: 9, 219: 9, 220: 9, 221: 9, 222: 9, 223: 9, 224: 9, 225: 9, 226: 9, 227: 9, 228: 9, 229: 9, 230: 9, 231: 9, 232: 9, 233: 9, 234: 9, 235: 9, 236: 9, 237: 9, 238: 9, 239: 9, 240: 9, 241: 9, 242: 9, 243: 9, 244: 9, 245: 9, 246: 9, 247: 9, 248: 9, 249: 9, 250: 9, 251: 9, 252: 9, 253: 9, 254: 9, 255: 9, 256: 9, 257: 9, 258: 9, 259: 9, 260: 9, 261: 9, 262: 9, 263: 9, 264: 9, 265: 9, 266: 9, 267: 9, 268: 9, 269: 9, 270: 9, 271: 9, 272: 9, 273: 9, 274: 9, 275: 9, 276: 9, 277: 9, 278: 9, 279: 9, 280: 9, 281: 9, 282: 9, 283: 9, 284: 9, 285: 9, 286: 9, 287: 9, 288: 9, 289: 9, 290: 9, 291: 9, 292: 9, 293: 9, 294: 9, 295: 9, 296: 9, 297: 9, 298: 9, 299: 9, 300: 9, 301: 9, 302: 9, 303: 9, 304: 9, 305: 9, 306: 9, 307: 9, 308: 9, 309: 9, 310: 9, 311: 9, 312: 9, 313: 9, 314: 9, 315: 9, 316: 9, 317: 9, 318: 9, 319: 9, 320: 9, 321: 9, 322: 9, 323: 9, 324: 9, 325: 9, 326: 9, 327: 9, 328: 9, 329: 9, 330: 9, 331: 9, 332: 9, 333: 9, 334: 9, 335: 9, 336: 9, 337: 9, 338: 9, 339: 9, 340: 9, 341: 9, 342: 9, 343: 9, 344: 9, 345: 9, 346: 9, 347: 9, 348: 9, 349: 9, 350: 9, 351: 9, 352: 9, 353: 9, 354: 9, 355: 9, 356: 9, 357: 9, 358: 9, 359: 9, 360: 9, 361: 9, 362: 9, 363: 9, 364: 9, 365: 9, 366: 9, 367: 9, 368: 9, 369: 9, 370: 9, 371: 9, 372: 9, 373: 9, 374: 9, 375: 9, 376: 9, 377: 9, 378: 9, 379: 9, 380: 9, 381: 9, 382: 9, 383: 9, 384: 9, 385: 9, 386: 9, 387: 9, 388: 9, 389: 9, 390: 9, 391: 9, 392: 9, 393: 9, 394: 9, 395: 9, 396: 9, 397: 9, 398: 9, 399: 9, 400: 9, 401: 9, 402: 9, 403: 9, 404: 9, 405: 9, 406: 9, 407: 9, 408: 9, 409: 9, 410: 9, 411: 9, 412: 9, 413: 9, 414: 9, 415: 9, 416: 9, 417: 9, 418: 9, 419: 9, 420: 9, 421: 9, 422: 9, 423: 9, 424: 9, 425: 9, 426: 9, 427: 9, 428: 9, 429: 9, 430: 9, 431: 9, 432: 9, 433: 9, 434: 9, 435: 9, 436: 9, 437: 9, 438: 9, 439: 9, 440: 9, 441: 9, 442: 9, 443: 9, 444: 9, 445: 9, 446: 9, 447: 9, 448: 9, 449: 9, 450: 9, 451: 9, 452: 9, 453: 9, 454: 9, 455: 9, 456: 9, 457: 9, 458: 9, 459: 9, 460: 9, 461: 9, 462: 9, 463: 9, 464: 9, 465: 9, 466: 9, 467: 9, 468: 9, 469: 9, 470: 9, 471: 9, 472: 9, 473: 9, 474: 9, 475: 9, 476: 9, 477: 9, 478: 9, 479: 9, 480: 9, 481: 9, 482: 9, 483: 9, 484: 9, 485: 9, 486: 9, 487: 9, 488: 9, 489: 9, 490: 9, 491: 9, 492: 9, 493: 9, 494: 9, 495: 9, 496: 9, 497: 9, 498: 9, 499: 9, 500: 9, 501: 9, 502: 9, 503: 9, 504: 9, 505: 9, 506: 9, 507: 9, 508: 9, 509: 9, 510: 9, 511: 9, 512: 9, 513: 9, 514: 9, 515: 9, 516: 9, 517: 9, 518: 9, 519: 9, 520: 9, 521: 9, 522: 9, 523: 9, 524: 9, 525: 9, 526: 9, 527: 9, 528: 9, 529: 9, 530: 9, 531: 9, 532: 9, 533: 9, 534: 9, 535: 9, 536: 9, 537: 9, 538: 9, 539: 9, 540: 9, 541: 9, 542: 9, 543: 9, 544: 9, 545: 9, 546: 9, 547: 9, 548: 9, 549: 9, 550: 9, 551: 9, 552: 9, 553: 9, 554: 9, 555: 9, 556: 9, 557: 9, 558: 9, 559: 9, 560: 9, 561: 9, 562: 9, 563: 9, 564: 9, 565: 9, 566: 9, 567: 9, 568: 9, 569: 9, 570: 9, 571: 9, 572: 9, 573: 9, 574: 9, 575: 9, 576: 9, 577: 9, 578: 9, 579: 9, 580: 9, 581: 9, 582: 9, 583: 9, 584: 9, 585: 9, 586: 9, 587: 9, 588: 9, 589: 9, 590: 9, 591: 9, 592: 9, 593: 9, 594: 9, 595: 9, 596: 9, 597: 9, 598: 9, 599: 9, 600: 9, 601: 9, 602: 9, 603: 9, 604: 9, 605: 9, 606: 9, 607: 9, 608: 9, 609: 9, 610: 9, 611: 9, 612: 9, 613: 9, 614: 9, 615: 9, 616: 9, 617: 9, 618: 9, 619: 9, 620: 9, 621: 9, 622: 9, 623: 9, 624: 9, 625: 9, 626: 9, 627: 9, 628: 9, 629: 9, 630: 9, 631: 9, 632: 9, 633: 9, 634: 9, 635: 9, 636: 9, 637: 9, 638: 9, 639: 9, 640: 9, 641: 9, 642: 9, 643: 9, 644: 9, 645: 9, 646: 9, 647: 9, 648: 9, 649: 9, 650: 9, 651: 9, 652: 9, 653: 9, 654: 9, 655: 9, 656: 9, 657: 9, 658: 9, 659: 9, 660: 9, 661: 9, 662: 9, 663: 9, 664: 9, 665: 9, 666: 9, 667: 9, 668: 9, 669: 9, 670: 9, 671: 9, 672: 9, 673: 9, 674: 9, 675: 9, 676: 9, 677: 9, 678: 9, 679: 9, 680: 9, 681: 9, 682: 9, 683: 9, 684: 9, 685: 9, 686: 9, 687: 9, 688: 9, 689: 9, 690: 9, 691: 9, 692: 9, 693: 9, 694: 9, 695: 9, 696: 9, 697: 9, 698: 9, 699: 9, 700: 9, 701: 9, 702: 9, 703: 9, 704: 9, 705: 9, 706: 9, 707: 9, 708: 9, 709: 9, 710: 9, 711: 9, 712: 9, 713: 9, 714: 9, 715: 9, 716: 9, 717: 9, 718: 9, 719: 9, 720: 9, 721: 9, 722: 9, 723: 9, 724: 9, 725: 9, 726: 9, 727: 9, 728: 9, 729: 9, 730: 9, 731: 9, 732: 9, 733: 9, 734: 9, 735: 9, 736: 9, 737: 9, 738: 9, 739: 9, 740: 9, 741: 9, 742: 9, 743: 9, 744: 9, 745: 9, 746: 9, 747: 9, 748: 9, 749: 9, 750: 9, 751: 9, 752: 9, 753: 9, 754: 9, 755: 9, 756: 9, 757: 9, 758: 9, 759: 9, 760: 9, 761: 9, 762: 9, 763: 9, 764: 9, 765: 9, 766: 9, 767: 9, 768: 9, 769: 9, 770: 9, 771: 9, 772: 9, 773: 9, 774: 9, 775: 9, 776: 9, 777: 9, 778: 9, 779: 9, 780: 9, 781: 9, 782: 9, 783: 9, 784: 9, 785: 9, 786: 9, 787: 9, 788: 9, 789: 9, 790: 9, 791: 9, 792: 9, 793: 9, 794: 9, 795: 9, 796: 9, 797: 9, 798: 9, 799: 9, 800: 9, 801: 9, 802: 9, 803: 9, 804: 9, 805: 9, 806: 9, 807: 9, 808: 9, 809: 9, 810: 9, 811: 9, 812: 9, 813: 9, 814: 9, 815: 9, 816: 9, 817: 9, 818: 9, 819: 9, 820: 9, 821: 9, 822: 9, 823: 9, 824: 9, 825: 9, 826: 9, 827: 9, 828: 9, 829: 9, 830: 9, 831: 9, 832: 9, 833: 9, 834: 9, 835: 9, 836: 9, 837: 9, 838: 9, 839: 9, 840: 9, 841: 9, 842: 9, 843: 9, 844: 9, 845: 9, 846: 9, 847: 9, 848: 9, 849: 9, 850: 9, 851: 9, 852: 9, 853: 9, 854: 9, 855: 9, 856: 9, 857: 9, 858: 9, 859: 9, 860: 9, 861: 9, 862: 9, 863: 9, 864: 9, 865: 9, 866: 9, 867: 9, 868: 9, 869: 9, 870: 9, 871: 9, 872: 9, 873: 9, 874: 9, 875: 9, 876: 9, 877: 9, 878: 9, 879: 9, 880: 9, 881: 9, 882: 9, 883: 9, 884: 9, 885: 9, 886: 9, 887: 9, 888: 9, 889: 9, 890: 9, 891: 9, 892: 9, 893: 9, 894: 9, 895: 9, 896: 9, 897: 9, 898: 9, 899: 9, 900: 9, 901: 9, 902: 9, 903: 9, 904: 9, 905: 9, 906: 9, 907: 9, 908: 9, 909: 9, 910: 9, 911: 9, 912: 9, 913: 9, 914: 9, 915: 9, 916: 9, 917: 9, 918: 9, 919: 9, 920: 9, 921: 9, 922: 9, 923: 9, 924: 9, 925: 9, 926: 9, 927: 9, 928: 9, 929: 9, 930: 9, 931: 9, 932: 9, 933: 9, 934: 9, 935: 9, 936: 9, 937: 9, 938: 9, 939: 9, 940: 9, 941: 9, 942: 9, 943: 9, 944: 9, 945: 9, 946: 9, 947: 9, 948: 9, 949: 9, 950: 9, 951: 9, 952: 9, 953: 9, 954: 9, 955: 9, 956: 9, 957: 9, 958: 9, 959: 9, 960: 9, 961: 9, 962: 9, 963: 9, 964: 9, 965: 9, 966: 9, 967: 9, 968: 9, 969: 9, 970: 9, 971: 9, 972: 9, 973: 9, 974: 9, 975: 9, 976: 9, 977: 9, 978: 9, 979: 9, 980: 9, 981: 9, 982: 9, 983: 9, 984: 9, 985: 9, 986: 9, 987: 9, 988: 9, 989: 9, 990: 9, 991: 9, 992: 9, 993: 9, 994: 9, 995: 9, 996: 9, 997: 9, 998: 9, 999: 9, 1000: 9, 1001: 9, 1002: 9, 1003: 9, 1004: 9, 1005: 9, 1006: 9, 1007: 9, 1008: 9, 1009: 9, 1010: 9, 1011: 9, 1012: 9, 1013: 9, 1014: 9, 1015: 9, 1016: 9, 1017: 9, 1018: 9, 1019: 9, 1020: 9, 1021: 9, 1022: 9, 1023: 9, 1024: 9, 1025: 9, 1026: 9, 1027: 9, 1028: 9, 1029: 9, 1030: 9, 1031: 9, 1032: 9, 1033: 9, 1034: 9, 1035: 9, 1036: 9, 1037: 9, 1038: 9, 1039: 9, 1040: 9, 1041: 9, 1042: 9, 1043: 9, 1044: 9, 1045: 9, 1046: 9, 1047: 9, 1048: 9, 1049: 9, 1050: 9, 1051: 9, 1052: 9, 1053: 9, 1054: 9, 1055: 9, 1056: 9, 1057: 9, 1058: 9, 1059: 9, 1060: 9, 1061: 9, 1062: 9, 1063: 9, 1064: 9, 1065: 9, 1066: 9, 1067: 9, 1068: 9, 1069: 9, 1070: 9, 1071: 9, 1072: 9, 1073: 9, 1074: 9, 1075: 9, 1076: 9, 1077: 9, 1078: 9, 1079: 9, 1080: 9, 1081: 9, 1082: 9, 1083: 9, 1084: 9, 1085: 9, 1086: 9, 1087: 9, 1088: 9, 1089: 9, 1090: 9, 1091: 9, 1092: 9, 1093: 9, 1094: 9, 1095: 9, 1096: 9, 1097: 9, 1098: 9, 1099: 9, 1100: 9, 1101: 9, 1102: 9, 1103: 9, 1104: 9, 1105: 9, 1106: 9, 1107: 9, 1108: 9, 1109: 9, 1110: 9, 1111: 9, 1112: 9, 1113: 9, 1114: 9, 1115: 9, 1116: 9, 1117: 9, 1118: 9, 1119: 9, 1120: 9, 1121: 9, 1122: 9, 1123: 9, 1124: 9, 1125: 9, 1126: 9, 1127: 9, 1128: 9, 1129: 9, 1130: 9, 1131: 9, 1132: 9, 1133: 9, 1134: 9, 1135: 9, 1136: 9, 1137: 9, 1138: 9, 1139: 9, 1140: 9, 1141: 9, 1142: 9, 1143: 9, 1144: 9, 1145: 9, 1146: 9, 1147: 9, 1148: 9, 1149: 9, 1150: 9, 1151: 9, 1152: 9, 1153: 9, 1154: 9, 1155: 9, 1156: 9, 1157: 9, 1158: 9, 1159: 9, 1160: 9, 1161: 9, 1162: 9, 1163: 9, 1164: 9, 1165: 9, 1166: 9, 1167: 9, 1168: 9, 1169: 9, 1170: 9, 1171: 9, 1172: 9, 1173: 9, 1174: 9, 1175: 9, 1176: 9, 1177: 9, 1178: 9, 1179: 9, 1180: 9, 1181: 9, 1182: 9, 1183: 9, 1184: 9, 1185: 9, 1186: 9, 1187: 9, 1188: 9, 1189: 9, 1190: 9, 1191: 9, 1192: 9, 1193: 9, 1194: 9, 1195: 9, 1196: 9, 1197: 9, 1198: 9, 1199: 9, 1200: 9, 1201: 9, 1202: 9, 1203: 9, 1204: 9, 1205: 9, 1206: 9, 1207: 9, 1208: 9, 1209: 9, 1210: 9, 1211: 9, 1212: 9, 1213: 9, 1214: 9, 1215: 9, 1216: 9, 1217: 9, 1218: 9, 1219: 9, 1220: 9, 1221: 9, 1222: 9, 1223: 9, 1224: 9, 1225: 9, 1226: 9, 1227: 9, 1228: 9, 1229: 9, 1230: 9, 1231: 9, 1232: 9, 1233: 9, 1234: 9, 1235: 9, 1236: 9, 1237: 9, 1238: 9, 1239: 9, 1240: 9, 1241: 9, 1242: 9, 1243: 9, 1244: 9, 1245: 9, 1246: 9, 1247: 9, 1248: 9, 1249: 9, 1250: 9, 1251: 9, 1252: 9, 1253: 9, 1254: 9, 1255: 9, 1256: 9, 1257: 9, 1258: 9, 1259: 9, 1260: 9, 1261: 9, 1262: 9, 1263: 9, 1264: 9, 1265: 9, 1266: 9, 1267: 9, 1268: 9, 1269: 9, 1270: 9, 1271: 9, 1272: 9, 1273: 9, 1274: 9, 1275: 9, 1276: 9, 1277: 9, 1278: 9, 1279: 9, 1280: 9, 1281: 9, 1282: 9, 1283: 9, 1284: 9, 1285: 9, 1286: 9, 1287: 9, 1288: 9, 1289: 9, 1290: 9, 1291: 9, 1292: 9, 1293: 9, 1294: 9, 1295: 9, 1296: 9, 1297: 9, 1298: 9, 1299: 9, 1300: 9, 1301: 9, 1302: 9, 1303: 9, 1304: 9, 1305: 9, 1306: 9, 1307: 9, 1308: 9, 1309: 9, 1310: 9, 1311: 9, 1312: 9, 1313: 9, 1314: 9, 1315: 9, 1316: 9, 1317: 9, 1318: 9, 1319: 9, 1320: 9, 1321: 9, 1322: 9, 1323: 9, 1324: 9, 1325: 9, 1326: 9, 1327: 9, 1328: 9, 1329: 9, 1330: 9, 1331: 9, 1332: 9, 1333: 9, 1334: 9, 1335: 9, 1336: 9, 1337: 9, 1338: 9, 1339: 9, 1340: 9, 1341: 9, 1342: 9, 1343: 9, 1344: 9, 1345: 9, 1346: 9, 1347: 9, 1348: 9, 1349: 9, 1350: 9, 1351: 9, 1352: 9, 1353: 9, 1354: 9, 1355: 9, 1356: 9, 1357: 9, 1358: 9, 1359: 9, 1360: 9, 1361: 9, 1362: 9, 1363: 9, 1364: 9, 1365: 9, 1366: 9, 1367: 9, 1368: 9, 1369: 9, 1370: 9, 1371: 9, 1372: 9, 1373: 9, 1374: 9, 1375: 9, 1376: 9, 1377: 9, 1378: 9, 1379: 9, 1380: 9, 1381: 9, 1382: 9, 1383: 9, 1384: 9, 1385: 9, 1386: 9, 1387: 9, 1388: 9, 1389: 9, 1390: 9, 1391: 9, 1392: 9, 1393: 9, 1394: 9, 1395: 9, 1396: 9, 1397: 9, 1398: 9, 1399: 9, 1400: 9, 1401: 9, 1402: 9, 1403: 9, 1404: 9, 1405: 9, 1406: 9, 1407: 9, 1408: 9, 1409: 9, 1410: 9, 1411: 9, 1412: 9, 1413: 9, 1414: 9, 1415: 9, 1416: 9, 1417: 9, 1418: 9, 1419: 9, 1420: 9, 1421: 9, 1422: 9, 1423: 9, 1424: 9, 1425: 9, 1426: 9, 1427: 9, 1428: 9, 1429: 9, 1430: 9, 1431: 9, 1432: 9, 1433: 9, 1434: 9, 1435: 9, 1436: 9, 1437: 9, 1438: 9, 1439: 9, 1440: 9, 1441: 9, 1442: 9, 1443: 9, 1444: 9, 1445: 9, 1446: 9, 1447: 9, 1448: 9, 1449: 9, 1450: 9, 1451: 9, 1452: 9, 1453: 9, 1454: 9, 1455: 9, 1456: 9, 1457: 9, 1458: 9, 1459: 9, 1460: 9, 1461: 9, 1462: 9, 1463: 9, 1464: 9, 1465: 9, 1466: 9, 1467: 9, 1468: 9, 1469: 9, 1470: 9, 1471: 9, 1472: 9, 1473: 9, 1474: 9, 1475: 9, 1476: 9, 1477: 9, 1478: 9, 1479: 9, 1480: 9, 1481: 9, 1482: 9, 1483: 9, 1484: 9, 1485: 9, 1486: 9, 1487: 9, 1488: 9, 1489: 9, 1490: 9, 1491: 9, 1492: 9, 1493: 9, 1494: 9, 1495: 10, 1496: 9, 1497: 9, 1498: 9, 1499: 9, 1500: 9, 1501: 9, 1502: 9, 1503: 9, 1504: 9, 1505: 9, 1506: 9, 1507: 9, 1508: 9, 1509: 9, 1510: 9, 1511: 9, 1512: 9, 1513: 9, 1514: 9, 1515: 9, 1516: 9, 1517: 9, 1518: 9, 1519: 9, 1520: 9, 1521: 9, 1522: 9, 1523: 9, 1524: 9, 1525: 9, 1526: 9, 1527: 9, 1528: 9, 1529: 9, 1530: 9, 1531: 9, 1532: 9, 1533: 9, 1534: 9, 1535: 9, 1536: 9, 1537: 9, 1538: 9, 1539: 9, 1540: 9, 1541: 9, 1542: 9, 1543: 9, 1544: 9, 1545: 9, 1546: 9, 1547: 9, 1548: 9, 1549: 9, 1550: 9, 1551: 9, 1552: 9, 1553: 9, 1554: 9, 1555: 9, 1556: 9, 1557: 9, 1558: 9, 1559: 9, 1560: 9, 1561: 9, 1562: 9, 1563: 9, 1564: 9, 1565: 9, 1566: 9, 1567: 9, 1568: 9, 1569: 9, 1570: 9, 1571: 9, 1572: 9, 1573: 9, 1574: 9, 1575: 9, 1576: 9, 1577: 9, 1578: 9, 1579: 9, 1580: 9, 1581: 9, 1582: 9, 1583: 9, 1584: 9, 1585: 9, 1586: 9, 1587: 9, 1588: 9, 1589: 9, 1590: 9, 1591: 9, 1592: 9, 1593: 9, 1594: 9, 1595: 9, 1596: 9, 1597: 9, 1598: 9, 1599: 9, 1600: 9, 1601: 9, 1602: 9, 1603: 9, 1604: 9, 1605: 9, 1606: 9, 1607: 9, 1608: 9, 1609: 9, 1610: 9, 1611: 9, 1612: 9, 1613: 9, 1614: 9, 1615: 9, 1616: 9, 1617: 9, 1618: 9, 1619: 9, 1620: 9, 1621: 9, 1622: 9, 1623: 9, 1624: 9, 1625: 9, 1626: 9, 1627: 9, 1628: 9, 1629: 9, 1630: 9, 1631: 9, 1632: 9, 1633: 9, 1634: 9, 1635: 9, 1636: 9, 1637: 9, 1638: 9, 1639: 9, 1640: 9, 1641: 9, 1642: 9, 1643: 9, 1644: 9, 1645: 9, 1646: 9, 1647: 9, 1648: 9, 1649: 9, 1650: 9, 1651: 9, 1652: 9, 1653: 9, 1654: 9, 1655: 9, 1656: 9, 1657: 9, 1658: 9, 1659: 9, 1660: 9, 1661: 9, 1662: 9, 1663: 9, 1664: 9, 1665: 9, 1666: 9, 1667: 9, 1668: 9, 1669: 9, 1670: 9, 1671: 9, 1672: 9, 1673: 9, 1674: 9, 1675: 9, 1676: 9, 1677: 9, 1678: 9, 1679: 9, 1680: 9, 1681: 9, 1682: 9, 1683: 9, 1684: 9, 1685: 9, 1686: 9, 1687: 9, 1688: 9, 1689: 9, 1690: 9, 1691: 9, 1692: 9, 1693: 9, 1694: 9, 1695: 9, 1696: 9, 1697: 9, 1698: 9, 1699: 9, 1700: 9, 1701: 9, 1702: 9, 1703: 9, 1704: 9, 1705: 9, 1706: 9, 1707: 9, 1708: 9, 1709: 9, 1710: 9, 1711: 9, 1712: 9, 1713: 9, 1714: 9, 1715: 9, 1716: 9, 1717: 9, 1718: 9, 1719: 9, 1720: 9, 1721: 9, 1722: 9, 1723: 9, 1724: 9, 1725: 9, 1726: 9, 1727: 9, 1728: 9, 1729: 9, 1730: 9, 1731: 9, 1732: 9, 1733: 9, 1734: 9, 1735: 9, 1736: 9, 1737: 9, 1738: 9, 1739: 9, 1740: 9, 1741: 9, 1742: 9, 1743: 9, 1744: 9, 1745: 9, 1746: 9, 1747: 9, 1748: 9, 1749: 9, 1750: 9, 1751: 9, 1752: 9, 1753: 9, 1754: 9, 1755: 9, 1756: 9, 1757: 9, 1758: 9, 1759: 9, 1760: 9, 1761: 9, 1762: 9, 1763: 9, 1764: 9, 1765: 9, 1766: 9, 1767: 9, 1768: 9, 1769: 9, 1770: 9, 1771: 9, 1772: 9, 1773: 9, 1774: 9, 1775: 9, 1776: 9, 1777: 9, 1778: 9, 1779: 9, 1780: 9, 1781: 9, 1782: 9, 1783: 9, 1784: 9, 1785: 9, 1786: 9, 1787: 9, 1788: 9, 1789: 9, 1790: 9, 1791: 9, 1792: 9, 1793: 9, 1794: 9, 1795: 9, 1796: 9, 1797: 9, 1798: 9, 1799: 9, 1800: 9, 1801: 9, 1802: 9, 1803: 9, 1804: 9, 1805: 9, 1806: 9, 1807: 9, 1808: 9, 1809: 9, 1810: 9, 1811: 9, 1812: 9, 1813: 9, 1814: 9, 1815: 9, 1816: 9, 1817: 9, 1818: 9, 1819: 9, 1820: 9, 1821: 9, 1822: 9, 1823: 9, 1824: 9, 1825: 9, 1826: 9, 1827: 9, 1828: 9, 1829: 9, 1830: 9, 1831: 9, 1832: 9, 1833: 9, 1834: 9, 1835: 9, 1836: 9, 1837: 9, 1838: 9, 1839: 9, 1840: 9, 1841: 9, 1842: 9, 1843: 9, 1844: 9, 1845: 9, 1846: 9, 1847: 9, 1848: 9, 1849: 9, 1850: 9, 1851: 9, 1852: 9, 1853: 9, 1854: 9, 1855: 9, 1856: 9, 1857: 9, 1858: 9, 1859: 9, 1860: 9, 1861: 9, 1862: 9, 1863: 9, 1864: 9, 1865: 9, 1866: 9, 1867: 9, 1868: 9, 1869: 9, 1870: 9, 1871: 9, 1872: 9, 1873: 9, 1874: 9, 1875: 9, 1876: 9, 1877: 9, 1878: 9, 1879: 9, 1880: 9, 1881: 9, 1882: 9, 1883: 9, 1884: 9, 1885: 9, 1886: 9, 1887: 9, 1888: 9, 1889: 9, 1890: 9, 1891: 9, 1892: 9, 1893: 9, 1894: 9, 1895: 9, 1896: 9, 1897: 9, 1898: 9, 1899: 9, 1900: 9, 1901: 9, 1902: 9, 1903: 9, 1904: 9, 1905: 9, 1906: 9, 1907: 9, 1908: 9, 1909: 9, 1910: 9, 1911: 9, 1912: 9, 1913: 9, 1914: 9, 1915: 9, 1916: 9, 1917: 9, 1918: 9, 1919: 9, 1920: 9, 1921: 9, 1922: 9, 1923: 9, 1924: 9, 1925: 9, 1926: 9, 1927: 9, 1928: 9, 1929: 9, 1930: 9, 1931: 9, 1932: 9, 1933: 9, 1934: 9, 1935: 9, 1936: 9, 1937: 9, 1938: 9, 1939: 9, 1940: 9, 1941: 9, 1942: 9, 1943: 9, 1944: 9, 1945: 9, 1946: 9, 1947: 9, 1948: 9, 1949: 9, 1950: 9, 1951: 9, 1952: 9, 1953: 9, 1954: 9, 1955: 9, 1956: 9, 1957: 9, 1958: 9, 1959: 9, 1960: 9, 1961: 9, 1962: 9, 1963: 9, 1964: 9, 1965: 9, 1966: 9, 1967: 9, 1968: 9, 1969: 9, 1970: 9, 1971: 9, 1972: 9, 1973: 9, 1974: 9, 1975: 9, 1976: 9, 1977: 9, 1978: 9, 1979: 9, 1980: 9, 1981: 9, 1982: 9, 1983: 9, 1984: 9, 1985: 9, 1986: 9, 1987: 9, 1988: 9, 1989: 9, 1990: 9, 1991: 9, 1992: 9, 1993: 9, 1994: 9, 1995: 9, 1996: 9, 1997: 9, 1998: 9, 1999: 9, 2000: 9, 2001: 9, 2002: 9, 2003: 9, 2004: 9, 2005: 9, 2006: 9, 2007: 9, 2008: 9, 2009: 9, 2010: 9, 2011: 9, 2012: 9, 2013: 9, 2014: 9, 2015: 9, 2016: 9, 2017: 9, 2018: 9, 2019: 9, 2020: 9, 2021: 9, 2022: 9, 2023: 9, 2024: 9, 2025: 9, 2026: 9, 2027: 9, 2028: 9, 2029: 9, 2030: 9, 2031: 9, 2032: 9, 2033: 9, 2034: 9, 2035: 9, 2036: 9, 2037: 9, 2038: 9, 2039: 9, 2040: 9, 2041: 9, 2042: 9, 2043: 9, 2044: 9, 2045: 9, 2046: 9, 2047: 9, 2048: 9, 2049: 9, 2050: 9, 2051: 9, 2052: 9, 2053: 9, 2054: 9, 2055: 9, 2056: 9, 2057: 9, 2058: 9, 2059: 9, 2060: 9, 2061: 9, 2062: 9, 2063: 9, 2064: 9, 2065: 9, 2066: 9, 2067: 9, 2068: 9, 2069: 9, 2070: 9, 2071: 9, 2072: 9, 2073: 9, 2074: 9, 2075: 9, 2076: 9, 2077: 9, 2078: 9, 2079: 9, 2080: 9, 2081: 9, 2082: 9, 2083: 9, 2084: 9, 2085: 9, 2086: 9, 2087: 9, 2088: 9, 2089: 9, 2090: 9, 2091: 9, 2092: 9, 2093: 9, 2094: 9, 2095: 9, 2096: 9, 2097: 9, 2098: 9, 2099: 9, 2100: 9, 2101: 9, 2102: 9, 2103: 9, 2104: 9, 2105: 9, 2106: 9, 2107: 9, 2108: 9, 2109: 9, 2110: 9, 2111: 9, 2112: 9, 2113: 9, 2114: 9, 2115: 9, 2116: 9, 2117: 9, 2118: 9, 2119: 9, 2120: 9, 2121: 9, 2122: 9, 2123: 9, 2124: 9, 2125: 9, 2126: 9, 2127: 9, 2128: 9, 2129: 9, 2130: 9, 2131: 9, 2132: 9, 2133: 9, 2134: 9, 2135: 9, 2136: 9, 2137: 9, 2138: 9, 2139: 9, 2140: 9, 2141: 9, 2142: 9, 2143: 9, 2144: 9, 2145: 9, 2146: 9, 2147: 9, 2148: 9, 2149: 9, 2150: 9, 2151: 9, 2152: 9, 2153: 9, 2154: 9, 2155: 9, 2156: 9, 2157: 9, 2158: 9, 2159: 9, 2160: 9, 2161: 9, 2162: 9, 2163: 9, 2164: 9, 2165: 9, 2166: 9, 2167: 9, 2168: 9, 2169: 9, 2170: 9, 2171: 9, 2172: 9, 2173: 9, 2174: 9, 2175: 9, 2176: 9, 2177: 9, 2178: 9, 2179: 9, 2180: 9, 2181: 9, 2182: 9, 2183: 9, 2184: 9, 2185: 9, 2186: 9, 2187: 9, 2188: 9, 2189: 9, 2190: 9, 2191: 9, 2192: 9, 2193: 9, 2194: 9, 2195: 9, 2196: 9, 2197: 9, 2198: 9, 2199: 9, 2200: 9, 2201: 9, 2202: 9, 2203: 9, 2204: 9, 2205: 9, 2206: 9, 2207: 9, 2208: 9, 2209: 9, 2210: 9, 2211: 9, 2212: 9, 2213: 9, 2214: 9, 2215: 9, 2216: 9, 2217: 9, 2218: 9, 2219: 9, 2220: 9, 2221: 9, 2222: 9, 2223: 9, 2224: 9, 2225: 9, 2226: 9, 2227: 9, 2228: 9, 2229: 9, 2230: 9, 2231: 9, 2232: 9, 2233: 9, 2234: 9, 2235: 9, 2236: 9, 2237: 9, 2238: 9, 2239: 9, 2240: 9, 2241: 9, 2242: 9, 2243: 9, 2244: 9, 2245: 9, 2246: 9, 2247: 9, 2248: 9, 2249: 9, 2250: 9, 2251: 9, 2252: 9, 2253: 9, 2254: 9, 2255: 9, 2256: 9, 2257: 9, 2258: 9, 2259: 9, 2260: 9, 2261: 9, 2262: 9, 2263: 9, 2264: 9, 2265: 9, 2266: 9, 2267: 9, 2268: 9, 2269: 9, 2270: 9, 2271: 9, 2272: 9, 2273: 9, 2274: 9, 2275: 9, 2276: 9, 2277: 9, 2278: 9, 2279: 9, 2280: 9, 2281: 9, 2282: 9, 2283: 9, 2284: 9, 2285: 9, 2286: 9, 2287: 9, 2288: 9, 2289: 9, 2290: 9, 2291: 9, 2292: 9, 2293: 9, 2294: 9, 2295: 9, 2296: 9, 2297: 9, 2298: 9, 2299: 9, 2300: 9, 2301: 9, 2302: 9, 2303: 9, 2304: 9, 2305: 9, 2306: 9, 2307: 9, 2308: 9, 2309: 9, 2310: 9, 2311: 9, 2312: 9, 2313: 9, 2314: 9, 2315: 9, 2316: 9, 2317: 9, 2318: 9, 2319: 9, 2320: 9, 2321: 9, 2322: 9, 2323: 9, 2324: 9, 2325: 9, 2326: 9, 2327: 9, 2328: 9, 2329: 9, 2330: 9, 2331: 9, 2332: 9, 2333: 9, 2334: 9, 2335: 9, 2336: 9, 2337: 9, 2338: 9, 2339: 9, 2340: 9, 2341: 9, 2342: 9, 2343: 9, 2344: 9, 2345: 9, 2346: 9, 2347: 9, 2348: 9, 2349: 9, 2350: 9, 2351: 9, 2352: 9, 2353: 9, 2354: 9, 2355: 9, 2356: 9, 2357: 9, 2358: 9, 2359: 9, 2360: 9, 2361: 9, 2362: 9, 2363: 9, 2364: 9, 2365: 9, 2366: 9, 2367: 9, 2368: 9, 2369: 9, 2370: 9, 2371: 9, 2372: 9, 2373: 9, 2374: 9, 2375: 9, 2376: 9, 2377: 9, 2378: 9, 2379: 9, 2380: 9, 2381: 9, 2382: 9, 2383: 9, 2384: 9, 2385: 9, 2386: 9, 2387: 9, 2388: 9, 2389: 9, 2390: 9, 2391: 9, 2392: 9, 2393: 9, 2394: 9, 2395: 9, 2396: 9, 2397: 9, 2398: 9, 2399: 9, 2400: 9, 2401: 9, 2402: 9, 2403: 9, 2404: 9, 2405: 9, 2406: 9, 2407: 9, 2408: 9, 2409: 9, 2410: 9, 2411: 9, 2412: 9, 2413: 9, 2414: 9, 2415: 9, 2416: 9, 2417: 9, 2418: 9, 2419: 9, 2420: 9, 2421: 9, 2422: 9, 2423: 9, 2424: 9, 2425: 9, 2426: 9, 2427: 9, 2428: 9, 2429: 9, 2430: 9, 2431: 9, 2432: 9, 2433: 9, 2434: 9, 2435: 9, 2436: 9, 2437: 9, 2438: 9, 2439: 9, 2440: 9, 2441: 9, 2442: 9, 2443: 9, 2444: 9, 2445: 9, 2446: 9, 2447: 9, 2448: 9, 2449: 9, 2450: 9, 2451: 9, 2452: 9, 2453: 9, 2454: 9, 2455: 9, 2456: 9, 2457: 9, 2458: 9, 2459: 9, 2460: 9, 2461: 9, 2462: 9, 2463: 9, 2464: 9, 2465: 9, 2466: 9, 2467: 9, 2468: 9, 2469: 9, 2470: 9, 2471: 9, 2472: 9, 2473: 9, 2474: 9, 2475: 9, 2476: 9, 2477: 9, 2478: 9, 2479: 9, 2480: 9, 2481: 9, 2482: 9, 2483: 9, 2484: 9, 2485: 9, 2486: 9, 2487: 9, 2488: 9, 2489: 9, 2490: 9, 2491: 9, 2492: 9, 2493: 9, 2494: 9, 2495: 9, 2496: 9, 2497: 9, 2498: 9, 2499: 9, 2500: 9, 2501: 9, 2502: 9, 2503: 9, 2504: 9, 2505: 9, 2506: 9, 2507: 9, 2508: 9, 2509: 9, 2510: 9, 2511: 9, 2512: 9, 2513: 9, 2514: 9, 2515: 9, 2516: 9, 2517: 9, 2518: 9, 2519: 9, 2520: 9, 2521: 9, 2522: 9, 2523: 9, 2524: 9, 2525: 9, 2526: 9, 2527: 9, 2528: 9, 2529: 9, 2530: 9, 2531: 9, 2532: 9, 2533: 9, 2534: 9, 2535: 9, 2536: 9, 2537: 9, 2538: 9, 2539: 9, 2540: 9, 2541: 9, 2542: 9, 2543: 9, 2544: 9, 2545: 9, 2546: 9, 2547: 9, 2548: 9, 2549: 9, 2550: 9, 2551: 9, 2552: 9, 2553: 9, 2554: 9, 2555: 9, 2556: 9, 2557: 9, 2558: 9, 2559: 9, 2560: 9, 2561: 9, 2562: 9, 2563: 9, 2564: 9, 2565: 9, 2566: 9, 2567: 9, 2568: 9, 2569: 9, 2570: 9, 2571: 9, 2572: 9, 2573: 9, 2574: 9, 2575: 9, 2576: 9, 2577: 9, 2578: 9, 2579: 9, 2580: 9, 2581: 9, 2582: 9, 2583: 9, 2584: 9, 2585: 9, 2586: 9, 2587: 9, 2588: 9, 2589: 9, 2590: 9, 2591: 9, 2592: 9, 2593: 9, 2594: 9, 2595: 9, 2596: 9, 2597: 9, 2598: 9, 2599: 9, 2600: 9, 2601: 9, 2602: 9, 2603: 9, 2604: 9, 2605: 9, 2606: 9, 2607: 9, 2608: 9, 2609: 9, 2610: 9, 2611: 9, 2612: 9, 2613: 9, 2614: 9, 2615: 9, 2616: 9, 2617: 9, 2618: 9, 2619: 9, 2620: 9, 2621: 9, 2622: 9, 2623: 9, 2624: 9, 2625: 9, 2626: 9, 2627: 9, 2628: 9, 2629: 9, 2630: 9, 2631: 9, 2632: 9, 2633: 9, 2634: 9, 2635: 9, 2636: 9, 2637: 9, 2638: 9, 2639: 9, 2640: 9, 2641: 9, 2642: 9, 2643: 9, 2644: 9, 2645: 9, 2646: 9, 2647: 9, 2648: 9, 2649: 9, 2650: 9, 2651: 9, 2652: 9, 2653: 9, 2654: 9, 2655: 9, 2656: 9, 2657: 9, 2658: 9, 2659: 9, 2660: 9, 2661: 9, 2662: 9, 2663: 9, 2664: 9, 2665: 9, 2666: 9, 2667: 9, 2668: 9, 2669: 9, 2670: 9, 2671: 9, 2672: 9, 2673: 9, 2674: 9, 2675: 9, 2676: 9, 2677: 9, 2678: 9, 2679: 9, 2680: 9, 2681: 9, 2682: 9, 2683: 9, 2684: 9, 2685: 9, 2686: 9, 2687: 9, 2688: 9, 2689: 9, 2690: 9, 2691: 9, 2692: 9, 2693: 9, 2694: 9, 2695: 9, 2696: 9, 2697: 9, 2698: 9, 2699: 9, 2700: 9, 2701: 9, 2702: 9, 2703: 9, 2704: 9, 2705: 9, 2706: 9, 2707: 9, 2708: 9, 2709: 9, 2710: 9, 2711: 9, 2712: 9, 2713: 9, 2714: 9, 2715: 9, 2716: 9, 2717: 9, 2718: 9, 2719: 9, 2720: 9, 2721: 9, 2722: 9, 2723: 9, 2724: 9, 2725: 9, 2726: 9, 2727: 9, 2728: 9, 2729: 9, 2730: 9, 2731: 9, 2732: 9, 2733: 9, 2734: 9, 2735: 9, 2736: 9, 2737: 9, 2738: 9, 2739: 9, 2740: 9, 2741: 9, 2742: 9, 2743: 9, 2744: 9, 2745: 9, 2746: 9, 2747: 9, 2748: 9, 2749: 9, 2750: 9, 2751: 9, 2752: 9, 2753: 9, 2754: 9, 2755: 9, 2756: 9, 2757: 9, 2758: 9, 2759: 9, 2760: 9, 2761: 9, 2762: 9, 2763: 9, 2764: 9, 2765: 9, 2766: 9, 2767: 9, 2768: 9, 2769: 9, 2770: 9, 2771: 9, 2772: 9, 2773: 9, 2774: 9, 2775: 9, 2776: 9, 2777: 9, 2778: 9, 2779: 9, 2780: 9, 2781: 9, 2782: 9, 2783: 9, 2784: 9, 2785: 9, 2786: 9, 2787: 9, 2788: 9, 2789: 9, 2790: 9, 2791: 9, 2792: 9, 2793: 9, 2794: 9, 2795: 9, 2796: 9, 2797: 9, 2798: 9, 2799: 9, 2800: 9, 2801: 9, 2802: 9, 2803: 9, 2804: 9, 2805: 9, 2806: 9, 2807: 9, 2808: 9, 2809: 9, 2810: 9, 2811: 9, 2812: 9, 2813: 9, 2814: 9, 2815: 9, 2816: 9, 2817: 9, 2818: 9, 2819: 9, 2820: 9, 2821: 9, 2822: 9, 2823: 9, 2824: 9, 2825: 9, 2826: 9, 2827: 9, 2828: 9, 2829: 9, 2830: 9, 2831: 9, 2832: 9, 2833: 9, 2834: 9, 2835: 9, 2836: 9, 2837: 9, 2838: 9, 2839: 9, 2840: 9, 2841: 9, 2842: 9, 2843: 9, 2844: 9, 2845: 9, 2846: 9, 2847: 9, 2848: 9, 2849: 9, 2850: 9, 2851: 9, 2852: 9, 2853: 9, 2854: 9, 2855: 9, 2856: 9, 2857: 9, 2858: 9, 2859: 9, 2860: 9, 2861: 9, 2862: 9, 2863: 9, 2864: 9, 2865: 9, 2866: 9, 2867: 9, 2868: 9, 2869: 9, 2870: 9, 2871: 9, 2872: 9, 2873: 9, 2874: 9, 2875: 9, 2876: 9, 2877: 9, 2878: 9, 2879: 9, 2880: 9, 2881: 9, 2882: 9, 2883: 9, 2884: 9, 2885: 9, 2886: 9, 2887: 9, 2888: 9, 2889: 9, 2890: 9, 2891: 9, 2892: 9, 2893: 9, 2894: 9, 2895: 9, 2896: 9, 2897: 9, 2898: 9, 2899: 9, 2900: 9, 2901: 9, 2902: 9, 2903: 9, 2904: 9, 2905: 9, 2906: 9, 2907: 9, 2908: 9, 2909: 9, 2910: 9, 2911: 9, 2912: 9, 2913: 9, 2914: 9, 2915: 9, 2916: 9, 2917: 9, 2918: 9, 2919: 9, 2920: 9, 2921: 9, 2922: 9, 2923: 9, 2924: 9, 2925: 9, 2926: 9, 2927: 9, 2928: 9, 2929: 9, 2930: 9, 2931: 9, 2932: 9, 2933: 9, 2934: 9, 2935: 9, 2936: 9, 2937: 9, 2938: 9, 2939: 9, 2940: 9, 2941: 9, 2942: 9, 2943: 9, 2944: 9, 2945: 9, 2946: 9, 2947: 9, 2948: 9, 2949: 9, 2950: 9, 2951: 9, 2952: 9, 2953: 9, 2954: 9, 2955: 9, 2956: 9, 2957: 9, 2958: 9, 2959: 9, 2960: 9, 2961: 9, 2962: 9, 2963: 9, 2964: 9, 2965: 9, 2966: 9, 2967: 9, 2968: 9, 2969: 9, 2970: 9, 2971: 9, 2972: 9, 2973: 9, 2974: 9, 2975: 9, 2976: 9, 2977: 9, 2978: 9, 2979: 9, 2980: 9, 2981: 9, 2982: 9, 2983: 9, 2984: 9, 2985: 9, 2986: 9, 2987: 9, 2988: 9, 2989: 9, 2990: 9, 2991: 9, 2992: 9, 2993: 9, 2994: 9, 2995: 9, 2996: 9, 2997: 9, 2998: 9, 2999: 9, 3000: 9, 3001: 9, 3002: 9, 3003: 9, 3004: 9, 3005: 9, 3006: 9, 3007: 9, 3008: 9, 3009: 9, 3010: 9, 3011: 9, 3012: 9, 3013: 9, 3014: 9, 3015: 9, 3016: 9, 3017: 9, 3018: 9, 3019: 9, 3020: 9, 3021: 9, 3022: 9, 3023: 9, 3024: 9, 3025: 9, 3026: 9, 3027: 9, 3028: 9, 3029: 9, 3030: 9, 3031: 9, 3032: 9, 3033: 9, 3034: 9, 3035: 9, 3036: 9, 3037: 9, 3038: 9, 3039: 9, 3040: 9, 3041: 9, 3042: 9, 3043: 9, 3044: 9, 3045: 9, 3046: 9, 3047: 9, 3048: 9, 3049: 9, 3050: 9, 3051: 9, 3052: 9, 3053: 9, 3054: 9, 3055: 9, 3056: 9, 3057: 9, 3058: 9, 3059: 9, 3060: 9, 3061: 9, 3062: 9, 3063: 9, 3064: 9, 3065: 9, 3066: 9, 3067: 9, 3068: 9, 3069: 9, 3070: 9, 3071: 9, 3072: 9, 3073: 9, 3074: 9, 3075: 9, 3076: 9, 3077: 9, 3078: 9, 3079: 9, 3080: 9, 3081: 9, 3082: 9, 3083: 9, 3084: 9, 3085: 9, 3086: 9, 3087: 9, 3088: 9, 3089: 9, 3090: 9, 3091: 9, 3092: 9, 3093: 9, 3094: 9, 3095: 9, 3096: 9, 3097: 9, 3098: 9, 3099: 9, 3100: 9, 3101: 9, 3102: 9 ~= num clips 9
[05/01 09:13:41][INFO] logging.py:  99: json_stats: {"split": "test_final", "top1_acc": "0.00", "top5_acc": "0.00"}
[05/01 09:25:00][INFO] test_net_gamma.py: 157: Test with config:
[05/01 09:25:00][INFO] test_net_gamma.py: 158: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: True
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  FRAME_PATH: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: True
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  PSEUDO_CSV: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 3
  SPECIAL_LABEL_LIST: [5, 9]
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
EVL:
  ADD_RESIDUAL: False
  AFTER_ME: False
  BACKBONE: vit_b16
  BEFORE_ME: False
  CLS_DROPOUT: 0.5
  FIRST_N: 0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  SHIFT_INIT: False
  SPATAIL_SIZE: 14
  USE_IMAGE_ATTNMAP: True
  USE_T_CONV: True
  USE_T_POS_EMBED: True
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: True
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  CHECKPOINT_NUM: [0, 0, 0, 0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 11
  PSEUDO_LOSS_FUNC: 
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'vip', 'swin', 'sf', 'evl']
  SOFT_T: 1
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: None
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]]
  QKV_BIAS: True
  SEP_POS_EMBED: True
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 2
NUM_SHARDS: 1
OUTPUT_DIR: ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SF:
  DROPOUT_RATE: 0.3
  FROZEN_BN: False
  NONLOCAL:
    FROZEN_BN: False
  PRETRAIN_NAME: SlowFast-ResNet101-8x8
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRADIENT: 20
  CLIP_GRAD_L2NORM: 1.0
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 40
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 10.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.03
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 64
  CHECKPOINT_FILE_PATH: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  DATA_SELECT: test
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 3
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
  THRESHOLD: 2
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  KS: 5
  MBCONV: False
  MLP_RATIO: 4
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/01 09:25:03][INFO] checkpoint.py: 223: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[05/01 09:25:08][INFO] ug2_sparse.py:  90: Constructing Ug2 test...
[05/01 09:25:08][INFO] ug2_sparse.py:  91: Number of clips 9
[05/01 09:25:08][INFO] ug2_sparse.py: 203: Constructing Ug2 dataloader (size: 27927) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/test.csv
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:25:09][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:25:10][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0f480d0680>
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:25:10][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0f480f9c20>
[05/01 09:25:10][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f1004074320>
[05/01 09:25:10][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0f480f99e0>
[05/01 09:25:10][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:25:10][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:25:10][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:25:10][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:25:10][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:25:10][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0f480d0680>
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0f480f9c20>
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0f10bf5dd0>
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0f480f99e0>
[05/01 09:25:11][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:25:11][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:25:11][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:25:11][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0f480d0680>
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0f480f9c20>
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0f1052ca70>
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0f480f99e0>
[05/01 09:25:11][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:25:11][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:25:11][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:25:11][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0f480d0680>
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0f480f9c20>
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0f09e4db90>
[05/01 09:25:11][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0f480f99e0>
[05/01 09:25:11][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:25:11][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:25:11][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:25:11][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:25:11][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:25:12][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0f480d0680>
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:25:12][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0f480f9c20>
[05/01 09:25:12][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0f097f9c20>
[05/01 09:25:12][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0f480f99e0>
[05/01 09:25:12][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:25:12][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:25:12][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/01 09:25:12][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/01 09:25:12][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f0f480d0680>
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/01 09:25:12][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f0f480f9c20>
[05/01 09:25:12][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f0f09122cb0>
[05/01 09:25:12][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f0f480f99e0>
[05/01 09:25:12][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/01 09:25:12][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/01 09:25:12][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/01 09:25:12][DEBUG] factory.py:  66: Loading s3:s3
[05/01 09:25:12][INFO] test_net_gamma.py: 169: Testing model for 437 iterations
[05/01 09:26:22][INFO] logging.py:  99: json_stats: {"cur_iter": "1", "eta": "8:31:09", "split": "test_iter", "time_diff": 70.18123}
[05/01 09:26:23][INFO] logging.py:  99: json_stats: {"cur_iter": "2", "eta": "0:06:21", "split": "test_iter", "time_diff": 0.87419}
[05/01 09:26:24][INFO] logging.py:  99: json_stats: {"cur_iter": "3", "eta": "0:06:20", "split": "test_iter", "time_diff": 0.87559}
[05/01 09:26:25][INFO] logging.py:  99: json_stats: {"cur_iter": "4", "eta": "0:06:19", "split": "test_iter", "time_diff": 0.87401}
[05/01 09:26:26][INFO] logging.py:  99: json_stats: {"cur_iter": "5", "eta": "0:06:19", "split": "test_iter", "time_diff": 0.87652}
[05/01 09:26:27][INFO] logging.py:  99: json_stats: {"cur_iter": "6", "eta": "0:06:17", "split": "test_iter", "time_diff": 0.87410}
[05/01 09:26:28][INFO] logging.py:  99: json_stats: {"cur_iter": "7", "eta": "0:06:16", "split": "test_iter", "time_diff": 0.87470}
[05/01 09:26:30][INFO] logging.py:  99: json_stats: {"cur_iter": "8", "eta": "0:14:13", "split": "test_iter", "time_diff": 1.98558}
[05/01 09:26:32][INFO] logging.py:  99: json_stats: {"cur_iter": "9", "eta": "0:17:35", "split": "test_iter", "time_diff": 2.45981}
[05/01 09:26:36][INFO] logging.py:  99: json_stats: {"cur_iter": "10", "eta": "0:30:39", "split": "test_iter", "time_diff": 4.29735}
[05/01 09:26:41][INFO] logging.py:  99: json_stats: {"cur_iter": "11", "eta": "0:32:06", "split": "test_iter", "time_diff": 4.51087}
[05/01 09:26:42][INFO] logging.py:  99: json_stats: {"cur_iter": "12", "eta": "0:06:13", "split": "test_iter", "time_diff": 0.87590}
[05/01 09:26:43][INFO] logging.py:  99: json_stats: {"cur_iter": "13", "eta": "0:10:10", "split": "test_iter", "time_diff": 1.43669}
[05/01 09:26:44][INFO] logging.py:  99: json_stats: {"cur_iter": "14", "eta": "0:06:11", "split": "test_iter", "time_diff": 0.87732}
[05/01 09:26:45][INFO] logging.py:  99: json_stats: {"cur_iter": "15", "eta": "0:10:09", "split": "test_iter", "time_diff": 1.43991}
[05/01 09:26:47][INFO] logging.py:  99: json_stats: {"cur_iter": "16", "eta": "0:08:11", "split": "test_iter", "time_diff": 1.16364}
[05/01 09:26:48][INFO] logging.py:  99: json_stats: {"cur_iter": "17", "eta": "0:06:31", "split": "test_iter", "time_diff": 0.92989}
[05/01 09:26:52][INFO] logging.py:  99: json_stats: {"cur_iter": "18", "eta": "0:32:13", "split": "test_iter", "time_diff": 4.60413}
[05/01 09:26:56][INFO] logging.py:  99: json_stats: {"cur_iter": "19", "eta": "0:27:27", "split": "test_iter", "time_diff": 3.93180}
[05/01 09:26:57][INFO] logging.py:  99: json_stats: {"cur_iter": "20", "eta": "0:05:57", "split": "test_iter", "time_diff": 0.85488}
[05/01 09:26:59][INFO] logging.py:  99: json_stats: {"cur_iter": "21", "eta": "0:15:27", "split": "test_iter", "time_diff": 2.22475}
[05/01 09:27:00][INFO] logging.py:  99: json_stats: {"cur_iter": "22", "eta": "0:05:56", "split": "test_iter", "time_diff": 0.85685}
[05/01 09:27:01][INFO] logging.py:  99: json_stats: {"cur_iter": "23", "eta": "0:06:38", "split": "test_iter", "time_diff": 0.95923}
[05/01 09:27:03][INFO] logging.py:  99: json_stats: {"cur_iter": "24", "eta": "0:12:43", "split": "test_iter", "time_diff": 1.84454}
[05/01 09:27:04][INFO] logging.py:  99: json_stats: {"cur_iter": "25", "eta": "0:08:11", "split": "test_iter", "time_diff": 1.19078}
[05/01 09:27:05][INFO] logging.py:  99: json_stats: {"cur_iter": "26", "eta": "0:09:20", "split": "test_iter", "time_diff": 1.35943}
[05/01 09:27:08][INFO] logging.py:  99: json_stats: {"cur_iter": "27", "eta": "0:15:32", "split": "test_iter", "time_diff": 2.26883}
[05/01 09:27:09][INFO] logging.py:  99: json_stats: {"cur_iter": "28", "eta": "0:11:19", "split": "test_iter", "time_diff": 1.65749}
[05/01 09:27:11][INFO] logging.py:  99: json_stats: {"cur_iter": "29", "eta": "0:09:11", "split": "test_iter", "time_diff": 1.34938}
[05/01 09:27:12][INFO] logging.py:  99: json_stats: {"cur_iter": "30", "eta": "0:11:05", "split": "test_iter", "time_diff": 1.63188}
[05/01 09:27:13][INFO] logging.py:  99: json_stats: {"cur_iter": "31", "eta": "0:05:49", "split": "test_iter", "time_diff": 0.85782}
[05/01 09:27:14][INFO] logging.py:  99: json_stats: {"cur_iter": "32", "eta": "0:05:55", "split": "test_iter", "time_diff": 0.87661}
[05/01 09:27:16][INFO] logging.py:  99: json_stats: {"cur_iter": "33", "eta": "0:10:00", "split": "test_iter", "time_diff": 1.48209}
[05/01 09:27:21][INFO] logging.py:  99: json_stats: {"cur_iter": "34", "eta": "0:39:01", "split": "test_iter", "time_diff": 5.79567}
[05/01 09:27:24][INFO] logging.py:  99: json_stats: {"cur_iter": "35", "eta": "0:20:52", "split": "test_iter", "time_diff": 3.10785}
[05/01 09:27:27][INFO] logging.py:  99: json_stats: {"cur_iter": "36", "eta": "0:14:15", "split": "test_iter", "time_diff": 2.12828}
[05/01 09:27:27][INFO] logging.py:  99: json_stats: {"cur_iter": "37", "eta": "0:05:51", "split": "test_iter", "time_diff": 0.87614}
[05/01 09:27:29][INFO] logging.py:  99: json_stats: {"cur_iter": "38", "eta": "0:05:50", "split": "test_iter", "time_diff": 0.87718}
[05/01 09:27:30][INFO] logging.py:  99: json_stats: {"cur_iter": "39", "eta": "0:05:42", "split": "test_iter", "time_diff": 0.85746}
[05/01 09:27:31][INFO] logging.py:  99: json_stats: {"cur_iter": "40", "eta": "0:09:27", "split": "test_iter", "time_diff": 1.42565}
[05/01 09:27:32][INFO] logging.py:  99: json_stats: {"cur_iter": "41", "eta": "0:05:48", "split": "test_iter", "time_diff": 0.87733}
[05/01 09:27:35][INFO] logging.py:  99: json_stats: {"cur_iter": "42", "eta": "0:16:17", "split": "test_iter", "time_diff": 2.46921}
[05/01 09:27:38][INFO] logging.py:  99: json_stats: {"cur_iter": "43", "eta": "0:20:57", "split": "test_iter", "time_diff": 3.18418}
[05/01 09:27:39][INFO] logging.py:  99: json_stats: {"cur_iter": "44", "eta": "0:08:02", "split": "test_iter", "time_diff": 1.22481}
[05/01 09:27:40][INFO] logging.py:  99: json_stats: {"cur_iter": "45", "eta": "0:10:17", "split": "test_iter", "time_diff": 1.57031}
[05/01 09:27:42][INFO] logging.py:  99: json_stats: {"cur_iter": "46", "eta": "0:09:34", "split": "test_iter", "time_diff": 1.46452}
[05/01 09:27:43][INFO] logging.py:  99: json_stats: {"cur_iter": "47", "eta": "0:05:36", "split": "test_iter", "time_diff": 0.86009}
[05/01 09:27:44][INFO] logging.py:  99: json_stats: {"cur_iter": "48", "eta": "0:08:17", "split": "test_iter", "time_diff": 1.27633}
[05/01 09:27:45][INFO] logging.py:  99: json_stats: {"cur_iter": "49", "eta": "0:08:28", "split": "test_iter", "time_diff": 1.30840}
[05/01 09:27:47][INFO] logging.py:  99: json_stats: {"cur_iter": "50", "eta": "0:12:53", "split": "test_iter", "time_diff": 1.99367}
[05/01 09:27:52][INFO] logging.py:  99: json_stats: {"cur_iter": "51", "eta": "0:30:26", "split": "test_iter", "time_diff": 4.72009}
[05/01 09:27:53][INFO] logging.py:  99: json_stats: {"cur_iter": "52", "eta": "0:08:42", "split": "test_iter", "time_diff": 1.35281}
[05/01 09:27:55][INFO] logging.py:  99: json_stats: {"cur_iter": "53", "eta": "0:09:26", "split": "test_iter", "time_diff": 1.47234}
[05/01 09:27:56][INFO] logging.py:  99: json_stats: {"cur_iter": "54", "eta": "0:08:22", "split": "test_iter", "time_diff": 1.30973}
[05/01 09:27:57][INFO] logging.py:  99: json_stats: {"cur_iter": "55", "eta": "0:06:13", "split": "test_iter", "time_diff": 0.97603}
[05/01 09:27:58][INFO] logging.py:  99: json_stats: {"cur_iter": "56", "eta": "0:07:08", "split": "test_iter", "time_diff": 1.12277}
[05/01 09:27:59][INFO] logging.py:  99: json_stats: {"cur_iter": "57", "eta": "0:05:34", "split": "test_iter", "time_diff": 0.87705}
[05/01 09:28:01][INFO] logging.py:  99: json_stats: {"cur_iter": "58", "eta": "0:09:00", "split": "test_iter", "time_diff": 1.42236}
[05/01 09:28:06][INFO] logging.py:  99: json_stats: {"cur_iter": "59", "eta": "0:32:23", "split": "test_iter", "time_diff": 5.12895}
[05/01 09:28:07][INFO] logging.py:  99: json_stats: {"cur_iter": "60", "eta": "0:10:16", "split": "test_iter", "time_diff": 1.62988}
[05/01 09:28:09][INFO] logging.py:  99: json_stats: {"cur_iter": "61", "eta": "0:11:41", "split": "test_iter", "time_diff": 1.86176}
[05/01 09:28:10][INFO] logging.py:  99: json_stats: {"cur_iter": "62", "eta": "0:05:30", "split": "test_iter", "time_diff": 0.87880}
[05/01 09:28:11][INFO] logging.py:  99: json_stats: {"cur_iter": "63", "eta": "0:05:30", "split": "test_iter", "time_diff": 0.88035}
[05/01 09:28:12][INFO] logging.py:  99: json_stats: {"cur_iter": "64", "eta": "0:08:30", "split": "test_iter", "time_diff": 1.36618}
[05/01 09:28:14][INFO] logging.py:  99: json_stats: {"cur_iter": "65", "eta": "0:07:21", "split": "test_iter", "time_diff": 1.18342}
[05/01 09:28:15][INFO] logging.py:  99: json_stats: {"cur_iter": "66", "eta": "0:08:10", "split": "test_iter", "time_diff": 1.31783}
[05/01 09:28:19][INFO] logging.py:  99: json_stats: {"cur_iter": "67", "eta": "0:23:10", "split": "test_iter", "time_diff": 3.74666}
[05/01 09:28:20][INFO] logging.py:  99: json_stats: {"cur_iter": "68", "eta": "0:07:57", "split": "test_iter", "time_diff": 1.29056}
[05/01 09:28:24][INFO] logging.py:  99: json_stats: {"cur_iter": "69", "eta": "0:26:40", "split": "test_iter", "time_diff": 4.33805}
[05/01 09:28:26][INFO] logging.py:  99: json_stats: {"cur_iter": "70", "eta": "0:07:42", "split": "test_iter", "time_diff": 1.25557}
[05/01 09:28:26][INFO] logging.py:  99: json_stats: {"cur_iter": "71", "eta": "0:05:22", "split": "test_iter", "time_diff": 0.87942}
[05/01 09:28:28][INFO] logging.py:  99: json_stats: {"cur_iter": "72", "eta": "0:07:25", "split": "test_iter", "time_diff": 1.21675}
[05/01 09:28:29][INFO] logging.py:  99: json_stats: {"cur_iter": "73", "eta": "0:10:59", "split": "test_iter", "time_diff": 1.80562}
[05/01 09:28:30][INFO] logging.py:  99: json_stats: {"cur_iter": "74", "eta": "0:06:03", "split": "test_iter", "time_diff": 0.99898}
[05/01 09:28:34][INFO] logging.py:  99: json_stats: {"cur_iter": "75", "eta": "0:20:09", "split": "test_iter", "time_diff": 3.33308}
[05/01 09:28:35][INFO] logging.py:  99: json_stats: {"cur_iter": "76", "eta": "0:06:57", "split": "test_iter", "time_diff": 1.15413}
[05/01 09:28:40][INFO] logging.py:  99: json_stats: {"cur_iter": "77", "eta": "0:29:23", "split": "test_iter", "time_diff": 4.88541}
[05/01 09:28:41][INFO] logging.py:  99: json_stats: {"cur_iter": "78", "eta": "0:05:16", "split": "test_iter", "time_diff": 0.87905}
[05/01 09:28:42][INFO] logging.py:  99: json_stats: {"cur_iter": "79", "eta": "0:06:40", "split": "test_iter", "time_diff": 1.11667}
[05/01 09:28:44][INFO] logging.py:  99: json_stats: {"cur_iter": "80", "eta": "0:08:01", "split": "test_iter", "time_diff": 1.34474}
[05/01 09:28:45][INFO] logging.py:  99: json_stats: {"cur_iter": "81", "eta": "0:08:56", "split": "test_iter", "time_diff": 1.50305}
[05/01 09:28:46][INFO] logging.py:  99: json_stats: {"cur_iter": "82", "eta": "0:05:15", "split": "test_iter", "time_diff": 0.88591}
[05/01 09:28:49][INFO] logging.py:  99: json_stats: {"cur_iter": "83", "eta": "0:15:19", "split": "test_iter", "time_diff": 2.59069}
[05/01 09:28:50][INFO] logging.py:  99: json_stats: {"cur_iter": "84", "eta": "0:07:41", "split": "test_iter", "time_diff": 1.30431}
[05/01 09:28:55][INFO] logging.py:  99: json_stats: {"cur_iter": "85", "eta": "0:30:16", "split": "test_iter", "time_diff": 5.14482}
[05/01 09:28:57][INFO] logging.py:  99: json_stats: {"cur_iter": "86", "eta": "0:05:09", "split": "test_iter", "time_diff": 0.88047}
[05/01 09:28:58][INFO] logging.py:  99: json_stats: {"cur_iter": "87", "eta": "0:08:48", "split": "test_iter", "time_diff": 1.50441}
[05/01 09:28:59][INFO] logging.py:  99: json_stats: {"cur_iter": "88", "eta": "0:05:06", "split": "test_iter", "time_diff": 0.87537}
[05/01 09:29:00][INFO] logging.py:  99: json_stats: {"cur_iter": "89", "eta": "0:05:08", "split": "test_iter", "time_diff": 0.88415}
[05/01 09:29:02][INFO] logging.py:  99: json_stats: {"cur_iter": "90", "eta": "0:11:17", "split": "test_iter", "time_diff": 1.94808}
[05/01 09:29:05][INFO] logging.py:  99: json_stats: {"cur_iter": "91", "eta": "0:18:01", "split": "test_iter", "time_diff": 3.11635}
[05/01 09:29:07][INFO] logging.py:  99: json_stats: {"cur_iter": "92", "eta": "0:04:57", "split": "test_iter", "time_diff": 0.85921}
[05/01 09:29:14][INFO] logging.py:  99: json_stats: {"cur_iter": "93", "eta": "0:44:26", "split": "test_iter", "time_diff": 7.72907}
[05/01 09:29:15][INFO] logging.py:  99: json_stats: {"cur_iter": "94", "eta": "0:05:16", "split": "test_iter", "time_diff": 0.91969}
[05/01 09:29:17][INFO] logging.py:  99: json_stats: {"cur_iter": "95", "eta": "0:08:25", "split": "test_iter", "time_diff": 1.47507}
[05/01 09:29:18][INFO] logging.py:  99: json_stats: {"cur_iter": "96", "eta": "0:04:58", "split": "test_iter", "time_diff": 0.87193}
[05/01 09:29:20][INFO] logging.py:  99: json_stats: {"cur_iter": "97", "eta": "0:04:58", "split": "test_iter", "time_diff": 0.87518}
[05/01 09:29:21][INFO] logging.py:  99: json_stats: {"cur_iter": "98", "eta": "0:08:49", "split": "test_iter", "time_diff": 1.55663}
[05/01 09:29:23][INFO] logging.py:  99: json_stats: {"cur_iter": "99", "eta": "0:07:12", "split": "test_iter", "time_diff": 1.27723}
[05/01 09:29:25][INFO] logging.py:  99: json_stats: {"cur_iter": "100", "eta": "0:14:03", "split": "test_iter", "time_diff": 2.49454}
[05/01 09:29:30][INFO] logging.py:  99: json_stats: {"cur_iter": "101", "eta": "0:29:23", "split": "test_iter", "time_diff": 5.23261}
[05/01 09:29:31][INFO] logging.py:  99: json_stats: {"cur_iter": "102", "eta": "0:04:48", "split": "test_iter", "time_diff": 0.85989}
[05/01 09:29:33][INFO] logging.py:  99: json_stats: {"cur_iter": "103", "eta": "0:08:33", "split": "test_iter", "time_diff": 1.53146}
[05/01 09:29:34][INFO] logging.py:  99: json_stats: {"cur_iter": "104", "eta": "0:07:49", "split": "test_iter", "time_diff": 1.40673}
[05/01 09:29:36][INFO] logging.py:  99: json_stats: {"cur_iter": "105", "eta": "0:07:50", "split": "test_iter", "time_diff": 1.41410}
[05/01 09:29:37][INFO] logging.py:  99: json_stats: {"cur_iter": "106", "eta": "0:08:53", "split": "test_iter", "time_diff": 1.60586}
[05/01 09:29:39][INFO] logging.py:  99: json_stats: {"cur_iter": "107", "eta": "0:07:47", "split": "test_iter", "time_diff": 1.41250}
[05/01 09:29:40][INFO] logging.py:  99: json_stats: {"cur_iter": "108", "eta": "0:08:54", "split": "test_iter", "time_diff": 1.61914}
[05/01 09:29:47][INFO] logging.py:  99: json_stats: {"cur_iter": "109", "eta": "0:38:42", "split": "test_iter", "time_diff": 7.05902}
[05/01 09:29:49][INFO] logging.py:  99: json_stats: {"cur_iter": "110", "eta": "0:07:40", "split": "test_iter", "time_diff": 1.40352}
[05/01 09:29:50][INFO] logging.py:  99: json_stats: {"cur_iter": "111", "eta": "0:07:06", "split": "test_iter", "time_diff": 1.30351}
[05/01 09:29:51][INFO] logging.py:  99: json_stats: {"cur_iter": "112", "eta": "0:07:05", "split": "test_iter", "time_diff": 1.30554}
[05/01 09:29:53][INFO] logging.py:  99: json_stats: {"cur_iter": "113", "eta": "0:07:41", "split": "test_iter", "time_diff": 1.42031}
[05/01 09:29:54][INFO] logging.py:  99: json_stats: {"cur_iter": "114", "eta": "0:08:03", "split": "test_iter", "time_diff": 1.49129}
[05/01 09:29:55][INFO] logging.py:  99: json_stats: {"cur_iter": "115", "eta": "0:05:14", "split": "test_iter", "time_diff": 0.97230}
[05/01 09:29:58][INFO] logging.py:  99: json_stats: {"cur_iter": "116", "eta": "0:13:55", "split": "test_iter", "time_diff": 2.59478}
[05/01 09:30:01][INFO] logging.py:  99: json_stats: {"cur_iter": "117", "eta": "0:18:14", "split": "test_iter", "time_diff": 3.41093}
[05/01 09:30:03][INFO] logging.py:  99: json_stats: {"cur_iter": "118", "eta": "0:07:53", "split": "test_iter", "time_diff": 1.47933}
[05/01 09:30:04][INFO] logging.py:  99: json_stats: {"cur_iter": "119", "eta": "0:08:25", "split": "test_iter", "time_diff": 1.58332}
[05/01 09:30:06][INFO] logging.py:  99: json_stats: {"cur_iter": "120", "eta": "0:08:23", "split": "test_iter", "time_diff": 1.58300}
[05/01 09:30:07][INFO] logging.py:  99: json_stats: {"cur_iter": "121", "eta": "0:06:57", "split": "test_iter", "time_diff": 1.31797}
[05/01 09:30:09][INFO] logging.py:  99: json_stats: {"cur_iter": "122", "eta": "0:04:31", "split": "test_iter", "time_diff": 0.85810}
[05/01 09:30:12][INFO] logging.py:  99: json_stats: {"cur_iter": "123", "eta": "0:16:38", "split": "test_iter", "time_diff": 3.17065}
[05/01 09:30:14][INFO] logging.py:  99: json_stats: {"cur_iter": "124", "eta": "0:11:38", "split": "test_iter", "time_diff": 2.22430}
[05/01 09:30:17][INFO] logging.py:  99: json_stats: {"cur_iter": "125", "eta": "0:14:47", "split": "test_iter", "time_diff": 2.83431}
[05/01 09:30:18][INFO] logging.py:  99: json_stats: {"cur_iter": "126", "eta": "0:07:14", "split": "test_iter", "time_diff": 1.39325}
[05/01 09:30:20][INFO] logging.py:  99: json_stats: {"cur_iter": "127", "eta": "0:04:30", "split": "test_iter", "time_diff": 0.86827}
[05/01 09:30:21][INFO] logging.py:  99: json_stats: {"cur_iter": "128", "eta": "0:07:25", "split": "test_iter", "time_diff": 1.43601}
[05/01 09:30:23][INFO] logging.py:  99: json_stats: {"cur_iter": "129", "eta": "0:07:18", "split": "test_iter", "time_diff": 1.41949}
[05/01 09:30:25][INFO] logging.py:  99: json_stats: {"cur_iter": "130", "eta": "0:10:36", "split": "test_iter", "time_diff": 2.06631}
[05/01 09:30:30][INFO] logging.py:  99: json_stats: {"cur_iter": "131", "eta": "0:25:35", "split": "test_iter", "time_diff": 5.00210}
[05/01 09:30:33][INFO] logging.py:  99: json_stats: {"cur_iter": "132", "eta": "0:14:57", "split": "test_iter", "time_diff": 2.93333}
[05/01 09:30:34][INFO] logging.py:  99: json_stats: {"cur_iter": "133", "eta": "0:05:13", "split": "test_iter", "time_diff": 1.02686}
[05/01 09:30:35][INFO] logging.py:  99: json_stats: {"cur_iter": "134", "eta": "0:06:57", "split": "test_iter", "time_diff": 1.37217}
[05/01 09:30:36][INFO] logging.py:  99: json_stats: {"cur_iter": "135", "eta": "0:07:06", "split": "test_iter", "time_diff": 1.40603}
[05/01 09:30:38][INFO] logging.py:  99: json_stats: {"cur_iter": "136", "eta": "0:04:19", "split": "test_iter", "time_diff": 0.85822}
[05/01 09:30:39][INFO] logging.py:  99: json_stats: {"cur_iter": "137", "eta": "0:07:46", "split": "test_iter", "time_diff": 1.55048}
[05/01 09:30:41][INFO] logging.py:  99: json_stats: {"cur_iter": "138", "eta": "0:07:53", "split": "test_iter", "time_diff": 1.57756}
[05/01 09:30:45][INFO] logging.py:  99: json_stats: {"cur_iter": "139", "eta": "0:23:07", "split": "test_iter", "time_diff": 4.63973}
[05/01 09:30:48][INFO] logging.py:  99: json_stats: {"cur_iter": "140", "eta": "0:10:25", "split": "test_iter", "time_diff": 2.09885}
[05/01 09:30:49][INFO] logging.py:  99: json_stats: {"cur_iter": "141", "eta": "0:07:34", "split": "test_iter", "time_diff": 1.52873}
[05/01 09:30:50][INFO] logging.py:  99: json_stats: {"cur_iter": "142", "eta": "0:04:13", "split": "test_iter", "time_diff": 0.85634}
[05/01 09:30:52][INFO] logging.py:  99: json_stats: {"cur_iter": "143", "eta": "0:05:01", "split": "test_iter", "time_diff": 1.02370}
[05/01 09:30:53][INFO] logging.py:  99: json_stats: {"cur_iter": "144", "eta": "0:06:11", "split": "test_iter", "time_diff": 1.26272}
[05/01 09:30:54][INFO] logging.py:  99: json_stats: {"cur_iter": "145", "eta": "0:07:39", "split": "test_iter", "time_diff": 1.56809}
[05/01 09:30:57][INFO] logging.py:  99: json_stats: {"cur_iter": "146", "eta": "0:13:29", "split": "test_iter", "time_diff": 2.77270}
[05/01 09:31:05][INFO] logging.py:  99: json_stats: {"cur_iter": "147", "eta": "0:36:02", "split": "test_iter", "time_diff": 7.43153}
[05/01 09:31:07][INFO] logging.py:  99: json_stats: {"cur_iter": "148", "eta": "0:09:56", "split": "test_iter", "time_diff": 2.05743}
[05/01 09:31:08][INFO] logging.py:  99: json_stats: {"cur_iter": "149", "eta": "0:06:48", "split": "test_iter", "time_diff": 1.41214}
[05/01 09:31:09][INFO] logging.py:  99: json_stats: {"cur_iter": "150", "eta": "0:04:31", "split": "test_iter", "time_diff": 0.94344}
[05/01 09:31:10][INFO] logging.py:  99: json_stats: {"cur_iter": "151", "eta": "0:05:46", "split": "test_iter", "time_diff": 1.20690}
[05/01 09:31:12][INFO] logging.py:  99: json_stats: {"cur_iter": "152", "eta": "0:09:22", "split": "test_iter", "time_diff": 1.96830}
[05/01 09:31:14][INFO] logging.py:  99: json_stats: {"cur_iter": "153", "eta": "0:07:49", "split": "test_iter", "time_diff": 1.64689}
[05/01 09:31:15][INFO] logging.py:  99: json_stats: {"cur_iter": "154", "eta": "0:06:30", "split": "test_iter", "time_diff": 1.37335}
[05/01 09:31:20][INFO] logging.py:  99: json_stats: {"cur_iter": "155", "eta": "0:22:41", "split": "test_iter", "time_diff": 4.81048}
[05/01 09:31:22][INFO] logging.py:  99: json_stats: {"cur_iter": "156", "eta": "0:04:01", "split": "test_iter", "time_diff": 0.85779}
[05/01 09:31:23][INFO] logging.py:  99: json_stats: {"cur_iter": "157", "eta": "0:04:38", "split": "test_iter", "time_diff": 0.99253}
[05/01 09:31:24][INFO] logging.py:  99: json_stats: {"cur_iter": "158", "eta": "0:05:28", "split": "test_iter", "time_diff": 1.17169}
[05/01 09:31:25][INFO] logging.py:  99: json_stats: {"cur_iter": "159", "eta": "0:07:03", "split": "test_iter", "time_diff": 1.51812}
[05/01 09:31:27][INFO] logging.py:  99: json_stats: {"cur_iter": "160", "eta": "0:06:40", "split": "test_iter", "time_diff": 1.44097}
[05/01 09:31:28][INFO] logging.py:  99: json_stats: {"cur_iter": "161", "eta": "0:06:47", "split": "test_iter", "time_diff": 1.47124}
[05/01 09:31:30][INFO] logging.py:  99: json_stats: {"cur_iter": "162", "eta": "0:06:57", "split": "test_iter", "time_diff": 1.51319}
[05/01 09:31:35][INFO] logging.py:  99: json_stats: {"cur_iter": "163", "eta": "0:26:25", "split": "test_iter", "time_diff": 5.76402}
[05/01 09:31:38][INFO] logging.py:  99: json_stats: {"cur_iter": "164", "eta": "0:10:36", "split": "test_iter", "time_diff": 2.32127}
[05/01 09:31:39][INFO] logging.py:  99: json_stats: {"cur_iter": "165", "eta": "0:04:17", "split": "test_iter", "time_diff": 0.94423}
[05/01 09:31:41][INFO] logging.py:  99: json_stats: {"cur_iter": "166", "eta": "0:06:13", "split": "test_iter", "time_diff": 1.37437}
[05/01 09:31:42][INFO] logging.py:  99: json_stats: {"cur_iter": "167", "eta": "0:05:37", "split": "test_iter", "time_diff": 1.24571}
[05/01 09:31:44][INFO] logging.py:  99: json_stats: {"cur_iter": "168", "eta": "0:05:53", "split": "test_iter", "time_diff": 1.30950}
[05/01 09:31:45][INFO] logging.py:  99: json_stats: {"cur_iter": "169", "eta": "0:06:38", "split": "test_iter", "time_diff": 1.48173}
[05/01 09:31:47][INFO] logging.py:  99: json_stats: {"cur_iter": "170", "eta": "0:07:22", "split": "test_iter", "time_diff": 1.65062}
[05/01 09:31:50][INFO] logging.py:  99: json_stats: {"cur_iter": "171", "eta": "0:16:11", "split": "test_iter", "time_diff": 3.63875}
[05/01 09:31:52][INFO] logging.py:  99: json_stats: {"cur_iter": "172", "eta": "0:03:48", "split": "test_iter", "time_diff": 0.85861}
[05/01 09:31:53][INFO] logging.py:  99: json_stats: {"cur_iter": "173", "eta": "0:05:11", "split": "test_iter", "time_diff": 1.17680}
[05/01 09:31:54][INFO] logging.py:  99: json_stats: {"cur_iter": "174", "eta": "0:03:46", "split": "test_iter", "time_diff": 0.85967}
[05/01 09:31:55][INFO] logging.py:  99: json_stats: {"cur_iter": "175", "eta": "0:05:25", "split": "test_iter", "time_diff": 1.23749}
[05/01 09:31:56][INFO] logging.py:  99: json_stats: {"cur_iter": "176", "eta": "0:03:45", "split": "test_iter", "time_diff": 0.86050}
[05/01 09:31:57][INFO] logging.py:  99: json_stats: {"cur_iter": "177", "eta": "0:03:50", "split": "test_iter", "time_diff": 0.88150}
[05/01 09:31:58][INFO] logging.py:  99: json_stats: {"cur_iter": "178", "eta": "0:07:11", "split": "test_iter", "time_diff": 1.65905}
[05/01 09:32:05][INFO] logging.py:  99: json_stats: {"cur_iter": "179", "eta": "0:28:13", "split": "test_iter", "time_diff": 6.53830}
[05/01 09:32:08][INFO] logging.py:  99: json_stats: {"cur_iter": "180", "eta": "0:11:48", "split": "test_iter", "time_diff": 2.74603}
[05/01 09:32:10][INFO] logging.py:  99: json_stats: {"cur_iter": "181", "eta": "0:03:40", "split": "test_iter", "time_diff": 0.85824}
[05/01 09:32:11][INFO] logging.py:  99: json_stats: {"cur_iter": "182", "eta": "0:06:10", "split": "test_iter", "time_diff": 1.44857}
[05/01 09:32:12][INFO] logging.py:  99: json_stats: {"cur_iter": "183", "eta": "0:03:38", "split": "test_iter", "time_diff": 0.85813}
[05/01 09:32:14][INFO] logging.py:  99: json_stats: {"cur_iter": "184", "eta": "0:06:26", "split": "test_iter", "time_diff": 1.52243}
[05/01 09:32:15][INFO] logging.py:  99: json_stats: {"cur_iter": "185", "eta": "0:05:45", "split": "test_iter", "time_diff": 1.36620}
[05/01 09:32:17][INFO] logging.py:  99: json_stats: {"cur_iter": "186", "eta": "0:06:28", "split": "test_iter", "time_diff": 1.54197}
[05/01 09:32:20][INFO] logging.py:  99: json_stats: {"cur_iter": "187", "eta": "0:14:20", "split": "test_iter", "time_diff": 3.42838}
[05/01 09:32:22][INFO] logging.py:  99: json_stats: {"cur_iter": "188", "eta": "0:05:02", "split": "test_iter", "time_diff": 1.20872}
[05/01 09:32:22][INFO] logging.py:  99: json_stats: {"cur_iter": "189", "eta": "0:03:33", "split": "test_iter", "time_diff": 0.85864}
[05/01 09:32:24][INFO] logging.py:  99: json_stats: {"cur_iter": "190", "eta": "0:05:34", "split": "test_iter", "time_diff": 1.34919}
[05/01 09:32:25][INFO] logging.py:  99: json_stats: {"cur_iter": "191", "eta": "0:03:37", "split": "test_iter", "time_diff": 0.87985}
[05/01 09:32:26][INFO] logging.py:  99: json_stats: {"cur_iter": "192", "eta": "0:03:36", "split": "test_iter", "time_diff": 0.87989}
[05/01 09:32:27][INFO] logging.py:  99: json_stats: {"cur_iter": "193", "eta": "0:03:29", "split": "test_iter", "time_diff": 0.85698}
[05/01 09:32:28][INFO] logging.py:  99: json_stats: {"cur_iter": "194", "eta": "0:04:19", "split": "test_iter", "time_diff": 1.06536}
[05/01 09:32:37][INFO] logging.py:  99: json_stats: {"cur_iter": "195", "eta": "0:34:19", "split": "test_iter", "time_diff": 8.47597}
[05/01 09:32:41][INFO] logging.py:  99: json_stats: {"cur_iter": "196", "eta": "0:15:52", "split": "test_iter", "time_diff": 3.93448}
[05/01 09:32:42][INFO] logging.py:  99: json_stats: {"cur_iter": "197", "eta": "0:03:26", "split": "test_iter", "time_diff": 0.85584}
[05/01 09:32:43][INFO] logging.py:  99: json_stats: {"cur_iter": "198", "eta": "0:05:38", "split": "test_iter", "time_diff": 1.40976}
[05/01 09:32:45][INFO] logging.py:  99: json_stats: {"cur_iter": "199", "eta": "0:05:01", "split": "test_iter", "time_diff": 1.26113}
[05/01 09:32:46][INFO] logging.py:  99: json_stats: {"cur_iter": "200", "eta": "0:03:24", "split": "test_iter", "time_diff": 0.86051}
[05/01 09:32:47][INFO] logging.py:  99: json_stats: {"cur_iter": "201", "eta": "0:05:37", "split": "test_iter", "time_diff": 1.42270}
[05/01 09:32:49][INFO] logging.py:  99: json_stats: {"cur_iter": "202", "eta": "0:05:45", "split": "test_iter", "time_diff": 1.46428}
[05/01 09:32:51][INFO] logging.py:  99: json_stats: {"cur_iter": "203", "eta": "0:08:22", "split": "test_iter", "time_diff": 2.13717}
[05/01 09:32:52][INFO] logging.py:  99: json_stats: {"cur_iter": "204", "eta": "0:04:52", "split": "test_iter", "time_diff": 1.25146}
[05/01 09:32:53][INFO] logging.py:  99: json_stats: {"cur_iter": "205", "eta": "0:03:20", "split": "test_iter", "time_diff": 0.86015}
[05/01 09:32:54][INFO] logging.py:  99: json_stats: {"cur_iter": "206", "eta": "0:04:48", "split": "test_iter", "time_diff": 1.24379}
[05/01 09:32:55][INFO] logging.py:  99: json_stats: {"cur_iter": "207", "eta": "0:03:22", "split": "test_iter", "time_diff": 0.87798}
[05/01 09:32:56][INFO] logging.py:  99: json_stats: {"cur_iter": "208", "eta": "0:03:48", "split": "test_iter", "time_diff": 0.99273}
[05/01 09:32:58][INFO] logging.py:  99: json_stats: {"cur_iter": "209", "eta": "0:06:27", "split": "test_iter", "time_diff": 1.69100}
[05/01 09:32:59][INFO] logging.py:  99: json_stats: {"cur_iter": "210", "eta": "0:03:35", "split": "test_iter", "time_diff": 0.94498}
[05/01 09:33:05][INFO] logging.py:  99: json_stats: {"cur_iter": "211", "eta": "0:23:02", "split": "test_iter", "time_diff": 6.08953}
[05/01 09:33:06][INFO] logging.py:  99: json_stats: {"cur_iter": "212", "eta": "0:05:27", "split": "test_iter", "time_diff": 1.44823}
[05/01 09:33:08][INFO] logging.py:  99: json_stats: {"cur_iter": "213", "eta": "0:05:34", "split": "test_iter", "time_diff": 1.48791}
[05/01 09:33:10][INFO] logging.py:  99: json_stats: {"cur_iter": "214", "eta": "0:05:43", "split": "test_iter", "time_diff": 1.53455}
[05/01 09:33:12][INFO] logging.py:  99: json_stats: {"cur_iter": "215", "eta": "0:07:40", "split": "test_iter", "time_diff": 2.06578}
[05/01 09:33:13][INFO] logging.py:  99: json_stats: {"cur_iter": "216", "eta": "0:04:48", "split": "test_iter", "time_diff": 1.30071}
[05/01 09:33:15][INFO] logging.py:  99: json_stats: {"cur_iter": "217", "eta": "0:05:03", "split": "test_iter", "time_diff": 1.37167}
[05/01 09:33:16][INFO] logging.py:  99: json_stats: {"cur_iter": "218", "eta": "0:05:16", "split": "test_iter", "time_diff": 1.43862}
[05/01 09:33:22][INFO] logging.py:  99: json_stats: {"cur_iter": "219", "eta": "0:21:43", "split": "test_iter", "time_diff": 5.95193}
[05/01 09:33:24][INFO] logging.py:  99: json_stats: {"cur_iter": "220", "eta": "0:06:46", "split": "test_iter", "time_diff": 1.86472}
[05/01 09:33:25][INFO] logging.py:  99: json_stats: {"cur_iter": "221", "eta": "0:04:55", "split": "test_iter", "time_diff": 1.36068}
[05/01 09:33:27][INFO] logging.py:  99: json_stats: {"cur_iter": "222", "eta": "0:03:10", "split": "test_iter", "time_diff": 0.88204}
[05/01 09:33:28][INFO] logging.py:  99: json_stats: {"cur_iter": "223", "eta": "0:04:55", "split": "test_iter", "time_diff": 1.37419}
[05/01 09:33:29][INFO] logging.py:  99: json_stats: {"cur_iter": "224", "eta": "0:04:24", "split": "test_iter", "time_diff": 1.23659}
[05/01 09:33:31][INFO] logging.py:  99: json_stats: {"cur_iter": "225", "eta": "0:04:59", "split": "test_iter", "time_diff": 1.40483}
[05/01 09:33:32][INFO] logging.py:  99: json_stats: {"cur_iter": "226", "eta": "0:03:06", "split": "test_iter", "time_diff": 0.87812}
[05/01 09:33:38][INFO] logging.py:  99: json_stats: {"cur_iter": "227", "eta": "0:19:45", "split": "test_iter", "time_diff": 5.62001}
[05/01 09:33:40][INFO] logging.py:  99: json_stats: {"cur_iter": "228", "eta": "0:07:07", "split": "test_iter", "time_diff": 2.03385}
[05/01 09:33:41][INFO] logging.py:  99: json_stats: {"cur_iter": "229", "eta": "0:03:01", "split": "test_iter", "time_diff": 0.87075}
[05/01 09:33:42][INFO] logging.py:  99: json_stats: {"cur_iter": "230", "eta": "0:02:58", "split": "test_iter", "time_diff": 0.85674}
[05/01 09:33:43][INFO] logging.py:  99: json_stats: {"cur_iter": "231", "eta": "0:05:04", "split": "test_iter", "time_diff": 1.47194}
[05/01 09:33:45][INFO] logging.py:  99: json_stats: {"cur_iter": "232", "eta": "0:05:39", "split": "test_iter", "time_diff": 1.64956}
[05/01 09:33:46][INFO] logging.py:  99: json_stats: {"cur_iter": "233", "eta": "0:03:32", "split": "test_iter", "time_diff": 1.03428}
[05/01 09:33:48][INFO] logging.py:  99: json_stats: {"cur_iter": "234", "eta": "0:05:15", "split": "test_iter", "time_diff": 1.54634}
[05/01 09:33:53][INFO] logging.py:  99: json_stats: {"cur_iter": "235", "eta": "0:17:00", "split": "test_iter", "time_diff": 5.02755}
[05/01 09:33:55][INFO] logging.py:  99: json_stats: {"cur_iter": "236", "eta": "0:07:12", "split": "test_iter", "time_diff": 2.14118}
[05/01 09:33:56][INFO] logging.py:  99: json_stats: {"cur_iter": "237", "eta": "0:03:07", "split": "test_iter", "time_diff": 0.93210}
[05/01 09:33:57][INFO] logging.py:  99: json_stats: {"cur_iter": "238", "eta": "0:04:02", "split": "test_iter", "time_diff": 1.21411}
[05/01 09:33:59][INFO] logging.py:  99: json_stats: {"cur_iter": "239", "eta": "0:04:00", "split": "test_iter", "time_diff": 1.20650}
[05/01 09:34:00][INFO] logging.py:  99: json_stats: {"cur_iter": "240", "eta": "0:03:08", "split": "test_iter", "time_diff": 0.94986}
[05/01 09:34:02][INFO] logging.py:  99: json_stats: {"cur_iter": "241", "eta": "0:05:36", "split": "test_iter", "time_diff": 1.70909}
[05/01 09:34:02][INFO] logging.py:  99: json_stats: {"cur_iter": "242", "eta": "0:02:50", "split": "test_iter", "time_diff": 0.86796}
[05/01 09:34:09][INFO] logging.py:  99: json_stats: {"cur_iter": "243", "eta": "0:19:35", "split": "test_iter", "time_diff": 6.03005}
[05/01 09:34:11][INFO] logging.py:  99: json_stats: {"cur_iter": "244", "eta": "0:07:34", "split": "test_iter", "time_diff": 2.34317}
[05/01 09:34:12][INFO] logging.py:  99: json_stats: {"cur_iter": "245", "eta": "0:04:13", "split": "test_iter", "time_diff": 1.31217}
[05/01 09:34:14][INFO] logging.py:  99: json_stats: {"cur_iter": "246", "eta": "0:04:59", "split": "test_iter", "time_diff": 1.56027}
[05/01 09:34:15][INFO] logging.py:  99: json_stats: {"cur_iter": "247", "eta": "0:03:58", "split": "test_iter", "time_diff": 1.25013}
[05/01 09:34:17][INFO] logging.py:  99: json_stats: {"cur_iter": "248", "eta": "0:02:43", "split": "test_iter", "time_diff": 0.85930}
[05/01 09:34:18][INFO] logging.py:  99: json_stats: {"cur_iter": "249", "eta": "0:04:32", "split": "test_iter", "time_diff": 1.44127}
[05/01 09:34:20][INFO] logging.py:  99: json_stats: {"cur_iter": "250", "eta": "0:04:25", "split": "test_iter", "time_diff": 1.41005}
[05/01 09:34:24][INFO] logging.py:  99: json_stats: {"cur_iter": "251", "eta": "0:12:46", "split": "test_iter", "time_diff": 4.10159}
[05/01 09:34:25][INFO] logging.py:  99: json_stats: {"cur_iter": "252", "eta": "0:05:22", "split": "test_iter", "time_diff": 1.73550}
[05/01 09:34:27][INFO] logging.py:  99: json_stats: {"cur_iter": "253", "eta": "0:03:58", "split": "test_iter", "time_diff": 1.29054}
[05/01 09:34:28][INFO] logging.py:  99: json_stats: {"cur_iter": "254", "eta": "0:02:41", "split": "test_iter", "time_diff": 0.87912}
[05/01 09:34:29][INFO] logging.py:  99: json_stats: {"cur_iter": "255", "eta": "0:03:36", "split": "test_iter", "time_diff": 1.18289}
[05/01 09:34:30][INFO] logging.py:  99: json_stats: {"cur_iter": "256", "eta": "0:04:05", "split": "test_iter", "time_diff": 1.35112}
[05/01 09:34:32][INFO] logging.py:  99: json_stats: {"cur_iter": "257", "eta": "0:04:22", "split": "test_iter", "time_diff": 1.45012}
[05/01 09:34:33][INFO] logging.py:  99: json_stats: {"cur_iter": "258", "eta": "0:02:37", "split": "test_iter", "time_diff": 0.87549}
[05/01 09:34:39][INFO] logging.py:  99: json_stats: {"cur_iter": "259", "eta": "0:19:08", "split": "test_iter", "time_diff": 6.41416}
[05/01 09:34:42][INFO] logging.py:  99: json_stats: {"cur_iter": "260", "eta": "0:08:04", "split": "test_iter", "time_diff": 2.72041}
[05/01 09:34:43][INFO] logging.py:  99: json_stats: {"cur_iter": "261", "eta": "0:02:35", "split": "test_iter", "time_diff": 0.87739}
[05/01 09:34:44][INFO] logging.py:  99: json_stats: {"cur_iter": "262", "eta": "0:02:34", "split": "test_iter", "time_diff": 0.87629}
[05/01 09:34:46][INFO] logging.py:  99: json_stats: {"cur_iter": "263", "eta": "0:04:23", "split": "test_iter", "time_diff": 1.50839}
[05/01 09:34:47][INFO] logging.py:  99: json_stats: {"cur_iter": "264", "eta": "0:02:29", "split": "test_iter", "time_diff": 0.85720}
[05/01 09:34:49][INFO] logging.py:  99: json_stats: {"cur_iter": "265", "eta": "0:02:28", "split": "test_iter", "time_diff": 0.85773}
[05/01 09:34:50][INFO] logging.py:  99: json_stats: {"cur_iter": "266", "eta": "0:03:29", "split": "test_iter", "time_diff": 1.21943}
[05/01 09:34:54][INFO] logging.py:  99: json_stats: {"cur_iter": "267", "eta": "0:10:12", "split": "test_iter", "time_diff": 3.57997}
[05/01 09:34:55][INFO] logging.py:  99: json_stats: {"cur_iter": "268", "eta": "0:03:53", "split": "test_iter", "time_diff": 1.37421}
[05/01 09:34:56][INFO] logging.py:  99: json_stats: {"cur_iter": "269", "eta": "0:02:44", "split": "test_iter", "time_diff": 0.97386}
[05/01 09:34:57][INFO] logging.py:  99: json_stats: {"cur_iter": "270", "eta": "0:02:27", "split": "test_iter", "time_diff": 0.87937}
[05/01 09:34:58][INFO] logging.py:  99: json_stats: {"cur_iter": "271", "eta": "0:02:26", "split": "test_iter", "time_diff": 0.88005}
[05/01 09:34:59][INFO] logging.py:  99: json_stats: {"cur_iter": "272", "eta": "0:03:53", "split": "test_iter", "time_diff": 1.40787}
[05/01 09:35:01][INFO] logging.py:  99: json_stats: {"cur_iter": "273", "eta": "0:04:13", "split": "test_iter", "time_diff": 1.53818}
[05/01 09:35:02][INFO] logging.py:  99: json_stats: {"cur_iter": "274", "eta": "0:02:24", "split": "test_iter", "time_diff": 0.87889}
[05/01 09:35:08][INFO] logging.py:  99: json_stats: {"cur_iter": "275", "eta": "0:15:09", "split": "test_iter", "time_diff": 5.58255}
[05/01 09:35:11][INFO] logging.py:  99: json_stats: {"cur_iter": "276", "eta": "0:08:45", "split": "test_iter", "time_diff": 3.24419}
[05/01 09:35:12][INFO] logging.py:  99: json_stats: {"cur_iter": "277", "eta": "0:02:21", "split": "test_iter", "time_diff": 0.88092}
[05/01 09:35:13][INFO] logging.py:  99: json_stats: {"cur_iter": "278", "eta": "0:02:21", "split": "test_iter", "time_diff": 0.88163}
[05/01 09:35:14][INFO] logging.py:  99: json_stats: {"cur_iter": "279", "eta": "0:03:41", "split": "test_iter", "time_diff": 1.39400}
[05/01 09:35:16][INFO] logging.py:  99: json_stats: {"cur_iter": "280", "eta": "0:03:51", "split": "test_iter", "time_diff": 1.46237}
[05/01 09:35:17][INFO] logging.py:  99: json_stats: {"cur_iter": "281", "eta": "0:03:26", "split": "test_iter", "time_diff": 1.31374}
[05/01 09:35:18][INFO] logging.py:  99: json_stats: {"cur_iter": "282", "eta": "0:02:45", "split": "test_iter", "time_diff": 1.06159}
[05/01 09:35:23][INFO] logging.py:  99: json_stats: {"cur_iter": "283", "eta": "0:11:18", "split": "test_iter", "time_diff": 4.37878}
[05/01 09:35:25][INFO] logging.py:  99: json_stats: {"cur_iter": "284", "eta": "0:05:25", "split": "test_iter", "time_diff": 2.11122}
[05/01 09:35:26][INFO] logging.py:  99: json_stats: {"cur_iter": "285", "eta": "0:02:11", "split": "test_iter", "time_diff": 0.85997}
[05/01 09:35:27][INFO] logging.py:  99: json_stats: {"cur_iter": "286", "eta": "0:02:13", "split": "test_iter", "time_diff": 0.88034}
[05/01 09:35:28][INFO] logging.py:  99: json_stats: {"cur_iter": "287", "eta": "0:02:27", "split": "test_iter", "time_diff": 0.97489}
[05/01 09:35:29][INFO] logging.py:  99: json_stats: {"cur_iter": "288", "eta": "0:03:30", "split": "test_iter", "time_diff": 1.40115}
[05/01 09:35:30][INFO] logging.py:  99: json_stats: {"cur_iter": "289", "eta": "0:03:05", "split": "test_iter", "time_diff": 1.24374}
[05/01 09:35:32][INFO] logging.py:  99: json_stats: {"cur_iter": "290", "eta": "0:03:50", "split": "test_iter", "time_diff": 1.55646}
[05/01 09:35:39][INFO] logging.py:  99: json_stats: {"cur_iter": "291", "eta": "0:17:55", "split": "test_iter", "time_diff": 7.31445}
[05/01 09:35:41][INFO] logging.py:  99: json_stats: {"cur_iter": "292", "eta": "0:05:51", "split": "test_iter", "time_diff": 2.40560}
[05/01 09:35:43][INFO] logging.py:  99: json_stats: {"cur_iter": "293", "eta": "0:02:59", "split": "test_iter", "time_diff": 1.23785}
[05/01 09:35:44][INFO] logging.py:  99: json_stats: {"cur_iter": "294", "eta": "0:02:06", "split": "test_iter", "time_diff": 0.87851}
[05/01 09:35:45][INFO] logging.py:  99: json_stats: {"cur_iter": "295", "eta": "0:02:58", "split": "test_iter", "time_diff": 1.25004}
[05/01 09:35:46][INFO] logging.py:  99: json_stats: {"cur_iter": "296", "eta": "0:03:11", "split": "test_iter", "time_diff": 1.35120}
[05/01 09:35:48][INFO] logging.py:  99: json_stats: {"cur_iter": "297", "eta": "0:02:53", "split": "test_iter", "time_diff": 1.22749}
[05/01 09:35:49][INFO] logging.py:  99: json_stats: {"cur_iter": "298", "eta": "0:02:02", "split": "test_iter", "time_diff": 0.87671}
[05/01 09:35:52][INFO] logging.py:  99: json_stats: {"cur_iter": "299", "eta": "0:08:47", "split": "test_iter", "time_diff": 3.79189}
[05/01 09:35:54][INFO] logging.py:  99: json_stats: {"cur_iter": "300", "eta": "0:03:58", "split": "test_iter", "time_diff": 1.72695}
[05/01 09:35:55][INFO] logging.py:  99: json_stats: {"cur_iter": "301", "eta": "0:02:01", "split": "test_iter", "time_diff": 0.88567}
[05/01 09:35:56][INFO] logging.py:  99: json_stats: {"cur_iter": "302", "eta": "0:02:12", "split": "test_iter", "time_diff": 0.97636}
[05/01 09:35:57][INFO] logging.py:  99: json_stats: {"cur_iter": "303", "eta": "0:01:58", "split": "test_iter", "time_diff": 0.87825}
[05/01 09:35:58][INFO] logging.py:  99: json_stats: {"cur_iter": "304", "eta": "0:03:21", "split": "test_iter", "time_diff": 1.50536}
[05/01 09:35:59][INFO] logging.py:  99: json_stats: {"cur_iter": "305", "eta": "0:01:56", "split": "test_iter", "time_diff": 0.87343}
[05/01 09:36:01][INFO] logging.py:  99: json_stats: {"cur_iter": "306", "eta": "0:03:05", "split": "test_iter", "time_diff": 1.40829}
[05/01 09:36:10][INFO] logging.py:  99: json_stats: {"cur_iter": "307", "eta": "0:19:07", "split": "test_iter", "time_diff": 8.75914}
[05/01 09:36:15][INFO] logging.py:  99: json_stats: {"cur_iter": "308", "eta": "0:10:39", "split": "test_iter", "time_diff": 4.91816}
[05/01 09:36:16][INFO] logging.py:  99: json_stats: {"cur_iter": "309", "eta": "0:02:55", "split": "test_iter", "time_diff": 1.35688}
[05/01 09:36:17][INFO] logging.py:  99: json_stats: {"cur_iter": "310", "eta": "0:02:44", "split": "test_iter", "time_diff": 1.28690}
[05/01 09:36:19][INFO] logging.py:  99: json_stats: {"cur_iter": "311", "eta": "0:02:41", "split": "test_iter", "time_diff": 1.27090}
[05/01 09:36:20][INFO] logging.py:  99: json_stats: {"cur_iter": "312", "eta": "0:02:42", "split": "test_iter", "time_diff": 1.28765}
[05/01 09:36:21][INFO] logging.py:  99: json_stats: {"cur_iter": "313", "eta": "0:02:58", "split": "test_iter", "time_diff": 1.43025}
[05/01 09:36:23][INFO] logging.py:  99: json_stats: {"cur_iter": "314", "eta": "0:03:34", "split": "test_iter", "time_diff": 1.72620}
[05/01 09:36:25][INFO] logging.py:  99: json_stats: {"cur_iter": "315", "eta": "0:04:22", "split": "test_iter", "time_diff": 2.13102}
[05/01 09:36:26][INFO] logging.py:  99: json_stats: {"cur_iter": "316", "eta": "0:01:47", "split": "test_iter", "time_diff": 0.87807}
[05/01 09:36:27][INFO] logging.py:  99: json_stats: {"cur_iter": "317", "eta": "0:02:41", "split": "test_iter", "time_diff": 1.33485}
[05/01 09:36:28][INFO] logging.py:  99: json_stats: {"cur_iter": "318", "eta": "0:01:45", "split": "test_iter", "time_diff": 0.87932}
[05/01 09:36:29][INFO] logging.py:  99: json_stats: {"cur_iter": "319", "eta": "0:01:44", "split": "test_iter", "time_diff": 0.88109}
[05/01 09:36:30][INFO] logging.py:  99: json_stats: {"cur_iter": "320", "eta": "0:01:43", "split": "test_iter", "time_diff": 0.87997}
[05/01 09:36:31][INFO] logging.py:  99: json_stats: {"cur_iter": "321", "eta": "0:01:51", "split": "test_iter", "time_diff": 0.95161}
[05/01 09:36:32][INFO] logging.py:  99: json_stats: {"cur_iter": "322", "eta": "0:02:34", "split": "test_iter", "time_diff": 1.32878}
[05/01 09:36:40][INFO] logging.py:  99: json_stats: {"cur_iter": "323", "eta": "0:15:24", "split": "test_iter", "time_diff": 8.03630}
[05/01 09:36:45][INFO] logging.py:  99: json_stats: {"cur_iter": "324", "eta": "0:08:25", "split": "test_iter", "time_diff": 4.43532}
[05/01 09:36:46][INFO] logging.py:  99: json_stats: {"cur_iter": "325", "eta": "0:02:14", "split": "test_iter", "time_diff": 1.19374}
[05/01 09:36:47][INFO] logging.py:  99: json_stats: {"cur_iter": "326", "eta": "0:02:39", "split": "test_iter", "time_diff": 1.42270}
[05/01 09:36:49][INFO] logging.py:  99: json_stats: {"cur_iter": "327", "eta": "0:01:37", "split": "test_iter", "time_diff": 0.87605}
[05/01 09:36:50][INFO] logging.py:  99: json_stats: {"cur_iter": "328", "eta": "0:01:36", "split": "test_iter", "time_diff": 0.87819}
[05/01 09:36:52][INFO] logging.py:  99: json_stats: {"cur_iter": "329", "eta": "0:02:39", "split": "test_iter", "time_diff": 1.46204}
[05/01 09:36:53][INFO] logging.py:  99: json_stats: {"cur_iter": "330", "eta": "0:01:34", "split": "test_iter", "time_diff": 0.87464}
[05/01 09:36:56][INFO] logging.py:  99: json_stats: {"cur_iter": "331", "eta": "0:05:20", "split": "test_iter", "time_diff": 2.99938}
[05/01 09:36:57][INFO] logging.py:  99: json_stats: {"cur_iter": "332", "eta": "0:02:08", "split": "test_iter", "time_diff": 1.21047}
[05/01 09:36:58][INFO] logging.py:  99: json_stats: {"cur_iter": "333", "eta": "0:01:30", "split": "test_iter", "time_diff": 0.85757}
[05/01 09:36:59][INFO] logging.py:  99: json_stats: {"cur_iter": "334", "eta": "0:01:31", "split": "test_iter", "time_diff": 0.88095}
[05/01 09:37:00][INFO] logging.py:  99: json_stats: {"cur_iter": "335", "eta": "0:01:30", "split": "test_iter", "time_diff": 0.87797}
[05/01 09:37:01][INFO] logging.py:  99: json_stats: {"cur_iter": "336", "eta": "0:01:29", "split": "test_iter", "time_diff": 0.88050}
[05/01 09:37:02][INFO] logging.py:  99: json_stats: {"cur_iter": "337", "eta": "0:01:28", "split": "test_iter", "time_diff": 0.88075}
[05/01 09:37:03][INFO] logging.py:  99: json_stats: {"cur_iter": "338", "eta": "0:01:27", "split": "test_iter", "time_diff": 0.87917}
[05/01 09:37:10][INFO] logging.py:  99: json_stats: {"cur_iter": "339", "eta": "0:11:50", "split": "test_iter", "time_diff": 7.17855}
[05/01 09:37:15][INFO] logging.py:  99: json_stats: {"cur_iter": "340", "eta": "0:08:03", "split": "test_iter", "time_diff": 4.93144}
[05/01 09:37:16][INFO] logging.py:  99: json_stats: {"cur_iter": "341", "eta": "0:01:55", "split": "test_iter", "time_diff": 1.19266}
[05/01 09:37:18][INFO] logging.py:  99: json_stats: {"cur_iter": "342", "eta": "0:02:15", "split": "test_iter", "time_diff": 1.41129}
[05/01 09:37:19][INFO] logging.py:  99: json_stats: {"cur_iter": "343", "eta": "0:01:23", "split": "test_iter", "time_diff": 0.87603}
[05/01 09:37:20][INFO] logging.py:  99: json_stats: {"cur_iter": "344", "eta": "0:02:05", "split": "test_iter", "time_diff": 1.33875}
[05/01 09:37:21][INFO] logging.py:  99: json_stats: {"cur_iter": "345", "eta": "0:01:48", "split": "test_iter", "time_diff": 1.16144}
[05/01 09:37:23][INFO] logging.py:  99: json_stats: {"cur_iter": "346", "eta": "0:01:58", "split": "test_iter", "time_diff": 1.28594}
[05/01 09:37:25][INFO] logging.py:  99: json_stats: {"cur_iter": "347", "eta": "0:02:41", "split": "test_iter", "time_diff": 1.77610}
[05/01 09:37:27][INFO] logging.py:  99: json_stats: {"cur_iter": "348", "eta": "0:03:05", "split": "test_iter", "time_diff": 2.06570}
[05/01 09:37:27][INFO] logging.py:  99: json_stats: {"cur_iter": "349", "eta": "0:01:18", "split": "test_iter", "time_diff": 0.87751}
[05/01 09:37:28][INFO] logging.py:  99: json_stats: {"cur_iter": "350", "eta": "0:01:17", "split": "test_iter", "time_diff": 0.87948}
[05/01 09:37:29][INFO] logging.py:  99: json_stats: {"cur_iter": "351", "eta": "0:01:16", "split": "test_iter", "time_diff": 0.88189}
[05/01 09:37:31][INFO] logging.py:  99: json_stats: {"cur_iter": "352", "eta": "0:01:56", "split": "test_iter", "time_diff": 1.35482}
[05/01 09:37:32][INFO] logging.py:  99: json_stats: {"cur_iter": "353", "eta": "0:01:50", "split": "test_iter", "time_diff": 1.30272}
[05/01 09:37:34][INFO] logging.py:  99: json_stats: {"cur_iter": "354", "eta": "0:01:53", "split": "test_iter", "time_diff": 1.34612}
[05/01 09:37:37][INFO] logging.py:  99: json_stats: {"cur_iter": "355", "eta": "0:04:23", "split": "test_iter", "time_diff": 3.17638}
[05/01 09:37:40][INFO] logging.py:  99: json_stats: {"cur_iter": "356", "eta": "0:04:45", "split": "test_iter", "time_diff": 3.48354}
[05/01 09:37:41][INFO] logging.py:  99: json_stats: {"cur_iter": "357", "eta": "0:01:09", "split": "test_iter", "time_diff": 0.86043}
[05/01 09:37:42][INFO] logging.py:  99: json_stats: {"cur_iter": "358", "eta": "0:01:39", "split": "test_iter", "time_diff": 1.24602}
[05/01 09:37:43][INFO] logging.py:  99: json_stats: {"cur_iter": "359", "eta": "0:01:09", "split": "test_iter", "time_diff": 0.87842}
[05/01 09:37:45][INFO] logging.py:  99: json_stats: {"cur_iter": "360", "eta": "0:01:40", "split": "test_iter", "time_diff": 1.28457}
[05/01 09:37:46][INFO] logging.py:  99: json_stats: {"cur_iter": "361", "eta": "0:01:06", "split": "test_iter", "time_diff": 0.85988}
[05/01 09:37:47][INFO] logging.py:  99: json_stats: {"cur_iter": "362", "eta": "0:01:12", "split": "test_iter", "time_diff": 0.95588}
[05/01 09:37:51][INFO] logging.py:  99: json_stats: {"cur_iter": "363", "eta": "0:04:57", "split": "test_iter", "time_diff": 3.96726}
[05/01 09:37:54][INFO] logging.py:  99: json_stats: {"cur_iter": "364", "eta": "0:02:52", "split": "test_iter", "time_diff": 2.32535}
[05/01 09:37:55][INFO] logging.py:  99: json_stats: {"cur_iter": "365", "eta": "0:01:51", "split": "test_iter", "time_diff": 1.52563}
[05/01 09:37:56][INFO] logging.py:  99: json_stats: {"cur_iter": "366", "eta": "0:01:04", "split": "test_iter", "time_diff": 0.90076}
[05/01 09:37:57][INFO] logging.py:  99: json_stats: {"cur_iter": "367", "eta": "0:01:02", "split": "test_iter", "time_diff": 0.87947}
[05/01 09:37:58][INFO] logging.py:  99: json_stats: {"cur_iter": "368", "eta": "0:01:38", "split": "test_iter", "time_diff": 1.40500}
[05/01 09:38:00][INFO] logging.py:  99: json_stats: {"cur_iter": "369", "eta": "0:01:47", "split": "test_iter", "time_diff": 1.56101}
[05/01 09:38:01][INFO] logging.py:  99: json_stats: {"cur_iter": "370", "eta": "0:00:58", "split": "test_iter", "time_diff": 0.85674}
[05/01 09:38:06][INFO] logging.py:  99: json_stats: {"cur_iter": "371", "eta": "0:04:48", "split": "test_iter", "time_diff": 4.30093}
[05/01 09:38:07][INFO] logging.py:  99: json_stats: {"cur_iter": "372", "eta": "0:01:14", "split": "test_iter", "time_diff": 1.13418}
[05/01 09:38:09][INFO] logging.py:  99: json_stats: {"cur_iter": "373", "eta": "0:01:28", "split": "test_iter", "time_diff": 1.36021}
[05/01 09:38:10][INFO] logging.py:  99: json_stats: {"cur_iter": "374", "eta": "0:00:54", "split": "test_iter", "time_diff": 0.85847}
[05/01 09:38:12][INFO] logging.py:  99: json_stats: {"cur_iter": "375", "eta": "0:01:29", "split": "test_iter", "time_diff": 1.42189}
[05/01 09:38:13][INFO] logging.py:  99: json_stats: {"cur_iter": "376", "eta": "0:01:23", "split": "test_iter", "time_diff": 1.34396}
[05/01 09:38:14][INFO] logging.py:  99: json_stats: {"cur_iter": "377", "eta": "0:00:52", "split": "test_iter", "time_diff": 0.85908}
[05/01 09:38:15][INFO] logging.py:  99: json_stats: {"cur_iter": "378", "eta": "0:00:52", "split": "test_iter", "time_diff": 0.87912}
[05/01 09:38:19][INFO] logging.py:  99: json_stats: {"cur_iter": "379", "eta": "0:04:11", "split": "test_iter", "time_diff": 4.26660}
[05/01 09:38:23][INFO] logging.py:  99: json_stats: {"cur_iter": "380", "eta": "0:03:49", "split": "test_iter", "time_diff": 3.95235}
[05/01 09:38:25][INFO] logging.py:  99: json_stats: {"cur_iter": "381", "eta": "0:01:55", "split": "test_iter", "time_diff": 2.03057}
[05/01 09:38:26][INFO] logging.py:  99: json_stats: {"cur_iter": "382", "eta": "0:00:48", "split": "test_iter", "time_diff": 0.86012}
[05/01 09:38:27][INFO] logging.py:  99: json_stats: {"cur_iter": "383", "eta": "0:00:48", "split": "test_iter", "time_diff": 0.88002}
[05/01 09:38:28][INFO] logging.py:  99: json_stats: {"cur_iter": "384", "eta": "0:01:06", "split": "test_iter", "time_diff": 1.23614}
[05/01 09:38:29][INFO] logging.py:  99: json_stats: {"cur_iter": "385", "eta": "0:01:02", "split": "test_iter", "time_diff": 1.18096}
[05/01 09:38:30][INFO] logging.py:  99: json_stats: {"cur_iter": "386", "eta": "0:00:45", "split": "test_iter", "time_diff": 0.87292}
[05/01 09:38:32][INFO] logging.py:  99: json_stats: {"cur_iter": "387", "eta": "0:01:27", "split": "test_iter", "time_diff": 1.71846}
[05/01 09:38:34][INFO] logging.py:  99: json_stats: {"cur_iter": "388", "eta": "0:01:34", "split": "test_iter", "time_diff": 1.89911}
[05/01 09:38:36][INFO] logging.py:  99: json_stats: {"cur_iter": "389", "eta": "0:01:44", "split": "test_iter", "time_diff": 2.12685}
[05/01 09:38:37][INFO] logging.py:  99: json_stats: {"cur_iter": "390", "eta": "0:00:41", "split": "test_iter", "time_diff": 0.85908}
[05/01 09:38:38][INFO] logging.py:  99: json_stats: {"cur_iter": "391", "eta": "0:00:45", "split": "test_iter", "time_diff": 0.97254}
[05/01 09:38:39][INFO] logging.py:  99: json_stats: {"cur_iter": "392", "eta": "0:00:57", "split": "test_iter", "time_diff": 1.25408}
[05/01 09:38:41][INFO] logging.py:  99: json_stats: {"cur_iter": "393", "eta": "0:00:52", "split": "test_iter", "time_diff": 1.17402}
[05/01 09:38:42][INFO] logging.py:  99: json_stats: {"cur_iter": "394", "eta": "0:00:47", "split": "test_iter", "time_diff": 1.08891}
[05/01 09:38:44][INFO] logging.py:  99: json_stats: {"cur_iter": "395", "eta": "0:01:53", "split": "test_iter", "time_diff": 2.64950}
[05/01 09:38:47][INFO] logging.py:  99: json_stats: {"cur_iter": "396", "eta": "0:01:57", "split": "test_iter", "time_diff": 2.79799}
[05/01 09:38:49][INFO] logging.py:  99: json_stats: {"cur_iter": "397", "eta": "0:01:06", "split": "test_iter", "time_diff": 1.62255}
[05/01 09:38:50][INFO] logging.py:  99: json_stats: {"cur_iter": "398", "eta": "0:00:43", "split": "test_iter", "time_diff": 1.09922}
[05/01 09:38:51][INFO] logging.py:  99: json_stats: {"cur_iter": "399", "eta": "0:00:42", "split": "test_iter", "time_diff": 1.09213}
[05/01 09:38:52][INFO] logging.py:  99: json_stats: {"cur_iter": "400", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.10266}
[05/01 09:38:53][INFO] logging.py:  99: json_stats: {"cur_iter": "401", "eta": "0:00:40", "split": "test_iter", "time_diff": 1.10127}
[05/01 09:38:55][INFO] logging.py:  99: json_stats: {"cur_iter": "402", "eta": "0:00:31", "split": "test_iter", "time_diff": 0.87680}
[05/01 09:38:57][INFO] logging.py:  99: json_stats: {"cur_iter": "403", "eta": "0:01:25", "split": "test_iter", "time_diff": 2.43516}
[05/01 09:38:58][INFO] logging.py:  99: json_stats: {"cur_iter": "404", "eta": "0:00:37", "split": "test_iter", "time_diff": 1.09618}
[05/01 09:39:00][INFO] logging.py:  99: json_stats: {"cur_iter": "405", "eta": "0:01:11", "split": "test_iter", "time_diff": 2.17706}
[05/01 09:39:01][INFO] logging.py:  99: json_stats: {"cur_iter": "406", "eta": "0:00:27", "split": "test_iter", "time_diff": 0.86072}
[05/01 09:39:02][INFO] logging.py:  99: json_stats: {"cur_iter": "407", "eta": "0:00:34", "split": "test_iter", "time_diff": 1.10802}
[05/01 09:39:03][INFO] logging.py:  99: json_stats: {"cur_iter": "408", "eta": "0:00:26", "split": "test_iter", "time_diff": 0.89498}
[05/01 09:39:04][INFO] logging.py:  99: json_stats: {"cur_iter": "409", "eta": "0:00:25", "split": "test_iter", "time_diff": 0.88095}
[05/01 09:39:05][INFO] logging.py:  99: json_stats: {"cur_iter": "410", "eta": "0:00:33", "split": "test_iter", "time_diff": 1.18774}
[05/01 09:39:07][INFO] logging.py:  99: json_stats: {"cur_iter": "411", "eta": "0:00:23", "split": "test_iter", "time_diff": 0.87745}
[05/01 09:39:08][INFO] logging.py:  99: json_stats: {"cur_iter": "412", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.60059}
[05/01 09:39:12][INFO] logging.py:  99: json_stats: {"cur_iter": "413", "eta": "0:01:20", "split": "test_iter", "time_diff": 3.20249}
[05/01 09:39:12][INFO] logging.py:  99: json_stats: {"cur_iter": "414", "eta": "0:00:20", "split": "test_iter", "time_diff": 0.85716}
[05/01 09:39:14][INFO] logging.py:  99: json_stats: {"cur_iter": "415", "eta": "0:00:20", "split": "test_iter", "time_diff": 0.88067}
[05/01 09:39:15][INFO] logging.py:  99: json_stats: {"cur_iter": "416", "eta": "0:00:23", "split": "test_iter", "time_diff": 1.06287}
[05/01 09:39:16][INFO] logging.py:  99: json_stats: {"cur_iter": "417", "eta": "0:00:26", "split": "test_iter", "time_diff": 1.28383}
[05/01 09:39:17][INFO] logging.py:  99: json_stats: {"cur_iter": "418", "eta": "0:00:27", "split": "test_iter", "time_diff": 1.37034}
[05/01 09:39:19][INFO] logging.py:  99: json_stats: {"cur_iter": "419", "eta": "0:00:25", "split": "test_iter", "time_diff": 1.33533}
[05/01 09:39:21][INFO] logging.py:  99: json_stats: {"cur_iter": "420", "eta": "0:00:32", "split": "test_iter", "time_diff": 1.82743}
[05/01 09:39:23][INFO] logging.py:  99: json_stats: {"cur_iter": "421", "eta": "0:00:40", "split": "test_iter", "time_diff": 2.37848}
[05/01 09:39:24][INFO] logging.py:  99: json_stats: {"cur_iter": "422", "eta": "0:00:13", "split": "test_iter", "time_diff": 0.86083}
[05/01 09:39:25][INFO] logging.py:  99: json_stats: {"cur_iter": "423", "eta": "0:00:13", "split": "test_iter", "time_diff": 0.88135}
[05/01 09:39:26][INFO] logging.py:  99: json_stats: {"cur_iter": "424", "eta": "0:00:17", "split": "test_iter", "time_diff": 1.23230}
[05/01 09:39:27][INFO] logging.py:  99: json_stats: {"cur_iter": "425", "eta": "0:00:11", "split": "test_iter", "time_diff": 0.85932}
[05/01 09:39:28][INFO] logging.py:  99: json_stats: {"cur_iter": "426", "eta": "0:00:13", "split": "test_iter", "time_diff": 1.09294}
[05/01 09:39:29][INFO] logging.py:  99: json_stats: {"cur_iter": "427", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.88008}
[05/01 09:39:31][INFO] logging.py:  99: json_stats: {"cur_iter": "428", "eta": "0:00:20", "split": "test_iter", "time_diff": 2.03154}
[05/01 09:39:33][INFO] logging.py:  99: json_stats: {"cur_iter": "429", "eta": "0:00:13", "split": "test_iter", "time_diff": 1.50996}
[05/01 09:39:34][INFO] logging.py:  99: json_stats: {"cur_iter": "430", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.85658}
[05/01 09:39:35][INFO] logging.py:  99: json_stats: {"cur_iter": "431", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.88180}
[05/01 09:39:36][INFO] logging.py:  99: json_stats: {"cur_iter": "432", "eta": "0:00:05", "split": "test_iter", "time_diff": 0.98898}
[05/01 09:39:37][INFO] logging.py:  99: json_stats: {"cur_iter": "433", "eta": "0:00:05", "split": "test_iter", "time_diff": 1.10560}
[05/01 09:39:38][INFO] logging.py:  99: json_stats: {"cur_iter": "434", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.88144}
[05/01 09:39:39][INFO] logging.py:  99: json_stats: {"cur_iter": "435", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.88273}
[05/01 09:39:39][INFO] logging.py:  99: json_stats: {"cur_iter": "436", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.88324}
[05/01 09:39:40][INFO] logging.py:  99: json_stats: {"cur_iter": "437", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.71529}
[05/01 09:39:40][WARNING] meters.py: 381: clip count 0: 9, 1: 9, 2: 9, 3: 9, 4: 9, 5: 9, 6: 9, 7: 9, 8: 9, 9: 9, 10: 9, 11: 9, 12: 9, 13: 9, 14: 9, 15: 9, 16: 9, 17: 9, 18: 9, 19: 9, 20: 9, 21: 9, 22: 9, 23: 9, 24: 9, 25: 9, 26: 9, 27: 9, 28: 9, 29: 9, 30: 9, 31: 9, 32: 9, 33: 9, 34: 9, 35: 9, 36: 9, 37: 9, 38: 9, 39: 9, 40: 9, 41: 9, 42: 9, 43: 9, 44: 9, 45: 9, 46: 9, 47: 9, 48: 9, 49: 9, 50: 9, 51: 9, 52: 9, 53: 9, 54: 9, 55: 9, 56: 9, 57: 9, 58: 9, 59: 9, 60: 9, 61: 9, 62: 9, 63: 9, 64: 9, 65: 9, 66: 9, 67: 9, 68: 9, 69: 9, 70: 9, 71: 9, 72: 9, 73: 9, 74: 9, 75: 9, 76: 9, 77: 9, 78: 9, 79: 9, 80: 9, 81: 9, 82: 9, 83: 9, 84: 9, 85: 9, 86: 9, 87: 9, 88: 9, 89: 9, 90: 9, 91: 9, 92: 9, 93: 9, 94: 9, 95: 9, 96: 9, 97: 9, 98: 9, 99: 9, 100: 9, 101: 9, 102: 9, 103: 9, 104: 9, 105: 9, 106: 9, 107: 9, 108: 9, 109: 9, 110: 9, 111: 9, 112: 9, 113: 9, 114: 9, 115: 9, 116: 9, 117: 9, 118: 9, 119: 9, 120: 9, 121: 9, 122: 9, 123: 9, 124: 9, 125: 9, 126: 9, 127: 9, 128: 9, 129: 9, 130: 9, 131: 9, 132: 9, 133: 9, 134: 9, 135: 9, 136: 9, 137: 9, 138: 9, 139: 9, 140: 9, 141: 9, 142: 9, 143: 9, 144: 9, 145: 9, 146: 9, 147: 9, 148: 9, 149: 9, 150: 9, 151: 9, 152: 9, 153: 9, 154: 9, 155: 9, 156: 9, 157: 9, 158: 9, 159: 9, 160: 9, 161: 9, 162: 9, 163: 9, 164: 9, 165: 9, 166: 9, 167: 9, 168: 9, 169: 9, 170: 9, 171: 9, 172: 9, 173: 9, 174: 9, 175: 9, 176: 9, 177: 9, 178: 9, 179: 9, 180: 9, 181: 9, 182: 9, 183: 9, 184: 9, 185: 9, 186: 9, 187: 9, 188: 9, 189: 9, 190: 9, 191: 9, 192: 9, 193: 9, 194: 9, 195: 9, 196: 9, 197: 9, 198: 9, 199: 9, 200: 9, 201: 9, 202: 9, 203: 9, 204: 9, 205: 9, 206: 9, 207: 9, 208: 9, 209: 9, 210: 9, 211: 9, 212: 9, 213: 9, 214: 9, 215: 9, 216: 9, 217: 9, 218: 9, 219: 9, 220: 9, 221: 9, 222: 9, 223: 9, 224: 9, 225: 9, 226: 9, 227: 9, 228: 9, 229: 9, 230: 9, 231: 9, 232: 9, 233: 9, 234: 9, 235: 9, 236: 9, 237: 9, 238: 9, 239: 9, 240: 9, 241: 9, 242: 9, 243: 9, 244: 9, 245: 9, 246: 9, 247: 9, 248: 9, 249: 9, 250: 9, 251: 9, 252: 9, 253: 9, 254: 9, 255: 9, 256: 9, 257: 9, 258: 9, 259: 9, 260: 9, 261: 9, 262: 9, 263: 9, 264: 9, 265: 9, 266: 9, 267: 9, 268: 9, 269: 9, 270: 9, 271: 9, 272: 9, 273: 9, 274: 9, 275: 9, 276: 9, 277: 9, 278: 9, 279: 9, 280: 9, 281: 9, 282: 9, 283: 9, 284: 9, 285: 9, 286: 9, 287: 9, 288: 9, 289: 9, 290: 9, 291: 9, 292: 9, 293: 9, 294: 9, 295: 9, 296: 9, 297: 9, 298: 9, 299: 9, 300: 9, 301: 9, 302: 9, 303: 9, 304: 9, 305: 9, 306: 9, 307: 9, 308: 9, 309: 9, 310: 9, 311: 9, 312: 9, 313: 9, 314: 9, 315: 9, 316: 9, 317: 9, 318: 9, 319: 9, 320: 9, 321: 9, 322: 9, 323: 9, 324: 9, 325: 9, 326: 9, 327: 9, 328: 9, 329: 9, 330: 9, 331: 9, 332: 9, 333: 9, 334: 9, 335: 9, 336: 9, 337: 9, 338: 9, 339: 9, 340: 9, 341: 9, 342: 9, 343: 9, 344: 9, 345: 9, 346: 9, 347: 9, 348: 9, 349: 9, 350: 9, 351: 9, 352: 9, 353: 9, 354: 9, 355: 9, 356: 9, 357: 9, 358: 9, 359: 9, 360: 9, 361: 9, 362: 9, 363: 9, 364: 9, 365: 9, 366: 9, 367: 9, 368: 9, 369: 9, 370: 9, 371: 9, 372: 9, 373: 9, 374: 9, 375: 9, 376: 9, 377: 9, 378: 9, 379: 9, 380: 9, 381: 9, 382: 9, 383: 9, 384: 9, 385: 9, 386: 9, 387: 9, 388: 9, 389: 9, 390: 9, 391: 9, 392: 9, 393: 9, 394: 9, 395: 9, 396: 9, 397: 9, 398: 9, 399: 9, 400: 9, 401: 9, 402: 9, 403: 9, 404: 9, 405: 9, 406: 9, 407: 9, 408: 9, 409: 9, 410: 9, 411: 9, 412: 9, 413: 9, 414: 9, 415: 9, 416: 9, 417: 9, 418: 9, 419: 9, 420: 9, 421: 9, 422: 9, 423: 9, 424: 9, 425: 9, 426: 9, 427: 9, 428: 9, 429: 9, 430: 9, 431: 9, 432: 9, 433: 9, 434: 9, 435: 9, 436: 9, 437: 9, 438: 9, 439: 9, 440: 9, 441: 9, 442: 9, 443: 9, 444: 9, 445: 9, 446: 9, 447: 9, 448: 9, 449: 9, 450: 9, 451: 9, 452: 9, 453: 9, 454: 9, 455: 9, 456: 9, 457: 9, 458: 9, 459: 9, 460: 9, 461: 9, 462: 9, 463: 9, 464: 9, 465: 9, 466: 9, 467: 9, 468: 9, 469: 9, 470: 9, 471: 9, 472: 9, 473: 9, 474: 9, 475: 9, 476: 9, 477: 9, 478: 9, 479: 9, 480: 9, 481: 9, 482: 9, 483: 9, 484: 9, 485: 9, 486: 9, 487: 9, 488: 9, 489: 9, 490: 9, 491: 9, 492: 9, 493: 9, 494: 9, 495: 9, 496: 9, 497: 9, 498: 9, 499: 9, 500: 9, 501: 9, 502: 9, 503: 9, 504: 9, 505: 9, 506: 9, 507: 9, 508: 9, 509: 9, 510: 9, 511: 9, 512: 9, 513: 9, 514: 9, 515: 9, 516: 9, 517: 9, 518: 9, 519: 9, 520: 9, 521: 9, 522: 9, 523: 9, 524: 9, 525: 9, 526: 9, 527: 9, 528: 9, 529: 9, 530: 9, 531: 9, 532: 9, 533: 9, 534: 9, 535: 9, 536: 9, 537: 9, 538: 9, 539: 9, 540: 9, 541: 9, 542: 9, 543: 9, 544: 9, 545: 9, 546: 9, 547: 9, 548: 9, 549: 9, 550: 9, 551: 9, 552: 9, 553: 9, 554: 9, 555: 9, 556: 9, 557: 9, 558: 9, 559: 9, 560: 9, 561: 9, 562: 9, 563: 9, 564: 9, 565: 9, 566: 9, 567: 9, 568: 9, 569: 9, 570: 9, 571: 9, 572: 9, 573: 9, 574: 9, 575: 9, 576: 9, 577: 9, 578: 9, 579: 9, 580: 9, 581: 9, 582: 9, 583: 9, 584: 9, 585: 9, 586: 9, 587: 9, 588: 9, 589: 9, 590: 9, 591: 9, 592: 9, 593: 9, 594: 9, 595: 9, 596: 9, 597: 9, 598: 9, 599: 9, 600: 9, 601: 9, 602: 9, 603: 9, 604: 9, 605: 9, 606: 9, 607: 9, 608: 9, 609: 9, 610: 9, 611: 9, 612: 9, 613: 9, 614: 9, 615: 9, 616: 9, 617: 9, 618: 9, 619: 9, 620: 9, 621: 9, 622: 9, 623: 9, 624: 9, 625: 9, 626: 9, 627: 9, 628: 9, 629: 9, 630: 9, 631: 9, 632: 9, 633: 9, 634: 9, 635: 9, 636: 9, 637: 9, 638: 9, 639: 9, 640: 9, 641: 9, 642: 9, 643: 9, 644: 9, 645: 9, 646: 9, 647: 9, 648: 9, 649: 9, 650: 9, 651: 9, 652: 9, 653: 9, 654: 9, 655: 9, 656: 9, 657: 9, 658: 9, 659: 9, 660: 9, 661: 9, 662: 9, 663: 9, 664: 9, 665: 9, 666: 9, 667: 9, 668: 9, 669: 9, 670: 9, 671: 9, 672: 9, 673: 9, 674: 9, 675: 9, 676: 9, 677: 9, 678: 9, 679: 9, 680: 9, 681: 9, 682: 9, 683: 9, 684: 9, 685: 9, 686: 9, 687: 9, 688: 9, 689: 9, 690: 9, 691: 9, 692: 9, 693: 9, 694: 9, 695: 9, 696: 9, 697: 9, 698: 9, 699: 9, 700: 9, 701: 9, 702: 9, 703: 9, 704: 9, 705: 9, 706: 9, 707: 9, 708: 9, 709: 9, 710: 9, 711: 9, 712: 9, 713: 9, 714: 9, 715: 9, 716: 9, 717: 9, 718: 9, 719: 9, 720: 9, 721: 9, 722: 9, 723: 9, 724: 9, 725: 9, 726: 9, 727: 9, 728: 9, 729: 9, 730: 9, 731: 9, 732: 9, 733: 9, 734: 9, 735: 9, 736: 9, 737: 9, 738: 9, 739: 9, 740: 9, 741: 9, 742: 9, 743: 9, 744: 9, 745: 9, 746: 9, 747: 9, 748: 9, 749: 9, 750: 9, 751: 9, 752: 9, 753: 9, 754: 9, 755: 9, 756: 9, 757: 9, 758: 9, 759: 9, 760: 9, 761: 9, 762: 9, 763: 9, 764: 9, 765: 9, 766: 9, 767: 9, 768: 9, 769: 9, 770: 9, 771: 9, 772: 9, 773: 9, 774: 9, 775: 9, 776: 9, 777: 9, 778: 9, 779: 9, 780: 9, 781: 9, 782: 9, 783: 9, 784: 9, 785: 9, 786: 9, 787: 9, 788: 9, 789: 9, 790: 9, 791: 9, 792: 9, 793: 9, 794: 9, 795: 9, 796: 9, 797: 9, 798: 9, 799: 9, 800: 9, 801: 9, 802: 9, 803: 9, 804: 9, 805: 9, 806: 9, 807: 9, 808: 9, 809: 9, 810: 9, 811: 9, 812: 9, 813: 9, 814: 9, 815: 9, 816: 9, 817: 9, 818: 9, 819: 9, 820: 9, 821: 9, 822: 9, 823: 9, 824: 9, 825: 9, 826: 9, 827: 9, 828: 9, 829: 9, 830: 9, 831: 9, 832: 9, 833: 9, 834: 9, 835: 9, 836: 9, 837: 9, 838: 9, 839: 9, 840: 9, 841: 9, 842: 9, 843: 9, 844: 9, 845: 9, 846: 9, 847: 9, 848: 9, 849: 9, 850: 9, 851: 9, 852: 9, 853: 9, 854: 9, 855: 9, 856: 9, 857: 9, 858: 9, 859: 9, 860: 9, 861: 9, 862: 9, 863: 9, 864: 9, 865: 9, 866: 9, 867: 9, 868: 9, 869: 9, 870: 9, 871: 9, 872: 9, 873: 9, 874: 9, 875: 9, 876: 9, 877: 9, 878: 9, 879: 9, 880: 9, 881: 9, 882: 9, 883: 9, 884: 9, 885: 9, 886: 9, 887: 9, 888: 9, 889: 9, 890: 9, 891: 9, 892: 9, 893: 9, 894: 9, 895: 9, 896: 9, 897: 9, 898: 9, 899: 9, 900: 9, 901: 9, 902: 9, 903: 9, 904: 9, 905: 9, 906: 9, 907: 9, 908: 9, 909: 9, 910: 9, 911: 9, 912: 9, 913: 9, 914: 9, 915: 9, 916: 9, 917: 9, 918: 9, 919: 9, 920: 9, 921: 9, 922: 9, 923: 9, 924: 9, 925: 9, 926: 9, 927: 9, 928: 9, 929: 9, 930: 9, 931: 9, 932: 9, 933: 9, 934: 9, 935: 9, 936: 9, 937: 9, 938: 9, 939: 9, 940: 9, 941: 9, 942: 9, 943: 9, 944: 9, 945: 9, 946: 9, 947: 9, 948: 9, 949: 9, 950: 9, 951: 9, 952: 9, 953: 9, 954: 9, 955: 9, 956: 9, 957: 9, 958: 9, 959: 9, 960: 9, 961: 9, 962: 9, 963: 9, 964: 9, 965: 9, 966: 9, 967: 9, 968: 9, 969: 9, 970: 9, 971: 9, 972: 9, 973: 9, 974: 9, 975: 9, 976: 9, 977: 9, 978: 9, 979: 9, 980: 9, 981: 9, 982: 9, 983: 9, 984: 9, 985: 9, 986: 9, 987: 9, 988: 9, 989: 9, 990: 9, 991: 9, 992: 9, 993: 9, 994: 9, 995: 9, 996: 9, 997: 9, 998: 9, 999: 9, 1000: 9, 1001: 9, 1002: 9, 1003: 9, 1004: 9, 1005: 9, 1006: 9, 1007: 9, 1008: 9, 1009: 9, 1010: 9, 1011: 9, 1012: 9, 1013: 9, 1014: 9, 1015: 9, 1016: 9, 1017: 9, 1018: 9, 1019: 9, 1020: 9, 1021: 9, 1022: 9, 1023: 9, 1024: 9, 1025: 9, 1026: 9, 1027: 9, 1028: 9, 1029: 9, 1030: 9, 1031: 9, 1032: 9, 1033: 9, 1034: 9, 1035: 9, 1036: 9, 1037: 9, 1038: 9, 1039: 9, 1040: 9, 1041: 9, 1042: 9, 1043: 9, 1044: 9, 1045: 9, 1046: 9, 1047: 9, 1048: 9, 1049: 9, 1050: 9, 1051: 9, 1052: 9, 1053: 9, 1054: 9, 1055: 9, 1056: 9, 1057: 9, 1058: 9, 1059: 9, 1060: 9, 1061: 9, 1062: 9, 1063: 9, 1064: 9, 1065: 9, 1066: 9, 1067: 9, 1068: 9, 1069: 9, 1070: 9, 1071: 9, 1072: 9, 1073: 9, 1074: 9, 1075: 9, 1076: 9, 1077: 9, 1078: 9, 1079: 9, 1080: 9, 1081: 9, 1082: 9, 1083: 9, 1084: 9, 1085: 9, 1086: 9, 1087: 9, 1088: 9, 1089: 9, 1090: 9, 1091: 9, 1092: 9, 1093: 9, 1094: 9, 1095: 9, 1096: 9, 1097: 9, 1098: 9, 1099: 9, 1100: 9, 1101: 9, 1102: 9, 1103: 9, 1104: 9, 1105: 9, 1106: 9, 1107: 9, 1108: 9, 1109: 9, 1110: 9, 1111: 9, 1112: 9, 1113: 9, 1114: 9, 1115: 9, 1116: 9, 1117: 9, 1118: 9, 1119: 9, 1120: 9, 1121: 9, 1122: 9, 1123: 9, 1124: 9, 1125: 9, 1126: 9, 1127: 9, 1128: 9, 1129: 9, 1130: 9, 1131: 9, 1132: 9, 1133: 9, 1134: 9, 1135: 9, 1136: 9, 1137: 9, 1138: 9, 1139: 9, 1140: 9, 1141: 9, 1142: 9, 1143: 9, 1144: 9, 1145: 9, 1146: 9, 1147: 9, 1148: 9, 1149: 9, 1150: 9, 1151: 9, 1152: 9, 1153: 9, 1154: 9, 1155: 9, 1156: 9, 1157: 9, 1158: 9, 1159: 9, 1160: 9, 1161: 9, 1162: 9, 1163: 9, 1164: 9, 1165: 9, 1166: 9, 1167: 9, 1168: 9, 1169: 9, 1170: 9, 1171: 9, 1172: 9, 1173: 9, 1174: 9, 1175: 9, 1176: 9, 1177: 9, 1178: 9, 1179: 9, 1180: 9, 1181: 9, 1182: 9, 1183: 9, 1184: 9, 1185: 9, 1186: 9, 1187: 9, 1188: 9, 1189: 9, 1190: 9, 1191: 9, 1192: 9, 1193: 9, 1194: 9, 1195: 9, 1196: 9, 1197: 9, 1198: 9, 1199: 9, 1200: 9, 1201: 9, 1202: 9, 1203: 9, 1204: 9, 1205: 9, 1206: 9, 1207: 9, 1208: 9, 1209: 9, 1210: 9, 1211: 9, 1212: 9, 1213: 9, 1214: 9, 1215: 9, 1216: 9, 1217: 9, 1218: 9, 1219: 9, 1220: 9, 1221: 9, 1222: 9, 1223: 9, 1224: 9, 1225: 9, 1226: 9, 1227: 9, 1228: 9, 1229: 9, 1230: 9, 1231: 9, 1232: 9, 1233: 9, 1234: 9, 1235: 9, 1236: 9, 1237: 9, 1238: 9, 1239: 9, 1240: 9, 1241: 9, 1242: 9, 1243: 9, 1244: 9, 1245: 9, 1246: 9, 1247: 9, 1248: 9, 1249: 9, 1250: 9, 1251: 9, 1252: 9, 1253: 9, 1254: 9, 1255: 9, 1256: 9, 1257: 9, 1258: 9, 1259: 9, 1260: 9, 1261: 9, 1262: 9, 1263: 9, 1264: 9, 1265: 9, 1266: 9, 1267: 9, 1268: 9, 1269: 9, 1270: 9, 1271: 9, 1272: 9, 1273: 9, 1274: 9, 1275: 9, 1276: 9, 1277: 9, 1278: 9, 1279: 9, 1280: 9, 1281: 9, 1282: 9, 1283: 9, 1284: 9, 1285: 9, 1286: 9, 1287: 9, 1288: 9, 1289: 9, 1290: 9, 1291: 9, 1292: 9, 1293: 9, 1294: 9, 1295: 9, 1296: 9, 1297: 9, 1298: 9, 1299: 9, 1300: 9, 1301: 9, 1302: 9, 1303: 9, 1304: 9, 1305: 9, 1306: 9, 1307: 9, 1308: 9, 1309: 9, 1310: 9, 1311: 9, 1312: 9, 1313: 9, 1314: 9, 1315: 9, 1316: 9, 1317: 9, 1318: 9, 1319: 9, 1320: 9, 1321: 9, 1322: 9, 1323: 9, 1324: 9, 1325: 9, 1326: 9, 1327: 9, 1328: 9, 1329: 9, 1330: 9, 1331: 9, 1332: 9, 1333: 9, 1334: 9, 1335: 9, 1336: 9, 1337: 9, 1338: 9, 1339: 9, 1340: 9, 1341: 9, 1342: 9, 1343: 9, 1344: 9, 1345: 9, 1346: 9, 1347: 9, 1348: 9, 1349: 9, 1350: 9, 1351: 9, 1352: 9, 1353: 9, 1354: 9, 1355: 9, 1356: 9, 1357: 9, 1358: 9, 1359: 9, 1360: 9, 1361: 9, 1362: 9, 1363: 9, 1364: 9, 1365: 9, 1366: 9, 1367: 9, 1368: 9, 1369: 9, 1370: 9, 1371: 9, 1372: 9, 1373: 9, 1374: 9, 1375: 9, 1376: 9, 1377: 9, 1378: 9, 1379: 9, 1380: 9, 1381: 9, 1382: 9, 1383: 9, 1384: 9, 1385: 9, 1386: 9, 1387: 9, 1388: 9, 1389: 9, 1390: 9, 1391: 9, 1392: 9, 1393: 9, 1394: 9, 1395: 9, 1396: 9, 1397: 9, 1398: 9, 1399: 9, 1400: 9, 1401: 9, 1402: 9, 1403: 9, 1404: 9, 1405: 9, 1406: 9, 1407: 9, 1408: 9, 1409: 9, 1410: 9, 1411: 9, 1412: 9, 1413: 9, 1414: 9, 1415: 9, 1416: 9, 1417: 9, 1418: 9, 1419: 9, 1420: 9, 1421: 9, 1422: 9, 1423: 9, 1424: 9, 1425: 9, 1426: 9, 1427: 9, 1428: 9, 1429: 9, 1430: 9, 1431: 9, 1432: 9, 1433: 9, 1434: 9, 1435: 9, 1436: 9, 1437: 9, 1438: 9, 1439: 9, 1440: 9, 1441: 9, 1442: 9, 1443: 9, 1444: 9, 1445: 9, 1446: 9, 1447: 9, 1448: 9, 1449: 9, 1450: 9, 1451: 9, 1452: 9, 1453: 9, 1454: 9, 1455: 9, 1456: 9, 1457: 9, 1458: 9, 1459: 9, 1460: 9, 1461: 9, 1462: 9, 1463: 9, 1464: 9, 1465: 9, 1466: 9, 1467: 9, 1468: 9, 1469: 9, 1470: 9, 1471: 9, 1472: 9, 1473: 9, 1474: 9, 1475: 9, 1476: 9, 1477: 9, 1478: 9, 1479: 9, 1480: 9, 1481: 9, 1482: 9, 1483: 9, 1484: 9, 1485: 9, 1486: 9, 1487: 9, 1488: 9, 1489: 9, 1490: 9, 1491: 9, 1492: 9, 1493: 9, 1494: 9, 1495: 10, 1496: 9, 1497: 9, 1498: 9, 1499: 9, 1500: 9, 1501: 9, 1502: 9, 1503: 9, 1504: 9, 1505: 9, 1506: 9, 1507: 9, 1508: 9, 1509: 9, 1510: 9, 1511: 9, 1512: 9, 1513: 9, 1514: 9, 1515: 9, 1516: 9, 1517: 9, 1518: 9, 1519: 9, 1520: 9, 1521: 9, 1522: 9, 1523: 9, 1524: 9, 1525: 9, 1526: 9, 1527: 9, 1528: 9, 1529: 9, 1530: 9, 1531: 9, 1532: 9, 1533: 9, 1534: 9, 1535: 9, 1536: 9, 1537: 9, 1538: 9, 1539: 9, 1540: 9, 1541: 9, 1542: 9, 1543: 9, 1544: 9, 1545: 9, 1546: 9, 1547: 9, 1548: 9, 1549: 9, 1550: 9, 1551: 9, 1552: 9, 1553: 9, 1554: 9, 1555: 9, 1556: 9, 1557: 9, 1558: 9, 1559: 9, 1560: 9, 1561: 9, 1562: 9, 1563: 9, 1564: 9, 1565: 9, 1566: 9, 1567: 9, 1568: 9, 1569: 9, 1570: 9, 1571: 9, 1572: 9, 1573: 9, 1574: 9, 1575: 9, 1576: 9, 1577: 9, 1578: 9, 1579: 9, 1580: 9, 1581: 9, 1582: 9, 1583: 9, 1584: 9, 1585: 9, 1586: 9, 1587: 9, 1588: 9, 1589: 9, 1590: 9, 1591: 9, 1592: 9, 1593: 9, 1594: 9, 1595: 9, 1596: 9, 1597: 9, 1598: 9, 1599: 9, 1600: 9, 1601: 9, 1602: 9, 1603: 9, 1604: 9, 1605: 9, 1606: 9, 1607: 9, 1608: 9, 1609: 9, 1610: 9, 1611: 9, 1612: 9, 1613: 9, 1614: 9, 1615: 9, 1616: 9, 1617: 9, 1618: 9, 1619: 9, 1620: 9, 1621: 9, 1622: 9, 1623: 9, 1624: 9, 1625: 9, 1626: 9, 1627: 9, 1628: 9, 1629: 9, 1630: 9, 1631: 9, 1632: 9, 1633: 9, 1634: 9, 1635: 9, 1636: 9, 1637: 9, 1638: 9, 1639: 9, 1640: 9, 1641: 9, 1642: 9, 1643: 9, 1644: 9, 1645: 9, 1646: 9, 1647: 9, 1648: 9, 1649: 9, 1650: 9, 1651: 9, 1652: 9, 1653: 9, 1654: 9, 1655: 9, 1656: 9, 1657: 9, 1658: 9, 1659: 9, 1660: 9, 1661: 9, 1662: 9, 1663: 9, 1664: 9, 1665: 9, 1666: 9, 1667: 9, 1668: 9, 1669: 9, 1670: 9, 1671: 9, 1672: 9, 1673: 9, 1674: 9, 1675: 9, 1676: 9, 1677: 9, 1678: 9, 1679: 9, 1680: 9, 1681: 9, 1682: 9, 1683: 9, 1684: 9, 1685: 9, 1686: 9, 1687: 9, 1688: 9, 1689: 9, 1690: 9, 1691: 9, 1692: 9, 1693: 9, 1694: 9, 1695: 9, 1696: 9, 1697: 9, 1698: 9, 1699: 9, 1700: 9, 1701: 9, 1702: 9, 1703: 9, 1704: 9, 1705: 9, 1706: 9, 1707: 9, 1708: 9, 1709: 9, 1710: 9, 1711: 9, 1712: 9, 1713: 9, 1714: 9, 1715: 9, 1716: 9, 1717: 9, 1718: 9, 1719: 9, 1720: 9, 1721: 9, 1722: 9, 1723: 9, 1724: 9, 1725: 9, 1726: 9, 1727: 9, 1728: 9, 1729: 9, 1730: 9, 1731: 9, 1732: 9, 1733: 9, 1734: 9, 1735: 9, 1736: 9, 1737: 9, 1738: 9, 1739: 9, 1740: 9, 1741: 9, 1742: 9, 1743: 9, 1744: 9, 1745: 9, 1746: 9, 1747: 9, 1748: 9, 1749: 9, 1750: 9, 1751: 9, 1752: 9, 1753: 9, 1754: 9, 1755: 9, 1756: 9, 1757: 9, 1758: 9, 1759: 9, 1760: 9, 1761: 9, 1762: 9, 1763: 9, 1764: 9, 1765: 9, 1766: 9, 1767: 9, 1768: 9, 1769: 9, 1770: 9, 1771: 9, 1772: 9, 1773: 9, 1774: 9, 1775: 9, 1776: 9, 1777: 9, 1778: 9, 1779: 9, 1780: 9, 1781: 9, 1782: 9, 1783: 9, 1784: 9, 1785: 9, 1786: 9, 1787: 9, 1788: 9, 1789: 9, 1790: 9, 1791: 9, 1792: 9, 1793: 9, 1794: 9, 1795: 9, 1796: 9, 1797: 9, 1798: 9, 1799: 9, 1800: 9, 1801: 9, 1802: 9, 1803: 9, 1804: 9, 1805: 9, 1806: 9, 1807: 9, 1808: 9, 1809: 9, 1810: 9, 1811: 9, 1812: 9, 1813: 9, 1814: 9, 1815: 9, 1816: 9, 1817: 9, 1818: 9, 1819: 9, 1820: 9, 1821: 9, 1822: 9, 1823: 9, 1824: 9, 1825: 9, 1826: 9, 1827: 9, 1828: 9, 1829: 9, 1830: 9, 1831: 9, 1832: 9, 1833: 9, 1834: 9, 1835: 9, 1836: 9, 1837: 9, 1838: 9, 1839: 9, 1840: 9, 1841: 9, 1842: 9, 1843: 9, 1844: 9, 1845: 9, 1846: 9, 1847: 9, 1848: 9, 1849: 9, 1850: 9, 1851: 9, 1852: 9, 1853: 9, 1854: 9, 1855: 9, 1856: 9, 1857: 9, 1858: 9, 1859: 9, 1860: 9, 1861: 9, 1862: 9, 1863: 9, 1864: 9, 1865: 9, 1866: 9, 1867: 9, 1868: 9, 1869: 9, 1870: 9, 1871: 9, 1872: 9, 1873: 9, 1874: 9, 1875: 9, 1876: 9, 1877: 9, 1878: 9, 1879: 9, 1880: 9, 1881: 9, 1882: 9, 1883: 9, 1884: 9, 1885: 9, 1886: 9, 1887: 9, 1888: 9, 1889: 9, 1890: 9, 1891: 9, 1892: 9, 1893: 9, 1894: 9, 1895: 9, 1896: 9, 1897: 9, 1898: 9, 1899: 9, 1900: 9, 1901: 9, 1902: 9, 1903: 9, 1904: 9, 1905: 9, 1906: 9, 1907: 9, 1908: 9, 1909: 9, 1910: 9, 1911: 9, 1912: 9, 1913: 9, 1914: 9, 1915: 9, 1916: 9, 1917: 9, 1918: 9, 1919: 9, 1920: 9, 1921: 9, 1922: 9, 1923: 9, 1924: 9, 1925: 9, 1926: 9, 1927: 9, 1928: 9, 1929: 9, 1930: 9, 1931: 9, 1932: 9, 1933: 9, 1934: 9, 1935: 9, 1936: 9, 1937: 9, 1938: 9, 1939: 9, 1940: 9, 1941: 9, 1942: 9, 1943: 9, 1944: 9, 1945: 9, 1946: 9, 1947: 9, 1948: 9, 1949: 9, 1950: 9, 1951: 9, 1952: 9, 1953: 9, 1954: 9, 1955: 9, 1956: 9, 1957: 9, 1958: 9, 1959: 9, 1960: 9, 1961: 9, 1962: 9, 1963: 9, 1964: 9, 1965: 9, 1966: 9, 1967: 9, 1968: 9, 1969: 9, 1970: 9, 1971: 9, 1972: 9, 1973: 9, 1974: 9, 1975: 9, 1976: 9, 1977: 9, 1978: 9, 1979: 9, 1980: 9, 1981: 9, 1982: 9, 1983: 9, 1984: 9, 1985: 9, 1986: 9, 1987: 9, 1988: 9, 1989: 9, 1990: 9, 1991: 9, 1992: 9, 1993: 9, 1994: 9, 1995: 9, 1996: 9, 1997: 9, 1998: 9, 1999: 9, 2000: 9, 2001: 9, 2002: 9, 2003: 9, 2004: 9, 2005: 9, 2006: 9, 2007: 9, 2008: 9, 2009: 9, 2010: 9, 2011: 9, 2012: 9, 2013: 9, 2014: 9, 2015: 9, 2016: 9, 2017: 9, 2018: 9, 2019: 9, 2020: 9, 2021: 9, 2022: 9, 2023: 9, 2024: 9, 2025: 9, 2026: 9, 2027: 9, 2028: 9, 2029: 9, 2030: 9, 2031: 9, 2032: 9, 2033: 9, 2034: 9, 2035: 9, 2036: 9, 2037: 9, 2038: 9, 2039: 9, 2040: 9, 2041: 9, 2042: 9, 2043: 9, 2044: 9, 2045: 9, 2046: 9, 2047: 9, 2048: 9, 2049: 9, 2050: 9, 2051: 9, 2052: 9, 2053: 9, 2054: 9, 2055: 9, 2056: 9, 2057: 9, 2058: 9, 2059: 9, 2060: 9, 2061: 9, 2062: 9, 2063: 9, 2064: 9, 2065: 9, 2066: 9, 2067: 9, 2068: 9, 2069: 9, 2070: 9, 2071: 9, 2072: 9, 2073: 9, 2074: 9, 2075: 9, 2076: 9, 2077: 9, 2078: 9, 2079: 9, 2080: 9, 2081: 9, 2082: 9, 2083: 9, 2084: 9, 2085: 9, 2086: 9, 2087: 9, 2088: 9, 2089: 9, 2090: 9, 2091: 9, 2092: 9, 2093: 9, 2094: 9, 2095: 9, 2096: 9, 2097: 9, 2098: 9, 2099: 9, 2100: 9, 2101: 9, 2102: 9, 2103: 9, 2104: 9, 2105: 9, 2106: 9, 2107: 9, 2108: 9, 2109: 9, 2110: 9, 2111: 9, 2112: 9, 2113: 9, 2114: 9, 2115: 9, 2116: 9, 2117: 9, 2118: 9, 2119: 9, 2120: 9, 2121: 9, 2122: 9, 2123: 9, 2124: 9, 2125: 9, 2126: 9, 2127: 9, 2128: 9, 2129: 9, 2130: 9, 2131: 9, 2132: 9, 2133: 9, 2134: 9, 2135: 9, 2136: 9, 2137: 9, 2138: 9, 2139: 9, 2140: 9, 2141: 9, 2142: 9, 2143: 9, 2144: 9, 2145: 9, 2146: 9, 2147: 9, 2148: 9, 2149: 9, 2150: 9, 2151: 9, 2152: 9, 2153: 9, 2154: 9, 2155: 9, 2156: 9, 2157: 9, 2158: 9, 2159: 9, 2160: 9, 2161: 9, 2162: 9, 2163: 9, 2164: 9, 2165: 9, 2166: 9, 2167: 9, 2168: 9, 2169: 9, 2170: 9, 2171: 9, 2172: 9, 2173: 9, 2174: 9, 2175: 9, 2176: 9, 2177: 9, 2178: 9, 2179: 9, 2180: 9, 2181: 9, 2182: 9, 2183: 9, 2184: 9, 2185: 9, 2186: 9, 2187: 9, 2188: 9, 2189: 9, 2190: 9, 2191: 9, 2192: 9, 2193: 9, 2194: 9, 2195: 9, 2196: 9, 2197: 9, 2198: 9, 2199: 9, 2200: 9, 2201: 9, 2202: 9, 2203: 9, 2204: 9, 2205: 9, 2206: 9, 2207: 9, 2208: 9, 2209: 9, 2210: 9, 2211: 9, 2212: 9, 2213: 9, 2214: 9, 2215: 9, 2216: 9, 2217: 9, 2218: 9, 2219: 9, 2220: 9, 2221: 9, 2222: 9, 2223: 9, 2224: 9, 2225: 9, 2226: 9, 2227: 9, 2228: 9, 2229: 9, 2230: 9, 2231: 9, 2232: 9, 2233: 9, 2234: 9, 2235: 9, 2236: 9, 2237: 9, 2238: 9, 2239: 9, 2240: 9, 2241: 9, 2242: 9, 2243: 9, 2244: 9, 2245: 9, 2246: 9, 2247: 9, 2248: 9, 2249: 9, 2250: 9, 2251: 9, 2252: 9, 2253: 9, 2254: 9, 2255: 9, 2256: 9, 2257: 9, 2258: 9, 2259: 9, 2260: 9, 2261: 9, 2262: 9, 2263: 9, 2264: 9, 2265: 9, 2266: 9, 2267: 9, 2268: 9, 2269: 9, 2270: 9, 2271: 9, 2272: 9, 2273: 9, 2274: 9, 2275: 9, 2276: 9, 2277: 9, 2278: 9, 2279: 9, 2280: 9, 2281: 9, 2282: 9, 2283: 9, 2284: 9, 2285: 9, 2286: 9, 2287: 9, 2288: 9, 2289: 9, 2290: 9, 2291: 9, 2292: 9, 2293: 9, 2294: 9, 2295: 9, 2296: 9, 2297: 9, 2298: 9, 2299: 9, 2300: 9, 2301: 9, 2302: 9, 2303: 9, 2304: 9, 2305: 9, 2306: 9, 2307: 9, 2308: 9, 2309: 9, 2310: 9, 2311: 9, 2312: 9, 2313: 9, 2314: 9, 2315: 9, 2316: 9, 2317: 9, 2318: 9, 2319: 9, 2320: 9, 2321: 9, 2322: 9, 2323: 9, 2324: 9, 2325: 9, 2326: 9, 2327: 9, 2328: 9, 2329: 9, 2330: 9, 2331: 9, 2332: 9, 2333: 9, 2334: 9, 2335: 9, 2336: 9, 2337: 9, 2338: 9, 2339: 9, 2340: 9, 2341: 9, 2342: 9, 2343: 9, 2344: 9, 2345: 9, 2346: 9, 2347: 9, 2348: 9, 2349: 9, 2350: 9, 2351: 9, 2352: 9, 2353: 9, 2354: 9, 2355: 9, 2356: 9, 2357: 9, 2358: 9, 2359: 9, 2360: 9, 2361: 9, 2362: 9, 2363: 9, 2364: 9, 2365: 9, 2366: 9, 2367: 9, 2368: 9, 2369: 9, 2370: 9, 2371: 9, 2372: 9, 2373: 9, 2374: 9, 2375: 9, 2376: 9, 2377: 9, 2378: 9, 2379: 9, 2380: 9, 2381: 9, 2382: 9, 2383: 9, 2384: 9, 2385: 9, 2386: 9, 2387: 9, 2388: 9, 2389: 9, 2390: 9, 2391: 9, 2392: 9, 2393: 9, 2394: 9, 2395: 9, 2396: 9, 2397: 9, 2398: 9, 2399: 9, 2400: 9, 2401: 9, 2402: 9, 2403: 9, 2404: 9, 2405: 9, 2406: 9, 2407: 9, 2408: 9, 2409: 9, 2410: 9, 2411: 9, 2412: 9, 2413: 9, 2414: 9, 2415: 9, 2416: 9, 2417: 9, 2418: 9, 2419: 9, 2420: 9, 2421: 9, 2422: 9, 2423: 9, 2424: 9, 2425: 9, 2426: 9, 2427: 9, 2428: 9, 2429: 9, 2430: 9, 2431: 9, 2432: 9, 2433: 9, 2434: 9, 2435: 9, 2436: 9, 2437: 9, 2438: 9, 2439: 9, 2440: 9, 2441: 9, 2442: 9, 2443: 9, 2444: 9, 2445: 9, 2446: 9, 2447: 9, 2448: 9, 2449: 9, 2450: 9, 2451: 9, 2452: 9, 2453: 9, 2454: 9, 2455: 9, 2456: 9, 2457: 9, 2458: 9, 2459: 9, 2460: 9, 2461: 9, 2462: 9, 2463: 9, 2464: 9, 2465: 9, 2466: 9, 2467: 9, 2468: 9, 2469: 9, 2470: 9, 2471: 9, 2472: 9, 2473: 9, 2474: 9, 2475: 9, 2476: 9, 2477: 9, 2478: 9, 2479: 9, 2480: 9, 2481: 9, 2482: 9, 2483: 9, 2484: 9, 2485: 9, 2486: 9, 2487: 9, 2488: 9, 2489: 9, 2490: 9, 2491: 9, 2492: 9, 2493: 9, 2494: 9, 2495: 9, 2496: 9, 2497: 9, 2498: 9, 2499: 9, 2500: 9, 2501: 9, 2502: 9, 2503: 9, 2504: 9, 2505: 9, 2506: 9, 2507: 9, 2508: 9, 2509: 9, 2510: 9, 2511: 9, 2512: 9, 2513: 9, 2514: 9, 2515: 9, 2516: 9, 2517: 9, 2518: 9, 2519: 9, 2520: 9, 2521: 9, 2522: 9, 2523: 9, 2524: 9, 2525: 9, 2526: 9, 2527: 9, 2528: 9, 2529: 9, 2530: 9, 2531: 9, 2532: 9, 2533: 9, 2534: 9, 2535: 9, 2536: 9, 2537: 9, 2538: 9, 2539: 9, 2540: 9, 2541: 9, 2542: 9, 2543: 9, 2544: 9, 2545: 9, 2546: 9, 2547: 9, 2548: 9, 2549: 9, 2550: 9, 2551: 9, 2552: 9, 2553: 9, 2554: 9, 2555: 9, 2556: 9, 2557: 9, 2558: 9, 2559: 9, 2560: 9, 2561: 9, 2562: 9, 2563: 9, 2564: 9, 2565: 9, 2566: 9, 2567: 9, 2568: 9, 2569: 9, 2570: 9, 2571: 9, 2572: 9, 2573: 9, 2574: 9, 2575: 9, 2576: 9, 2577: 9, 2578: 9, 2579: 9, 2580: 9, 2581: 9, 2582: 9, 2583: 9, 2584: 9, 2585: 9, 2586: 9, 2587: 9, 2588: 9, 2589: 9, 2590: 9, 2591: 9, 2592: 9, 2593: 9, 2594: 9, 2595: 9, 2596: 9, 2597: 9, 2598: 9, 2599: 9, 2600: 9, 2601: 9, 2602: 9, 2603: 9, 2604: 9, 2605: 9, 2606: 9, 2607: 9, 2608: 9, 2609: 9, 2610: 9, 2611: 9, 2612: 9, 2613: 9, 2614: 9, 2615: 9, 2616: 9, 2617: 9, 2618: 9, 2619: 9, 2620: 9, 2621: 9, 2622: 9, 2623: 9, 2624: 9, 2625: 9, 2626: 9, 2627: 9, 2628: 9, 2629: 9, 2630: 9, 2631: 9, 2632: 9, 2633: 9, 2634: 9, 2635: 9, 2636: 9, 2637: 9, 2638: 9, 2639: 9, 2640: 9, 2641: 9, 2642: 9, 2643: 9, 2644: 9, 2645: 9, 2646: 9, 2647: 9, 2648: 9, 2649: 9, 2650: 9, 2651: 9, 2652: 9, 2653: 9, 2654: 9, 2655: 9, 2656: 9, 2657: 9, 2658: 9, 2659: 9, 2660: 9, 2661: 9, 2662: 9, 2663: 9, 2664: 9, 2665: 9, 2666: 9, 2667: 9, 2668: 9, 2669: 9, 2670: 9, 2671: 9, 2672: 9, 2673: 9, 2674: 9, 2675: 9, 2676: 9, 2677: 9, 2678: 9, 2679: 9, 2680: 9, 2681: 9, 2682: 9, 2683: 9, 2684: 9, 2685: 9, 2686: 9, 2687: 9, 2688: 9, 2689: 9, 2690: 9, 2691: 9, 2692: 9, 2693: 9, 2694: 9, 2695: 9, 2696: 9, 2697: 9, 2698: 9, 2699: 9, 2700: 9, 2701: 9, 2702: 9, 2703: 9, 2704: 9, 2705: 9, 2706: 9, 2707: 9, 2708: 9, 2709: 9, 2710: 9, 2711: 9, 2712: 9, 2713: 9, 2714: 9, 2715: 9, 2716: 9, 2717: 9, 2718: 9, 2719: 9, 2720: 9, 2721: 9, 2722: 9, 2723: 9, 2724: 9, 2725: 9, 2726: 9, 2727: 9, 2728: 9, 2729: 9, 2730: 9, 2731: 9, 2732: 9, 2733: 9, 2734: 9, 2735: 9, 2736: 9, 2737: 9, 2738: 9, 2739: 9, 2740: 9, 2741: 9, 2742: 9, 2743: 9, 2744: 9, 2745: 9, 2746: 9, 2747: 9, 2748: 9, 2749: 9, 2750: 9, 2751: 9, 2752: 9, 2753: 9, 2754: 9, 2755: 9, 2756: 9, 2757: 9, 2758: 9, 2759: 9, 2760: 9, 2761: 9, 2762: 9, 2763: 9, 2764: 9, 2765: 9, 2766: 9, 2767: 9, 2768: 9, 2769: 9, 2770: 9, 2771: 9, 2772: 9, 2773: 9, 2774: 9, 2775: 9, 2776: 9, 2777: 9, 2778: 9, 2779: 9, 2780: 9, 2781: 9, 2782: 9, 2783: 9, 2784: 9, 2785: 9, 2786: 9, 2787: 9, 2788: 9, 2789: 9, 2790: 9, 2791: 9, 2792: 9, 2793: 9, 2794: 9, 2795: 9, 2796: 9, 2797: 9, 2798: 9, 2799: 9, 2800: 9, 2801: 9, 2802: 9, 2803: 9, 2804: 9, 2805: 9, 2806: 9, 2807: 9, 2808: 9, 2809: 9, 2810: 9, 2811: 9, 2812: 9, 2813: 9, 2814: 9, 2815: 9, 2816: 9, 2817: 9, 2818: 9, 2819: 9, 2820: 9, 2821: 9, 2822: 9, 2823: 9, 2824: 9, 2825: 9, 2826: 9, 2827: 9, 2828: 9, 2829: 9, 2830: 9, 2831: 9, 2832: 9, 2833: 9, 2834: 9, 2835: 9, 2836: 9, 2837: 9, 2838: 9, 2839: 9, 2840: 9, 2841: 9, 2842: 9, 2843: 9, 2844: 9, 2845: 9, 2846: 9, 2847: 9, 2848: 9, 2849: 9, 2850: 9, 2851: 9, 2852: 9, 2853: 9, 2854: 9, 2855: 9, 2856: 9, 2857: 9, 2858: 9, 2859: 9, 2860: 9, 2861: 9, 2862: 9, 2863: 9, 2864: 9, 2865: 9, 2866: 9, 2867: 9, 2868: 9, 2869: 9, 2870: 9, 2871: 9, 2872: 9, 2873: 9, 2874: 9, 2875: 9, 2876: 9, 2877: 9, 2878: 9, 2879: 9, 2880: 9, 2881: 9, 2882: 9, 2883: 9, 2884: 9, 2885: 9, 2886: 9, 2887: 9, 2888: 9, 2889: 9, 2890: 9, 2891: 9, 2892: 9, 2893: 9, 2894: 9, 2895: 9, 2896: 9, 2897: 9, 2898: 9, 2899: 9, 2900: 9, 2901: 9, 2902: 9, 2903: 9, 2904: 9, 2905: 9, 2906: 9, 2907: 9, 2908: 9, 2909: 9, 2910: 9, 2911: 9, 2912: 9, 2913: 9, 2914: 9, 2915: 9, 2916: 9, 2917: 9, 2918: 9, 2919: 9, 2920: 9, 2921: 9, 2922: 9, 2923: 9, 2924: 9, 2925: 9, 2926: 9, 2927: 9, 2928: 9, 2929: 9, 2930: 9, 2931: 9, 2932: 9, 2933: 9, 2934: 9, 2935: 9, 2936: 9, 2937: 9, 2938: 9, 2939: 9, 2940: 9, 2941: 9, 2942: 9, 2943: 9, 2944: 9, 2945: 9, 2946: 9, 2947: 9, 2948: 9, 2949: 9, 2950: 9, 2951: 9, 2952: 9, 2953: 9, 2954: 9, 2955: 9, 2956: 9, 2957: 9, 2958: 9, 2959: 9, 2960: 9, 2961: 9, 2962: 9, 2963: 9, 2964: 9, 2965: 9, 2966: 9, 2967: 9, 2968: 9, 2969: 9, 2970: 9, 2971: 9, 2972: 9, 2973: 9, 2974: 9, 2975: 9, 2976: 9, 2977: 9, 2978: 9, 2979: 9, 2980: 9, 2981: 9, 2982: 9, 2983: 9, 2984: 9, 2985: 9, 2986: 9, 2987: 9, 2988: 9, 2989: 9, 2990: 9, 2991: 9, 2992: 9, 2993: 9, 2994: 9, 2995: 9, 2996: 9, 2997: 9, 2998: 9, 2999: 9, 3000: 9, 3001: 9, 3002: 9, 3003: 9, 3004: 9, 3005: 9, 3006: 9, 3007: 9, 3008: 9, 3009: 9, 3010: 9, 3011: 9, 3012: 9, 3013: 9, 3014: 9, 3015: 9, 3016: 9, 3017: 9, 3018: 9, 3019: 9, 3020: 9, 3021: 9, 3022: 9, 3023: 9, 3024: 9, 3025: 9, 3026: 9, 3027: 9, 3028: 9, 3029: 9, 3030: 9, 3031: 9, 3032: 9, 3033: 9, 3034: 9, 3035: 9, 3036: 9, 3037: 9, 3038: 9, 3039: 9, 3040: 9, 3041: 9, 3042: 9, 3043: 9, 3044: 9, 3045: 9, 3046: 9, 3047: 9, 3048: 9, 3049: 9, 3050: 9, 3051: 9, 3052: 9, 3053: 9, 3054: 9, 3055: 9, 3056: 9, 3057: 9, 3058: 9, 3059: 9, 3060: 9, 3061: 9, 3062: 9, 3063: 9, 3064: 9, 3065: 9, 3066: 9, 3067: 9, 3068: 9, 3069: 9, 3070: 9, 3071: 9, 3072: 9, 3073: 9, 3074: 9, 3075: 9, 3076: 9, 3077: 9, 3078: 9, 3079: 9, 3080: 9, 3081: 9, 3082: 9, 3083: 9, 3084: 9, 3085: 9, 3086: 9, 3087: 9, 3088: 9, 3089: 9, 3090: 9, 3091: 9, 3092: 9, 3093: 9, 3094: 9, 3095: 9, 3096: 9, 3097: 9, 3098: 9, 3099: 9, 3100: 9, 3101: 9, 3102: 9 ~= num clips 9
[05/01 09:39:40][INFO] logging.py:  99: json_stats: {"split": "test_final", "top1_acc": "0.00", "top5_acc": "0.00"}
[05/04 16:16:23][INFO] test_net_gamma.py: 157: Test with config:
[05/04 16:16:24][INFO] test_net_gamma.py: 158: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  INTERPOLATION: bicubic
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: True
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: decord
  ENSEMBLE_METHOD: sum
  FRAME_PATH: 
  IMAGE_TEMPLATE: {:05d}.jpg
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  LABEL_PATH_TEMPLATE: somesomev1_rgb_{}_split.txt
  MC: True
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  PSEUDO_CSV: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 3
  SPECIAL_LABEL_LIST: [5, 9]
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
EVL:
  ADD_RESIDUAL: False
  AFTER_ME: False
  BACKBONE: vit_b16
  BEFORE_ME: False
  CLS_DROPOUT: 0.5
  FIRST_N: 0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  MLP_FACTOR: 4.0
  N_DIM: 768
  N_HEAD: 12
  N_LAYERS: 4
  SHIFT_INIT: False
  SPATAIL_SIZE: 14
  USE_IMAGE_ATTNMAP: True
  USE_T_CONV: True
  USE_T_POS_EMBED: True
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: True
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  CHECKPOINT_NUM: [0, 0, 0, 0]
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 11
  PSEUDO_LOSS_FUNC: 
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'uniformer', 'vip', 'swin', 'sf', 'evl']
  SOFT_T: 1
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: None
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[2, 1, 2, 2], [5, 1, 2, 2], [21, 1, 2, 2]]
  QKV_BIAS: True
  SEP_POS_EMBED: True
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 2
NUM_SHARDS: 1
OUTPUT_DIR: ./exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 6666
SF:
  DROPOUT_RATE: 0.3
  FROZEN_BN: False
  NONLOCAL:
    FROZEN_BN: False
  PRETRAIN_NAME: SlowFast-ResNet101-8x8
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRADIENT: 20
  CLIP_GRAD_L2NORM: 1.0
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-06
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 40
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 10.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.03
  ZERO_WD_1D_PARAM: True
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 64
  CHECKPOINT_FILE_PATH: /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  DATA_SELECT: real_unlabel
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 3
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
  TEST_BEST: True
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ug2_sparse
  ENABLE: False
  EVAL_PERIOD: 1
  SAVE_LATEST: False
  THRESHOLD: 2
UNIFORMER:
  ADD_MLP: True
  ATTENTION_DROPOUT_RATE: 0
  DEPTH: [3, 4, 8, 3]
  DPE: True
  DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIM: [64, 128, 320, 512]
  HEAD_DIM: 64
  KS: 5
  MBCONV: False
  MLP_RATIO: 4
  NUM_HEADS: [1, 2, 5, 8]
  PRETRAIN_NAME: None
  PRUNE_RATIO: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
  QKV_BIAS: True
  QKV_SCALE: None
  RATIO: 1
  REPRESENTATION_SIZE: None
  SPLIT: False
  STAGE_TYPE: [0, 0, 1, 1]
  STD: False
  TAU: 3
  TRADE_OFF: [[], [], [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]
VIP:
  ATTENTION_DROPOUT_RATE: 0
  DROP_DEPTH_RATE: 0.1
  EMBED_DIMS: [192, 384, 384, 384]
  LAYERS: [4, 3, 8, 3]
  MLP_RATIOS: [3, 3, 3, 3]
  PATCH_SIZE: 7
  PRETRAIN_NAME: None
  QKV_BIAS: True
  QKV_SCALE: None
  SEGMENT_DIM: [32, 16, 16, 16]
  ST_TYPE: st_skip
  TRANSITIONS: [True, False, False, False]
  T_STRIDE: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/04 16:16:27][INFO] checkpoint.py: 223: Loading network weights from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/exp_pseudo_arid_stage4/mvit_b32_k600_dp0.3_ce/dark/best.pyth.
[05/04 16:17:08][INFO] ug2_sparse.py:  90: Constructing Ug2 real_unlabel...
[05/04 16:17:08][INFO] ug2_sparse.py:  91: Number of clips 9
[05/04 16:17:08][INFO] ug2_sparse.py: 203: Constructing Ug2 dataloader (size: 83655) from /mnt/lustre/likunchang.vendor/sjj/ug2_uniformer_competition/data/real+arid_unlabel.csv
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/04 16:17:15][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/04 16:17:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/04 16:17:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/04 16:17:15][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/04 16:17:15][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f5f29630f80>
[05/04 16:17:16][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/04 16:17:16][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f5f30036560>
[05/04 16:17:16][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f601400eb90>
[05/04 16:17:16][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f5f30036320>
[05/04 16:17:16][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/04 16:17:16][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/04 16:17:16][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/04 16:17:16][DEBUG] factory.py:  66: Loading s3:s3
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/04 16:17:16][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/04 16:17:16][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/04 16:17:16][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/04 16:17:16][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f5f29630f80>
[05/04 16:17:16][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/04 16:17:16][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f5f30036560>
[05/04 16:17:16][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f5f28e04710>
[05/04 16:17:16][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f5f30036320>
[05/04 16:17:16][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/04 16:17:16][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/04 16:17:16][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/04 16:17:16][DEBUG] factory.py:  66: Loading s3:s3
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/04 16:17:16][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/04 16:17:17][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f5f29630f80>
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f5f30036560>
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f5f28737440>
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f5f30036320>
[05/04 16:17:17][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/04 16:17:17][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/04 16:17:17][DEBUG] factory.py:  66: Loading s3:s3
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/04 16:17:17][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f5f29630f80>
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f5f30036560>
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f5f280df4d0>
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f5f30036320>
[05/04 16:17:17][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/04 16:17:17][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/04 16:17:17][DEBUG] factory.py:  66: Loading s3:s3
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/04 16:17:17][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f5f29630f80>
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f5f30036560>
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f5f219e1560>
[05/04 16:17:17][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f5f30036320>
[05/04 16:17:17][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/04 16:17:17][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/04 16:17:17][DEBUG] factory.py:  66: Loading s3:s3
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-call.apigateway to before-call.api-gateway
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.route53 to before-parameter-build.route-53
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search
[05/04 16:17:17][DEBUG] hooks.py: 422: Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/lustre/likunchang.vendor/.local/lib/python3.7/site-packages/boto3/data/s3/2006-03-01/resources-1.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/endpoints.json
[05/04 16:17:17][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/sdk-default-configuration.json
[05/04 16:17:17][DEBUG] hooks.py: 211: Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f5f29630f80>
[05/04 16:17:18][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/s3/2006-03-01/service-2.json
[05/04 16:17:18][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f5f30036560>
[05/04 16:17:18][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f5f2130b5f0>
[05/04 16:17:18][DEBUG] hooks.py: 211: Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f5f30036320>
[05/04 16:17:18][DEBUG] endpoint.py: 345: Setting s3 timeout as (60, 60)
[05/04 16:17:18][DEBUG] loaders.py: 173: Loading JSON file: /mnt/cache/likunchang.vendor/.conda/envs/torch1.9/lib/python3.7/site-packages/botocore/data/_retry.json
[05/04 16:17:18][DEBUG] client.py: 207: Registering retry handlers for service: s3
[05/04 16:17:18][DEBUG] factory.py:  66: Loading s3:s3
[05/04 16:17:18][INFO] test_net_gamma.py: 169: Testing model for 1308 iterations
[05/04 16:20:11][INFO] logging.py:  99: json_stats: {"cur_iter": "1", "eta": "2 days, 15:03:04", "split": "test_iter", "time_diff": 173.53526}
[05/04 16:20:12][INFO] logging.py:  99: json_stats: {"cur_iter": "2", "eta": "0:18:34", "split": "test_iter", "time_diff": 0.85239}
[05/04 16:20:13][INFO] logging.py:  99: json_stats: {"cur_iter": "3", "eta": "0:21:39", "split": "test_iter", "time_diff": 0.99470}
[05/04 16:20:14][INFO] logging.py:  99: json_stats: {"cur_iter": "4", "eta": "0:18:42", "split": "test_iter", "time_diff": 0.86010}
[05/04 16:20:15][INFO] logging.py:  99: json_stats: {"cur_iter": "5", "eta": "0:21:36", "split": "test_iter", "time_diff": 0.99433}
[05/04 16:20:16][INFO] logging.py:  99: json_stats: {"cur_iter": "6", "eta": "0:20:24", "split": "test_iter", "time_diff": 0.93942}
[05/04 16:20:17][INFO] logging.py:  99: json_stats: {"cur_iter": "7", "eta": "0:21:37", "split": "test_iter", "time_diff": 0.99657}
[05/04 16:20:18][INFO] logging.py:  99: json_stats: {"cur_iter": "8", "eta": "0:21:40", "split": "test_iter", "time_diff": 0.99937}
[05/04 16:20:19][INFO] logging.py:  99: json_stats: {"cur_iter": "9", "eta": "0:22:30", "split": "test_iter", "time_diff": 1.03850}
[05/04 16:20:20][INFO] logging.py:  99: json_stats: {"cur_iter": "10", "eta": "0:23:17", "split": "test_iter", "time_diff": 1.07573}
[05/04 16:20:21][INFO] logging.py:  99: json_stats: {"cur_iter": "11", "eta": "0:22:10", "split": "test_iter", "time_diff": 1.02533}
[05/04 16:20:22][INFO] logging.py:  99: json_stats: {"cur_iter": "12", "eta": "0:18:22", "split": "test_iter", "time_diff": 0.84988}
[05/04 16:20:23][INFO] logging.py:  99: json_stats: {"cur_iter": "13", "eta": "0:20:39", "split": "test_iter", "time_diff": 0.95625}
[05/04 16:20:24][INFO] logging.py:  99: json_stats: {"cur_iter": "14", "eta": "0:21:59", "split": "test_iter", "time_diff": 1.01877}
[05/04 16:20:25][INFO] logging.py:  99: json_stats: {"cur_iter": "15", "eta": "0:22:03", "split": "test_iter", "time_diff": 1.02249}
[05/04 16:20:26][INFO] logging.py:  99: json_stats: {"cur_iter": "16", "eta": "0:22:15", "split": "test_iter", "time_diff": 1.03262}
[05/04 16:20:27][INFO] logging.py:  99: json_stats: {"cur_iter": "17", "eta": "0:21:55", "split": "test_iter", "time_diff": 1.01848}
[05/04 16:20:28][INFO] logging.py:  99: json_stats: {"cur_iter": "18", "eta": "0:21:50", "split": "test_iter", "time_diff": 1.01518}
[05/04 16:20:29][INFO] logging.py:  99: json_stats: {"cur_iter": "19", "eta": "0:18:51", "split": "test_iter", "time_diff": 0.87714}
[05/04 16:20:30][INFO] logging.py:  99: json_stats: {"cur_iter": "20", "eta": "0:18:45", "split": "test_iter", "time_diff": 0.87320}
[05/04 16:20:31][INFO] logging.py:  99: json_stats: {"cur_iter": "21", "eta": "0:21:13", "split": "test_iter", "time_diff": 0.98850}
[05/04 16:20:32][INFO] logging.py:  99: json_stats: {"cur_iter": "22", "eta": "0:19:05", "split": "test_iter", "time_diff": 0.89001}
[05/04 16:20:33][INFO] logging.py:  99: json_stats: {"cur_iter": "23", "eta": "0:20:24", "split": "test_iter", "time_diff": 0.95205}
[05/04 16:20:34][INFO] logging.py:  99: json_stats: {"cur_iter": "24", "eta": "0:21:24", "split": "test_iter", "time_diff": 0.99964}
[05/04 16:20:35][INFO] logging.py:  99: json_stats: {"cur_iter": "25", "eta": "0:21:03", "split": "test_iter", "time_diff": 0.98415}
[05/04 16:20:36][INFO] logging.py:  99: json_stats: {"cur_iter": "26", "eta": "0:20:37", "split": "test_iter", "time_diff": 0.96416}
[05/04 16:20:37][INFO] logging.py:  99: json_stats: {"cur_iter": "27", "eta": "0:21:09", "split": "test_iter", "time_diff": 0.99026}
[05/04 16:20:38][INFO] logging.py:  99: json_stats: {"cur_iter": "28", "eta": "0:18:35", "split": "test_iter", "time_diff": 0.87091}
[05/04 16:20:39][INFO] logging.py:  99: json_stats: {"cur_iter": "29", "eta": "0:21:51", "split": "test_iter", "time_diff": 1.02495}
[05/04 16:20:40][INFO] logging.py:  99: json_stats: {"cur_iter": "30", "eta": "0:20:51", "split": "test_iter", "time_diff": 0.97877}
[05/04 16:20:41][INFO] logging.py:  99: json_stats: {"cur_iter": "31", "eta": "0:21:02", "split": "test_iter", "time_diff": 0.98764}
[05/04 16:20:42][INFO] logging.py:  99: json_stats: {"cur_iter": "32", "eta": "0:20:28", "split": "test_iter", "time_diff": 0.96190}
[05/04 16:20:43][INFO] logging.py:  99: json_stats: {"cur_iter": "33", "eta": "0:24:51", "split": "test_iter", "time_diff": 1.16855}
[05/04 16:20:44][INFO] logging.py:  99: json_stats: {"cur_iter": "34", "eta": "0:21:36", "split": "test_iter", "time_diff": 1.01670}
[05/04 16:20:45][INFO] logging.py:  99: json_stats: {"cur_iter": "35", "eta": "0:21:03", "split": "test_iter", "time_diff": 0.99175}
[05/04 16:20:46][INFO] logging.py:  99: json_stats: {"cur_iter": "36", "eta": "0:21:13", "split": "test_iter", "time_diff": 1.00010}
[05/04 16:20:47][INFO] logging.py:  99: json_stats: {"cur_iter": "37", "eta": "0:21:22", "split": "test_iter", "time_diff": 1.00836}
[05/04 16:20:48][INFO] logging.py:  99: json_stats: {"cur_iter": "38", "eta": "0:20:55", "split": "test_iter", "time_diff": 0.98792}
[05/04 16:20:49][INFO] logging.py:  99: json_stats: {"cur_iter": "39", "eta": "0:21:05", "split": "test_iter", "time_diff": 0.99613}
[05/04 16:20:50][INFO] logging.py:  99: json_stats: {"cur_iter": "40", "eta": "0:18:22", "split": "test_iter", "time_diff": 0.86878}
[05/04 16:20:52][INFO] logging.py:  99: json_stats: {"cur_iter": "41", "eta": "0:28:25", "split": "test_iter", "time_diff": 1.34510}
[05/04 16:20:53][INFO] logging.py:  99: json_stats: {"cur_iter": "42", "eta": "0:23:33", "split": "test_iter", "time_diff": 1.11525}
[05/04 16:20:54][INFO] logging.py:  99: json_stats: {"cur_iter": "43", "eta": "0:21:30", "split": "test_iter", "time_diff": 1.01920}
[05/04 16:20:55][INFO] logging.py:  99: json_stats: {"cur_iter": "44", "eta": "0:21:07", "split": "test_iter", "time_diff": 1.00195}
[05/04 16:20:56][INFO] logging.py:  99: json_stats: {"cur_iter": "45", "eta": "0:18:00", "split": "test_iter", "time_diff": 0.85470}
[05/04 16:20:57][INFO] logging.py:  99: json_stats: {"cur_iter": "46", "eta": "0:18:09", "split": "test_iter", "time_diff": 0.86242}
[05/04 16:20:58][INFO] logging.py:  99: json_stats: {"cur_iter": "47", "eta": "0:22:03", "split": "test_iter", "time_diff": 1.04839}
[05/04 16:20:59][INFO] logging.py:  99: json_stats: {"cur_iter": "48", "eta": "0:21:18", "split": "test_iter", "time_diff": 1.01422}
[05/04 16:21:00][INFO] logging.py:  99: json_stats: {"cur_iter": "49", "eta": "0:32:46", "split": "test_iter", "time_diff": 1.56077}
[05/04 16:21:01][INFO] logging.py:  99: json_stats: {"cur_iter": "50", "eta": "0:21:08", "split": "test_iter", "time_diff": 1.00758}
[05/04 16:21:02][INFO] logging.py:  99: json_stats: {"cur_iter": "51", "eta": "0:21:00", "split": "test_iter", "time_diff": 1.00230}
[05/04 16:21:03][INFO] logging.py:  99: json_stats: {"cur_iter": "52", "eta": "0:20:57", "split": "test_iter", "time_diff": 1.00005}
[05/04 16:21:04][INFO] logging.py:  99: json_stats: {"cur_iter": "53", "eta": "0:18:33", "split": "test_iter", "time_diff": 0.88669}
[05/04 16:21:05][INFO] logging.py:  99: json_stats: {"cur_iter": "54", "eta": "0:17:52", "split": "test_iter", "time_diff": 0.85470}
[05/04 16:21:06][INFO] logging.py:  99: json_stats: {"cur_iter": "55", "eta": "0:18:22", "split": "test_iter", "time_diff": 0.87892}
[05/04 16:21:07][INFO] logging.py:  99: json_stats: {"cur_iter": "56", "eta": "0:19:56", "split": "test_iter", "time_diff": 0.95476}
[05/04 16:21:09][INFO] logging.py:  99: json_stats: {"cur_iter": "57", "eta": "0:26:46", "split": "test_iter", "time_diff": 1.28276}
[05/04 16:21:09][INFO] logging.py:  99: json_stats: {"cur_iter": "58", "eta": "0:20:05", "split": "test_iter", "time_diff": 0.96334}
[05/04 16:21:10][INFO] logging.py:  99: json_stats: {"cur_iter": "59", "eta": "0:20:24", "split": "test_iter", "time_diff": 0.97974}
[05/04 16:21:11][INFO] logging.py:  99: json_stats: {"cur_iter": "60", "eta": "0:21:02", "split": "test_iter", "time_diff": 1.01094}
[05/04 16:21:13][INFO] logging.py:  99: json_stats: {"cur_iter": "61", "eta": "0:21:13", "split": "test_iter", "time_diff": 1.02012}
[05/04 16:21:13][INFO] logging.py:  99: json_stats: {"cur_iter": "62", "eta": "0:19:59", "split": "test_iter", "time_diff": 0.96182}
[05/04 16:21:14][INFO] logging.py:  99: json_stats: {"cur_iter": "63", "eta": "0:20:24", "split": "test_iter", "time_diff": 0.98278}
[05/04 16:21:15][INFO] logging.py:  99: json_stats: {"cur_iter": "64", "eta": "0:20:19", "split": "test_iter", "time_diff": 0.97967}
[05/04 16:21:17][INFO] logging.py:  99: json_stats: {"cur_iter": "65", "eta": "0:26:30", "split": "test_iter", "time_diff": 1.27814}
[05/04 16:21:18][INFO] logging.py:  99: json_stats: {"cur_iter": "66", "eta": "0:20:34", "split": "test_iter", "time_diff": 0.99318}
[05/04 16:21:19][INFO] logging.py:  99: json_stats: {"cur_iter": "67", "eta": "0:20:21", "split": "test_iter", "time_diff": 0.98387}
[05/04 16:21:20][INFO] logging.py:  99: json_stats: {"cur_iter": "68", "eta": "0:20:30", "split": "test_iter", "time_diff": 0.99129}
[05/04 16:21:21][INFO] logging.py:  99: json_stats: {"cur_iter": "69", "eta": "0:20:22", "split": "test_iter", "time_diff": 0.98593}
[05/04 16:21:22][INFO] logging.py:  99: json_stats: {"cur_iter": "70", "eta": "0:18:16", "split": "test_iter", "time_diff": 0.88530}
[05/04 16:21:23][INFO] logging.py:  99: json_stats: {"cur_iter": "71", "eta": "0:22:27", "split": "test_iter", "time_diff": 1.08812}
[05/04 16:21:24][INFO] logging.py:  99: json_stats: {"cur_iter": "72", "eta": "0:20:17", "split": "test_iter", "time_diff": 0.98404}
[05/04 16:21:25][INFO] logging.py:  99: json_stats: {"cur_iter": "73", "eta": "0:26:39", "split": "test_iter", "time_diff": 1.29394}
[05/04 16:21:26][INFO] logging.py:  99: json_stats: {"cur_iter": "74", "eta": "0:19:28", "split": "test_iter", "time_diff": 0.94649}
[05/04 16:21:27][INFO] logging.py:  99: json_stats: {"cur_iter": "75", "eta": "0:19:37", "split": "test_iter", "time_diff": 0.95416}
[05/04 16:21:28][INFO] logging.py:  99: json_stats: {"cur_iter": "76", "eta": "0:20:23", "split": "test_iter", "time_diff": 0.99263}
[05/04 16:21:29][INFO] logging.py:  99: json_stats: {"cur_iter": "77", "eta": "0:33:11", "split": "test_iter", "time_diff": 1.61678}
[05/04 16:21:30][INFO] logging.py:  99: json_stats: {"cur_iter": "78", "eta": "0:20:32", "split": "test_iter", "time_diff": 1.00122}
[05/04 16:21:31][INFO] logging.py:  99: json_stats: {"cur_iter": "79", "eta": "0:19:47", "split": "test_iter", "time_diff": 0.96529}
[05/04 16:21:32][INFO] logging.py:  99: json_stats: {"cur_iter": "80", "eta": "0:21:05", "split": "test_iter", "time_diff": 1.03009}
[05/04 16:21:34][INFO] logging.py:  99: json_stats: {"cur_iter": "81", "eta": "0:23:05", "split": "test_iter", "time_diff": 1.12794}
[05/04 16:21:35][INFO] logging.py:  99: json_stats: {"cur_iter": "82", "eta": "0:19:48", "split": "test_iter", "time_diff": 0.96858}
[05/04 16:21:36][INFO] logging.py:  99: json_stats: {"cur_iter": "83", "eta": "0:20:36", "split": "test_iter", "time_diff": 1.00896}
[05/04 16:21:37][INFO] logging.py:  99: json_stats: {"cur_iter": "84", "eta": "0:20:37", "split": "test_iter", "time_diff": 1.00998}
[05/04 16:21:38][INFO] logging.py:  99: json_stats: {"cur_iter": "85", "eta": "0:26:15", "split": "test_iter", "time_diff": 1.28745}
[05/04 16:21:39][INFO] logging.py:  99: json_stats: {"cur_iter": "86", "eta": "0:20:22", "split": "test_iter", "time_diff": 0.99952}
[05/04 16:21:40][INFO] logging.py:  99: json_stats: {"cur_iter": "87", "eta": "0:20:19", "split": "test_iter", "time_diff": 0.99765}
[05/04 16:21:41][INFO] logging.py:  99: json_stats: {"cur_iter": "88", "eta": "0:19:50", "split": "test_iter", "time_diff": 0.97499}
[05/04 16:21:42][INFO] logging.py:  99: json_stats: {"cur_iter": "89", "eta": "0:27:25", "split": "test_iter", "time_diff": 1.34898}
[05/04 16:21:43][INFO] logging.py:  99: json_stats: {"cur_iter": "90", "eta": "0:24:03", "split": "test_iter", "time_diff": 1.18438}
[05/04 16:21:45][INFO] logging.py:  99: json_stats: {"cur_iter": "91", "eta": "0:22:12", "split": "test_iter", "time_diff": 1.09388}
[05/04 16:21:46][INFO] logging.py:  99: json_stats: {"cur_iter": "92", "eta": "0:20:18", "split": "test_iter", "time_diff": 1.00085}
[05/04 16:21:47][INFO] logging.py:  99: json_stats: {"cur_iter": "93", "eta": "0:23:36", "split": "test_iter", "time_diff": 1.16493}
[05/04 16:21:48][INFO] logging.py:  99: json_stats: {"cur_iter": "94", "eta": "0:20:32", "split": "test_iter", "time_diff": 1.01475}
[05/04 16:21:49][INFO] logging.py:  99: json_stats: {"cur_iter": "95", "eta": "0:19:35", "split": "test_iter", "time_diff": 0.96790}
[05/04 16:21:50][INFO] logging.py:  99: json_stats: {"cur_iter": "96", "eta": "0:17:19", "split": "test_iter", "time_diff": 0.85673}
[05/04 16:21:52][INFO] logging.py:  99: json_stats: {"cur_iter": "97", "eta": "0:32:48", "split": "test_iter", "time_diff": 1.62415}
[05/04 16:21:53][INFO] logging.py:  99: json_stats: {"cur_iter": "98", "eta": "0:26:07", "split": "test_iter", "time_diff": 1.29461}
[05/04 16:21:54][INFO] logging.py:  99: json_stats: {"cur_iter": "99", "eta": "0:17:12", "split": "test_iter", "time_diff": 0.85338}
[05/04 16:21:55][INFO] logging.py:  99: json_stats: {"cur_iter": "100", "eta": "0:19:55", "split": "test_iter", "time_diff": 0.98907}
[05/04 16:21:56][INFO] logging.py:  99: json_stats: {"cur_iter": "101", "eta": "0:19:23", "split": "test_iter", "time_diff": 0.96349}
[05/04 16:21:57][INFO] logging.py:  99: json_stats: {"cur_iter": "102", "eta": "0:20:04", "split": "test_iter", "time_diff": 0.99828}
[05/04 16:21:58][INFO] logging.py:  99: json_stats: {"cur_iter": "103", "eta": "0:19:31", "split": "test_iter", "time_diff": 0.97175}
[05/04 16:21:59][INFO] logging.py:  99: json_stats: {"cur_iter": "104", "eta": "0:19:10", "split": "test_iter", "time_diff": 0.95463}
[05/04 16:22:00][INFO] logging.py:  99: json_stats: {"cur_iter": "105", "eta": "0:31:46", "split": "test_iter", "time_diff": 1.58362}
[05/04 16:22:01][INFO] logging.py:  99: json_stats: {"cur_iter": "106", "eta": "0:22:53", "split": "test_iter", "time_diff": 1.14156}
[05/04 16:22:02][INFO] logging.py:  99: json_stats: {"cur_iter": "107", "eta": "0:19:11", "split": "test_iter", "time_diff": 0.95765}
[05/04 16:22:03][INFO] logging.py:  99: json_stats: {"cur_iter": "108", "eta": "0:19:59", "split": "test_iter", "time_diff": 0.99851}
[05/04 16:22:04][INFO] logging.py:  99: json_stats: {"cur_iter": "109", "eta": "0:19:49", "split": "test_iter", "time_diff": 0.99135}
[05/04 16:22:05][INFO] logging.py:  99: json_stats: {"cur_iter": "110", "eta": "0:19:46", "split": "test_iter", "time_diff": 0.98953}
[05/04 16:22:06][INFO] logging.py:  99: json_stats: {"cur_iter": "111", "eta": "0:19:38", "split": "test_iter", "time_diff": 0.98382}
[05/04 16:22:07][INFO] logging.py:  99: json_stats: {"cur_iter": "112", "eta": "0:18:58", "split": "test_iter", "time_diff": 0.95104}
[05/04 16:22:10][INFO] logging.py:  99: json_stats: {"cur_iter": "113", "eta": "0:43:47", "split": "test_iter", "time_diff": 2.19688}
[05/04 16:22:11][INFO] logging.py:  99: json_stats: {"cur_iter": "114", "eta": "0:26:12", "split": "test_iter", "time_diff": 1.31600}
[05/04 16:22:12][INFO] logging.py:  99: json_stats: {"cur_iter": "115", "eta": "0:19:48", "split": "test_iter", "time_diff": 0.99516}
[05/04 16:22:13][INFO] logging.py:  99: json_stats: {"cur_iter": "116", "eta": "0:19:25", "split": "test_iter", "time_diff": 0.97701}
[05/04 16:22:14][INFO] logging.py:  99: json_stats: {"cur_iter": "117", "eta": "0:17:31", "split": "test_iter", "time_diff": 0.88209}
[05/04 16:22:15][INFO] logging.py:  99: json_stats: {"cur_iter": "118", "eta": "0:17:32", "split": "test_iter", "time_diff": 0.88397}
[05/04 16:22:16][INFO] logging.py:  99: json_stats: {"cur_iter": "119", "eta": "0:16:55", "split": "test_iter", "time_diff": 0.85375}
[05/04 16:22:17][INFO] logging.py:  99: json_stats: {"cur_iter": "120", "eta": "0:19:51", "split": "test_iter", "time_diff": 1.00217}
[05/04 16:22:18][INFO] logging.py:  99: json_stats: {"cur_iter": "121", "eta": "0:38:33", "split": "test_iter", "time_diff": 1.94712}
[05/04 16:22:20][INFO] logging.py:  99: json_stats: {"cur_iter": "122", "eta": "0:23:03", "split": "test_iter", "time_diff": 1.16514}
[05/04 16:22:21][INFO] logging.py:  99: json_stats: {"cur_iter": "123", "eta": "0:19:39", "split": "test_iter", "time_diff": 0.99465}
[05/04 16:22:22][INFO] logging.py:  99: json_stats: {"cur_iter": "124", "eta": "0:16:52", "split": "test_iter", "time_diff": 0.85466}
[05/04 16:22:23][INFO] logging.py:  99: json_stats: {"cur_iter": "125", "eta": "0:19:30", "split": "test_iter", "time_diff": 0.98869}
[05/04 16:22:24][INFO] logging.py:  99: json_stats: {"cur_iter": "126", "eta": "0:19:28", "split": "test_iter", "time_diff": 0.98759}
[05/04 16:22:25][INFO] logging.py:  99: json_stats: {"cur_iter": "127", "eta": "0:19:06", "split": "test_iter", "time_diff": 0.97002}
[05/04 16:22:26][INFO] logging.py:  99: json_stats: {"cur_iter": "128", "eta": "0:20:15", "split": "test_iter", "time_diff": 1.02908}
[05/04 16:22:27][INFO] logging.py:  99: json_stats: {"cur_iter": "129", "eta": "0:32:43", "split": "test_iter", "time_diff": 1.66429}
[05/04 16:22:28][INFO] logging.py:  99: json_stats: {"cur_iter": "130", "eta": "0:23:04", "split": "test_iter", "time_diff": 1.17408}
[05/04 16:22:30][INFO] logging.py:  99: json_stats: {"cur_iter": "131", "eta": "0:20:59", "split": "test_iter", "time_diff": 1.06884}
[05/04 16:22:31][INFO] logging.py:  99: json_stats: {"cur_iter": "132", "eta": "0:18:52", "split": "test_iter", "time_diff": 0.96210}
[05/04 16:22:32][INFO] logging.py:  99: json_stats: {"cur_iter": "133", "eta": "0:19:17", "split": "test_iter", "time_diff": 0.98398}
[05/04 16:22:33][INFO] logging.py:  99: json_stats: {"cur_iter": "134", "eta": "0:25:49", "split": "test_iter", "time_diff": 1.31861}
[05/04 16:22:34][INFO] logging.py:  99: json_stats: {"cur_iter": "135", "eta": "0:18:50", "split": "test_iter", "time_diff": 0.96311}
[05/04 16:22:35][INFO] logging.py:  99: json_stats: {"cur_iter": "136", "eta": "0:19:30", "split": "test_iter", "time_diff": 0.99812}
[05/04 16:22:37][INFO] logging.py:  99: json_stats: {"cur_iter": "137", "eta": "0:40:56", "split": "test_iter", "time_diff": 2.09636}
[05/04 16:22:38][INFO] logging.py:  99: json_stats: {"cur_iter": "138", "eta": "0:18:57", "split": "test_iter", "time_diff": 0.97148}
[05/04 16:22:39][INFO] logging.py:  99: json_stats: {"cur_iter": "139", "eta": "0:18:34", "split": "test_iter", "time_diff": 0.95297}
[05/04 16:22:40][INFO] logging.py:  99: json_stats: {"cur_iter": "140", "eta": "0:16:40", "split": "test_iter", "time_diff": 0.85559}
[05/04 16:22:41][INFO] logging.py:  99: json_stats: {"cur_iter": "141", "eta": "0:18:32", "split": "test_iter", "time_diff": 0.95264}
[05/04 16:22:42][INFO] logging.py:  99: json_stats: {"cur_iter": "142", "eta": "0:17:07", "split": "test_iter", "time_diff": 0.88072}
[05/04 16:22:43][INFO] logging.py:  99: json_stats: {"cur_iter": "143", "eta": "0:19:07", "split": "test_iter", "time_diff": 0.98380}
[05/04 16:22:44][INFO] logging.py:  99: json_stats: {"cur_iter": "144", "eta": "0:19:12", "split": "test_iter", "time_diff": 0.98926}
[05/04 16:22:46][INFO] logging.py:  99: json_stats: {"cur_iter": "145", "eta": "0:38:41", "split": "test_iter", "time_diff": 1.99481}
[05/04 16:22:47][INFO] logging.py:  99: json_stats: {"cur_iter": "146", "eta": "0:16:48", "split": "test_iter", "time_diff": 0.86693}
[05/04 16:22:48][INFO] logging.py:  99: json_stats: {"cur_iter": "147", "eta": "0:18:25", "split": "test_iter", "time_diff": 0.95177}
[05/04 16:22:49][INFO] logging.py:  99: json_stats: {"cur_iter": "148", "eta": "0:16:33", "split": "test_iter", "time_diff": 0.85598}
[05/04 16:22:50][INFO] logging.py:  99: json_stats: {"cur_iter": "149", "eta": "0:18:19", "split": "test_iter", "time_diff": 0.94753}
[05/04 16:22:51][INFO] logging.py:  99: json_stats: {"cur_iter": "150", "eta": "0:19:05", "split": "test_iter", "time_diff": 0.98812}
[05/04 16:22:52][INFO] logging.py:  99: json_stats: {"cur_iter": "151", "eta": "0:18:42", "split": "test_iter", "time_diff": 0.96967}
[05/04 16:22:53][INFO] logging.py:  99: json_stats: {"cur_iter": "152", "eta": "0:19:08", "split": "test_iter", "time_diff": 0.99261}
[05/04 16:22:55][INFO] logging.py:  99: json_stats: {"cur_iter": "153", "eta": "0:35:28", "split": "test_iter", "time_diff": 1.84134}
[05/04 16:22:56][INFO] logging.py:  99: json_stats: {"cur_iter": "154", "eta": "0:16:27", "split": "test_iter", "time_diff": 0.85540}
[05/04 16:22:57][INFO] logging.py:  99: json_stats: {"cur_iter": "155", "eta": "0:18:47", "split": "test_iter", "time_diff": 0.97662}
[05/04 16:22:57][INFO] logging.py:  99: json_stats: {"cur_iter": "156", "eta": "0:18:07", "split": "test_iter", "time_diff": 0.94342}
[05/04 16:22:58][INFO] logging.py:  99: json_stats: {"cur_iter": "157", "eta": "0:19:13", "split": "test_iter", "time_diff": 1.00147}
[05/04 16:22:59][INFO] logging.py:  99: json_stats: {"cur_iter": "158", "eta": "0:19:17", "split": "test_iter", "time_diff": 1.00539}
[05/04 16:23:00][INFO] logging.py:  99: json_stats: {"cur_iter": "159", "eta": "0:19:37", "split": "test_iter", "time_diff": 1.02407}
[05/04 16:23:01][INFO] logging.py:  99: json_stats: {"cur_iter": "160", "eta": "0:18:41", "split": "test_iter", "time_diff": 0.97563}
[05/04 16:23:04][INFO] logging.py:  99: json_stats: {"cur_iter": "161", "eta": "0:39:19", "split": "test_iter", "time_diff": 2.05531}
[05/04 16:23:05][INFO] logging.py:  99: json_stats: {"cur_iter": "162", "eta": "0:18:59", "split": "test_iter", "time_diff": 0.99304}
[05/04 16:23:05][INFO] logging.py:  99: json_stats: {"cur_iter": "163", "eta": "0:18:09", "split": "test_iter", "time_diff": 0.95071}
[05/04 16:23:06][INFO] logging.py:  99: json_stats: {"cur_iter": "164", "eta": "0:18:19", "split": "test_iter", "time_diff": 0.96048}
[05/04 16:23:07][INFO] logging.py:  99: json_stats: {"cur_iter": "165", "eta": "0:18:29", "split": "test_iter", "time_diff": 0.96946}
[05/04 16:23:08][INFO] logging.py:  99: json_stats: {"cur_iter": "166", "eta": "0:16:47", "split": "test_iter", "time_diff": 0.88177}
[05/04 16:23:09][INFO] logging.py:  99: json_stats: {"cur_iter": "167", "eta": "0:19:25", "split": "test_iter", "time_diff": 1.02095}
[05/04 16:23:10][INFO] logging.py:  99: json_stats: {"cur_iter": "168", "eta": "0:18:41", "split": "test_iter", "time_diff": 0.98274}
[05/04 16:23:12][INFO] logging.py:  99: json_stats: {"cur_iter": "169", "eta": "0:35:15", "split": "test_iter", "time_diff": 1.85591}
[05/04 16:23:13][INFO] logging.py:  99: json_stats: {"cur_iter": "170", "eta": "0:18:47", "split": "test_iter", "time_diff": 0.98968}
[05/04 16:23:14][INFO] logging.py:  99: json_stats: {"cur_iter": "171", "eta": "0:18:33", "split": "test_iter", "time_diff": 0.97807}
[05/04 16:23:15][INFO] logging.py:  99: json_stats: {"cur_iter": "172", "eta": "0:18:57", "split": "test_iter", "time_diff": 1.00052}
[05/04 16:23:16][INFO] logging.py:  99: json_stats: {"cur_iter": "173", "eta": "0:21:08", "split": "test_iter", "time_diff": 1.11667}
[05/04 16:23:17][INFO] logging.py:  99: json_stats: {"cur_iter": "174", "eta": "0:19:11", "split": "test_iter", "time_diff": 1.01444}
[05/04 16:23:18][INFO] logging.py:  99: json_stats: {"cur_iter": "175", "eta": "0:18:56", "split": "test_iter", "time_diff": 1.00198}
[05/04 16:23:19][INFO] logging.py:  99: json_stats: {"cur_iter": "176", "eta": "0:18:46", "split": "test_iter", "time_diff": 0.99464}
[05/04 16:23:21][INFO] logging.py:  99: json_stats: {"cur_iter": "177", "eta": "0:30:34", "split": "test_iter", "time_diff": 1.62027}
[05/04 16:23:22][INFO] logging.py:  99: json_stats: {"cur_iter": "178", "eta": "0:16:25", "split": "test_iter", "time_diff": 0.87150}
[05/04 16:23:23][INFO] logging.py:  99: json_stats: {"cur_iter": "179", "eta": "0:17:03", "split": "test_iter", "time_diff": 0.90616}
[05/04 16:23:24][INFO] logging.py:  99: json_stats: {"cur_iter": "180", "eta": "0:19:02", "split": "test_iter", "time_diff": 1.01206}
[05/04 16:23:25][INFO] logging.py:  99: json_stats: {"cur_iter": "181", "eta": "0:16:00", "split": "test_iter", "time_diff": 0.85167}
[05/04 16:23:26][INFO] logging.py:  99: json_stats: {"cur_iter": "182", "eta": "0:20:27", "split": "test_iter", "time_diff": 1.08887}
[05/04 16:23:27][INFO] logging.py:  99: json_stats: {"cur_iter": "183", "eta": "0:18:37", "split": "test_iter", "time_diff": 0.99257}
[05/04 16:23:28][INFO] logging.py:  99: json_stats: {"cur_iter": "184", "eta": "0:18:44", "split": "test_iter", "time_diff": 0.99919}
[05/04 16:23:29][INFO] logging.py:  99: json_stats: {"cur_iter": "185", "eta": "0:23:38", "split": "test_iter", "time_diff": 1.26210}
[05/04 16:23:30][INFO] logging.py:  99: json_stats: {"cur_iter": "186", "eta": "0:18:12", "split": "test_iter", "time_diff": 0.97263}
[05/04 16:23:31][INFO] logging.py:  99: json_stats: {"cur_iter": "187", "eta": "0:16:32", "split": "test_iter", "time_diff": 0.88464}
[05/04 16:23:32][INFO] logging.py:  99: json_stats: {"cur_iter": "188", "eta": "0:18:06", "split": "test_iter", "time_diff": 0.96910}
[05/04 16:23:33][INFO] logging.py:  99: json_stats: {"cur_iter": "189", "eta": "0:19:15", "split": "test_iter", "time_diff": 1.03191}
[05/04 16:23:34][INFO] logging.py:  99: json_stats: {"cur_iter": "190", "eta": "0:17:36", "split": "test_iter", "time_diff": 0.94393}
[05/04 16:23:35][INFO] logging.py:  99: json_stats: {"cur_iter": "191", "eta": "0:18:51", "split": "test_iter", "time_diff": 1.01184}
[05/04 16:23:36][INFO] logging.py:  99: json_stats: {"cur_iter": "192", "eta": "0:15:52", "split": "test_iter", "time_diff": 0.85274}
[05/04 16:23:37][INFO] logging.py:  99: json_stats: {"cur_iter": "193", "eta": "0:16:29", "split": "test_iter", "time_diff": 0.88674}
[05/04 16:23:38][INFO] logging.py:  99: json_stats: {"cur_iter": "194", "eta": "0:17:53", "split": "test_iter", "time_diff": 0.96256}
[05/04 16:23:39][INFO] logging.py:  99: json_stats: {"cur_iter": "195", "eta": "0:18:37", "split": "test_iter", "time_diff": 1.00348}
[05/04 16:23:40][INFO] logging.py:  99: json_stats: {"cur_iter": "196", "eta": "0:16:19", "split": "test_iter", "time_diff": 0.87972}
[05/04 16:23:41][INFO] logging.py:  99: json_stats: {"cur_iter": "197", "eta": "0:18:37", "split": "test_iter", "time_diff": 1.00509}
[05/04 16:23:42][INFO] logging.py:  99: json_stats: {"cur_iter": "198", "eta": "0:16:25", "split": "test_iter", "time_diff": 0.88739}
[05/04 16:23:43][INFO] logging.py:  99: json_stats: {"cur_iter": "199", "eta": "0:18:45", "split": "test_iter", "time_diff": 1.01423}
[05/04 16:23:44][INFO] logging.py:  99: json_stats: {"cur_iter": "200", "eta": "0:18:10", "split": "test_iter", "time_diff": 0.98291}
[05/04 16:23:45][INFO] logging.py:  99: json_stats: {"cur_iter": "201", "eta": "0:23:59", "split": "test_iter", "time_diff": 1.29900}
[05/04 16:23:46][INFO] logging.py:  99: json_stats: {"cur_iter": "202", "eta": "0:17:59", "split": "test_iter", "time_diff": 0.97515}
[05/04 16:23:47][INFO] logging.py:  99: json_stats: {"cur_iter": "203", "eta": "0:18:20", "split": "test_iter", "time_diff": 0.99542}
[05/04 16:23:48][INFO] logging.py:  99: json_stats: {"cur_iter": "204", "eta": "0:18:00", "split": "test_iter", "time_diff": 0.97784}
[05/04 16:23:49][INFO] logging.py:  99: json_stats: {"cur_iter": "205", "eta": "0:15:44", "split": "test_iter", "time_diff": 0.85509}
[05/04 16:23:50][INFO] logging.py:  99: json_stats: {"cur_iter": "206", "eta": "0:19:28", "split": "test_iter", "time_diff": 1.05940}
[05/04 16:23:51][INFO] logging.py:  99: json_stats: {"cur_iter": "207", "eta": "0:18:16", "split": "test_iter", "time_diff": 0.99476}
[05/04 16:23:52][INFO] logging.py:  99: json_stats: {"cur_iter": "208", "eta": "0:18:17", "split": "test_iter", "time_diff": 0.99697}
[05/04 16:23:53][INFO] logging.py:  99: json_stats: {"cur_iter": "209", "eta": "0:20:47", "split": "test_iter", "time_diff": 1.13404}
[05/04 16:23:54][INFO] logging.py:  99: json_stats: {"cur_iter": "210", "eta": "0:16:08", "split": "test_iter", "time_diff": 0.88146}
[05/04 16:23:55][INFO] logging.py:  99: json_stats: {"cur_iter": "211", "eta": "0:18:35", "split": "test_iter", "time_diff": 1.01570}
[05/04 16:23:56][INFO] logging.py:  99: json_stats: {"cur_iter": "212", "eta": "0:19:31", "split": "test_iter", "time_diff": 1.06794}
[05/04 16:23:57][INFO] logging.py:  99: json_stats: {"cur_iter": "213", "eta": "0:18:05", "split": "test_iter", "time_diff": 0.99085}
[05/04 16:23:58][INFO] logging.py:  99: json_stats: {"cur_iter": "214", "eta": "0:17:36", "split": "test_iter", "time_diff": 0.96479}
[05/04 16:23:59][INFO] logging.py:  99: json_stats: {"cur_iter": "215", "eta": "0:18:27", "split": "test_iter", "time_diff": 1.01222}
[05/04 16:24:00][INFO] logging.py:  99: json_stats: {"cur_iter": "216", "eta": "0:18:01", "split": "test_iter", "time_diff": 0.98940}
[05/04 16:24:02][INFO] logging.py:  99: json_stats: {"cur_iter": "217", "eta": "0:34:25", "split": "test_iter", "time_diff": 1.89152}
[05/04 16:24:03][INFO] logging.py:  99: json_stats: {"cur_iter": "218", "eta": "0:18:02", "split": "test_iter", "time_diff": 0.99256}
[05/04 16:24:04][INFO] logging.py:  99: json_stats: {"cur_iter": "219", "eta": "0:17:57", "split": "test_iter", "time_diff": 0.98855}
[05/04 16:24:05][INFO] logging.py:  99: json_stats: {"cur_iter": "220", "eta": "0:17:19", "split": "test_iter", "time_diff": 0.95449}
[05/04 16:24:06][INFO] logging.py:  99: json_stats: {"cur_iter": "221", "eta": "0:18:17", "split": "test_iter", "time_diff": 1.00845}
[05/04 16:24:07][INFO] logging.py:  99: json_stats: {"cur_iter": "222", "eta": "0:15:29", "split": "test_iter", "time_diff": 0.85498}
[05/04 16:24:08][INFO] logging.py:  99: json_stats: {"cur_iter": "223", "eta": "0:17:52", "split": "test_iter", "time_diff": 0.98720}
[05/04 16:24:09][INFO] logging.py:  99: json_stats: {"cur_iter": "224", "eta": "0:17:31", "split": "test_iter", "time_diff": 0.96951}
[05/04 16:24:11][INFO] logging.py:  99: json_stats: {"cur_iter": "225", "eta": "0:28:23", "split": "test_iter", "time_diff": 1.57105}
[05/04 16:24:12][INFO] logging.py:  99: json_stats: {"cur_iter": "226", "eta": "0:16:11", "split": "test_iter", "time_diff": 0.89665}
[05/04 16:24:13][INFO] logging.py:  99: json_stats: {"cur_iter": "227", "eta": "0:20:26", "split": "test_iter", "time_diff": 1.13327}
[05/04 16:24:14][INFO] logging.py:  99: json_stats: {"cur_iter": "228", "eta": "0:18:43", "split": "test_iter", "time_diff": 1.03948}
[05/04 16:24:15][INFO] logging.py:  99: json_stats: {"cur_iter": "229", "eta": "0:17:38", "split": "test_iter", "time_diff": 0.98053}
[05/04 16:24:16][INFO] logging.py:  99: json_stats: {"cur_iter": "230", "eta": "0:17:26", "split": "test_iter", "time_diff": 0.96998}
[05/04 16:24:17][INFO] logging.py:  99: json_stats: {"cur_iter": "231", "eta": "0:15:20", "split": "test_iter", "time_diff": 0.85359}
[05/04 16:24:18][INFO] logging.py:  99: json_stats: {"cur_iter": "232", "eta": "0:17:10", "split": "test_iter", "time_diff": 0.95716}
[05/04 16:24:19][INFO] logging.py:  99: json_stats: {"cur_iter": "233", "eta": "0:24:15", "split": "test_iter", "time_diff": 1.35305}
[05/04 16:24:20][INFO] logging.py:  99: json_stats: {"cur_iter": "234", "eta": "0:22:50", "split": "test_iter", "time_diff": 1.27514}
[05/04 16:24:21][INFO] logging.py:  99: json_stats: {"cur_iter": "235", "eta": "0:17:40", "split": "test_iter", "time_diff": 0.98733}
[05/04 16:24:22][INFO] logging.py:  99: json_stats: {"cur_iter": "236", "eta": "0:17:30", "split": "test_iter", "time_diff": 0.97878}
[05/04 16:24:23][INFO] logging.py:  99: json_stats: {"cur_iter": "237", "eta": "0:17:21", "split": "test_iter", "time_diff": 0.97119}
[05/04 16:24:24][INFO] logging.py:  99: json_stats: {"cur_iter": "238", "eta": "0:16:52", "split": "test_iter", "time_diff": 0.94498}
[05/04 16:24:25][INFO] logging.py:  99: json_stats: {"cur_iter": "239", "eta": "0:17:30", "split": "test_iter", "time_diff": 0.98161}
[05/04 16:24:26][INFO] logging.py:  99: json_stats: {"cur_iter": "240", "eta": "0:17:44", "split": "test_iter", "time_diff": 0.99605}
[05/04 16:24:28][INFO] logging.py:  99: json_stats: {"cur_iter": "241", "eta": "0:28:22", "split": "test_iter", "time_diff": 1.59456}
[05/04 16:24:29][INFO] logging.py:  99: json_stats: {"cur_iter": "242", "eta": "0:17:37", "split": "test_iter", "time_diff": 0.99098}
[05/04 16:24:30][INFO] logging.py:  99: json_stats: {"cur_iter": "243", "eta": "0:17:34", "split": "test_iter", "time_diff": 0.98956}
[05/04 16:24:31][INFO] logging.py:  99: json_stats: {"cur_iter": "244", "eta": "0:17:32", "split": "test_iter", "time_diff": 0.98833}
[05/04 16:24:32][INFO] logging.py:  99: json_stats: {"cur_iter": "245", "eta": "0:17:29", "split": "test_iter", "time_diff": 0.98602}
[05/04 16:24:33][INFO] logging.py:  99: json_stats: {"cur_iter": "246", "eta": "0:18:11", "split": "test_iter", "time_diff": 1.02646}
[05/04 16:24:34][INFO] logging.py:  99: json_stats: {"cur_iter": "247", "eta": "0:16:59", "split": "test_iter", "time_diff": 0.96010}
[05/04 16:24:35][INFO] logging.py:  99: json_stats: {"cur_iter": "248", "eta": "0:18:43", "split": "test_iter", "time_diff": 1.05899}
[05/04 16:24:37][INFO] logging.py:  99: json_stats: {"cur_iter": "249", "eta": "0:31:35", "split": "test_iter", "time_diff": 1.78780}
[05/04 16:24:38][INFO] logging.py:  99: json_stats: {"cur_iter": "250", "eta": "0:19:01", "split": "test_iter", "time_diff": 1.07773}
[05/04 16:24:39][INFO] logging.py:  99: json_stats: {"cur_iter": "251", "eta": "0:17:53", "split": "test_iter", "time_diff": 1.01433}
[05/04 16:24:40][INFO] logging.py:  99: json_stats: {"cur_iter": "252", "eta": "0:16:44", "split": "test_iter", "time_diff": 0.95039}
[05/04 16:24:41][INFO] logging.py:  99: json_stats: {"cur_iter": "253", "eta": "0:17:19", "split": "test_iter", "time_diff": 0.98442}
[05/04 16:24:42][INFO] logging.py:  99: json_stats: {"cur_iter": "254", "eta": "0:16:32", "split": "test_iter", "time_diff": 0.94063}
[05/04 16:24:43][INFO] logging.py:  99: json_stats: {"cur_iter": "255", "eta": "0:16:57", "split": "test_iter", "time_diff": 0.96498}
[05/04 16:24:44][INFO] logging.py:  99: json_stats: {"cur_iter": "256", "eta": "0:18:07", "split": "test_iter", "time_diff": 1.03232}
[05/04 16:24:46][INFO] logging.py:  99: json_stats: {"cur_iter": "257", "eta": "0:43:37", "split": "test_iter", "time_diff": 2.48851}
[05/04 16:24:47][INFO] logging.py:  99: json_stats: {"cur_iter": "258", "eta": "0:17:16", "split": "test_iter", "time_diff": 0.98607}
[05/04 16:24:48][INFO] logging.py:  99: json_stats: {"cur_iter": "259", "eta": "0:16:50", "split": "test_iter", "time_diff": 0.96216}
[05/04 16:24:49][INFO] logging.py:  99: json_stats: {"cur_iter": "260", "eta": "0:16:49", "split": "test_iter", "time_diff": 0.96188}
[05/04 16:24:50][INFO] logging.py:  99: json_stats: {"cur_iter": "261", "eta": "0:16:57", "split": "test_iter", "time_diff": 0.97054}
[05/04 16:24:51][INFO] logging.py:  99: json_stats: {"cur_iter": "262", "eta": "0:16:53", "split": "test_iter", "time_diff": 0.96779}
[05/04 16:24:52][INFO] logging.py:  99: json_stats: {"cur_iter": "263", "eta": "0:18:21", "split": "test_iter", "time_diff": 1.05259}
[05/04 16:24:53][INFO] logging.py:  99: json_stats: {"cur_iter": "264", "eta": "0:17:26", "split": "test_iter", "time_diff": 1.00119}
[05/04 16:24:55][INFO] logging.py:  99: json_stats: {"cur_iter": "265", "eta": "0:25:14", "split": "test_iter", "time_diff": 1.45086}
[05/04 16:24:56][INFO] logging.py:  99: json_stats: {"cur_iter": "266", "eta": "0:17:11", "split": "test_iter", "time_diff": 0.98916}
[05/04 16:24:57][INFO] logging.py:  99: json_stats: {"cur_iter": "267", "eta": "0:16:38", "split": "test_iter", "time_diff": 0.95853}
[05/04 16:24:57][INFO] logging.py:  99: json_stats: {"cur_iter": "268", "eta": "0:16:32", "split": "test_iter", "time_diff": 0.95387}
[05/04 16:24:58][INFO] logging.py:  99: json_stats: {"cur_iter": "269", "eta": "0:17:03", "split": "test_iter", "time_diff": 0.98434}
[05/04 16:24:59][INFO] logging.py:  99: json_stats: {"cur_iter": "270", "eta": "0:17:29", "split": "test_iter", "time_diff": 1.01028}
[05/04 16:25:00][INFO] logging.py:  99: json_stats: {"cur_iter": "271", "eta": "0:17:17", "split": "test_iter", "time_diff": 0.99907}
[05/04 16:25:01][INFO] logging.py:  99: json_stats: {"cur_iter": "272", "eta": "0:17:02", "split": "test_iter", "time_diff": 0.98560}
[05/04 16:25:03][INFO] logging.py:  99: json_stats: {"cur_iter": "273", "eta": "0:31:38", "split": "test_iter", "time_diff": 1.83221}
[05/04 16:25:04][INFO] logging.py:  99: json_stats: {"cur_iter": "274", "eta": "0:16:57", "split": "test_iter", "time_diff": 0.98306}
[05/04 16:25:05][INFO] logging.py:  99: json_stats: {"cur_iter": "275", "eta": "0:16:32", "split": "test_iter", "time_diff": 0.95943}
[05/04 16:25:06][INFO] logging.py:  99: json_stats: {"cur_iter": "276", "eta": "0:16:22", "split": "test_iter", "time_diff": 0.95111}
[05/04 16:25:07][INFO] logging.py:  99: json_stats: {"cur_iter": "277", "eta": "0:16:30", "split": "test_iter", "time_diff": 0.95941}
[05/04 16:25:08][INFO] logging.py:  99: json_stats: {"cur_iter": "278", "eta": "0:16:47", "split": "test_iter", "time_diff": 0.97733}
[05/04 16:25:09][INFO] logging.py:  99: json_stats: {"cur_iter": "279", "eta": "0:16:36", "split": "test_iter", "time_diff": 0.96759}
[05/04 16:25:10][INFO] logging.py:  99: json_stats: {"cur_iter": "280", "eta": "0:17:18", "split": "test_iter", "time_diff": 1.00961}
[05/04 16:25:12][INFO] logging.py:  99: json_stats: {"cur_iter": "281", "eta": "0:31:21", "split": "test_iter", "time_diff": 1.83010}
[05/04 16:25:13][INFO] logging.py:  99: json_stats: {"cur_iter": "282", "eta": "0:16:51", "split": "test_iter", "time_diff": 0.98520}
[05/04 16:25:14][INFO] logging.py:  99: json_stats: {"cur_iter": "283", "eta": "0:15:04", "split": "test_iter", "time_diff": 0.88196}
[05/04 16:25:15][INFO] logging.py:  99: json_stats: {"cur_iter": "284", "eta": "0:15:06", "split": "test_iter", "time_diff": 0.88430}
[05/04 16:25:16][INFO] logging.py:  99: json_stats: {"cur_iter": "285", "eta": "0:16:54", "split": "test_iter", "time_diff": 0.99037}
[05/04 16:25:17][INFO] logging.py:  99: json_stats: {"cur_iter": "286", "eta": "0:16:15", "split": "test_iter", "time_diff": 0.95379}
[05/04 16:25:18][INFO] logging.py:  99: json_stats: {"cur_iter": "287", "eta": "0:16:31", "split": "test_iter", "time_diff": 0.97006}
[05/04 16:25:19][INFO] logging.py:  99: json_stats: {"cur_iter": "288", "eta": "0:16:58", "split": "test_iter", "time_diff": 0.99708}
[05/04 16:25:21][INFO] logging.py:  99: json_stats: {"cur_iter": "289", "eta": "0:44:08", "split": "test_iter", "time_diff": 2.59647}
[05/04 16:25:23][INFO] logging.py:  99: json_stats: {"cur_iter": "290", "eta": "0:18:10", "split": "test_iter", "time_diff": 1.06974}
[05/04 16:25:24][INFO] logging.py:  99: json_stats: {"cur_iter": "291", "eta": "0:16:44", "split": "test_iter", "time_diff": 0.98678}
[05/04 16:25:24][INFO] logging.py:  99: json_stats: {"cur_iter": "292", "eta": "0:15:58", "split": "test_iter", "time_diff": 0.94205}
[05/04 16:25:25][INFO] logging.py:  99: json_stats: {"cur_iter": "293", "eta": "0:14:28", "split": "test_iter", "time_diff": 0.85473}
[05/04 16:25:26][INFO] logging.py:  99: json_stats: {"cur_iter": "294", "eta": "0:14:54", "split": "test_iter", "time_diff": 0.88167}
[05/04 16:25:27][INFO] logging.py:  99: json_stats: {"cur_iter": "295", "eta": "0:16:33", "split": "test_iter", "time_diff": 0.97930}
[05/04 16:25:28][INFO] logging.py:  99: json_stats: {"cur_iter": "296", "eta": "0:14:44", "split": "test_iter", "time_diff": 0.87331}
[05/04 16:25:31][INFO] logging.py:  99: json_stats: {"cur_iter": "297", "eta": "0:48:13", "split": "test_iter", "time_diff": 2.85943}
[05/04 16:25:32][INFO] logging.py:  99: json_stats: {"cur_iter": "298", "eta": "0:16:42", "split": "test_iter", "time_diff": 0.99184}
[05/04 16:25:33][INFO] logging.py:  99: json_stats: {"cur_iter": "299", "eta": "0:16:26", "split": "test_iter", "time_diff": 0.97721}
[05/04 16:25:34][INFO] logging.py:  99: json_stats: {"cur_iter": "300", "eta": "0:16:03", "split": "test_iter", "time_diff": 0.95495}
[05/04 16:25:35][INFO] logging.py:  99: json_stats: {"cur_iter": "301", "eta": "0:21:57", "split": "test_iter", "time_diff": 1.30695}
[05/04 16:25:36][INFO] logging.py:  99: json_stats: {"cur_iter": "302", "eta": "0:16:50", "split": "test_iter", "time_diff": 1.00374}
[05/04 16:25:37][INFO] logging.py:  99: json_stats: {"cur_iter": "303", "eta": "0:16:11", "split": "test_iter", "time_diff": 0.96607}
[05/04 16:25:38][INFO] logging.py:  99: json_stats: {"cur_iter": "304", "eta": "0:16:31", "split": "test_iter", "time_diff": 0.98661}
[05/04 16:25:41][INFO] logging.py:  99: json_stats: {"cur_iter": "305", "eta": "0:37:50", "split": "test_iter", "time_diff": 2.26133}
[05/04 16:25:41][INFO] logging.py:  99: json_stats: {"cur_iter": "306", "eta": "0:16:26", "split": "test_iter", "time_diff": 0.98343}
[05/04 16:25:42][INFO] logging.py:  99: json_stats: {"cur_iter": "307", "eta": "0:16:04", "split": "test_iter", "time_diff": 0.96290}
[05/04 16:25:43][INFO] logging.py:  99: json_stats: {"cur_iter": "308", "eta": "0:16:48", "split": "test_iter", "time_diff": 1.00727}
[05/04 16:25:45][INFO] logging.py:  99: json_stats: {"cur_iter": "309", "eta": "0:22:00", "split": "test_iter", "time_diff": 1.32005}
[05/04 16:25:46][INFO] logging.py:  99: json_stats: {"cur_iter": "310", "eta": "0:16:30", "split": "test_iter", "time_diff": 0.99160}
[05/04 16:25:47][INFO] logging.py:  99: json_stats: {"cur_iter": "311", "eta": "0:15:54", "split": "test_iter", "time_diff": 0.95652}
[05/04 16:25:48][INFO] logging.py:  99: json_stats: {"cur_iter": "312", "eta": "0:14:38", "split": "test_iter", "time_diff": 0.88087}
[05/04 16:25:50][INFO] logging.py:  99: json_stats: {"cur_iter": "313", "eta": "0:37:26", "split": "test_iter", "time_diff": 2.25522}
[05/04 16:25:51][INFO] logging.py:  99: json_stats: {"cur_iter": "314", "eta": "0:16:49", "split": "test_iter", "time_diff": 1.01469}
[05/04 16:25:52][INFO] logging.py:  99: json_stats: {"cur_iter": "315", "eta": "0:16:31", "split": "test_iter", "time_diff": 0.99781}
[05/04 16:25:53][INFO] logging.py:  99: json_stats: {"cur_iter": "316", "eta": "0:17:17", "split": "test_iter", "time_diff": 1.04437}
[05/04 16:25:54][INFO] logging.py:  99: json_stats: {"cur_iter": "317", "eta": "0:20:48", "split": "test_iter", "time_diff": 1.25879}
[05/04 16:25:55][INFO] logging.py:  99: json_stats: {"cur_iter": "318", "eta": "0:15:57", "split": "test_iter", "time_diff": 0.96598}
[05/04 16:25:56][INFO] logging.py:  99: json_stats: {"cur_iter": "319", "eta": "0:16:20", "split": "test_iter", "time_diff": 0.99003}
[05/04 16:25:57][INFO] logging.py:  99: json_stats: {"cur_iter": "320", "eta": "0:14:32", "split": "test_iter", "time_diff": 0.88233}
[05/04 16:25:59][INFO] logging.py:  99: json_stats: {"cur_iter": "321", "eta": "0:21:56", "split": "test_iter", "time_diff": 1.33286}
[05/04 16:26:00][INFO] logging.py:  99: json_stats: {"cur_iter": "322", "eta": "0:15:50", "split": "test_iter", "time_diff": 0.96315}
[05/04 16:26:01][INFO] logging.py:  99: json_stats: {"cur_iter": "323", "eta": "0:15:36", "split": "test_iter", "time_diff": 0.94955}
[05/04 16:26:02][INFO] logging.py:  99: json_stats: {"cur_iter": "324", "eta": "0:16:00", "split": "test_iter", "time_diff": 0.97560}
[05/04 16:26:03][INFO] logging.py:  99: json_stats: {"cur_iter": "325", "eta": "0:17:22", "split": "test_iter", "time_diff": 1.05986}
[05/04 16:26:04][INFO] logging.py:  99: json_stats: {"cur_iter": "326", "eta": "0:16:49", "split": "test_iter", "time_diff": 1.02711}
[05/04 16:26:05][INFO] logging.py:  99: json_stats: {"cur_iter": "327", "eta": "0:15:55", "split": "test_iter", "time_diff": 0.97273}
[05/04 16:26:06][INFO] logging.py:  99: json_stats: {"cur_iter": "328", "eta": "0:16:12", "split": "test_iter", "time_diff": 0.99101}
[05/04 16:26:07][INFO] logging.py:  99: json_stats: {"cur_iter": "329", "eta": "0:20:41", "split": "test_iter", "time_diff": 1.26655}
[05/04 16:26:08][INFO] logging.py:  99: json_stats: {"cur_iter": "330", "eta": "0:15:59", "split": "test_iter", "time_diff": 0.98041}
[05/04 16:26:09][INFO] logging.py:  99: json_stats: {"cur_iter": "331", "eta": "0:16:11", "split": "test_iter", "time_diff": 0.99297}
[05/04 16:26:10][INFO] logging.py:  99: json_stats: {"cur_iter": "332", "eta": "0:16:05", "split": "test_iter", "time_diff": 0.98867}
[05/04 16:26:11][INFO] logging.py:  99: json_stats: {"cur_iter": "333", "eta": "0:16:38", "split": "test_iter", "time_diff": 1.02327}
[05/04 16:26:12][INFO] logging.py:  99: json_stats: {"cur_iter": "334", "eta": "0:16:15", "split": "test_iter", "time_diff": 1.00063}
[05/04 16:26:13][INFO] logging.py:  99: json_stats: {"cur_iter": "335", "eta": "0:17:25", "split": "test_iter", "time_diff": 1.07382}
[05/04 16:26:14][INFO] logging.py:  99: json_stats: {"cur_iter": "336", "eta": "0:14:20", "split": "test_iter", "time_diff": 0.88416}
[05/04 16:26:15][INFO] logging.py:  99: json_stats: {"cur_iter": "337", "eta": "0:15:47", "split": "test_iter", "time_diff": 0.97472}
[05/04 16:26:16][INFO] logging.py:  99: json_stats: {"cur_iter": "338", "eta": "0:17:34", "split": "test_iter", "time_diff": 1.08619}
[05/04 16:26:17][INFO] logging.py:  99: json_stats: {"cur_iter": "339", "eta": "0:13:49", "split": "test_iter", "time_diff": 0.85554}
[05/04 16:26:18][INFO] logging.py:  99: json_stats: {"cur_iter": "340", "eta": "0:15:57", "split": "test_iter", "time_diff": 0.98864}
[05/04 16:26:19][INFO] logging.py:  99: json_stats: {"cur_iter": "341", "eta": "0:15:49", "split": "test_iter", "time_diff": 0.98119}
[05/04 16:26:20][INFO] logging.py:  99: json_stats: {"cur_iter": "342", "eta": "0:16:06", "split": "test_iter", "time_diff": 0.99921}
[05/04 16:26:21][INFO] logging.py:  99: json_stats: {"cur_iter": "343", "eta": "0:15:35", "split": "test_iter", "time_diff": 0.96795}
[05/04 16:26:22][INFO] logging.py:  99: json_stats: {"cur_iter": "344", "eta": "0:15:50", "split": "test_iter", "time_diff": 0.98514}
[05/04 16:26:23][INFO] logging.py:  99: json_stats: {"cur_iter": "345", "eta": "0:26:12", "split": "test_iter", "time_diff": 1.63136}
[05/04 16:26:24][INFO] logging.py:  99: json_stats: {"cur_iter": "346", "eta": "0:14:13", "split": "test_iter", "time_diff": 0.88590}
[05/04 16:26:25][INFO] logging.py:  99: json_stats: {"cur_iter": "347", "eta": "0:16:31", "split": "test_iter", "time_diff": 1.03051}
[05/04 16:26:26][INFO] logging.py:  99: json_stats: {"cur_iter": "348", "eta": "0:15:31", "split": "test_iter", "time_diff": 0.96973}
[05/04 16:26:27][INFO] logging.py:  99: json_stats: {"cur_iter": "349", "eta": "0:15:28", "split": "test_iter", "time_diff": 0.96710}
[05/04 16:26:29][INFO] logging.py:  99: json_stats: {"cur_iter": "350", "eta": "0:25:36", "split": "test_iter", "time_diff": 1.60180}
[05/04 16:26:30][INFO] logging.py:  99: json_stats: {"cur_iter": "351", "eta": "0:16:31", "split": "test_iter", "time_diff": 1.03447}
[05/04 16:26:31][INFO] logging.py:  99: json_stats: {"cur_iter": "352", "eta": "0:15:48", "split": "test_iter", "time_diff": 0.99123}
[05/04 16:26:33][INFO] logging.py:  99: json_stats: {"cur_iter": "353", "eta": "0:30:30", "split": "test_iter", "time_diff": 1.91437}
[05/04 16:26:34][INFO] logging.py:  99: json_stats: {"cur_iter": "354", "eta": "0:14:02", "split": "test_iter", "time_diff": 0.88263}
[05/04 16:26:35][INFO] logging.py:  99: json_stats: {"cur_iter": "355", "eta": "0:15:43", "split": "test_iter", "time_diff": 0.98857}
[05/04 16:26:36][INFO] logging.py:  99: json_stats: {"cur_iter": "356", "eta": "0:15:50", "split": "test_iter", "time_diff": 0.99725}
[05/04 16:26:37][INFO] logging.py:  99: json_stats: {"cur_iter": "357", "eta": "0:15:45", "split": "test_iter", "time_diff": 0.99267}
[05/04 16:26:38][INFO] logging.py:  99: json_stats: {"cur_iter": "358", "eta": "0:25:48", "split": "test_iter", "time_diff": 1.62778}
[05/04 16:26:39][INFO] logging.py:  99: json_stats: {"cur_iter": "359", "eta": "0:14:00", "split": "test_iter", "time_diff": 0.88451}
[05/04 16:26:40][INFO] logging.py:  99: json_stats: {"cur_iter": "360", "eta": "0:16:58", "split": "test_iter", "time_diff": 1.07309}
[05/04 16:26:42][INFO] logging.py:  99: json_stats: {"cur_iter": "361", "eta": "0:23:48", "split": "test_iter", "time_diff": 1.50662}
[05/04 16:26:43][INFO] logging.py:  99: json_stats: {"cur_iter": "362", "eta": "0:15:38", "split": "test_iter", "time_diff": 0.99097}
[05/04 16:26:44][INFO] logging.py:  99: json_stats: {"cur_iter": "363", "eta": "0:15:34", "split": "test_iter", "time_diff": 0.98819}
[05/04 16:26:45][INFO] logging.py:  99: json_stats: {"cur_iter": "364", "eta": "0:15:48", "split": "test_iter", "time_diff": 1.00415}
[05/04 16:26:46][INFO] logging.py:  99: json_stats: {"cur_iter": "365", "eta": "0:15:58", "split": "test_iter", "time_diff": 1.01586}
[05/04 16:26:47][INFO] logging.py:  99: json_stats: {"cur_iter": "366", "eta": "0:15:33", "split": "test_iter", "time_diff": 0.99023}
[05/04 16:26:48][INFO] logging.py:  99: json_stats: {"cur_iter": "367", "eta": "0:15:25", "split": "test_iter", "time_diff": 0.98217}
[05/04 16:26:49][INFO] logging.py:  99: json_stats: {"cur_iter": "368", "eta": "0:13:23", "split": "test_iter", "time_diff": 0.85389}
[05/04 16:26:50][INFO] logging.py:  99: json_stats: {"cur_iter": "369", "eta": "0:23:16", "split": "test_iter", "time_diff": 1.48569}
[05/04 16:26:51][INFO] logging.py:  99: json_stats: {"cur_iter": "370", "eta": "0:13:53", "split": "test_iter", "time_diff": 0.88770}
[05/04 16:26:52][INFO] logging.py:  99: json_stats: {"cur_iter": "371", "eta": "0:15:33", "split": "test_iter", "time_diff": 0.99468}
[05/04 16:26:53][INFO] logging.py:  99: json_stats: {"cur_iter": "372", "eta": "0:14:57", "split": "test_iter", "time_diff": 0.95823}
[05/04 16:26:54][INFO] logging.py:  99: json_stats: {"cur_iter": "373", "eta": "0:15:22", "split": "test_iter", "time_diff": 0.98555}
[05/04 16:26:55][INFO] logging.py:  99: json_stats: {"cur_iter": "374", "eta": "0:15:33", "split": "test_iter", "time_diff": 0.99878}
[05/04 16:26:56][INFO] logging.py:  99: json_stats: {"cur_iter": "375", "eta": "0:15:36", "split": "test_iter", "time_diff": 1.00319}
[05/04 16:26:57][INFO] logging.py:  99: json_stats: {"cur_iter": "376", "eta": "0:15:10", "split": "test_iter", "time_diff": 0.97616}
[05/04 16:27:00][INFO] logging.py:  99: json_stats: {"cur_iter": "377", "eta": "0:41:03", "split": "test_iter", "time_diff": 2.64330}
[05/04 16:27:01][INFO] logging.py:  99: json_stats: {"cur_iter": "378", "eta": "0:15:21", "split": "test_iter", "time_diff": 0.99012}
[05/04 16:27:02][INFO] logging.py:  99: json_stats: {"cur_iter": "379", "eta": "0:14:45", "split": "test_iter", "time_diff": 0.95209}
[05/04 16:27:03][INFO] logging.py:  99: json_stats: {"cur_iter": "380", "eta": "0:14:55", "split": "test_iter", "time_diff": 0.96406}
[05/04 16:27:04][INFO] logging.py:  99: json_stats: {"cur_iter": "381", "eta": "0:13:47", "split": "test_iter", "time_diff": 0.89146}
[05/04 16:27:05][INFO] logging.py:  99: json_stats: {"cur_iter": "382", "eta": "0:15:20", "split": "test_iter", "time_diff": 0.99281}
[05/04 16:27:06][INFO] logging.py:  99: json_stats: {"cur_iter": "383", "eta": "0:15:16", "split": "test_iter", "time_diff": 0.98960}
[05/04 16:27:07][INFO] logging.py:  99: json_stats: {"cur_iter": "384", "eta": "0:13:36", "split": "test_iter", "time_diff": 0.88244}
[05/04 16:27:10][INFO] logging.py:  99: json_stats: {"cur_iter": "385", "eta": "0:41:49", "split": "test_iter", "time_diff": 2.71636}
[05/04 16:27:10][INFO] logging.py:  99: json_stats: {"cur_iter": "386", "eta": "0:13:08", "split": "test_iter", "time_diff": 0.85454}
[05/04 16:27:11][INFO] logging.py:  99: json_stats: {"cur_iter": "387", "eta": "0:14:54", "split": "test_iter", "time_diff": 0.97008}
[05/04 16:27:12][INFO] logging.py:  99: json_stats: {"cur_iter": "388", "eta": "0:14:41", "split": "test_iter", "time_diff": 0.95694}
[05/04 16:27:13][INFO] logging.py:  99: json_stats: {"cur_iter": "389", "eta": "0:15:30", "split": "test_iter", "time_diff": 1.01151}
[05/04 16:27:14][INFO] logging.py:  99: json_stats: {"cur_iter": "390", "eta": "0:15:08", "split": "test_iter", "time_diff": 0.98838}
[05/04 16:27:15][INFO] logging.py:  99: json_stats: {"cur_iter": "391", "eta": "0:15:25", "split": "test_iter", "time_diff": 1.00852}
[05/04 16:27:16][INFO] logging.py:  99: json_stats: {"cur_iter": "392", "eta": "0:13:31", "split": "test_iter", "time_diff": 0.88509}
[05/04 16:27:18][INFO] logging.py:  99: json_stats: {"cur_iter": "393", "eta": "0:25:08", "split": "test_iter", "time_diff": 1.64692}
[05/04 16:27:19][INFO] logging.py:  99: json_stats: {"cur_iter": "394", "eta": "0:13:02", "split": "test_iter", "time_diff": 0.85548}
[05/04 16:27:20][INFO] logging.py:  99: json_stats: {"cur_iter": "395", "eta": "0:14:42", "split": "test_iter", "time_diff": 0.96587}
[05/04 16:27:21][INFO] logging.py:  99: json_stats: {"cur_iter": "396", "eta": "0:15:42", "split": "test_iter", "time_diff": 1.03278}
[05/04 16:27:22][INFO] logging.py:  99: json_stats: {"cur_iter": "397", "eta": "0:13:04", "split": "test_iter", "time_diff": 0.86012}
[05/04 16:27:23][INFO] logging.py:  99: json_stats: {"cur_iter": "398", "eta": "0:16:22", "split": "test_iter", "time_diff": 1.07862}
[05/04 16:27:24][INFO] logging.py:  99: json_stats: {"cur_iter": "399", "eta": "0:15:01", "split": "test_iter", "time_diff": 0.99024}
[05/04 16:27:25][INFO] logging.py:  99: json_stats: {"cur_iter": "400", "eta": "0:14:49", "split": "test_iter", "time_diff": 0.97851}
[05/04 16:27:27][INFO] logging.py:  99: json_stats: {"cur_iter": "401", "eta": "0:29:21", "split": "test_iter", "time_diff": 1.94011}
[05/04 16:27:28][INFO] logging.py:  99: json_stats: {"cur_iter": "402", "eta": "0:12:55", "split": "test_iter", "time_diff": 0.85504}
[05/04 16:27:29][INFO] logging.py:  99: json_stats: {"cur_iter": "403", "eta": "0:15:59", "split": "test_iter", "time_diff": 1.05920}
[05/04 16:27:30][INFO] logging.py:  99: json_stats: {"cur_iter": "404", "eta": "0:12:52", "split": "test_iter", "time_diff": 0.85331}
[05/04 16:27:31][INFO] logging.py:  99: json_stats: {"cur_iter": "405", "eta": "0:14:56", "split": "test_iter", "time_diff": 0.99182}
[05/04 16:27:32][INFO] logging.py:  99: json_stats: {"cur_iter": "406", "eta": "0:14:56", "split": "test_iter", "time_diff": 0.99301}
[05/04 16:27:33][INFO] logging.py:  99: json_stats: {"cur_iter": "407", "eta": "0:13:51", "split": "test_iter", "time_diff": 0.92191}
[05/04 16:27:34][INFO] logging.py:  99: json_stats: {"cur_iter": "408", "eta": "0:14:33", "split": "test_iter", "time_diff": 0.96979}
[05/04 16:27:36][INFO] logging.py:  99: json_stats: {"cur_iter": "409", "eta": "0:31:30", "split": "test_iter", "time_diff": 2.10102}
[05/04 16:27:37][INFO] logging.py:  99: json_stats: {"cur_iter": "410", "eta": "0:14:55", "split": "test_iter", "time_diff": 0.99607}
[05/04 16:27:38][INFO] logging.py:  99: json_stats: {"cur_iter": "411", "eta": "0:14:37", "split": "test_iter", "time_diff": 0.97701}
[05/04 16:27:39][INFO] logging.py:  99: json_stats: {"cur_iter": "412", "eta": "0:14:14", "split": "test_iter", "time_diff": 0.95271}
[05/04 16:27:40][INFO] logging.py:  99: json_stats: {"cur_iter": "413", "eta": "0:14:44", "split": "test_iter", "time_diff": 0.98743}
[05/04 16:27:41][INFO] logging.py:  99: json_stats: {"cur_iter": "414", "eta": "0:14:45", "split": "test_iter", "time_diff": 0.98896}
[05/04 16:27:42][INFO] logging.py:  99: json_stats: {"cur_iter": "415", "eta": "0:15:10", "split": "test_iter", "time_diff": 1.01803}
[05/04 16:27:43][INFO] logging.py:  99: json_stats: {"cur_iter": "416", "eta": "0:14:13", "split": "test_iter", "time_diff": 0.95561}
[05/04 16:27:44][INFO] logging.py:  99: json_stats: {"cur_iter": "417", "eta": "0:19:59", "split": "test_iter", "time_diff": 1.34433}
[05/04 16:27:45][INFO] logging.py:  99: json_stats: {"cur_iter": "418", "eta": "0:13:05", "split": "test_iter", "time_diff": 0.88205}
[05/04 16:27:46][INFO] logging.py:  99: json_stats: {"cur_iter": "419", "eta": "0:14:48", "split": "test_iter", "time_diff": 0.99794}
[05/04 16:27:47][INFO] logging.py:  99: json_stats: {"cur_iter": "420", "eta": "0:14:49", "split": "test_iter", "time_diff": 1.00030}
[05/04 16:27:48][INFO] logging.py:  99: json_stats: {"cur_iter": "421", "eta": "0:12:38", "split": "test_iter", "time_diff": 0.85466}
[05/04 16:27:49][INFO] logging.py:  99: json_stats: {"cur_iter": "422", "eta": "0:14:26", "split": "test_iter", "time_diff": 0.97672}
[05/04 16:27:50][INFO] logging.py:  99: json_stats: {"cur_iter": "423", "eta": "0:14:37", "split": "test_iter", "time_diff": 0.99059}
[05/04 16:27:51][INFO] logging.py:  99: json_stats: {"cur_iter": "424", "eta": "0:14:34", "split": "test_iter", "time_diff": 0.98788}
[05/04 16:27:52][INFO] logging.py:  99: json_stats: {"cur_iter": "425", "eta": "0:18:35", "split": "test_iter", "time_diff": 1.26147}
[05/04 16:27:53][INFO] logging.py:  99: json_stats: {"cur_iter": "426", "eta": "0:15:36", "split": "test_iter", "time_diff": 1.06010}
[05/04 16:27:54][INFO] logging.py:  99: json_stats: {"cur_iter": "427", "eta": "0:14:41", "split": "test_iter", "time_diff": 0.99942}
[05/04 16:27:55][INFO] logging.py:  99: json_stats: {"cur_iter": "428", "eta": "0:14:11", "split": "test_iter", "time_diff": 0.96620}
[05/04 16:27:56][INFO] logging.py:  99: json_stats: {"cur_iter": "429", "eta": "0:14:23", "split": "test_iter", "time_diff": 0.98157}
[05/04 16:27:57][INFO] logging.py:  99: json_stats: {"cur_iter": "430", "eta": "0:12:55", "split": "test_iter", "time_diff": 0.88205}
[05/04 16:27:58][INFO] logging.py:  99: json_stats: {"cur_iter": "431", "eta": "0:13:15", "split": "test_iter", "time_diff": 0.90549}
[05/04 16:27:59][INFO] logging.py:  99: json_stats: {"cur_iter": "432", "eta": "0:14:02", "split": "test_iter", "time_diff": 0.96120}
[05/04 16:28:01][INFO] logging.py:  99: json_stats: {"cur_iter": "433", "eta": "0:19:34", "split": "test_iter", "time_diff": 1.34121}
[05/04 16:28:02][INFO] logging.py:  99: json_stats: {"cur_iter": "434", "eta": "0:16:08", "split": "test_iter", "time_diff": 1.10694}
[05/04 16:28:03][INFO] logging.py:  99: json_stats: {"cur_iter": "435", "eta": "0:14:08", "split": "test_iter", "time_diff": 0.97025}
[05/04 16:28:04][INFO] logging.py:  99: json_stats: {"cur_iter": "436", "eta": "0:12:26", "split": "test_iter", "time_diff": 0.85556}
[05/04 16:28:05][INFO] logging.py:  99: json_stats: {"cur_iter": "437", "eta": "0:14:00", "split": "test_iter", "time_diff": 0.96436}
[05/04 16:28:06][INFO] logging.py:  99: json_stats: {"cur_iter": "438", "eta": "0:14:05", "split": "test_iter", "time_diff": 0.97021}
[05/04 16:28:07][INFO] logging.py:  99: json_stats: {"cur_iter": "439", "eta": "0:14:20", "split": "test_iter", "time_diff": 0.98919}
[05/04 16:28:08][INFO] logging.py:  99: json_stats: {"cur_iter": "440", "eta": "0:14:21", "split": "test_iter", "time_diff": 0.99101}
[05/04 16:28:10][INFO] logging.py:  99: json_stats: {"cur_iter": "441", "eta": "0:32:07", "split": "test_iter", "time_diff": 2.22040}
[05/04 16:28:11][INFO] logging.py:  99: json_stats: {"cur_iter": "442", "eta": "0:12:46", "split": "test_iter", "time_diff": 0.88392}
[05/04 16:28:12][INFO] logging.py:  99: json_stats: {"cur_iter": "443", "eta": "0:12:48", "split": "test_iter", "time_diff": 0.88718}
[05/04 16:28:13][INFO] logging.py:  99: json_stats: {"cur_iter": "444", "eta": "0:12:49", "split": "test_iter", "time_diff": 0.88974}
[05/04 16:28:13][INFO] logging.py:  99: json_stats: {"cur_iter": "445", "eta": "0:13:59", "split": "test_iter", "time_diff": 0.97151}
[05/04 16:28:14][INFO] logging.py:  99: json_stats: {"cur_iter": "446", "eta": "0:13:53", "split": "test_iter", "time_diff": 0.96616}
[05/04 16:28:15][INFO] logging.py:  99: json_stats: {"cur_iter": "447", "eta": "0:13:50", "split": "test_iter", "time_diff": 0.96355}
[05/04 16:28:16][INFO] logging.py:  99: json_stats: {"cur_iter": "448", "eta": "0:14:08", "split": "test_iter", "time_diff": 0.98542}
[05/04 16:28:18][INFO] logging.py:  99: json_stats: {"cur_iter": "449", "eta": "0:28:33", "split": "test_iter", "time_diff": 1.99211}
[05/04 16:28:19][INFO] logging.py:  99: json_stats: {"cur_iter": "450", "eta": "0:12:16", "split": "test_iter", "time_diff": 0.85736}
[05/04 16:28:20][INFO] logging.py:  99: json_stats: {"cur_iter": "451", "eta": "0:14:03", "split": "test_iter", "time_diff": 0.98307}
[05/04 16:28:21][INFO] logging.py:  99: json_stats: {"cur_iter": "452", "eta": "0:13:39", "split": "test_iter", "time_diff": 0.95682}
[05/04 16:28:22][INFO] logging.py:  99: json_stats: {"cur_iter": "453", "eta": "0:12:15", "split": "test_iter", "time_diff": 0.85948}
[05/04 16:28:23][INFO] logging.py:  99: json_stats: {"cur_iter": "454", "eta": "0:13:03", "split": "test_iter", "time_diff": 0.91610}
[05/04 16:28:24][INFO] logging.py:  99: json_stats: {"cur_iter": "455", "eta": "0:14:08", "split": "test_iter", "time_diff": 0.99368}
[05/04 16:28:25][INFO] logging.py:  99: json_stats: {"cur_iter": "456", "eta": "0:18:09", "split": "test_iter", "time_diff": 1.27714}
[05/04 16:28:28][INFO] logging.py:  99: json_stats: {"cur_iter": "457", "eta": "0:31:39", "split": "test_iter", "time_diff": 2.22957}
[05/04 16:28:29][INFO] logging.py:  99: json_stats: {"cur_iter": "458", "eta": "0:12:06", "split": "test_iter", "time_diff": 0.85404}
[05/04 16:28:30][INFO] logging.py:  99: json_stats: {"cur_iter": "459", "eta": "0:14:08", "split": "test_iter", "time_diff": 0.99856}
[05/04 16:28:31][INFO] logging.py:  99: json_stats: {"cur_iter": "460", "eta": "0:12:05", "split": "test_iter", "time_diff": 0.85426}
[05/04 16:28:32][INFO] logging.py:  99: json_stats: {"cur_iter": "461", "eta": "0:13:23", "split": "test_iter", "time_diff": 0.94793}
[05/04 16:28:32][INFO] logging.py:  99: json_stats: {"cur_iter": "462", "eta": "0:13:46", "split": "test_iter", "time_diff": 0.97533}
[05/04 16:28:34][INFO] logging.py:  99: json_stats: {"cur_iter": "463", "eta": "0:14:02", "split": "test_iter", "time_diff": 0.99559}
[05/04 16:28:34][INFO] logging.py:  99: json_stats: {"cur_iter": "464", "eta": "0:13:29", "split": "test_iter", "time_diff": 0.95844}
[05/04 16:28:37][INFO] logging.py:  99: json_stats: {"cur_iter": "465", "eta": "0:30:51", "split": "test_iter", "time_diff": 2.19399}
[05/04 16:28:38][INFO] logging.py:  99: json_stats: {"cur_iter": "466", "eta": "0:13:54", "split": "test_iter", "time_diff": 0.99036}
[05/04 16:28:39][INFO] logging.py:  99: json_stats: {"cur_iter": "467", "eta": "0:13:30", "split": "test_iter", "time_diff": 0.96210}
[05/04 16:28:40][INFO] logging.py:  99: json_stats: {"cur_iter": "468", "eta": "0:13:27", "split": "test_iter", "time_diff": 0.96014}
[05/04 16:28:41][INFO] logging.py:  99: json_stats: {"cur_iter": "469", "eta": "0:13:49", "split": "test_iter", "time_diff": 0.98773}
[05/04 16:28:42][INFO] logging.py:  99: json_stats: {"cur_iter": "470", "eta": "0:14:10", "split": "test_iter", "time_diff": 1.01381}
[05/04 16:28:43][INFO] logging.py:  99: json_stats: {"cur_iter": "471", "eta": "0:14:08", "split": "test_iter", "time_diff": 1.01247}
[05/04 16:28:44][INFO] logging.py:  99: json_stats: {"cur_iter": "472", "eta": "0:12:20", "split": "test_iter", "time_diff": 0.88427}
[05/04 16:28:46][INFO] logging.py:  99: json_stats: {"cur_iter": "473", "eta": "0:27:23", "split": "test_iter", "time_diff": 1.96549}
[05/04 16:28:47][INFO] logging.py:  99: json_stats: {"cur_iter": "474", "eta": "0:13:19", "split": "test_iter", "time_diff": 0.95728}
[05/04 16:28:48][INFO] logging.py:  99: json_stats: {"cur_iter": "475", "eta": "0:13:13", "split": "test_iter", "time_diff": 0.95172}
[05/04 16:28:48][INFO] logging.py:  99: json_stats: {"cur_iter": "476", "eta": "0:11:51", "split": "test_iter", "time_diff": 0.85468}
[05/04 16:28:49][INFO] logging.py:  99: json_stats: {"cur_iter": "477", "eta": "0:13:27", "split": "test_iter", "time_diff": 0.97044}
[05/04 16:28:50][INFO] logging.py:  99: json_stats: {"cur_iter": "478", "eta": "0:14:05", "split": "test_iter", "time_diff": 1.01755}
[05/04 16:28:52][INFO] logging.py:  99: json_stats: {"cur_iter": "479", "eta": "0:14:05", "split": "test_iter", "time_diff": 1.01919}
[05/04 16:28:53][INFO] logging.py:  99: json_stats: {"cur_iter": "480", "eta": "0:14:12", "split": "test_iter", "time_diff": 1.02864}
[05/04 16:28:55][INFO] logging.py:  99: json_stats: {"cur_iter": "481", "eta": "0:28:51", "split": "test_iter", "time_diff": 2.09118}
[05/04 16:28:56][INFO] logging.py:  99: json_stats: {"cur_iter": "482", "eta": "0:13:11", "split": "test_iter", "time_diff": 0.95715}
[05/04 16:28:57][INFO] logging.py:  99: json_stats: {"cur_iter": "483", "eta": "0:13:07", "split": "test_iter", "time_diff": 0.95386}
[05/04 16:28:58][INFO] logging.py:  99: json_stats: {"cur_iter": "484", "eta": "0:13:10", "split": "test_iter", "time_diff": 0.95773}
[05/04 16:28:59][INFO] logging.py:  99: json_stats: {"cur_iter": "485", "eta": "0:13:29", "split": "test_iter", "time_diff": 0.98212}
[05/04 16:29:00][INFO] logging.py:  99: json_stats: {"cur_iter": "486", "eta": "0:13:24", "split": "test_iter", "time_diff": 0.97722}
[05/04 16:29:00][INFO] logging.py:  99: json_stats: {"cur_iter": "487", "eta": "0:12:08", "split": "test_iter", "time_diff": 0.88686}
[05/04 16:29:01][INFO] logging.py:  99: json_stats: {"cur_iter": "488", "eta": "0:14:33", "split": "test_iter", "time_diff": 1.06445}
[05/04 16:29:03][INFO] logging.py:  99: json_stats: {"cur_iter": "489", "eta": "0:25:04", "split": "test_iter", "time_diff": 1.83437}
[05/04 16:29:04][INFO] logging.py:  99: json_stats: {"cur_iter": "490", "eta": "0:13:21", "split": "test_iter", "time_diff": 0.97815}
[05/04 16:29:05][INFO] logging.py:  99: json_stats: {"cur_iter": "491", "eta": "0:13:08", "split": "test_iter", "time_diff": 0.96440}
[05/04 16:29:06][INFO] logging.py:  99: json_stats: {"cur_iter": "492", "eta": "0:13:14", "split": "test_iter", "time_diff": 0.97295}
[05/04 16:29:07][INFO] logging.py:  99: json_stats: {"cur_iter": "493", "eta": "0:13:58", "split": "test_iter", "time_diff": 1.02716}
[05/04 16:29:08][INFO] logging.py:  99: json_stats: {"cur_iter": "494", "eta": "0:13:04", "split": "test_iter", "time_diff": 0.96244}
[05/04 16:29:09][INFO] logging.py:  99: json_stats: {"cur_iter": "495", "eta": "0:13:19", "split": "test_iter", "time_diff": 0.98195}
[05/04 16:29:10][INFO] logging.py:  99: json_stats: {"cur_iter": "496", "eta": "0:14:05", "split": "test_iter", "time_diff": 1.03939}
[05/04 16:29:12][INFO] logging.py:  99: json_stats: {"cur_iter": "497", "eta": "0:26:10", "split": "test_iter", "time_diff": 1.93360}
[05/04 16:29:13][INFO] logging.py:  99: json_stats: {"cur_iter": "498", "eta": "0:13:17", "split": "test_iter", "time_diff": 0.98350}
[05/04 16:29:14][INFO] logging.py:  99: json_stats: {"cur_iter": "499", "eta": "0:12:59", "split": "test_iter", "time_diff": 0.96251}
[05/04 16:29:15][INFO] logging.py:  99: json_stats: {"cur_iter": "500", "eta": "0:13:02", "split": "test_iter", "time_diff": 0.96678}
[05/04 16:29:16][INFO] logging.py:  99: json_stats: {"cur_iter": "501", "eta": "0:13:03", "split": "test_iter", "time_diff": 0.96915}
[05/04 16:29:17][INFO] logging.py:  99: json_stats: {"cur_iter": "502", "eta": "0:13:13", "split": "test_iter", "time_diff": 0.98336}
[05/04 16:29:18][INFO] logging.py:  99: json_stats: {"cur_iter": "503", "eta": "0:13:16", "split": "test_iter", "time_diff": 0.98866}
[05/04 16:29:19][INFO] logging.py:  99: json_stats: {"cur_iter": "504", "eta": "0:13:38", "split": "test_iter", "time_diff": 1.01722}
[05/04 16:29:21][INFO] logging.py:  99: json_stats: {"cur_iter": "505", "eta": "0:26:29", "split": "test_iter", "time_diff": 1.97751}
[05/04 16:29:22][INFO] logging.py:  99: json_stats: {"cur_iter": "506", "eta": "0:11:26", "split": "test_iter", "time_diff": 0.85540}
[05/04 16:29:23][INFO] logging.py:  99: json_stats: {"cur_iter": "507", "eta": "0:12:51", "split": "test_iter", "time_diff": 0.96159}
[05/04 16:29:24][INFO] logging.py:  99: json_stats: {"cur_iter": "508", "eta": "0:13:08", "split": "test_iter", "time_diff": 0.98417}
[05/04 16:29:25][INFO] logging.py:  99: json_stats: {"cur_iter": "509", "eta": "0:13:49", "split": "test_iter", "time_diff": 1.03697}
[05/04 16:29:26][INFO] logging.py:  99: json_stats: {"cur_iter": "510", "eta": "0:13:15", "split": "test_iter", "time_diff": 0.99586}
[05/04 16:29:27][INFO] logging.py:  99: json_stats: {"cur_iter": "511", "eta": "0:13:02", "split": "test_iter", "time_diff": 0.98088}
[05/04 16:29:28][INFO] logging.py:  99: json_stats: {"cur_iter": "512", "eta": "0:13:14", "split": "test_iter", "time_diff": 0.99630}
[05/04 16:29:30][INFO] logging.py:  99: json_stats: {"cur_iter": "513", "eta": "0:20:50", "split": "test_iter", "time_diff": 1.57094}
[05/04 16:29:31][INFO] logging.py:  99: json_stats: {"cur_iter": "514", "eta": "0:12:59", "split": "test_iter", "time_diff": 0.98049}
[05/04 16:29:32][INFO] logging.py:  99: json_stats: {"cur_iter": "515", "eta": "0:12:45", "split": "test_iter", "time_diff": 0.96423}
[05/04 16:29:33][INFO] logging.py:  99: json_stats: {"cur_iter": "516", "eta": "0:14:28", "split": "test_iter", "time_diff": 1.09550}
[05/04 16:29:34][INFO] logging.py:  99: json_stats: {"cur_iter": "517", "eta": "0:13:29", "split": "test_iter", "time_diff": 1.02221}
[05/04 16:29:35][INFO] logging.py:  99: json_stats: {"cur_iter": "518", "eta": "0:11:15", "split": "test_iter", "time_diff": 0.85459}
[05/04 16:29:36][INFO] logging.py:  99: json_stats: {"cur_iter": "519", "eta": "0:12:41", "split": "test_iter", "time_diff": 0.96340}
[05/04 16:29:37][INFO] logging.py:  99: json_stats: {"cur_iter": "520", "eta": "0:14:48", "split": "test_iter", "time_diff": 1.12553}
[05/04 16:29:38][INFO] logging.py:  99: json_stats: {"cur_iter": "521", "eta": "0:16:21", "split": "test_iter", "time_diff": 1.24571}
[05/04 16:29:39][INFO] logging.py:  99: json_stats: {"cur_iter": "522", "eta": "0:11:11", "split": "test_iter", "time_diff": 0.85387}
[05/04 16:29:40][INFO] logging.py:  99: json_stats: {"cur_iter": "523", "eta": "0:15:40", "split": "test_iter", "time_diff": 1.19630}
[05/04 16:29:41][INFO] logging.py:  99: json_stats: {"cur_iter": "524", "eta": "0:13:03", "split": "test_iter", "time_diff": 0.99769}
[05/04 16:29:42][INFO] logging.py:  99: json_stats: {"cur_iter": "525", "eta": "0:12:28", "split": "test_iter", "time_diff": 0.95527}
[05/04 16:29:43][INFO] logging.py:  99: json_stats: {"cur_iter": "526", "eta": "0:12:52", "split": "test_iter", "time_diff": 0.98668}
[05/04 16:29:44][INFO] logging.py:  99: json_stats: {"cur_iter": "527", "eta": "0:13:41", "split": "test_iter", "time_diff": 1.05109}
[05/04 16:29:45][INFO] logging.py:  99: json_stats: {"cur_iter": "528", "eta": "0:11:26", "split": "test_iter", "time_diff": 0.87938}
[05/04 16:29:47][INFO] logging.py:  99: json_stats: {"cur_iter": "529", "eta": "0:27:57", "split": "test_iter", "time_diff": 2.15124}
[05/04 16:29:48][INFO] logging.py:  99: json_stats: {"cur_iter": "530", "eta": "0:11:29", "split": "test_iter", "time_diff": 0.88485}
[05/04 16:29:49][INFO] logging.py:  99: json_stats: {"cur_iter": "531", "eta": "0:16:36", "split": "test_iter", "time_diff": 1.28051}
[05/04 16:29:50][INFO] logging.py:  99: json_stats: {"cur_iter": "532", "eta": "0:12:32", "split": "test_iter", "time_diff": 0.96906}
[05/04 16:29:51][INFO] logging.py:  99: json_stats: {"cur_iter": "533", "eta": "0:12:41", "split": "test_iter", "time_diff": 0.98094}
[05/04 16:29:52][INFO] logging.py:  99: json_stats: {"cur_iter": "534", "eta": "0:12:42", "split": "test_iter", "time_diff": 0.98337}
[05/04 16:29:54][INFO] logging.py:  99: json_stats: {"cur_iter": "535", "eta": "0:12:22", "split": "test_iter", "time_diff": 0.95959}
[05/04 16:29:54][INFO] logging.py:  99: json_stats: {"cur_iter": "536", "eta": "0:11:23", "split": "test_iter", "time_diff": 0.88453}
[05/04 16:29:56][INFO] logging.py:  99: json_stats: {"cur_iter": "537", "eta": "0:26:55", "split": "test_iter", "time_diff": 2.09217}
[05/04 16:29:57][INFO] logging.py:  99: json_stats: {"cur_iter": "538", "eta": "0:12:37", "split": "test_iter", "time_diff": 0.98278}
[05/04 16:29:59][INFO] logging.py:  99: json_stats: {"cur_iter": "539", "eta": "0:20:30", "split": "test_iter", "time_diff": 1.59775}
[05/04 16:30:00][INFO] logging.py:  99: json_stats: {"cur_iter": "540", "eta": "0:12:23", "split": "test_iter", "time_diff": 0.96658}
[05/04 16:30:01][INFO] logging.py:  99: json_stats: {"cur_iter": "541", "eta": "0:12:25", "split": "test_iter", "time_diff": 0.97061}
[05/04 16:30:02][INFO] logging.py:  99: json_stats: {"cur_iter": "542", "eta": "0:10:55", "split": "test_iter", "time_diff": 0.85476}
[05/04 16:30:03][INFO] logging.py:  99: json_stats: {"cur_iter": "543", "eta": "0:13:07", "split": "test_iter", "time_diff": 1.02809}
[05/04 16:30:04][INFO] logging.py:  99: json_stats: {"cur_iter": "544", "eta": "0:13:56", "split": "test_iter", "time_diff": 1.09360}
[05/04 16:30:06][INFO] logging.py:  99: json_stats: {"cur_iter": "545", "eta": "0:20:23", "split": "test_iter", "time_diff": 1.60157}
[05/04 16:30:07][INFO] logging.py:  99: json_stats: {"cur_iter": "546", "eta": "0:12:37", "split": "test_iter", "time_diff": 0.99338}
[05/04 16:30:08][INFO] logging.py:  99: json_stats: {"cur_iter": "547", "eta": "0:21:38", "split": "test_iter", "time_diff": 1.70432}
[05/04 16:30:09][INFO] logging.py:  99: json_stats: {"cur_iter": "548", "eta": "0:12:03", "split": "test_iter", "time_diff": 0.95049}
[05/04 16:30:10][INFO] logging.py:  99: json_stats: {"cur_iter": "549", "eta": "0:11:13", "split": "test_iter", "time_diff": 0.88627}
[05/04 16:30:11][INFO] logging.py:  99: json_stats: {"cur_iter": "550", "eta": "0:11:13", "split": "test_iter", "time_diff": 0.88681}
[05/04 16:30:12][INFO] logging.py:  99: json_stats: {"cur_iter": "551", "eta": "0:13:44", "split": "test_iter", "time_diff": 1.08752}
[05/04 16:30:13][INFO] logging.py:  99: json_stats: {"cur_iter": "552", "eta": "0:12:43", "split": "test_iter", "time_diff": 1.00808}
[05/04 16:30:15][INFO] logging.py:  99: json_stats: {"cur_iter": "553", "eta": "0:19:28", "split": "test_iter", "time_diff": 1.54628}
[05/04 16:30:16][INFO] logging.py:  99: json_stats: {"cur_iter": "554", "eta": "0:11:07", "split": "test_iter", "time_diff": 0.88353}
[05/04 16:30:19][INFO] logging.py:  99: json_stats: {"cur_iter": "555", "eta": "0:38:26", "split": "test_iter", "time_diff": 3.05860}
[05/04 16:30:20][INFO] logging.py:  99: json_stats: {"cur_iter": "556", "eta": "0:13:21", "split": "test_iter", "time_diff": 1.06464}
[05/04 16:30:21][INFO] logging.py:  99: json_stats: {"cur_iter": "557", "eta": "0:12:13", "split": "test_iter", "time_diff": 0.97489}
[05/04 16:30:22][INFO] logging.py:  99: json_stats: {"cur_iter": "558", "eta": "0:12:39", "split": "test_iter", "time_diff": 1.01196}
[05/04 16:30:23][INFO] logging.py:  99: json_stats: {"cur_iter": "559", "eta": "0:10:44", "split": "test_iter", "time_diff": 0.85896}
[05/04 16:30:24][INFO] logging.py:  99: json_stats: {"cur_iter": "560", "eta": "0:21:48", "split": "test_iter", "time_diff": 1.74705}
[05/04 16:30:25][INFO] logging.py:  99: json_stats: {"cur_iter": "561", "eta": "0:12:03", "split": "test_iter", "time_diff": 0.96769}
[05/04 16:30:26][INFO] logging.py:  99: json_stats: {"cur_iter": "562", "eta": "0:12:15", "split": "test_iter", "time_diff": 0.98397}
[05/04 16:30:28][INFO] logging.py:  99: json_stats: {"cur_iter": "563", "eta": "0:22:39", "split": "test_iter", "time_diff": 1.82303}
[05/04 16:30:29][INFO] logging.py:  99: json_stats: {"cur_iter": "564", "eta": "0:13:18", "split": "test_iter", "time_diff": 1.07201}
[05/04 16:30:30][INFO] logging.py:  99: json_stats: {"cur_iter": "565", "eta": "0:12:17", "split": "test_iter", "time_diff": 0.99086}
[05/04 16:30:31][INFO] logging.py:  99: json_stats: {"cur_iter": "566", "eta": "0:12:02", "split": "test_iter", "time_diff": 0.97270}
[05/04 16:30:32][INFO] logging.py:  99: json_stats: {"cur_iter": "567", "eta": "0:10:55", "split": "test_iter", "time_diff": 0.88406}
[05/04 16:30:33][INFO] logging.py:  99: json_stats: {"cur_iter": "568", "eta": "0:12:09", "split": "test_iter", "time_diff": 0.98485}
[05/04 16:30:34][INFO] logging.py:  99: json_stats: {"cur_iter": "569", "eta": "0:11:58", "split": "test_iter", "time_diff": 0.97081}
[05/04 16:30:35][INFO] logging.py:  99: json_stats: {"cur_iter": "570", "eta": "0:12:13", "split": "test_iter", "time_diff": 0.99246}
[05/04 16:30:37][INFO] logging.py:  99: json_stats: {"cur_iter": "571", "eta": "0:23:01", "split": "test_iter", "time_diff": 1.87180}
[05/04 16:30:38][INFO] logging.py:  99: json_stats: {"cur_iter": "572", "eta": "0:11:56", "split": "test_iter", "time_diff": 0.97169}
[05/04 16:30:39][INFO] logging.py:  99: json_stats: {"cur_iter": "573", "eta": "0:12:13", "split": "test_iter", "time_diff": 0.99635}
[05/04 16:30:40][INFO] logging.py:  99: json_stats: {"cur_iter": "574", "eta": "0:12:11", "split": "test_iter", "time_diff": 0.99572}
[05/04 16:30:41][INFO] logging.py:  99: json_stats: {"cur_iter": "575", "eta": "0:10:49", "split": "test_iter", "time_diff": 0.88468}
[05/04 16:30:42][INFO] logging.py:  99: json_stats: {"cur_iter": "576", "eta": "0:12:14", "split": "test_iter", "time_diff": 1.00142}
[05/04 16:30:43][INFO] logging.py:  99: json_stats: {"cur_iter": "577", "eta": "0:14:22", "split": "test_iter", "time_diff": 1.17810}
[05/04 16:30:44][INFO] logging.py:  99: json_stats: {"cur_iter": "578", "eta": "0:13:04", "split": "test_iter", "time_diff": 1.07358}
[05/04 16:30:46][INFO] logging.py:  99: json_stats: {"cur_iter": "579", "eta": "0:19:45", "split": "test_iter", "time_diff": 1.62428}
[05/04 16:30:47][INFO] logging.py:  99: json_stats: {"cur_iter": "580", "eta": "0:12:00", "split": "test_iter", "time_diff": 0.98805}
[05/04 16:30:48][INFO] logging.py:  99: json_stats: {"cur_iter": "581", "eta": "0:12:09", "split": "test_iter", "time_diff": 1.00261}
[05/04 16:30:49][INFO] logging.py:  99: json_stats: {"cur_iter": "582", "eta": "0:11:32", "split": "test_iter", "time_diff": 0.95285}
[05/04 16:30:50][INFO] logging.py:  99: json_stats: {"cur_iter": "583", "eta": "0:10:44", "split": "test_iter", "time_diff": 0.88715}
[05/04 16:30:51][INFO] logging.py:  99: json_stats: {"cur_iter": "584", "eta": "0:12:12", "split": "test_iter", "time_diff": 1.01038}
[05/04 16:30:52][INFO] logging.py:  99: json_stats: {"cur_iter": "585", "eta": "0:12:47", "split": "test_iter", "time_diff": 1.06049}
[05/04 16:30:53][INFO] logging.py:  99: json_stats: {"cur_iter": "586", "eta": "0:11:46", "split": "test_iter", "time_diff": 0.97728}
[05/04 16:30:54][INFO] logging.py:  99: json_stats: {"cur_iter": "587", "eta": "0:18:51", "split": "test_iter", "time_diff": 1.56742}
[05/04 16:30:55][INFO] logging.py:  99: json_stats: {"cur_iter": "588", "eta": "0:10:36", "split": "test_iter", "time_diff": 0.88326}
[05/04 16:30:56][INFO] logging.py:  99: json_stats: {"cur_iter": "589", "eta": "0:11:31", "split": "test_iter", "time_diff": 0.96109}
[05/04 16:30:57][INFO] logging.py:  99: json_stats: {"cur_iter": "590", "eta": "0:12:08", "split": "test_iter", "time_diff": 1.01361}
[05/04 16:30:58][INFO] logging.py:  99: json_stats: {"cur_iter": "591", "eta": "0:11:33", "split": "test_iter", "time_diff": 0.96525}
[05/04 16:30:59][INFO] logging.py:  99: json_stats: {"cur_iter": "592", "eta": "0:10:25", "split": "test_iter", "time_diff": 0.87305}
[05/04 16:31:00][INFO] logging.py:  99: json_stats: {"cur_iter": "593", "eta": "0:12:48", "split": "test_iter", "time_diff": 1.07328}
[05/04 16:31:01][INFO] logging.py:  99: json_stats: {"cur_iter": "594", "eta": "0:11:45", "split": "test_iter", "time_diff": 0.98641}
[05/04 16:31:02][INFO] logging.py:  99: json_stats: {"cur_iter": "595", "eta": "0:15:22", "split": "test_iter", "time_diff": 1.29229}
[05/04 16:31:04][INFO] logging.py:  99: json_stats: {"cur_iter": "596", "eta": "0:13:18", "split": "test_iter", "time_diff": 1.11937}
[05/04 16:31:04][INFO] logging.py:  99: json_stats: {"cur_iter": "597", "eta": "0:10:07", "split": "test_iter", "time_diff": 0.85382}
[05/04 16:31:05][INFO] logging.py:  99: json_stats: {"cur_iter": "598", "eta": "0:12:43", "split": "test_iter", "time_diff": 1.07394}
[05/04 16:31:06][INFO] logging.py:  99: json_stats: {"cur_iter": "599", "eta": "0:11:26", "split": "test_iter", "time_diff": 0.96646}
[05/04 16:31:07][INFO] logging.py:  99: json_stats: {"cur_iter": "600", "eta": "0:11:48", "split": "test_iter", "time_diff": 0.99881}
[05/04 16:31:08][INFO] logging.py:  99: json_stats: {"cur_iter": "601", "eta": "0:10:20", "split": "test_iter", "time_diff": 0.87665}
[05/04 16:31:09][INFO] logging.py:  99: json_stats: {"cur_iter": "602", "eta": "0:12:53", "split": "test_iter", "time_diff": 1.09463}
[05/04 16:31:11][INFO] logging.py:  99: json_stats: {"cur_iter": "603", "eta": "0:17:37", "split": "test_iter", "time_diff": 1.49845}
[05/04 16:31:12][INFO] logging.py:  99: json_stats: {"cur_iter": "604", "eta": "0:11:35", "split": "test_iter", "time_diff": 0.98677}
[05/04 16:31:13][INFO] logging.py:  99: json_stats: {"cur_iter": "605", "eta": "0:11:20", "split": "test_iter", "time_diff": 0.96625}
[05/04 16:31:14][INFO] logging.py:  99: json_stats: {"cur_iter": "606", "eta": "0:10:37", "split": "test_iter", "time_diff": 0.90719}
[05/04 16:31:15][INFO] logging.py:  99: json_stats: {"cur_iter": "607", "eta": "0:10:19", "split": "test_iter", "time_diff": 0.88243}
[05/04 16:31:16][INFO] logging.py:  99: json_stats: {"cur_iter": "608", "eta": "0:15:02", "split": "test_iter", "time_diff": 1.28692}
[05/04 16:31:18][INFO] logging.py:  99: json_stats: {"cur_iter": "609", "eta": "0:18:10", "split": "test_iter", "time_diff": 1.55724}
[05/04 16:31:19][INFO] logging.py:  99: json_stats: {"cur_iter": "610", "eta": "0:12:40", "split": "test_iter", "time_diff": 1.08777}
[05/04 16:31:20][INFO] logging.py:  99: json_stats: {"cur_iter": "611", "eta": "0:16:08", "split": "test_iter", "time_diff": 1.38767}
[05/04 16:31:21][INFO] logging.py:  99: json_stats: {"cur_iter": "612", "eta": "0:11:03", "split": "test_iter", "time_diff": 0.95222}
[05/04 16:31:22][INFO] logging.py:  99: json_stats: {"cur_iter": "613", "eta": "0:09:56", "split": "test_iter", "time_diff": 0.85633}
[05/04 16:31:23][INFO] logging.py:  99: json_stats: {"cur_iter": "614", "eta": "0:11:39", "split": "test_iter", "time_diff": 1.00625}
[05/04 16:31:24][INFO] logging.py:  99: json_stats: {"cur_iter": "615", "eta": "0:11:16", "split": "test_iter", "time_diff": 0.97520}
[05/04 16:31:25][INFO] logging.py:  99: json_stats: {"cur_iter": "616", "eta": "0:10:10", "split": "test_iter", "time_diff": 0.88101}
[05/04 16:31:27][INFO] logging.py:  99: json_stats: {"cur_iter": "617", "eta": "0:26:59", "split": "test_iter", "time_diff": 2.33973}
[05/04 16:31:28][INFO] logging.py:  99: json_stats: {"cur_iter": "618", "eta": "0:10:10", "split": "test_iter", "time_diff": 0.88413}
[05/04 16:31:29][INFO] logging.py:  99: json_stats: {"cur_iter": "619", "eta": "0:11:03", "split": "test_iter", "time_diff": 0.96165}
[05/04 16:31:30][INFO] logging.py:  99: json_stats: {"cur_iter": "620", "eta": "0:10:56", "split": "test_iter", "time_diff": 0.95250}
[05/04 16:31:31][INFO] logging.py:  99: json_stats: {"cur_iter": "621", "eta": "0:11:23", "split": "test_iter", "time_diff": 0.99332}
[05/04 16:31:32][INFO] logging.py:  99: json_stats: {"cur_iter": "622", "eta": "0:11:29", "split": "test_iter", "time_diff": 1.00373}
[05/04 16:31:33][INFO] logging.py:  99: json_stats: {"cur_iter": "623", "eta": "0:12:15", "split": "test_iter", "time_diff": 1.07167}
[05/04 16:31:34][INFO] logging.py:  99: json_stats: {"cur_iter": "624", "eta": "0:09:45", "split": "test_iter", "time_diff": 0.85438}
[05/04 16:31:36][INFO] logging.py:  99: json_stats: {"cur_iter": "625", "eta": "0:17:32", "split": "test_iter", "time_diff": 1.53925}
[05/04 16:31:37][INFO] logging.py:  99: json_stats: {"cur_iter": "626", "eta": "0:10:54", "split": "test_iter", "time_diff": 0.95781}
[05/04 16:31:38][INFO] logging.py:  99: json_stats: {"cur_iter": "627", "eta": "0:10:03", "split": "test_iter", "time_diff": 0.88479}
[05/04 16:31:39][INFO] logging.py:  99: json_stats: {"cur_iter": "628", "eta": "0:09:43", "split": "test_iter", "time_diff": 0.85634}
[05/04 16:31:40][INFO] logging.py:  99: json_stats: {"cur_iter": "629", "eta": "0:11:08", "split": "test_iter", "time_diff": 0.98328}
[05/04 16:31:41][INFO] logging.py:  99: json_stats: {"cur_iter": "630", "eta": "0:10:47", "split": "test_iter", "time_diff": 0.95418}
[05/04 16:31:42][INFO] logging.py:  99: json_stats: {"cur_iter": "631", "eta": "0:10:54", "split": "test_iter", "time_diff": 0.96577}
[05/04 16:31:43][INFO] logging.py:  99: json_stats: {"cur_iter": "632", "eta": "0:14:15", "split": "test_iter", "time_diff": 1.26323}
[05/04 16:31:46][INFO] logging.py:  99: json_stats: {"cur_iter": "633", "eta": "0:31:00", "split": "test_iter", "time_diff": 2.75226}
[05/04 16:31:47][INFO] logging.py:  99: json_stats: {"cur_iter": "634", "eta": "0:10:49", "split": "test_iter", "time_diff": 0.96229}
[05/04 16:31:48][INFO] logging.py:  99: json_stats: {"cur_iter": "635", "eta": "0:11:05", "split": "test_iter", "time_diff": 0.98743}
[05/04 16:31:48][INFO] logging.py:  99: json_stats: {"cur_iter": "636", "eta": "0:10:35", "split": "test_iter", "time_diff": 0.94440}
[05/04 16:31:49][INFO] logging.py:  99: json_stats: {"cur_iter": "637", "eta": "0:11:06", "split": "test_iter", "time_diff": 0.99224}
[05/04 16:31:50][INFO] logging.py:  99: json_stats: {"cur_iter": "638", "eta": "0:09:47", "split": "test_iter", "time_diff": 0.87622}
[05/04 16:31:51][INFO] logging.py:  99: json_stats: {"cur_iter": "639", "eta": "0:12:02", "split": "test_iter", "time_diff": 1.07884}
[05/04 16:31:52][INFO] logging.py:  99: json_stats: {"cur_iter": "640", "eta": "0:11:17", "split": "test_iter", "time_diff": 1.01245}
[05/04 16:31:54][INFO] logging.py:  99: json_stats: {"cur_iter": "641", "eta": "0:20:16", "split": "test_iter", "time_diff": 1.82116}
[05/04 16:31:55][INFO] logging.py:  99: json_stats: {"cur_iter": "642", "eta": "0:09:49", "split": "test_iter", "time_diff": 0.88414}
[05/04 16:31:56][INFO] logging.py:  99: json_stats: {"cur_iter": "643", "eta": "0:09:49", "split": "test_iter", "time_diff": 0.88495}
[05/04 16:31:57][INFO] logging.py:  99: json_stats: {"cur_iter": "644", "eta": "0:10:57", "split": "test_iter", "time_diff": 0.98924}
[05/04 16:31:58][INFO] logging.py:  99: json_stats: {"cur_iter": "645", "eta": "0:10:41", "split": "test_iter", "time_diff": 0.96638}
[05/04 16:31:59][INFO] logging.py:  99: json_stats: {"cur_iter": "646", "eta": "0:10:59", "split": "test_iter", "time_diff": 0.99487}
[05/04 16:32:00][INFO] logging.py:  99: json_stats: {"cur_iter": "647", "eta": "0:09:44", "split": "test_iter", "time_diff": 0.88246}
[05/04 16:32:02][INFO] logging.py:  99: json_stats: {"cur_iter": "648", "eta": "0:18:14", "split": "test_iter", "time_diff": 1.65587}
[05/04 16:32:04][INFO] logging.py:  99: json_stats: {"cur_iter": "649", "eta": "0:27:26", "split": "test_iter", "time_diff": 2.49541}
[05/04 16:32:05][INFO] logging.py:  99: json_stats: {"cur_iter": "650", "eta": "0:09:40", "split": "test_iter", "time_diff": 0.88104}
[05/04 16:32:06][INFO] logging.py:  99: json_stats: {"cur_iter": "651", "eta": "0:10:48", "split": "test_iter", "time_diff": 0.98566}
[05/04 16:32:07][INFO] logging.py:  99: json_stats: {"cur_iter": "652", "eta": "0:10:40", "split": "test_iter", "time_diff": 0.97485}
[05/04 16:32:08][INFO] logging.py:  99: json_stats: {"cur_iter": "653", "eta": "0:10:55", "split": "test_iter", "time_diff": 0.99876}
[05/04 16:32:09][INFO] logging.py:  99: json_stats: {"cur_iter": "654", "eta": "0:09:29", "split": "test_iter", "time_diff": 0.86892}
[05/04 16:32:10][INFO] logging.py:  99: json_stats: {"cur_iter": "655", "eta": "0:10:53", "split": "test_iter", "time_diff": 0.99962}
[05/04 16:32:12][INFO] logging.py:  99: json_stats: {"cur_iter": "656", "eta": "0:23:44", "split": "test_iter", "time_diff": 2.18084}
[05/04 16:32:14][INFO] logging.py:  99: json_stats: {"cur_iter": "657", "eta": "0:21:48", "split": "test_iter", "time_diff": 2.00675}
[05/04 16:32:15][INFO] logging.py:  99: json_stats: {"cur_iter": "658", "eta": "0:10:49", "split": "test_iter", "time_diff": 0.99799}
[05/04 16:32:16][INFO] logging.py:  99: json_stats: {"cur_iter": "659", "eta": "0:10:41", "split": "test_iter", "time_diff": 0.98693}
[05/04 16:32:17][INFO] logging.py:  99: json_stats: {"cur_iter": "660", "eta": "0:10:48", "split": "test_iter", "time_diff": 0.99905}
[05/04 16:32:18][INFO] logging.py:  99: json_stats: {"cur_iter": "661", "eta": "0:09:22", "split": "test_iter", "time_diff": 0.86831}
[05/04 16:32:19][INFO] logging.py:  99: json_stats: {"cur_iter": "662", "eta": "0:10:37", "split": "test_iter", "time_diff": 0.98494}
[05/04 16:32:20][INFO] logging.py:  99: json_stats: {"cur_iter": "663", "eta": "0:10:18", "split": "test_iter", "time_diff": 0.95789}
[05/04 16:32:21][INFO] logging.py:  99: json_stats: {"cur_iter": "664", "eta": "0:16:17", "split": "test_iter", "time_diff": 1.51505}
[05/04 16:32:26][INFO] logging.py:  99: json_stats: {"cur_iter": "665", "eta": "0:50:47", "split": "test_iter", "time_diff": 4.73179}
[05/04 16:32:27][INFO] logging.py:  99: json_stats: {"cur_iter": "666", "eta": "0:09:09", "split": "test_iter", "time_diff": 0.85489}
[05/04 16:32:28][INFO] logging.py:  99: json_stats: {"cur_iter": "667", "eta": "0:09:27", "split": "test_iter", "time_diff": 0.88390}
[05/04 16:32:29][INFO] logging.py:  99: json_stats: {"cur_iter": "668", "eta": "0:10:39", "split": "test_iter", "time_diff": 0.99705}
[05/04 16:32:30][INFO] logging.py:  99: json_stats: {"cur_iter": "669", "eta": "0:10:24", "split": "test_iter", "time_diff": 0.97606}
[05/04 16:32:31][INFO] logging.py:  99: json_stats: {"cur_iter": "670", "eta": "0:12:07", "split": "test_iter", "time_diff": 1.13805}
[05/04 16:32:32][INFO] logging.py:  99: json_stats: {"cur_iter": "671", "eta": "0:09:06", "split": "test_iter", "time_diff": 0.85628}
[05/04 16:32:34][INFO] logging.py:  99: json_stats: {"cur_iter": "672", "eta": "0:16:21", "split": "test_iter", "time_diff": 1.54123}
[05/04 16:32:35][INFO] logging.py:  99: json_stats: {"cur_iter": "673", "eta": "0:17:26", "split": "test_iter", "time_diff": 1.64587}
[05/04 16:32:36][INFO] logging.py:  99: json_stats: {"cur_iter": "674", "eta": "0:10:15", "split": "test_iter", "time_diff": 0.96975}
[05/04 16:32:37][INFO] logging.py:  99: json_stats: {"cur_iter": "675", "eta": "0:10:40", "split": "test_iter", "time_diff": 1.01091}
[05/04 16:32:38][INFO] logging.py:  99: json_stats: {"cur_iter": "676", "eta": "0:10:34", "split": "test_iter", "time_diff": 1.00210}
[05/04 16:32:39][INFO] logging.py:  99: json_stats: {"cur_iter": "677", "eta": "0:09:14", "split": "test_iter", "time_diff": 0.87765}
[05/04 16:32:40][INFO] logging.py:  99: json_stats: {"cur_iter": "678", "eta": "0:09:17", "split": "test_iter", "time_diff": 0.88344}
[05/04 16:32:41][INFO] logging.py:  99: json_stats: {"cur_iter": "679", "eta": "0:10:07", "split": "test_iter", "time_diff": 0.96491}
[05/04 16:32:43][INFO] logging.py:  99: json_stats: {"cur_iter": "680", "eta": "0:17:10", "split": "test_iter", "time_diff": 1.63894}
[05/04 16:32:45][INFO] logging.py:  99: json_stats: {"cur_iter": "681", "eta": "0:23:43", "split": "test_iter", "time_diff": 2.26598}
[05/04 16:32:46][INFO] logging.py:  99: json_stats: {"cur_iter": "682", "eta": "0:11:21", "split": "test_iter", "time_diff": 1.08622}
[05/04 16:32:47][INFO] logging.py:  99: json_stats: {"cur_iter": "683", "eta": "0:10:19", "split": "test_iter", "time_diff": 0.99027}
[05/04 16:32:48][INFO] logging.py:  99: json_stats: {"cur_iter": "684", "eta": "0:09:01", "split": "test_iter", "time_diff": 0.86691}
[05/04 16:32:49][INFO] logging.py:  99: json_stats: {"cur_iter": "685", "eta": "0:10:04", "split": "test_iter", "time_diff": 0.96880}
[05/04 16:32:50][INFO] logging.py:  99: json_stats: {"cur_iter": "686", "eta": "0:10:08", "split": "test_iter", "time_diff": 0.97645}
[05/04 16:32:51][INFO] logging.py:  99: json_stats: {"cur_iter": "687", "eta": "0:09:53", "split": "test_iter", "time_diff": 0.95474}
[05/04 16:32:52][INFO] logging.py:  99: json_stats: {"cur_iter": "688", "eta": "0:14:14", "split": "test_iter", "time_diff": 1.37604}
[05/04 16:32:54][INFO] logging.py:  99: json_stats: {"cur_iter": "689", "eta": "0:17:35", "split": "test_iter", "time_diff": 1.70304}
[05/04 16:32:55][INFO] logging.py:  99: json_stats: {"cur_iter": "690", "eta": "0:10:58", "split": "test_iter", "time_diff": 1.06391}
[05/04 16:32:56][INFO] logging.py:  99: json_stats: {"cur_iter": "691", "eta": "0:08:47", "split": "test_iter", "time_diff": 0.85422}
[05/04 16:32:57][INFO] logging.py:  99: json_stats: {"cur_iter": "692", "eta": "0:10:11", "split": "test_iter", "time_diff": 0.99176}
[05/04 16:32:58][INFO] logging.py:  99: json_stats: {"cur_iter": "693", "eta": "0:09:03", "split": "test_iter", "time_diff": 0.88290}
[05/04 16:32:59][INFO] logging.py:  99: json_stats: {"cur_iter": "694", "eta": "0:09:54", "split": "test_iter", "time_diff": 0.96643}
[05/04 16:33:00][INFO] logging.py:  99: json_stats: {"cur_iter": "695", "eta": "0:10:49", "split": "test_iter", "time_diff": 1.05855}
[05/04 16:33:01][INFO] logging.py:  99: json_stats: {"cur_iter": "696", "eta": "0:10:10", "split": "test_iter", "time_diff": 0.99574}
[05/04 16:33:03][INFO] logging.py:  99: json_stats: {"cur_iter": "697", "eta": "0:18:05", "split": "test_iter", "time_diff": 1.77315}
[05/04 16:33:04][INFO] logging.py:  99: json_stats: {"cur_iter": "698", "eta": "0:09:41", "split": "test_iter", "time_diff": 0.95096}
[05/04 16:33:05][INFO] logging.py:  99: json_stats: {"cur_iter": "699", "eta": "0:08:40", "split": "test_iter", "time_diff": 0.85367}
[05/04 16:33:06][INFO] logging.py:  99: json_stats: {"cur_iter": "700", "eta": "0:10:04", "split": "test_iter", "time_diff": 0.99269}
[05/04 16:33:07][INFO] logging.py:  99: json_stats: {"cur_iter": "701", "eta": "0:09:56", "split": "test_iter", "time_diff": 0.98049}
[05/04 16:33:08][INFO] logging.py:  99: json_stats: {"cur_iter": "702", "eta": "0:10:18", "split": "test_iter", "time_diff": 1.01874}
[05/04 16:33:09][INFO] logging.py:  99: json_stats: {"cur_iter": "703", "eta": "0:09:45", "split": "test_iter", "time_diff": 0.96590}
[05/04 16:33:10][INFO] logging.py:  99: json_stats: {"cur_iter": "704", "eta": "0:12:20", "split": "test_iter", "time_diff": 1.22326}
[05/04 16:33:13][INFO] logging.py:  99: json_stats: {"cur_iter": "705", "eta": "0:28:30", "split": "test_iter", "time_diff": 2.83268}
[05/04 16:33:14][INFO] logging.py:  99: json_stats: {"cur_iter": "706", "eta": "0:10:55", "split": "test_iter", "time_diff": 1.08628}
[05/04 16:33:15][INFO] logging.py:  99: json_stats: {"cur_iter": "707", "eta": "0:09:40", "split": "test_iter", "time_diff": 0.96445}
[05/04 16:33:16][INFO] logging.py:  99: json_stats: {"cur_iter": "708", "eta": "0:09:34", "split": "test_iter", "time_diff": 0.95623}
[05/04 16:33:17][INFO] logging.py:  99: json_stats: {"cur_iter": "709", "eta": "0:10:31", "split": "test_iter", "time_diff": 1.05311}
[05/04 16:33:18][INFO] logging.py:  99: json_stats: {"cur_iter": "710", "eta": "0:09:54", "split": "test_iter", "time_diff": 0.99285}
[05/04 16:33:19][INFO] logging.py:  99: json_stats: {"cur_iter": "711", "eta": "0:09:55", "split": "test_iter", "time_diff": 0.99561}
[05/04 16:33:20][INFO] logging.py:  99: json_stats: {"cur_iter": "712", "eta": "0:08:48", "split": "test_iter", "time_diff": 0.88609}
[05/04 16:33:21][INFO] logging.py:  99: json_stats: {"cur_iter": "713", "eta": "0:15:28", "split": "test_iter", "time_diff": 1.55755}
[05/04 16:33:22][INFO] logging.py:  99: json_stats: {"cur_iter": "714", "eta": "0:10:35", "split": "test_iter", "time_diff": 1.06772}
[05/04 16:33:23][INFO] logging.py:  99: json_stats: {"cur_iter": "715", "eta": "0:09:37", "split": "test_iter", "time_diff": 0.97281}
[05/04 16:33:24][INFO] logging.py:  99: json_stats: {"cur_iter": "716", "eta": "0:08:26", "split": "test_iter", "time_diff": 0.85446}
[05/04 16:33:25][INFO] logging.py:  99: json_stats: {"cur_iter": "717", "eta": "0:11:02", "split": "test_iter", "time_diff": 1.11978}
[05/04 16:33:26][INFO] logging.py:  99: json_stats: {"cur_iter": "718", "eta": "0:09:38", "split": "test_iter", "time_diff": 0.97850}
[05/04 16:33:27][INFO] logging.py:  99: json_stats: {"cur_iter": "719", "eta": "0:10:00", "split": "test_iter", "time_diff": 1.01846}
[05/04 16:33:29][INFO] logging.py:  99: json_stats: {"cur_iter": "720", "eta": "0:11:39", "split": "test_iter", "time_diff": 1.18820}
[05/04 16:33:31][INFO] logging.py:  99: json_stats: {"cur_iter": "721", "eta": "0:23:55", "split": "test_iter", "time_diff": 2.44079}
[05/04 16:33:32][INFO] logging.py:  99: json_stats: {"cur_iter": "722", "eta": "0:10:00", "split": "test_iter", "time_diff": 1.02316}
[05/04 16:33:33][INFO] logging.py:  99: json_stats: {"cur_iter": "723", "eta": "0:09:27", "split": "test_iter", "time_diff": 0.96870}
[05/04 16:33:34][INFO] logging.py:  99: json_stats: {"cur_iter": "724", "eta": "0:10:23", "split": "test_iter", "time_diff": 1.06564}
[05/04 16:33:35][INFO] logging.py:  99: json_stats: {"cur_iter": "725", "eta": "0:08:43", "split": "test_iter", "time_diff": 0.89569}
[05/04 16:33:36][INFO] logging.py:  99: json_stats: {"cur_iter": "726", "eta": "0:09:31", "split": "test_iter", "time_diff": 0.98085}
[05/04 16:33:37][INFO] logging.py:  99: json_stats: {"cur_iter": "727", "eta": "0:09:31", "split": "test_iter", "time_diff": 0.98186}
[05/04 16:33:38][INFO] logging.py:  99: json_stats: {"cur_iter": "728", "eta": "0:08:34", "split": "test_iter", "time_diff": 0.88511}
[05/04 16:33:39][INFO] logging.py:  99: json_stats: {"cur_iter": "729", "eta": "0:12:59", "split": "test_iter", "time_diff": 1.34407}
[05/04 16:33:40][INFO] logging.py:  99: json_stats: {"cur_iter": "730", "eta": "0:09:36", "split": "test_iter", "time_diff": 0.99557}
[05/04 16:33:41][INFO] logging.py:  99: json_stats: {"cur_iter": "731", "eta": "0:09:10", "split": "test_iter", "time_diff": 0.95246}
[05/04 16:33:42][INFO] logging.py:  99: json_stats: {"cur_iter": "732", "eta": "0:09:31", "split": "test_iter", "time_diff": 0.98971}
[05/04 16:33:43][INFO] logging.py:  99: json_stats: {"cur_iter": "733", "eta": "0:09:07", "split": "test_iter", "time_diff": 0.95135}
[05/04 16:33:44][INFO] logging.py:  99: json_stats: {"cur_iter": "734", "eta": "0:09:08", "split": "test_iter", "time_diff": 0.95347}
[05/04 16:33:45][INFO] logging.py:  99: json_stats: {"cur_iter": "735", "eta": "0:09:29", "split": "test_iter", "time_diff": 0.99173}
[05/04 16:33:46][INFO] logging.py:  99: json_stats: {"cur_iter": "736", "eta": "0:11:23", "split": "test_iter", "time_diff": 1.19262}
[05/04 16:33:48][INFO] logging.py:  99: json_stats: {"cur_iter": "737", "eta": "0:18:06", "split": "test_iter", "time_diff": 1.89998}
[05/04 16:33:49][INFO] logging.py:  99: json_stats: {"cur_iter": "738", "eta": "0:08:23", "split": "test_iter", "time_diff": 0.88159}
[05/04 16:33:50][INFO] logging.py:  99: json_stats: {"cur_iter": "739", "eta": "0:10:27", "split": "test_iter", "time_diff": 1.10159}
[05/04 16:33:51][INFO] logging.py:  99: json_stats: {"cur_iter": "740", "eta": "0:09:23", "split": "test_iter", "time_diff": 0.99115}
[05/04 16:33:52][INFO] logging.py:  99: json_stats: {"cur_iter": "741", "eta": "0:09:35", "split": "test_iter", "time_diff": 1.01396}
[05/04 16:33:53][INFO] logging.py:  99: json_stats: {"cur_iter": "742", "eta": "0:09:11", "split": "test_iter", "time_diff": 0.97238}
[05/04 16:33:54][INFO] logging.py:  99: json_stats: {"cur_iter": "743", "eta": "0:09:43", "split": "test_iter", "time_diff": 1.03111}
[05/04 16:33:55][INFO] logging.py:  99: json_stats: {"cur_iter": "744", "eta": "0:08:15", "split": "test_iter", "time_diff": 0.87723}
[05/04 16:33:57][INFO] logging.py:  99: json_stats: {"cur_iter": "745", "eta": "0:15:43", "split": "test_iter", "time_diff": 1.67292}
[05/04 16:33:58][INFO] logging.py:  99: json_stats: {"cur_iter": "746", "eta": "0:09:01", "split": "test_iter", "time_diff": 0.96146}
[05/04 16:33:59][INFO] logging.py:  99: json_stats: {"cur_iter": "747", "eta": "0:08:59", "split": "test_iter", "time_diff": 0.96050}
[05/04 16:34:00][INFO] logging.py:  99: json_stats: {"cur_iter": "748", "eta": "0:08:00", "split": "test_iter", "time_diff": 0.85629}
[05/04 16:34:01][INFO] logging.py:  99: json_stats: {"cur_iter": "749", "eta": "0:09:01", "split": "test_iter", "time_diff": 0.96774}
[05/04 16:34:02][INFO] logging.py:  99: json_stats: {"cur_iter": "750", "eta": "0:08:03", "split": "test_iter", "time_diff": 0.86459}
[05/04 16:34:03][INFO] logging.py:  99: json_stats: {"cur_iter": "751", "eta": "0:09:01", "split": "test_iter", "time_diff": 0.97038}
[05/04 16:34:04][INFO] logging.py:  99: json_stats: {"cur_iter": "752", "eta": "0:11:00", "split": "test_iter", "time_diff": 1.18578}
[05/04 16:34:06][INFO] logging.py:  99: json_stats: {"cur_iter": "753", "eta": "0:14:48", "split": "test_iter", "time_diff": 1.59831}
[05/04 16:34:07][INFO] logging.py:  99: json_stats: {"cur_iter": "754", "eta": "0:09:05", "split": "test_iter", "time_diff": 0.98346}
[05/04 16:34:08][INFO] logging.py:  99: json_stats: {"cur_iter": "755", "eta": "0:08:51", "split": "test_iter", "time_diff": 0.95878}
[05/04 16:34:09][INFO] logging.py:  99: json_stats: {"cur_iter": "756", "eta": "0:08:56", "split": "test_iter", "time_diff": 0.96927}
[05/04 16:34:10][INFO] logging.py:  99: json_stats: {"cur_iter": "757", "eta": "0:09:20", "split": "test_iter", "time_diff": 1.01487}
[05/04 16:34:11][INFO] logging.py:  99: json_stats: {"cur_iter": "758", "eta": "0:08:41", "split": "test_iter", "time_diff": 0.94569}
[05/04 16:34:12][INFO] logging.py:  99: json_stats: {"cur_iter": "759", "eta": "0:08:05", "split": "test_iter", "time_diff": 0.88363}
[05/04 16:34:13][INFO] logging.py:  99: json_stats: {"cur_iter": "760", "eta": "0:10:48", "split": "test_iter", "time_diff": 1.18156}
[05/04 16:34:15][INFO] logging.py:  99: json_stats: {"cur_iter": "761", "eta": "0:19:15", "split": "test_iter", "time_diff": 2.10821}
[05/04 16:34:16][INFO] logging.py:  99: json_stats: {"cur_iter": "762", "eta": "0:08:01", "split": "test_iter", "time_diff": 0.87949}
[05/04 16:34:17][INFO] logging.py:  99: json_stats: {"cur_iter": "763", "eta": "0:09:50", "split": "test_iter", "time_diff": 1.08222}
[05/04 16:34:18][INFO] logging.py:  99: json_stats: {"cur_iter": "764", "eta": "0:08:45", "split": "test_iter", "time_diff": 0.96383}
[05/04 16:34:19][INFO] logging.py:  99: json_stats: {"cur_iter": "765", "eta": "0:08:45", "split": "test_iter", "time_diff": 0.96631}
[05/04 16:34:20][INFO] logging.py:  99: json_stats: {"cur_iter": "766", "eta": "0:09:03", "split": "test_iter", "time_diff": 1.00026}
[05/04 16:34:21][INFO] logging.py:  99: json_stats: {"cur_iter": "767", "eta": "0:07:51", "split": "test_iter", "time_diff": 0.86968}
[05/04 16:34:22][INFO] logging.py:  99: json_stats: {"cur_iter": "768", "eta": "0:10:46", "split": "test_iter", "time_diff": 1.19532}
[05/04 16:34:24][INFO] logging.py:  99: json_stats: {"cur_iter": "769", "eta": "0:16:14", "split": "test_iter", "time_diff": 1.80377}
[05/04 16:34:25][INFO] logging.py:  99: json_stats: {"cur_iter": "770", "eta": "0:08:53", "split": "test_iter", "time_diff": 0.98983}
[05/04 16:34:26][INFO] logging.py:  99: json_stats: {"cur_iter": "771", "eta": "0:08:50", "split": "test_iter", "time_diff": 0.98584}
[05/04 16:34:27][INFO] logging.py:  99: json_stats: {"cur_iter": "772", "eta": "0:08:39", "split": "test_iter", "time_diff": 0.96820}
[05/04 16:34:28][INFO] logging.py:  99: json_stats: {"cur_iter": "773", "eta": "0:08:39", "split": "test_iter", "time_diff": 0.96873}
[05/04 16:34:29][INFO] logging.py:  99: json_stats: {"cur_iter": "774", "eta": "0:08:45", "split": "test_iter", "time_diff": 0.98228}
[05/04 16:34:30][INFO] logging.py:  99: json_stats: {"cur_iter": "775", "eta": "0:08:48", "split": "test_iter", "time_diff": 0.98943}
[05/04 16:34:31][INFO] logging.py:  99: json_stats: {"cur_iter": "776", "eta": "0:07:38", "split": "test_iter", "time_diff": 0.85999}
[05/04 16:34:33][INFO] logging.py:  99: json_stats: {"cur_iter": "777", "eta": "0:20:00", "split": "test_iter", "time_diff": 2.25580}
[05/04 16:34:34][INFO] logging.py:  99: json_stats: {"cur_iter": "778", "eta": "0:09:34", "split": "test_iter", "time_diff": 1.08179}
[05/04 16:34:35][INFO] logging.py:  99: json_stats: {"cur_iter": "779", "eta": "0:09:30", "split": "test_iter", "time_diff": 1.07562}
[05/04 16:34:36][INFO] logging.py:  99: json_stats: {"cur_iter": "780", "eta": "0:07:31", "split": "test_iter", "time_diff": 0.85438}
[05/04 16:34:37][INFO] logging.py:  99: json_stats: {"cur_iter": "781", "eta": "0:08:32", "split": "test_iter", "time_diff": 0.96993}
[05/04 16:34:38][INFO] logging.py:  99: json_stats: {"cur_iter": "782", "eta": "0:09:20", "split": "test_iter", "time_diff": 1.06430}
[05/04 16:34:39][INFO] logging.py:  99: json_stats: {"cur_iter": "783", "eta": "0:07:44", "split": "test_iter", "time_diff": 0.88324}
[05/04 16:34:40][INFO] logging.py:  99: json_stats: {"cur_iter": "784", "eta": "0:07:44", "split": "test_iter", "time_diff": 0.88496}
[05/04 16:34:42][INFO] logging.py:  99: json_stats: {"cur_iter": "785", "eta": "0:20:29", "split": "test_iter", "time_diff": 2.34721}
[05/04 16:34:43][INFO] logging.py:  99: json_stats: {"cur_iter": "786", "eta": "0:07:58", "split": "test_iter", "time_diff": 0.91491}
[05/04 16:34:44][INFO] logging.py:  99: json_stats: {"cur_iter": "787", "eta": "0:08:30", "split": "test_iter", "time_diff": 0.97831}
[05/04 16:34:45][INFO] logging.py:  99: json_stats: {"cur_iter": "788", "eta": "0:08:38", "split": "test_iter", "time_diff": 0.99560}
[05/04 16:34:46][INFO] logging.py:  99: json_stats: {"cur_iter": "789", "eta": "0:07:40", "split": "test_iter", "time_diff": 0.88633}
[05/04 16:34:47][INFO] logging.py:  99: json_stats: {"cur_iter": "790", "eta": "0:08:24", "split": "test_iter", "time_diff": 0.97265}
[05/04 16:34:48][INFO] logging.py:  99: json_stats: {"cur_iter": "791", "eta": "0:08:11", "split": "test_iter", "time_diff": 0.94796}
[05/04 16:34:49][INFO] logging.py:  99: json_stats: {"cur_iter": "792", "eta": "0:08:12", "split": "test_iter", "time_diff": 0.95272}
[05/04 16:34:55][INFO] logging.py:  99: json_stats: {"cur_iter": "793", "eta": "0:47:51", "split": "test_iter", "time_diff": 5.56413}
[05/04 16:34:56][INFO] logging.py:  99: json_stats: {"cur_iter": "794", "eta": "0:08:12", "split": "test_iter", "time_diff": 0.95719}
[05/04 16:34:57][INFO] logging.py:  99: json_stats: {"cur_iter": "795", "eta": "0:07:25", "split": "test_iter", "time_diff": 0.86638}
[05/04 16:34:58][INFO] logging.py:  99: json_stats: {"cur_iter": "796", "eta": "0:08:16", "split": "test_iter", "time_diff": 0.96873}
[05/04 16:34:59][INFO] logging.py:  99: json_stats: {"cur_iter": "797", "eta": "0:09:20", "split": "test_iter", "time_diff": 1.09389}
[05/04 16:35:00][INFO] logging.py:  99: json_stats: {"cur_iter": "798", "eta": "0:08:32", "split": "test_iter", "time_diff": 1.00388}
[05/04 16:35:01][INFO] logging.py:  99: json_stats: {"cur_iter": "799", "eta": "0:08:15", "split": "test_iter", "time_diff": 0.97184}
[05/04 16:35:02][INFO] logging.py:  99: json_stats: {"cur_iter": "800", "eta": "0:07:29", "split": "test_iter", "time_diff": 0.88359}
[05/04 16:35:04][INFO] logging.py:  99: json_stats: {"cur_iter": "801", "eta": "0:17:35", "split": "test_iter", "time_diff": 2.07864}
[05/04 16:35:05][INFO] logging.py:  99: json_stats: {"cur_iter": "802", "eta": "0:08:33", "split": "test_iter", "time_diff": 1.01187}
[05/04 16:35:06][INFO] logging.py:  99: json_stats: {"cur_iter": "803", "eta": "0:09:19", "split": "test_iter", "time_diff": 1.10516}
[05/04 16:35:07][INFO] logging.py:  99: json_stats: {"cur_iter": "804", "eta": "0:08:12", "split": "test_iter", "time_diff": 0.97577}
[05/04 16:35:08][INFO] logging.py:  99: json_stats: {"cur_iter": "805", "eta": "0:08:04", "split": "test_iter", "time_diff": 0.96074}
[05/04 16:35:09][INFO] logging.py:  99: json_stats: {"cur_iter": "806", "eta": "0:08:21", "split": "test_iter", "time_diff": 0.99737}
[05/04 16:35:10][INFO] logging.py:  99: json_stats: {"cur_iter": "807", "eta": "0:09:15", "split": "test_iter", "time_diff": 1.10572}
[05/04 16:35:11][INFO] logging.py:  99: json_stats: {"cur_iter": "808", "eta": "0:08:00", "split": "test_iter", "time_diff": 0.95937}
[05/04 16:35:12][INFO] logging.py:  99: json_stats: {"cur_iter": "809", "eta": "0:09:41", "split": "test_iter", "time_diff": 1.16299}
[05/04 16:35:13][INFO] logging.py:  99: json_stats: {"cur_iter": "810", "eta": "0:08:49", "split": "test_iter", "time_diff": 1.06119}
[05/04 16:35:14][INFO] logging.py:  99: json_stats: {"cur_iter": "811", "eta": "0:07:05", "split": "test_iter", "time_diff": 0.85485}
[05/04 16:35:15][INFO] logging.py:  99: json_stats: {"cur_iter": "812", "eta": "0:07:52", "split": "test_iter", "time_diff": 0.95119}
[05/04 16:35:16][INFO] logging.py:  99: json_stats: {"cur_iter": "813", "eta": "0:07:20", "split": "test_iter", "time_diff": 0.88809}
[05/04 16:35:17][INFO] logging.py:  99: json_stats: {"cur_iter": "814", "eta": "0:07:19", "split": "test_iter", "time_diff": 0.88827}
[05/04 16:35:18][INFO] logging.py:  99: json_stats: {"cur_iter": "815", "eta": "0:09:06", "split": "test_iter", "time_diff": 1.10664}
[05/04 16:35:19][INFO] logging.py:  99: json_stats: {"cur_iter": "816", "eta": "0:10:35", "split": "test_iter", "time_diff": 1.28892}
[05/04 16:35:22][INFO] logging.py:  99: json_stats: {"cur_iter": "817", "eta": "0:22:01", "split": "test_iter", "time_diff": 2.68638}
[05/04 16:35:23][INFO] logging.py:  99: json_stats: {"cur_iter": "818", "eta": "0:08:10", "split": "test_iter", "time_diff": 0.99870}
[05/04 16:35:24][INFO] logging.py:  99: json_stats: {"cur_iter": "819", "eta": "0:08:44", "split": "test_iter", "time_diff": 1.06997}
[05/04 16:35:25][INFO] logging.py:  99: json_stats: {"cur_iter": "820", "eta": "0:07:11", "split": "test_iter", "time_diff": 0.88234}
[05/04 16:35:26][INFO] logging.py:  99: json_stats: {"cur_iter": "821", "eta": "0:08:43", "split": "test_iter", "time_diff": 1.07283}
[05/04 16:35:27][INFO] logging.py:  99: json_stats: {"cur_iter": "822", "eta": "0:08:02", "split": "test_iter", "time_diff": 0.99098}
[05/04 16:35:28][INFO] logging.py:  99: json_stats: {"cur_iter": "823", "eta": "0:08:16", "split": "test_iter", "time_diff": 1.02161}
[05/04 16:35:29][INFO] logging.py:  99: json_stats: {"cur_iter": "824", "eta": "0:08:10", "split": "test_iter", "time_diff": 1.01070}
[05/04 16:35:31][INFO] logging.py:  99: json_stats: {"cur_iter": "825", "eta": "0:20:49", "split": "test_iter", "time_diff": 2.58258}
[05/04 16:35:32][INFO] logging.py:  99: json_stats: {"cur_iter": "826", "eta": "0:07:44", "split": "test_iter", "time_diff": 0.96141}
[05/04 16:35:33][INFO] logging.py:  99: json_stats: {"cur_iter": "827", "eta": "0:08:32", "split": "test_iter", "time_diff": 1.06270}
[05/04 16:35:34][INFO] logging.py:  99: json_stats: {"cur_iter": "828", "eta": "0:08:20", "split": "test_iter", "time_diff": 1.03976}
[05/04 16:35:35][INFO] logging.py:  99: json_stats: {"cur_iter": "829", "eta": "0:06:48", "split": "test_iter", "time_diff": 0.85025}
[05/04 16:35:36][INFO] logging.py:  99: json_stats: {"cur_iter": "830", "eta": "0:08:58", "split": "test_iter", "time_diff": 1.12344}
[05/04 16:35:37][INFO] logging.py:  99: json_stats: {"cur_iter": "831", "eta": "0:07:40", "split": "test_iter", "time_diff": 0.96316}
[05/04 16:35:39][INFO] logging.py:  99: json_stats: {"cur_iter": "832", "eta": "0:08:52", "split": "test_iter", "time_diff": 1.11668}
[05/04 16:35:40][INFO] logging.py:  99: json_stats: {"cur_iter": "833", "eta": "0:15:02", "split": "test_iter", "time_diff": 1.89657}
[05/04 16:35:41][INFO] logging.py:  99: json_stats: {"cur_iter": "834", "eta": "0:07:30", "split": "test_iter", "time_diff": 0.94768}
[05/04 16:35:42][INFO] logging.py:  99: json_stats: {"cur_iter": "835", "eta": "0:06:58", "split": "test_iter", "time_diff": 0.88310}
[05/04 16:35:43][INFO] logging.py:  99: json_stats: {"cur_iter": "836", "eta": "0:07:35", "split": "test_iter", "time_diff": 0.96253}
[05/04 16:35:44][INFO] logging.py:  99: json_stats: {"cur_iter": "837", "eta": "0:07:50", "split": "test_iter", "time_diff": 0.99722}
[05/04 16:35:45][INFO] logging.py:  99: json_stats: {"cur_iter": "838", "eta": "0:07:46", "split": "test_iter", "time_diff": 0.99136}
[05/04 16:35:46][INFO] logging.py:  99: json_stats: {"cur_iter": "839", "eta": "0:07:48", "split": "test_iter", "time_diff": 0.99751}
[05/04 16:35:47][INFO] logging.py:  99: json_stats: {"cur_iter": "840", "eta": "0:07:47", "split": "test_iter", "time_diff": 0.99774}
[05/04 16:35:49][INFO] logging.py:  99: json_stats: {"cur_iter": "841", "eta": "0:14:43", "split": "test_iter", "time_diff": 1.88832}
[05/04 16:35:50][INFO] logging.py:  99: json_stats: {"cur_iter": "842", "eta": "0:07:26", "split": "test_iter", "time_diff": 0.95549}
[05/04 16:35:51][INFO] logging.py:  99: json_stats: {"cur_iter": "843", "eta": "0:07:29", "split": "test_iter", "time_diff": 0.96538}
[05/04 16:35:52][INFO] logging.py:  99: json_stats: {"cur_iter": "844", "eta": "0:07:29", "split": "test_iter", "time_diff": 0.96616}
[05/04 16:35:53][INFO] logging.py:  99: json_stats: {"cur_iter": "845", "eta": "0:08:14", "split": "test_iter", "time_diff": 1.06571}
[05/04 16:35:54][INFO] logging.py:  99: json_stats: {"cur_iter": "846", "eta": "0:07:41", "split": "test_iter", "time_diff": 0.99611}
[05/04 16:35:55][INFO] logging.py:  99: json_stats: {"cur_iter": "847", "eta": "0:07:43", "split": "test_iter", "time_diff": 1.00226}
[05/04 16:35:56][INFO] logging.py:  99: json_stats: {"cur_iter": "848", "eta": "0:06:34", "split": "test_iter", "time_diff": 0.85600}
[05/04 16:35:59][INFO] logging.py:  99: json_stats: {"cur_iter": "849", "eta": "0:25:14", "split": "test_iter", "time_diff": 3.29331}
[05/04 16:36:00][INFO] logging.py:  99: json_stats: {"cur_iter": "850", "eta": "0:07:26", "split": "test_iter", "time_diff": 0.97300}
[05/04 16:36:01][INFO] logging.py:  99: json_stats: {"cur_iter": "851", "eta": "0:07:39", "split": "test_iter", "time_diff": 1.00428}
[05/04 16:36:02][INFO] logging.py:  99: json_stats: {"cur_iter": "852", "eta": "0:08:29", "split": "test_iter", "time_diff": 1.11589}
[05/04 16:36:03][INFO] logging.py:  99: json_stats: {"cur_iter": "853", "eta": "0:07:38", "split": "test_iter", "time_diff": 1.00570}
[05/04 16:36:04][INFO] logging.py:  99: json_stats: {"cur_iter": "854", "eta": "0:07:18", "split": "test_iter", "time_diff": 0.96431}
[05/04 16:36:05][INFO] logging.py:  99: json_stats: {"cur_iter": "855", "eta": "0:07:23", "split": "test_iter", "time_diff": 0.97690}
[05/04 16:36:06][INFO] logging.py:  99: json_stats: {"cur_iter": "856", "eta": "0:06:37", "split": "test_iter", "time_diff": 0.87793}
[05/04 16:36:09][INFO] logging.py:  99: json_stats: {"cur_iter": "857", "eta": "0:17:49", "split": "test_iter", "time_diff": 2.36577}
[05/04 16:36:10][INFO] logging.py:  99: json_stats: {"cur_iter": "858", "eta": "0:06:38", "split": "test_iter", "time_diff": 0.88282}
[05/04 16:36:11][INFO] logging.py:  99: json_stats: {"cur_iter": "859", "eta": "0:08:11", "split": "test_iter", "time_diff": 1.09278}
[05/04 16:36:12][INFO] logging.py:  99: json_stats: {"cur_iter": "860", "eta": "0:07:18", "split": "test_iter", "time_diff": 0.97638}
[05/04 16:36:13][INFO] logging.py:  99: json_stats: {"cur_iter": "861", "eta": "0:07:41", "split": "test_iter", "time_diff": 1.03057}
[05/04 16:36:14][INFO] logging.py:  99: json_stats: {"cur_iter": "862", "eta": "0:07:50", "split": "test_iter", "time_diff": 1.05272}
[05/04 16:36:15][INFO] logging.py:  99: json_stats: {"cur_iter": "863", "eta": "0:07:28", "split": "test_iter", "time_diff": 1.00471}
[05/04 16:36:16][INFO] logging.py:  99: json_stats: {"cur_iter": "864", "eta": "0:07:14", "split": "test_iter", "time_diff": 0.97551}
[05/04 16:36:17][INFO] logging.py:  99: json_stats: {"cur_iter": "865", "eta": "0:12:21", "split": "test_iter", "time_diff": 1.67005}
[05/04 16:36:18][INFO] logging.py:  99: json_stats: {"cur_iter": "866", "eta": "0:07:06", "split": "test_iter", "time_diff": 0.96209}
[05/04 16:36:20][INFO] logging.py:  99: json_stats: {"cur_iter": "867", "eta": "0:07:56", "split": "test_iter", "time_diff": 1.07845}
[05/04 16:36:21][INFO] logging.py:  99: json_stats: {"cur_iter": "868", "eta": "0:07:14", "split": "test_iter", "time_diff": 0.98527}
[05/04 16:36:22][INFO] logging.py:  99: json_stats: {"cur_iter": "869", "eta": "0:07:16", "split": "test_iter", "time_diff": 0.99303}
[05/04 16:36:22][INFO] logging.py:  99: json_stats: {"cur_iter": "870", "eta": "0:07:10", "split": "test_iter", "time_diff": 0.98016}
[05/04 16:36:24][INFO] logging.py:  99: json_stats: {"cur_iter": "871", "eta": "0:07:16", "split": "test_iter", "time_diff": 0.99678}
[05/04 16:36:25][INFO] logging.py:  99: json_stats: {"cur_iter": "872", "eta": "0:07:25", "split": "test_iter", "time_diff": 1.01969}
[05/04 16:36:27][INFO] logging.py:  99: json_stats: {"cur_iter": "873", "eta": "0:20:29", "split": "test_iter", "time_diff": 2.82106}
[05/04 16:36:28][INFO] logging.py:  99: json_stats: {"cur_iter": "874", "eta": "0:07:42", "split": "test_iter", "time_diff": 1.06221}
[05/04 16:36:29][INFO] logging.py:  99: json_stats: {"cur_iter": "875", "eta": "0:07:14", "split": "test_iter", "time_diff": 1.00197}
[05/04 16:36:30][INFO] logging.py:  99: json_stats: {"cur_iter": "876", "eta": "0:06:22", "split": "test_iter", "time_diff": 0.88378}
[05/04 16:36:31][INFO] logging.py:  99: json_stats: {"cur_iter": "877", "eta": "0:07:23", "split": "test_iter", "time_diff": 1.02767}
[05/04 16:36:32][INFO] logging.py:  99: json_stats: {"cur_iter": "878", "eta": "0:07:07", "split": "test_iter", "time_diff": 0.99183}
[05/04 16:36:33][INFO] logging.py:  99: json_stats: {"cur_iter": "879", "eta": "0:07:10", "split": "test_iter", "time_diff": 1.00113}
[05/04 16:36:34][INFO] logging.py:  99: json_stats: {"cur_iter": "880", "eta": "0:06:58", "split": "test_iter", "time_diff": 0.97455}
[05/04 16:36:36][INFO] logging.py:  99: json_stats: {"cur_iter": "881", "eta": "0:11:36", "split": "test_iter", "time_diff": 1.62741}
[05/04 16:36:37][INFO] logging.py:  99: json_stats: {"cur_iter": "882", "eta": "0:07:31", "split": "test_iter", "time_diff": 1.05783}
[05/04 16:36:38][INFO] logging.py:  99: json_stats: {"cur_iter": "883", "eta": "0:06:15", "split": "test_iter", "time_diff": 0.88066}
[05/04 16:36:39][INFO] logging.py:  99: json_stats: {"cur_iter": "884", "eta": "0:06:52", "split": "test_iter", "time_diff": 0.97023}
[05/04 16:36:40][INFO] logging.py:  99: json_stats: {"cur_iter": "885", "eta": "0:06:58", "split": "test_iter", "time_diff": 0.98688}
[05/04 16:36:41][INFO] logging.py:  99: json_stats: {"cur_iter": "886", "eta": "0:06:13", "split": "test_iter", "time_diff": 0.88198}
[05/04 16:36:42][INFO] logging.py:  99: json_stats: {"cur_iter": "887", "eta": "0:06:53", "split": "test_iter", "time_diff": 0.97956}
[05/04 16:36:43][INFO] logging.py:  99: json_stats: {"cur_iter": "888", "eta": "0:06:53", "split": "test_iter", "time_diff": 0.98327}
[05/04 16:36:46][INFO] logging.py:  99: json_stats: {"cur_iter": "889", "eta": "0:18:43", "split": "test_iter", "time_diff": 2.67531}
[05/04 16:36:47][INFO] logging.py:  99: json_stats: {"cur_iter": "890", "eta": "0:07:02", "split": "test_iter", "time_diff": 1.00753}
[05/04 16:36:48][INFO] logging.py:  99: json_stats: {"cur_iter": "891", "eta": "0:07:26", "split": "test_iter", "time_diff": 1.06726}
[05/04 16:36:49][INFO] logging.py:  99: json_stats: {"cur_iter": "892", "eta": "0:06:59", "split": "test_iter", "time_diff": 1.00680}
[05/04 16:36:50][INFO] logging.py:  99: json_stats: {"cur_iter": "893", "eta": "0:06:49", "split": "test_iter", "time_diff": 0.98393}
[05/04 16:36:51][INFO] logging.py:  99: json_stats: {"cur_iter": "894", "eta": "0:06:43", "split": "test_iter", "time_diff": 0.97126}
[05/04 16:36:52][INFO] logging.py:  99: json_stats: {"cur_iter": "895", "eta": "0:06:44", "split": "test_iter", "time_diff": 0.97694}
[05/04 16:36:53][INFO] logging.py:  99: json_stats: {"cur_iter": "896", "eta": "0:06:04", "split": "test_iter", "time_diff": 0.88284}
[05/04 16:36:54][INFO] logging.py:  99: json_stats: {"cur_iter": "897", "eta": "0:12:25", "split": "test_iter", "time_diff": 1.80870}
[05/04 16:36:55][INFO] logging.py:  99: json_stats: {"cur_iter": "898", "eta": "0:06:47", "split": "test_iter", "time_diff": 0.99114}
[05/04 16:36:56][INFO] logging.py:  99: json_stats: {"cur_iter": "899", "eta": "0:06:35", "split": "test_iter", "time_diff": 0.96409}
[05/04 16:36:57][INFO] logging.py:  99: json_stats: {"cur_iter": "900", "eta": "0:06:57", "split": "test_iter", "time_diff": 1.02123}
[05/04 16:36:58][INFO] logging.py:  99: json_stats: {"cur_iter": "901", "eta": "0:06:55", "split": "test_iter", "time_diff": 1.01843}
[05/04 16:36:59][INFO] logging.py:  99: json_stats: {"cur_iter": "902", "eta": "0:06:45", "split": "test_iter", "time_diff": 0.99511}
[05/04 16:37:00][INFO] logging.py:  99: json_stats: {"cur_iter": "903", "eta": "0:05:50", "split": "test_iter", "time_diff": 0.86349}
[05/04 16:37:01][INFO] logging.py:  99: json_stats: {"cur_iter": "904", "eta": "0:07:02", "split": "test_iter", "time_diff": 1.04265}
[05/04 16:37:04][INFO] logging.py:  99: json_stats: {"cur_iter": "905", "eta": "0:15:31", "split": "test_iter", "time_diff": 2.30678}
[05/04 16:37:05][INFO] logging.py:  99: json_stats: {"cur_iter": "906", "eta": "0:06:03", "split": "test_iter", "time_diff": 0.90217}
[05/04 16:37:06][INFO] logging.py:  99: json_stats: {"cur_iter": "907", "eta": "0:05:55", "split": "test_iter", "time_diff": 0.88488}
[05/04 16:37:07][INFO] logging.py:  99: json_stats: {"cur_iter": "908", "eta": "0:07:16", "split": "test_iter", "time_diff": 1.08823}
[05/04 16:37:08][INFO] logging.py:  99: json_stats: {"cur_iter": "909", "eta": "0:06:42", "split": "test_iter", "time_diff": 1.00574}
[05/04 16:37:09][INFO] logging.py:  99: json_stats: {"cur_iter": "910", "eta": "0:06:35", "split": "test_iter", "time_diff": 0.99133}
[05/04 16:37:10][INFO] logging.py:  99: json_stats: {"cur_iter": "911", "eta": "0:05:47", "split": "test_iter", "time_diff": 0.87266}
[05/04 16:37:11][INFO] logging.py:  99: json_stats: {"cur_iter": "912", "eta": "0:05:52", "split": "test_iter", "time_diff": 0.88671}
[05/04 16:37:12][INFO] logging.py:  99: json_stats: {"cur_iter": "913", "eta": "0:07:43", "split": "test_iter", "time_diff": 1.16988}
[05/04 16:37:13][INFO] logging.py:  99: json_stats: {"cur_iter": "914", "eta": "0:07:30", "split": "test_iter", "time_diff": 1.13994}
[05/04 16:37:14][INFO] logging.py:  99: json_stats: {"cur_iter": "915", "eta": "0:06:29", "split": "test_iter", "time_diff": 0.98883}
[05/04 16:37:15][INFO] logging.py:  99: json_stats: {"cur_iter": "916", "eta": "0:05:47", "split": "test_iter", "time_diff": 0.88446}
[05/04 16:37:16][INFO] logging.py:  99: json_stats: {"cur_iter": "917", "eta": "0:05:47", "split": "test_iter", "time_diff": 0.88600}
[05/04 16:37:17][INFO] logging.py:  99: json_stats: {"cur_iter": "918", "eta": "0:05:46", "split": "test_iter", "time_diff": 0.88589}
[05/04 16:37:18][INFO] logging.py:  99: json_stats: {"cur_iter": "919", "eta": "0:06:22", "split": "test_iter", "time_diff": 0.98188}
[05/04 16:37:19][INFO] logging.py:  99: json_stats: {"cur_iter": "920", "eta": "0:05:35", "split": "test_iter", "time_diff": 0.86278}
[05/04 16:37:20][INFO] logging.py:  99: json_stats: {"cur_iter": "921", "eta": "0:10:18", "split": "test_iter", "time_diff": 1.59399}
[05/04 16:37:21][INFO] logging.py:  99: json_stats: {"cur_iter": "922", "eta": "0:06:17", "split": "test_iter", "time_diff": 0.97652}
[05/04 16:37:22][INFO] logging.py:  99: json_stats: {"cur_iter": "923", "eta": "0:07:09", "split": "test_iter", "time_diff": 1.11298}
[05/04 16:37:24][INFO] logging.py:  99: json_stats: {"cur_iter": "924", "eta": "0:06:25", "split": "test_iter", "time_diff": 1.00112}
[05/04 16:37:25][INFO] logging.py:  99: json_stats: {"cur_iter": "925", "eta": "0:06:19", "split": "test_iter", "time_diff": 0.98909}
[05/04 16:37:26][INFO] logging.py:  99: json_stats: {"cur_iter": "926", "eta": "0:06:25", "split": "test_iter", "time_diff": 1.00730}
[05/04 16:37:27][INFO] logging.py:  99: json_stats: {"cur_iter": "927", "eta": "0:06:29", "split": "test_iter", "time_diff": 1.01894}
[05/04 16:37:28][INFO] logging.py:  99: json_stats: {"cur_iter": "928", "eta": "0:06:09", "split": "test_iter", "time_diff": 0.97005}
[05/04 16:37:29][INFO] logging.py:  99: json_stats: {"cur_iter": "929", "eta": "0:12:08", "split": "test_iter", "time_diff": 1.91702}
[05/04 16:37:30][INFO] logging.py:  99: json_stats: {"cur_iter": "930", "eta": "0:05:34", "split": "test_iter", "time_diff": 0.88230}
[05/04 16:37:31][INFO] logging.py:  99: json_stats: {"cur_iter": "931", "eta": "0:06:47", "split": "test_iter", "time_diff": 1.07931}
[05/04 16:37:32][INFO] logging.py:  99: json_stats: {"cur_iter": "932", "eta": "0:06:20", "split": "test_iter", "time_diff": 1.00948}
[05/04 16:37:33][INFO] logging.py:  99: json_stats: {"cur_iter": "933", "eta": "0:06:14", "split": "test_iter", "time_diff": 0.99514}
[05/04 16:37:35][INFO] logging.py:  99: json_stats: {"cur_iter": "934", "eta": "0:06:49", "split": "test_iter", "time_diff": 1.09095}
[05/04 16:37:35][INFO] logging.py:  99: json_stats: {"cur_iter": "935", "eta": "0:05:30", "split": "test_iter", "time_diff": 0.88303}
[05/04 16:37:36][INFO] logging.py:  99: json_stats: {"cur_iter": "936", "eta": "0:06:46", "split": "test_iter", "time_diff": 1.09009}
[05/04 16:37:38][INFO] logging.py:  99: json_stats: {"cur_iter": "937", "eta": "0:09:35", "split": "test_iter", "time_diff": 1.54657}
[05/04 16:37:39][INFO] logging.py:  99: json_stats: {"cur_iter": "938", "eta": "0:05:58", "split": "test_iter", "time_diff": 0.96734}
[05/04 16:37:40][INFO] logging.py:  99: json_stats: {"cur_iter": "939", "eta": "0:05:56", "split": "test_iter", "time_diff": 0.96447}
[05/04 16:37:41][INFO] logging.py:  99: json_stats: {"cur_iter": "940", "eta": "0:05:57", "split": "test_iter", "time_diff": 0.96781}
[05/04 16:37:42][INFO] logging.py:  99: json_stats: {"cur_iter": "941", "eta": "0:06:07", "split": "test_iter", "time_diff": 0.99957}
[05/04 16:37:43][INFO] logging.py:  99: json_stats: {"cur_iter": "942", "eta": "0:05:55", "split": "test_iter", "time_diff": 0.96931}
[05/04 16:37:44][INFO] logging.py:  99: json_stats: {"cur_iter": "943", "eta": "0:06:15", "split": "test_iter", "time_diff": 1.02694}
[05/04 16:37:45][INFO] logging.py:  99: json_stats: {"cur_iter": "944", "eta": "0:05:11", "split": "test_iter", "time_diff": 0.85357}
[05/04 16:37:46][INFO] logging.py:  99: json_stats: {"cur_iter": "945", "eta": "0:09:01", "split": "test_iter", "time_diff": 1.48759}
[05/04 16:37:47][INFO] logging.py:  99: json_stats: {"cur_iter": "946", "eta": "0:05:53", "split": "test_iter", "time_diff": 0.97259}
[05/04 16:37:48][INFO] logging.py:  99: json_stats: {"cur_iter": "947", "eta": "0:06:25", "split": "test_iter", "time_diff": 1.06534}
[05/04 16:37:49][INFO] logging.py:  99: json_stats: {"cur_iter": "948", "eta": "0:05:48", "split": "test_iter", "time_diff": 0.96547}
[05/04 16:37:50][INFO] logging.py:  99: json_stats: {"cur_iter": "949", "eta": "0:05:07", "split": "test_iter", "time_diff": 0.85333}
[05/04 16:37:51][INFO] logging.py:  99: json_stats: {"cur_iter": "950", "eta": "0:05:53", "split": "test_iter", "time_diff": 0.98344}
[05/04 16:37:53][INFO] logging.py:  99: json_stats: {"cur_iter": "951", "eta": "0:06:59", "split": "test_iter", "time_diff": 1.17227}
[05/04 16:37:54][INFO] logging.py:  99: json_stats: {"cur_iter": "952", "eta": "0:08:06", "split": "test_iter", "time_diff": 1.36239}
[05/04 16:37:56][INFO] logging.py:  99: json_stats: {"cur_iter": "953", "eta": "0:09:59", "split": "test_iter", "time_diff": 1.68536}
[05/04 16:37:57][INFO] logging.py:  99: json_stats: {"cur_iter": "954", "eta": "0:05:51", "split": "test_iter", "time_diff": 0.99054}
[05/04 16:37:58][INFO] logging.py:  99: json_stats: {"cur_iter": "955", "eta": "0:05:51", "split": "test_iter", "time_diff": 0.99379}
[05/04 16:37:59][INFO] logging.py:  99: json_stats: {"cur_iter": "956", "eta": "0:05:58", "split": "test_iter", "time_diff": 1.01516}
[05/04 16:38:00][INFO] logging.py:  99: json_stats: {"cur_iter": "957", "eta": "0:05:41", "split": "test_iter", "time_diff": 0.96965}
[05/04 16:38:01][INFO] logging.py:  99: json_stats: {"cur_iter": "958", "eta": "0:05:55", "split": "test_iter", "time_diff": 1.01352}
[05/04 16:38:02][INFO] logging.py:  99: json_stats: {"cur_iter": "959", "eta": "0:05:37", "split": "test_iter", "time_diff": 0.96334}
[05/04 16:38:02][INFO] logging.py:  99: json_stats: {"cur_iter": "960", "eta": "0:05:08", "split": "test_iter", "time_diff": 0.88440}
[05/04 16:38:04][INFO] logging.py:  99: json_stats: {"cur_iter": "961", "eta": "0:09:29", "split": "test_iter", "time_diff": 1.63603}
[05/04 16:38:05][INFO] logging.py:  99: json_stats: {"cur_iter": "962", "eta": "0:06:24", "split": "test_iter", "time_diff": 1.10921}
[05/04 16:38:06][INFO] logging.py:  99: json_stats: {"cur_iter": "963", "eta": "0:05:41", "split": "test_iter", "time_diff": 0.98671}
[05/04 16:38:07][INFO] logging.py:  99: json_stats: {"cur_iter": "964", "eta": "0:05:35", "split": "test_iter", "time_diff": 0.97340}
[05/04 16:38:08][INFO] logging.py:  99: json_stats: {"cur_iter": "965", "eta": "0:06:19", "split": "test_iter", "time_diff": 1.10418}
[05/04 16:38:09][INFO] logging.py:  99: json_stats: {"cur_iter": "966", "eta": "0:05:46", "split": "test_iter", "time_diff": 1.00978}
[05/04 16:38:11][INFO] logging.py:  99: json_stats: {"cur_iter": "967", "eta": "0:07:20", "split": "test_iter", "time_diff": 1.28940}
[05/04 16:38:11][INFO] logging.py:  99: json_stats: {"cur_iter": "968", "eta": "0:05:00", "split": "test_iter", "time_diff": 0.88156}
[05/04 16:38:13][INFO] logging.py:  99: json_stats: {"cur_iter": "969", "eta": "0:07:16", "split": "test_iter", "time_diff": 1.28488}
[05/04 16:38:14][INFO] logging.py:  99: json_stats: {"cur_iter": "970", "eta": "0:06:10", "split": "test_iter", "time_diff": 1.09192}
[05/04 16:38:15][INFO] logging.py:  99: json_stats: {"cur_iter": "971", "eta": "0:04:48", "split": "test_iter", "time_diff": 0.85295}
[05/04 16:38:16][INFO] logging.py:  99: json_stats: {"cur_iter": "972", "eta": "0:05:25", "split": "test_iter", "time_diff": 0.96441}
[05/04 16:38:17][INFO] logging.py:  99: json_stats: {"cur_iter": "973", "eta": "0:05:32", "split": "test_iter", "time_diff": 0.98827}
[05/04 16:38:18][INFO] logging.py:  99: json_stats: {"cur_iter": "974", "eta": "0:05:45", "split": "test_iter", "time_diff": 1.02990}
[05/04 16:38:19][INFO] logging.py:  99: json_stats: {"cur_iter": "975", "eta": "0:07:33", "split": "test_iter", "time_diff": 1.35903}
[05/04 16:38:20][INFO] logging.py:  99: json_stats: {"cur_iter": "976", "eta": "0:04:48", "split": "test_iter", "time_diff": 0.86633}
[05/04 16:38:22][INFO] logging.py:  99: json_stats: {"cur_iter": "977", "eta": "0:08:04", "split": "test_iter", "time_diff": 1.45893}
[05/04 16:38:23][INFO] logging.py:  99: json_stats: {"cur_iter": "978", "eta": "0:05:59", "split": "test_iter", "time_diff": 1.08734}
[05/04 16:38:24][INFO] logging.py:  99: json_stats: {"cur_iter": "979", "eta": "0:05:22", "split": "test_iter", "time_diff": 0.97606}
[05/04 16:38:25][INFO] logging.py:  99: json_stats: {"cur_iter": "980", "eta": "0:05:37", "split": "test_iter", "time_diff": 1.02491}
[05/04 16:38:26][INFO] logging.py:  99: json_stats: {"cur_iter": "981", "eta": "0:05:13", "split": "test_iter", "time_diff": 0.95498}
[05/04 16:38:27][INFO] logging.py:  99: json_stats: {"cur_iter": "982", "eta": "0:05:23", "split": "test_iter", "time_diff": 0.98917}
[05/04 16:38:28][INFO] logging.py:  99: json_stats: {"cur_iter": "983", "eta": "0:05:28", "split": "test_iter", "time_diff": 1.00768}
[05/04 16:38:29][INFO] logging.py:  99: json_stats: {"cur_iter": "984", "eta": "0:06:26", "split": "test_iter", "time_diff": 1.18775}
[05/04 16:38:30][INFO] logging.py:  99: json_stats: {"cur_iter": "985", "eta": "0:08:38", "split": "test_iter", "time_diff": 1.60046}
[05/04 16:38:31][INFO] logging.py:  99: json_stats: {"cur_iter": "986", "eta": "0:05:39", "split": "test_iter", "time_diff": 1.05097}
[05/04 16:38:32][INFO] logging.py:  99: json_stats: {"cur_iter": "987", "eta": "0:05:08", "split": "test_iter", "time_diff": 0.95897}
[05/04 16:38:33][INFO] logging.py:  99: json_stats: {"cur_iter": "988", "eta": "0:05:09", "split": "test_iter", "time_diff": 0.96342}
[05/04 16:38:35][INFO] logging.py:  99: json_stats: {"cur_iter": "989", "eta": "0:06:35", "split": "test_iter", "time_diff": 1.23651}
[05/04 16:38:36][INFO] logging.py:  99: json_stats: {"cur_iter": "990", "eta": "0:04:42", "split": "test_iter", "time_diff": 0.88574}
[05/04 16:38:37][INFO] logging.py:  99: json_stats: {"cur_iter": "991", "eta": "0:04:32", "split": "test_iter", "time_diff": 0.85658}
[05/04 16:38:38][INFO] logging.py:  99: json_stats: {"cur_iter": "992", "eta": "0:10:16", "split": "test_iter", "time_diff": 1.94347}
[05/04 16:38:41][INFO] logging.py:  99: json_stats: {"cur_iter": "993", "eta": "0:15:23", "split": "test_iter", "time_diff": 2.92175}
[05/04 16:38:42][INFO] logging.py:  99: json_stats: {"cur_iter": "994", "eta": "0:05:07", "split": "test_iter", "time_diff": 0.97647}
[05/04 16:38:43][INFO] logging.py:  99: json_stats: {"cur_iter": "995", "eta": "0:04:28", "split": "test_iter", "time_diff": 0.85493}
[05/04 16:38:44][INFO] logging.py:  99: json_stats: {"cur_iter": "996", "eta": "0:04:26", "split": "test_iter", "time_diff": 0.85218}
[05/04 16:38:46][INFO] logging.py:  99: json_stats: {"cur_iter": "997", "eta": "0:06:27", "split": "test_iter", "time_diff": 1.24266}
[05/04 16:38:47][INFO] logging.py:  99: json_stats: {"cur_iter": "998", "eta": "0:04:55", "split": "test_iter", "time_diff": 0.95087}
[05/04 16:38:48][INFO] logging.py:  99: json_stats: {"cur_iter": "999", "eta": "0:05:01", "split": "test_iter", "time_diff": 0.97147}
[05/04 16:38:49][INFO] logging.py:  99: json_stats: {"cur_iter": "1000", "eta": "0:05:54", "split": "test_iter", "time_diff": 1.14564}
[05/04 16:38:51][INFO] logging.py:  99: json_stats: {"cur_iter": "1001", "eta": "0:11:47", "split": "test_iter", "time_diff": 2.29625}
[05/04 16:38:52][INFO] logging.py:  99: json_stats: {"cur_iter": "1002", "eta": "0:05:04", "split": "test_iter", "time_diff": 0.99117}
[05/04 16:38:53][INFO] logging.py:  99: json_stats: {"cur_iter": "1003", "eta": "0:04:55", "split": "test_iter", "time_diff": 0.96527}
[05/04 16:38:54][INFO] logging.py:  99: json_stats: {"cur_iter": "1004", "eta": "0:04:19", "split": "test_iter", "time_diff": 0.85186}
[05/04 16:38:55][INFO] logging.py:  99: json_stats: {"cur_iter": "1005", "eta": "0:05:59", "split": "test_iter", "time_diff": 1.18180}
[05/04 16:38:56][INFO] logging.py:  99: json_stats: {"cur_iter": "1006", "eta": "0:04:58", "split": "test_iter", "time_diff": 0.98668}
[05/04 16:38:57][INFO] logging.py:  99: json_stats: {"cur_iter": "1007", "eta": "0:04:59", "split": "test_iter", "time_diff": 0.99227}
[05/04 16:38:58][INFO] logging.py:  99: json_stats: {"cur_iter": "1008", "eta": "0:05:58", "split": "test_iter", "time_diff": 1.19006}
[05/04 16:39:01][INFO] logging.py:  99: json_stats: {"cur_iter": "1009", "eta": "0:14:44", "split": "test_iter", "time_diff": 2.94917}
[05/04 16:39:02][INFO] logging.py:  99: json_stats: {"cur_iter": "1010", "eta": "0:04:53", "split": "test_iter", "time_diff": 0.98116}
[05/04 16:39:03][INFO] logging.py:  99: json_stats: {"cur_iter": "1011", "eta": "0:04:15", "split": "test_iter", "time_diff": 0.85722}
[05/04 16:39:04][INFO] logging.py:  99: json_stats: {"cur_iter": "1012", "eta": "0:04:39", "split": "test_iter", "time_diff": 0.94043}
[05/04 16:39:05][INFO] logging.py:  99: json_stats: {"cur_iter": "1013", "eta": "0:05:01", "split": "test_iter", "time_diff": 1.01780}
[05/04 16:39:06][INFO] logging.py:  99: json_stats: {"cur_iter": "1014", "eta": "0:04:44", "split": "test_iter", "time_diff": 0.96493}
[05/04 16:39:07][INFO] logging.py:  99: json_stats: {"cur_iter": "1015", "eta": "0:04:47", "split": "test_iter", "time_diff": 0.97672}
[05/04 16:39:08][INFO] logging.py:  99: json_stats: {"cur_iter": "1016", "eta": "0:05:46", "split": "test_iter", "time_diff": 1.18426}
[05/04 16:39:12][INFO] logging.py:  99: json_stats: {"cur_iter": "1017", "eta": "0:20:06", "split": "test_iter", "time_diff": 4.13184}
[05/04 16:39:13][INFO] logging.py:  99: json_stats: {"cur_iter": "1018", "eta": "0:04:16", "split": "test_iter", "time_diff": 0.88072}
[05/04 16:39:14][INFO] logging.py:  99: json_stats: {"cur_iter": "1019", "eta": "0:04:34", "split": "test_iter", "time_diff": 0.94774}
[05/04 16:39:15][INFO] logging.py:  99: json_stats: {"cur_iter": "1020", "eta": "0:04:07", "split": "test_iter", "time_diff": 0.85564}
[05/04 16:39:16][INFO] logging.py:  99: json_stats: {"cur_iter": "1021", "eta": "0:04:43", "split": "test_iter", "time_diff": 0.98390}
[05/04 16:39:17][INFO] logging.py:  99: json_stats: {"cur_iter": "1022", "eta": "0:04:43", "split": "test_iter", "time_diff": 0.98750}
[05/04 16:39:18][INFO] logging.py:  99: json_stats: {"cur_iter": "1023", "eta": "0:04:33", "split": "test_iter", "time_diff": 0.95610}
[05/04 16:39:20][INFO] logging.py:  99: json_stats: {"cur_iter": "1024", "eta": "0:06:24", "split": "test_iter", "time_diff": 1.34927}
[05/04 16:39:22][INFO] logging.py:  99: json_stats: {"cur_iter": "1025", "eta": "0:09:23", "split": "test_iter", "time_diff": 1.98562}
[05/04 16:39:23][INFO] logging.py:  99: json_stats: {"cur_iter": "1026", "eta": "0:04:28", "split": "test_iter", "time_diff": 0.95011}
[05/04 16:39:24][INFO] logging.py:  99: json_stats: {"cur_iter": "1027", "eta": "0:04:03", "split": "test_iter", "time_diff": 0.86390}
[05/04 16:39:25][INFO] logging.py:  99: json_stats: {"cur_iter": "1028", "eta": "0:04:35", "split": "test_iter", "time_diff": 0.97976}
[05/04 16:39:26][INFO] logging.py:  99: json_stats: {"cur_iter": "1029", "eta": "0:04:35", "split": "test_iter", "time_diff": 0.98459}
[05/04 16:39:27][INFO] logging.py:  99: json_stats: {"cur_iter": "1030", "eta": "0:03:58", "split": "test_iter", "time_diff": 0.85647}
[05/04 16:39:27][INFO] logging.py:  99: json_stats: {"cur_iter": "1031", "eta": "0:04:30", "split": "test_iter", "time_diff": 0.97270}
[05/04 16:39:28][INFO] logging.py:  99: json_stats: {"cur_iter": "1032", "eta": "0:04:34", "split": "test_iter", "time_diff": 0.99262}
[05/04 16:39:31][INFO] logging.py:  99: json_stats: {"cur_iter": "1033", "eta": "0:10:22", "split": "test_iter", "time_diff": 2.25553}
[05/04 16:39:32][INFO] logging.py:  99: json_stats: {"cur_iter": "1034", "eta": "0:04:02", "split": "test_iter", "time_diff": 0.88258}
[05/04 16:39:33][INFO] logging.py:  99: json_stats: {"cur_iter": "1035", "eta": "0:04:02", "split": "test_iter", "time_diff": 0.88389}
[05/04 16:39:34][INFO] logging.py:  99: json_stats: {"cur_iter": "1036", "eta": "0:04:16", "split": "test_iter", "time_diff": 0.93848}
[05/04 16:39:35][INFO] logging.py:  99: json_stats: {"cur_iter": "1037", "eta": "0:04:29", "split": "test_iter", "time_diff": 0.99195}
[05/04 16:39:35][INFO] logging.py:  99: json_stats: {"cur_iter": "1038", "eta": "0:03:55", "split": "test_iter", "time_diff": 0.86889}
[05/04 16:39:36][INFO] logging.py:  99: json_stats: {"cur_iter": "1039", "eta": "0:04:20", "split": "test_iter", "time_diff": 0.96656}
[05/04 16:39:38][INFO] logging.py:  99: json_stats: {"cur_iter": "1040", "eta": "0:05:44", "split": "test_iter", "time_diff": 1.28111}
[05/04 16:39:40][INFO] logging.py:  99: json_stats: {"cur_iter": "1041", "eta": "0:12:06", "split": "test_iter", "time_diff": 2.71145}
[05/04 16:39:41][INFO] logging.py:  99: json_stats: {"cur_iter": "1042", "eta": "0:03:48", "split": "test_iter", "time_diff": 0.85457}
[05/04 16:39:42][INFO] logging.py:  99: json_stats: {"cur_iter": "1043", "eta": "0:03:47", "split": "test_iter", "time_diff": 0.85479}
[05/04 16:39:43][INFO] logging.py:  99: json_stats: {"cur_iter": "1044", "eta": "0:04:14", "split": "test_iter", "time_diff": 0.95891}
[05/04 16:39:44][INFO] logging.py:  99: json_stats: {"cur_iter": "1045", "eta": "0:05:10", "split": "test_iter", "time_diff": 1.17522}
[05/04 16:39:45][INFO] logging.py:  99: json_stats: {"cur_iter": "1046", "eta": "0:04:23", "split": "test_iter", "time_diff": 1.00247}
[05/04 16:39:46][INFO] logging.py:  99: json_stats: {"cur_iter": "1047", "eta": "0:04:08", "split": "test_iter", "time_diff": 0.94963}
[05/04 16:39:47][INFO] logging.py:  99: json_stats: {"cur_iter": "1048", "eta": "0:04:08", "split": "test_iter", "time_diff": 0.95214}
[05/04 16:39:50][INFO] logging.py:  99: json_stats: {"cur_iter": "1049", "eta": "0:10:06", "split": "test_iter", "time_diff": 2.33351}
[05/04 16:39:51][INFO] logging.py:  99: json_stats: {"cur_iter": "1050", "eta": "0:04:08", "split": "test_iter", "time_diff": 0.96085}
[05/04 16:39:52][INFO] logging.py:  99: json_stats: {"cur_iter": "1051", "eta": "0:04:21", "split": "test_iter", "time_diff": 1.01424}
[05/04 16:39:53][INFO] logging.py:  99: json_stats: {"cur_iter": "1052", "eta": "0:04:05", "split": "test_iter", "time_diff": 0.95353}
[05/04 16:39:54][INFO] logging.py:  99: json_stats: {"cur_iter": "1053", "eta": "0:04:01", "split": "test_iter", "time_diff": 0.94417}
[05/04 16:39:55][INFO] logging.py:  99: json_stats: {"cur_iter": "1054", "eta": "0:03:46", "split": "test_iter", "time_diff": 0.88735}
[05/04 16:39:55][INFO] logging.py:  99: json_stats: {"cur_iter": "1055", "eta": "0:03:44", "split": "test_iter", "time_diff": 0.88508}
[05/04 16:39:59][INFO] logging.py:  99: json_stats: {"cur_iter": "1056", "eta": "0:13:45", "split": "test_iter", "time_diff": 3.26344}
[05/04 16:40:01][INFO] logging.py:  99: json_stats: {"cur_iter": "1057", "eta": "0:10:28", "split": "test_iter", "time_diff": 2.49354}
[05/04 16:40:02][INFO] logging.py:  99: json_stats: {"cur_iter": "1058", "eta": "0:03:57", "split": "test_iter", "time_diff": 0.94731}
[05/04 16:40:03][INFO] logging.py:  99: json_stats: {"cur_iter": "1059", "eta": "0:04:02", "split": "test_iter", "time_diff": 0.96956}
[05/04 16:40:04][INFO] logging.py:  99: json_stats: {"cur_iter": "1060", "eta": "0:04:14", "split": "test_iter", "time_diff": 1.02260}
[05/04 16:40:05][INFO] logging.py:  99: json_stats: {"cur_iter": "1061", "eta": "0:03:38", "split": "test_iter", "time_diff": 0.88133}
[05/04 16:40:06][INFO] logging.py:  99: json_stats: {"cur_iter": "1062", "eta": "0:04:25", "split": "test_iter", "time_diff": 1.07489}
[05/04 16:40:07][INFO] logging.py:  99: json_stats: {"cur_iter": "1063", "eta": "0:04:10", "split": "test_iter", "time_diff": 1.01806}
[05/04 16:40:08][INFO] logging.py:  99: json_stats: {"cur_iter": "1064", "eta": "0:05:14", "split": "test_iter", "time_diff": 1.28491}
[05/04 16:40:09][INFO] logging.py:  99: json_stats: {"cur_iter": "1065", "eta": "0:04:02", "split": "test_iter", "time_diff": 0.99308}
[05/04 16:40:10][INFO] logging.py:  99: json_stats: {"cur_iter": "1066", "eta": "0:03:54", "split": "test_iter", "time_diff": 0.96687}
[05/04 16:40:11][INFO] logging.py:  99: json_stats: {"cur_iter": "1067", "eta": "0:04:01", "split": "test_iter", "time_diff": 0.99669}
[05/04 16:40:12][INFO] logging.py:  99: json_stats: {"cur_iter": "1068", "eta": "0:03:56", "split": "test_iter", "time_diff": 0.97998}
[05/04 16:40:13][INFO] logging.py:  99: json_stats: {"cur_iter": "1069", "eta": "0:03:34", "split": "test_iter", "time_diff": 0.89196}
[05/04 16:40:14][INFO] logging.py:  99: json_stats: {"cur_iter": "1070", "eta": "0:04:04", "split": "test_iter", "time_diff": 1.02425}
[05/04 16:40:15][INFO] logging.py:  99: json_stats: {"cur_iter": "1071", "eta": "0:03:37", "split": "test_iter", "time_diff": 0.91277}
[05/04 16:40:17][INFO] logging.py:  99: json_stats: {"cur_iter": "1072", "eta": "0:06:01", "split": "test_iter", "time_diff": 1.52374}
[05/04 16:40:18][INFO] logging.py:  99: json_stats: {"cur_iter": "1073", "eta": "0:05:06", "split": "test_iter", "time_diff": 1.30039}
[05/04 16:40:19][INFO] logging.py:  99: json_stats: {"cur_iter": "1074", "eta": "0:03:55", "split": "test_iter", "time_diff": 1.00153}
[05/04 16:40:20][INFO] logging.py:  99: json_stats: {"cur_iter": "1075", "eta": "0:03:24", "split": "test_iter", "time_diff": 0.87235}
[05/04 16:40:21][INFO] logging.py:  99: json_stats: {"cur_iter": "1076", "eta": "0:04:16", "split": "test_iter", "time_diff": 1.10218}
[05/04 16:40:22][INFO] logging.py:  99: json_stats: {"cur_iter": "1077", "eta": "0:03:46", "split": "test_iter", "time_diff": 0.97567}
[05/04 16:40:23][INFO] logging.py:  99: json_stats: {"cur_iter": "1078", "eta": "0:03:52", "split": "test_iter", "time_diff": 1.00760}
[05/04 16:40:24][INFO] logging.py:  99: json_stats: {"cur_iter": "1079", "eta": "0:03:23", "split": "test_iter", "time_diff": 0.88348}
[05/04 16:40:26][INFO] logging.py:  99: json_stats: {"cur_iter": "1080", "eta": "0:07:37", "split": "test_iter", "time_diff": 1.99631}
[05/04 16:40:28][INFO] logging.py:  99: json_stats: {"cur_iter": "1081", "eta": "0:06:55", "split": "test_iter", "time_diff": 1.82086}
[05/04 16:40:29][INFO] logging.py:  99: json_stats: {"cur_iter": "1082", "eta": "0:04:01", "split": "test_iter", "time_diff": 1.06270}
[05/04 16:40:30][INFO] logging.py:  99: json_stats: {"cur_iter": "1083", "eta": "0:03:20", "split": "test_iter", "time_diff": 0.88519}
[05/04 16:40:31][INFO] logging.py:  99: json_stats: {"cur_iter": "1084", "eta": "0:03:18", "split": "test_iter", "time_diff": 0.88415}
[05/04 16:40:32][INFO] logging.py:  99: json_stats: {"cur_iter": "1085", "eta": "0:03:41", "split": "test_iter", "time_diff": 0.98701}
[05/04 16:40:33][INFO] logging.py:  99: json_stats: {"cur_iter": "1086", "eta": "0:03:41", "split": "test_iter", "time_diff": 0.99179}
[05/04 16:40:34][INFO] logging.py:  99: json_stats: {"cur_iter": "1087", "eta": "0:03:35", "split": "test_iter", "time_diff": 0.97176}
[05/04 16:40:36][INFO] logging.py:  99: json_stats: {"cur_iter": "1088", "eta": "0:07:25", "split": "test_iter", "time_diff": 2.01689}
[05/04 16:40:38][INFO] logging.py:  99: json_stats: {"cur_iter": "1089", "eta": "0:08:29", "split": "test_iter", "time_diff": 2.31472}
[05/04 16:40:39][INFO] logging.py:  99: json_stats: {"cur_iter": "1090", "eta": "0:03:39", "split": "test_iter", "time_diff": 1.00135}
[05/04 16:40:40][INFO] logging.py:  99: json_stats: {"cur_iter": "1091", "eta": "0:03:10", "split": "test_iter", "time_diff": 0.87169}
[05/04 16:40:41][INFO] logging.py:  99: json_stats: {"cur_iter": "1092", "eta": "0:03:40", "split": "test_iter", "time_diff": 1.01541}
[05/04 16:40:42][INFO] logging.py:  99: json_stats: {"cur_iter": "1093", "eta": "0:03:27", "split": "test_iter", "time_diff": 0.96077}
[05/04 16:40:43][INFO] logging.py:  99: json_stats: {"cur_iter": "1094", "eta": "0:03:20", "split": "test_iter", "time_diff": 0.93330}
[05/04 16:40:44][INFO] logging.py:  99: json_stats: {"cur_iter": "1095", "eta": "0:03:06", "split": "test_iter", "time_diff": 0.87161}
[05/04 16:40:45][INFO] logging.py:  99: json_stats: {"cur_iter": "1096", "eta": "0:05:39", "split": "test_iter", "time_diff": 1.59537}
[05/04 16:40:47][INFO] logging.py:  99: json_stats: {"cur_iter": "1097", "eta": "0:05:46", "split": "test_iter", "time_diff": 1.63515}
[05/04 16:40:48][INFO] logging.py:  99: json_stats: {"cur_iter": "1098", "eta": "0:03:03", "split": "test_iter", "time_diff": 0.86934}
[05/04 16:40:49][INFO] logging.py:  99: json_stats: {"cur_iter": "1099", "eta": "0:03:29", "split": "test_iter", "time_diff": 0.99562}
[05/04 16:40:50][INFO] logging.py:  99: json_stats: {"cur_iter": "1100", "eta": "0:03:04", "split": "test_iter", "time_diff": 0.88069}
[05/04 16:40:51][INFO] logging.py:  99: json_stats: {"cur_iter": "1101", "eta": "0:03:24", "split": "test_iter", "time_diff": 0.98292}
[05/04 16:40:52][INFO] logging.py:  99: json_stats: {"cur_iter": "1102", "eta": "0:03:23", "split": "test_iter", "time_diff": 0.98550}
[05/04 16:40:53][INFO] logging.py:  99: json_stats: {"cur_iter": "1103", "eta": "0:03:16", "split": "test_iter", "time_diff": 0.95447}
[05/04 16:40:54][INFO] logging.py:  99: json_stats: {"cur_iter": "1104", "eta": "0:04:08", "split": "test_iter", "time_diff": 1.21390}
[05/04 16:40:55][INFO] logging.py:  99: json_stats: {"cur_iter": "1105", "eta": "0:04:21", "split": "test_iter", "time_diff": 1.28266}
[05/04 16:40:57][INFO] logging.py:  99: json_stats: {"cur_iter": "1106", "eta": "0:05:01", "split": "test_iter", "time_diff": 1.48407}
[05/04 16:40:58][INFO] logging.py:  99: json_stats: {"cur_iter": "1107", "eta": "0:03:15", "split": "test_iter", "time_diff": 0.96737}
[05/04 16:40:59][INFO] logging.py:  99: json_stats: {"cur_iter": "1108", "eta": "0:02:57", "split": "test_iter", "time_diff": 0.88323}
[05/04 16:41:00][INFO] logging.py:  99: json_stats: {"cur_iter": "1109", "eta": "0:03:15", "split": "test_iter", "time_diff": 0.97713}
[05/04 16:41:01][INFO] logging.py:  99: json_stats: {"cur_iter": "1110", "eta": "0:03:37", "split": "test_iter", "time_diff": 1.09067}
[05/04 16:41:02][INFO] logging.py:  99: json_stats: {"cur_iter": "1111", "eta": "0:03:08", "split": "test_iter", "time_diff": 0.95230}
[05/04 16:41:03][INFO] logging.py:  99: json_stats: {"cur_iter": "1112", "eta": "0:04:57", "split": "test_iter", "time_diff": 1.51070}
[05/04 16:41:05][INFO] logging.py:  99: json_stats: {"cur_iter": "1113", "eta": "0:04:01", "split": "test_iter", "time_diff": 1.23059}
[05/04 16:41:05][INFO] logging.py:  99: json_stats: {"cur_iter": "1114", "eta": "0:02:46", "split": "test_iter", "time_diff": 0.85613}
[05/04 16:41:06][INFO] logging.py:  99: json_stats: {"cur_iter": "1115", "eta": "0:03:23", "split": "test_iter", "time_diff": 1.05103}
[05/04 16:41:07][INFO] logging.py:  99: json_stats: {"cur_iter": "1116", "eta": "0:02:50", "split": "test_iter", "time_diff": 0.88471}
[05/04 16:41:08][INFO] logging.py:  99: json_stats: {"cur_iter": "1117", "eta": "0:03:43", "split": "test_iter", "time_diff": 1.16317}
[05/04 16:41:09][INFO] logging.py:  99: json_stats: {"cur_iter": "1118", "eta": "0:02:48", "split": "test_iter", "time_diff": 0.88242}
[05/04 16:41:10][INFO] logging.py:  99: json_stats: {"cur_iter": "1119", "eta": "0:03:22", "split": "test_iter", "time_diff": 1.06595}
[05/04 16:41:13][INFO] logging.py:  99: json_stats: {"cur_iter": "1120", "eta": "0:09:27", "split": "test_iter", "time_diff": 3.00398}
[05/04 16:41:15][INFO] logging.py:  99: json_stats: {"cur_iter": "1121", "eta": "0:04:29", "split": "test_iter", "time_diff": 1.43189}
[05/04 16:41:16][INFO] logging.py:  99: json_stats: {"cur_iter": "1122", "eta": "0:04:00", "split": "test_iter", "time_diff": 1.28427}
[05/04 16:41:17][INFO] logging.py:  99: json_stats: {"cur_iter": "1123", "eta": "0:03:10", "split": "test_iter", "time_diff": 1.02326}
[05/04 16:41:18][INFO] logging.py:  99: json_stats: {"cur_iter": "1124", "eta": "0:02:43", "split": "test_iter", "time_diff": 0.88127}
[05/04 16:41:19][INFO] logging.py:  99: json_stats: {"cur_iter": "1125", "eta": "0:02:53", "split": "test_iter", "time_diff": 0.94127}
[05/04 16:41:20][INFO] logging.py:  99: json_stats: {"cur_iter": "1126", "eta": "0:02:41", "split": "test_iter", "time_diff": 0.88190}
[05/04 16:41:21][INFO] logging.py:  99: json_stats: {"cur_iter": "1127", "eta": "0:03:02", "split": "test_iter", "time_diff": 1.00168}
[05/04 16:41:23][INFO] logging.py:  99: json_stats: {"cur_iter": "1128", "eta": "0:06:00", "split": "test_iter", "time_diff": 1.98895}
[05/04 16:41:24][INFO] logging.py:  99: json_stats: {"cur_iter": "1129", "eta": "0:02:51", "split": "test_iter", "time_diff": 0.95316}
[05/04 16:41:26][INFO] logging.py:  99: json_stats: {"cur_iter": "1130", "eta": "0:05:10", "split": "test_iter", "time_diff": 1.73278}
[05/04 16:41:27][INFO] logging.py:  99: json_stats: {"cur_iter": "1131", "eta": "0:03:02", "split": "test_iter", "time_diff": 1.02800}
[05/04 16:41:28][INFO] logging.py:  99: json_stats: {"cur_iter": "1132", "eta": "0:02:53", "split": "test_iter", "time_diff": 0.98069}
[05/04 16:41:29][INFO] logging.py:  99: json_stats: {"cur_iter": "1133", "eta": "0:02:47", "split": "test_iter", "time_diff": 0.95297}
[05/04 16:41:30][INFO] logging.py:  99: json_stats: {"cur_iter": "1134", "eta": "0:02:29", "split": "test_iter", "time_diff": 0.85513}
[05/04 16:41:31][INFO] logging.py:  99: json_stats: {"cur_iter": "1135", "eta": "0:02:49", "split": "test_iter", "time_diff": 0.97470}
[05/04 16:41:33][INFO] logging.py:  99: json_stats: {"cur_iter": "1136", "eta": "0:07:00", "split": "test_iter", "time_diff": 2.42831}
[05/04 16:41:34][INFO] logging.py:  99: json_stats: {"cur_iter": "1137", "eta": "0:02:59", "split": "test_iter", "time_diff": 1.04087}
[05/04 16:41:35][INFO] logging.py:  99: json_stats: {"cur_iter": "1138", "eta": "0:02:49", "split": "test_iter", "time_diff": 0.99061}
[05/04 16:41:36][INFO] logging.py:  99: json_stats: {"cur_iter": "1139", "eta": "0:02:30", "split": "test_iter", "time_diff": 0.88258}
[05/04 16:41:37][INFO] logging.py:  99: json_stats: {"cur_iter": "1140", "eta": "0:03:03", "split": "test_iter", "time_diff": 1.08745}
[05/04 16:41:38][INFO] logging.py:  99: json_stats: {"cur_iter": "1141", "eta": "0:02:54", "split": "test_iter", "time_diff": 1.03663}
[05/04 16:41:39][INFO] logging.py:  99: json_stats: {"cur_iter": "1142", "eta": "0:02:49", "split": "test_iter", "time_diff": 1.01263}
[05/04 16:41:40][INFO] logging.py:  99: json_stats: {"cur_iter": "1143", "eta": "0:02:41", "split": "test_iter", "time_diff": 0.97222}
[05/04 16:41:43][INFO] logging.py:  99: json_stats: {"cur_iter": "1144", "eta": "0:06:57", "split": "test_iter", "time_diff": 2.52947}
[05/04 16:41:44][INFO] logging.py:  99: json_stats: {"cur_iter": "1145", "eta": "0:02:37", "split": "test_iter", "time_diff": 0.96272}
[05/04 16:41:45][INFO] logging.py:  99: json_stats: {"cur_iter": "1146", "eta": "0:02:54", "split": "test_iter", "time_diff": 1.07040}
[05/04 16:41:46][INFO] logging.py:  99: json_stats: {"cur_iter": "1147", "eta": "0:03:04", "split": "test_iter", "time_diff": 1.13819}
[05/04 16:41:47][INFO] logging.py:  99: json_stats: {"cur_iter": "1148", "eta": "0:02:17", "split": "test_iter", "time_diff": 0.85468}
[05/04 16:41:48][INFO] logging.py:  99: json_stats: {"cur_iter": "1149", "eta": "0:02:39", "split": "test_iter", "time_diff": 0.99443}
[05/04 16:41:49][INFO] logging.py:  99: json_stats: {"cur_iter": "1150", "eta": "0:02:34", "split": "test_iter", "time_diff": 0.97299}
[05/04 16:41:50][INFO] logging.py:  99: json_stats: {"cur_iter": "1151", "eta": "0:02:32", "split": "test_iter", "time_diff": 0.96482}
[05/04 16:41:51][INFO] logging.py:  99: json_stats: {"cur_iter": "1152", "eta": "0:03:33", "split": "test_iter", "time_diff": 1.35757}
[05/04 16:41:52][INFO] logging.py:  99: json_stats: {"cur_iter": "1153", "eta": "0:03:13", "split": "test_iter", "time_diff": 1.23937}
[05/04 16:41:54][INFO] logging.py:  99: json_stats: {"cur_iter": "1154", "eta": "0:02:50", "split": "test_iter", "time_diff": 1.09715}
[05/04 16:41:55][INFO] logging.py:  99: json_stats: {"cur_iter": "1155", "eta": "0:02:31", "split": "test_iter", "time_diff": 0.98491}
[05/04 16:41:56][INFO] logging.py:  99: json_stats: {"cur_iter": "1156", "eta": "0:02:31", "split": "test_iter", "time_diff": 0.99306}
[05/04 16:41:57][INFO] logging.py:  99: json_stats: {"cur_iter": "1157", "eta": "0:02:31", "split": "test_iter", "time_diff": 0.99731}
[05/04 16:41:58][INFO] logging.py:  99: json_stats: {"cur_iter": "1158", "eta": "0:02:27", "split": "test_iter", "time_diff": 0.97941}
[05/04 16:41:59][INFO] logging.py:  99: json_stats: {"cur_iter": "1159", "eta": "0:02:27", "split": "test_iter", "time_diff": 0.98654}
[05/04 16:42:00][INFO] logging.py:  99: json_stats: {"cur_iter": "1160", "eta": "0:03:08", "split": "test_iter", "time_diff": 1.26553}
[05/04 16:42:02][INFO] logging.py:  99: json_stats: {"cur_iter": "1161", "eta": "0:04:46", "split": "test_iter", "time_diff": 1.93380}
[05/04 16:42:03][INFO] logging.py:  99: json_stats: {"cur_iter": "1162", "eta": "0:02:33", "split": "test_iter", "time_diff": 1.04701}
[05/04 16:42:04][INFO] logging.py:  99: json_stats: {"cur_iter": "1163", "eta": "0:02:23", "split": "test_iter", "time_diff": 0.98123}
[05/04 16:42:05][INFO] logging.py:  99: json_stats: {"cur_iter": "1164", "eta": "0:02:25", "split": "test_iter", "time_diff": 1.00075}
[05/04 16:42:06][INFO] logging.py:  99: json_stats: {"cur_iter": "1165", "eta": "0:02:06", "split": "test_iter", "time_diff": 0.88108}
[05/04 16:42:07][INFO] logging.py:  99: json_stats: {"cur_iter": "1166", "eta": "0:02:06", "split": "test_iter", "time_diff": 0.88439}
[05/04 16:42:08][INFO] logging.py:  99: json_stats: {"cur_iter": "1167", "eta": "0:02:20", "split": "test_iter", "time_diff": 0.98791}
[05/04 16:42:10][INFO] logging.py:  99: json_stats: {"cur_iter": "1168", "eta": "0:05:11", "split": "test_iter", "time_diff": 2.20598}
[05/04 16:42:12][INFO] logging.py:  99: json_stats: {"cur_iter": "1169", "eta": "0:04:41", "split": "test_iter", "time_diff": 2.00998}
[05/04 16:42:13][INFO] logging.py:  99: json_stats: {"cur_iter": "1170", "eta": "0:02:16", "split": "test_iter", "time_diff": 0.98164}
[05/04 16:42:14][INFO] logging.py:  99: json_stats: {"cur_iter": "1171", "eta": "0:02:11", "split": "test_iter", "time_diff": 0.95185}
[05/04 16:42:15][INFO] logging.py:  99: json_stats: {"cur_iter": "1172", "eta": "0:02:02", "split": "test_iter", "time_diff": 0.89358}
[05/04 16:42:16][INFO] logging.py:  99: json_stats: {"cur_iter": "1173", "eta": "0:02:14", "split": "test_iter", "time_diff": 0.98865}
[05/04 16:42:17][INFO] logging.py:  99: json_stats: {"cur_iter": "1174", "eta": "0:01:55", "split": "test_iter", "time_diff": 0.85402}
[05/04 16:42:18][INFO] logging.py:  99: json_stats: {"cur_iter": "1175", "eta": "0:02:13", "split": "test_iter", "time_diff": 0.99759}
[05/04 16:42:19][INFO] logging.py:  99: json_stats: {"cur_iter": "1176", "eta": "0:03:24", "split": "test_iter", "time_diff": 1.53734}
[05/04 16:42:21][INFO] logging.py:  99: json_stats: {"cur_iter": "1177", "eta": "0:04:20", "split": "test_iter", "time_diff": 1.97309}
[05/04 16:42:22][INFO] logging.py:  99: json_stats: {"cur_iter": "1178", "eta": "0:02:23", "split": "test_iter", "time_diff": 1.09321}
[05/04 16:42:23][INFO] logging.py:  99: json_stats: {"cur_iter": "1179", "eta": "0:02:06", "split": "test_iter", "time_diff": 0.97313}
[05/04 16:42:24][INFO] logging.py:  99: json_stats: {"cur_iter": "1180", "eta": "0:02:15", "split": "test_iter", "time_diff": 1.04986}
[05/04 16:42:26][INFO] logging.py:  99: json_stats: {"cur_iter": "1181", "eta": "0:02:51", "split": "test_iter", "time_diff": 1.34007}
[05/04 16:42:27][INFO] logging.py:  99: json_stats: {"cur_iter": "1182", "eta": "0:02:01", "split": "test_iter", "time_diff": 0.95444}
[05/04 16:42:28][INFO] logging.py:  99: json_stats: {"cur_iter": "1183", "eta": "0:01:50", "split": "test_iter", "time_diff": 0.87821}
[05/04 16:42:30][INFO] logging.py:  99: json_stats: {"cur_iter": "1184", "eta": "0:04:54", "split": "test_iter", "time_diff": 2.35779}
[05/04 16:42:32][INFO] logging.py:  99: json_stats: {"cur_iter": "1185", "eta": "0:04:12", "split": "test_iter", "time_diff": 2.03237}
[05/04 16:42:33][INFO] logging.py:  99: json_stats: {"cur_iter": "1186", "eta": "0:01:45", "split": "test_iter", "time_diff": 0.85411}
[05/04 16:42:34][INFO] logging.py:  99: json_stats: {"cur_iter": "1187", "eta": "0:01:58", "split": "test_iter", "time_diff": 0.97045}
[05/04 16:42:35][INFO] logging.py:  99: json_stats: {"cur_iter": "1188", "eta": "0:02:00", "split": "test_iter", "time_diff": 0.99576}
[05/04 16:42:36][INFO] logging.py:  99: json_stats: {"cur_iter": "1189", "eta": "0:01:42", "split": "test_iter", "time_diff": 0.85395}
[05/04 16:42:37][INFO] logging.py:  99: json_stats: {"cur_iter": "1190", "eta": "0:02:01", "split": "test_iter", "time_diff": 1.02281}
[05/04 16:42:38][INFO] logging.py:  99: json_stats: {"cur_iter": "1191", "eta": "0:01:40", "split": "test_iter", "time_diff": 0.85451}
[05/04 16:42:40][INFO] logging.py:  99: json_stats: {"cur_iter": "1192", "eta": "0:03:48", "split": "test_iter", "time_diff": 1.95183}
[05/04 16:42:42][INFO] logging.py:  99: json_stats: {"cur_iter": "1193", "eta": "0:04:14", "split": "test_iter", "time_diff": 2.19656}
[05/04 16:42:43][INFO] logging.py:  99: json_stats: {"cur_iter": "1194", "eta": "0:01:54", "split": "test_iter", "time_diff": 0.99315}
[05/04 16:42:44][INFO] logging.py:  99: json_stats: {"cur_iter": "1195", "eta": "0:01:51", "split": "test_iter", "time_diff": 0.97757}
[05/04 16:42:45][INFO] logging.py:  99: json_stats: {"cur_iter": "1196", "eta": "0:01:59", "split": "test_iter", "time_diff": 1.05689}
[05/04 16:42:46][INFO] logging.py:  99: json_stats: {"cur_iter": "1197", "eta": "0:01:50", "split": "test_iter", "time_diff": 0.98505}
[05/04 16:42:47][INFO] logging.py:  99: json_stats: {"cur_iter": "1198", "eta": "0:01:47", "split": "test_iter", "time_diff": 0.96937}
[05/04 16:42:48][INFO] logging.py:  99: json_stats: {"cur_iter": "1199", "eta": "0:01:35", "split": "test_iter", "time_diff": 0.86755}
[05/04 16:42:49][INFO] logging.py:  99: json_stats: {"cur_iter": "1200", "eta": "0:02:56", "split": "test_iter", "time_diff": 1.62026}
[05/04 16:42:51][INFO] logging.py:  99: json_stats: {"cur_iter": "1201", "eta": "0:02:53", "split": "test_iter", "time_diff": 1.60862}
[05/04 16:42:52][INFO] logging.py:  99: json_stats: {"cur_iter": "1202", "eta": "0:01:34", "split": "test_iter", "time_diff": 0.88508}
[05/04 16:42:53][INFO] logging.py:  99: json_stats: {"cur_iter": "1203", "eta": "0:01:42", "split": "test_iter", "time_diff": 0.96877}
[05/04 16:42:54][INFO] logging.py:  99: json_stats: {"cur_iter": "1204", "eta": "0:01:41", "split": "test_iter", "time_diff": 0.96802}
[05/04 16:42:55][INFO] logging.py:  99: json_stats: {"cur_iter": "1205", "eta": "0:01:45", "split": "test_iter", "time_diff": 1.01233}
[05/04 16:42:56][INFO] logging.py:  99: json_stats: {"cur_iter": "1206", "eta": "0:01:39", "split": "test_iter", "time_diff": 0.96694}
[05/04 16:42:57][INFO] logging.py:  99: json_stats: {"cur_iter": "1207", "eta": "0:01:27", "split": "test_iter", "time_diff": 0.85316}
[05/04 16:42:58][INFO] logging.py:  99: json_stats: {"cur_iter": "1208", "eta": "0:02:10", "split": "test_iter", "time_diff": 1.29530}
[05/04 16:43:00][INFO] logging.py:  99: json_stats: {"cur_iter": "1209", "eta": "0:02:56", "split": "test_iter", "time_diff": 1.76853}
[05/04 16:43:01][INFO] logging.py:  99: json_stats: {"cur_iter": "1210", "eta": "0:01:40", "split": "test_iter", "time_diff": 1.01167}
[05/04 16:43:02][INFO] logging.py:  99: json_stats: {"cur_iter": "1211", "eta": "0:01:33", "split": "test_iter", "time_diff": 0.94961}
[05/04 16:43:03][INFO] logging.py:  99: json_stats: {"cur_iter": "1212", "eta": "0:01:35", "split": "test_iter", "time_diff": 0.98015}
[05/04 16:43:04][INFO] logging.py:  99: json_stats: {"cur_iter": "1213", "eta": "0:01:32", "split": "test_iter", "time_diff": 0.95892}
[05/04 16:43:05][INFO] logging.py:  99: json_stats: {"cur_iter": "1214", "eta": "0:01:41", "split": "test_iter", "time_diff": 1.06728}
[05/04 16:43:06][INFO] logging.py:  99: json_stats: {"cur_iter": "1215", "eta": "0:01:23", "split": "test_iter", "time_diff": 0.88438}
[05/04 16:43:09][INFO] logging.py:  99: json_stats: {"cur_iter": "1216", "eta": "0:04:35", "split": "test_iter", "time_diff": 2.96016}
[05/04 16:43:10][INFO] logging.py:  99: json_stats: {"cur_iter": "1217", "eta": "0:02:32", "split": "test_iter", "time_diff": 1.65475}
[05/04 16:43:11][INFO] logging.py:  99: json_stats: {"cur_iter": "1218", "eta": "0:01:30", "split": "test_iter", "time_diff": 0.99513}
[05/04 16:43:12][INFO] logging.py:  99: json_stats: {"cur_iter": "1219", "eta": "0:01:19", "split": "test_iter", "time_diff": 0.88499}
[05/04 16:43:13][INFO] logging.py:  99: json_stats: {"cur_iter": "1220", "eta": "0:01:37", "split": "test_iter", "time_diff": 1.09912}
[05/04 16:43:14][INFO] logging.py:  99: json_stats: {"cur_iter": "1221", "eta": "0:01:28", "split": "test_iter", "time_diff": 1.00162}
[05/04 16:43:15][INFO] logging.py:  99: json_stats: {"cur_iter": "1222", "eta": "0:01:22", "split": "test_iter", "time_diff": 0.94999}
[05/04 16:43:16][INFO] logging.py:  99: json_stats: {"cur_iter": "1223", "eta": "0:01:25", "split": "test_iter", "time_diff": 0.99531}
[05/04 16:43:18][INFO] logging.py:  99: json_stats: {"cur_iter": "1224", "eta": "0:02:32", "split": "test_iter", "time_diff": 1.79341}
[05/04 16:43:19][INFO] logging.py:  99: json_stats: {"cur_iter": "1225", "eta": "0:01:48", "split": "test_iter", "time_diff": 1.29365}
[05/04 16:43:21][INFO] logging.py:  99: json_stats: {"cur_iter": "1226", "eta": "0:01:28", "split": "test_iter", "time_diff": 1.06837}
[05/04 16:43:21][INFO] logging.py:  99: json_stats: {"cur_iter": "1227", "eta": "0:01:18", "split": "test_iter", "time_diff": 0.95267}
[05/04 16:43:22][INFO] logging.py:  99: json_stats: {"cur_iter": "1228", "eta": "0:01:16", "split": "test_iter", "time_diff": 0.94937}
[05/04 16:43:23][INFO] logging.py:  99: json_stats: {"cur_iter": "1229", "eta": "0:01:22", "split": "test_iter", "time_diff": 1.02879}
[05/04 16:43:25][INFO] logging.py:  99: json_stats: {"cur_iter": "1230", "eta": "0:01:26", "split": "test_iter", "time_diff": 1.09282}
[05/04 16:43:25][INFO] logging.py:  99: json_stats: {"cur_iter": "1231", "eta": "0:01:08", "split": "test_iter", "time_diff": 0.87948}
[05/04 16:43:28][INFO] logging.py:  99: json_stats: {"cur_iter": "1232", "eta": "0:03:01", "split": "test_iter", "time_diff": 2.35399}
[05/04 16:43:29][INFO] logging.py:  99: json_stats: {"cur_iter": "1233", "eta": "0:01:29", "split": "test_iter", "time_diff": 1.17983}
[05/04 16:43:30][INFO] logging.py:  99: json_stats: {"cur_iter": "1234", "eta": "0:01:13", "split": "test_iter", "time_diff": 0.97539}
[05/04 16:43:31][INFO] logging.py:  99: json_stats: {"cur_iter": "1235", "eta": "0:01:14", "split": "test_iter", "time_diff": 1.00255}
[05/04 16:43:32][INFO] logging.py:  99: json_stats: {"cur_iter": "1236", "eta": "0:01:10", "split": "test_iter", "time_diff": 0.96975}
[05/04 16:43:33][INFO] logging.py:  99: json_stats: {"cur_iter": "1237", "eta": "0:01:10", "split": "test_iter", "time_diff": 0.98080}
[05/04 16:43:34][INFO] logging.py:  99: json_stats: {"cur_iter": "1238", "eta": "0:01:09", "split": "test_iter", "time_diff": 0.97986}
[05/04 16:43:35][INFO] logging.py:  99: json_stats: {"cur_iter": "1239", "eta": "0:01:07", "split": "test_iter", "time_diff": 0.96419}
[05/04 16:43:37][INFO] logging.py:  99: json_stats: {"cur_iter": "1240", "eta": "0:01:43", "split": "test_iter", "time_diff": 1.50490}
[05/04 16:43:37][INFO] logging.py:  99: json_stats: {"cur_iter": "1241", "eta": "0:00:58", "split": "test_iter", "time_diff": 0.85891}
[05/04 16:43:38][INFO] logging.py:  99: json_stats: {"cur_iter": "1242", "eta": "0:01:05", "split": "test_iter", "time_diff": 0.97783}
[05/04 16:43:39][INFO] logging.py:  99: json_stats: {"cur_iter": "1243", "eta": "0:01:04", "split": "test_iter", "time_diff": 0.98360}
[05/04 16:43:40][INFO] logging.py:  99: json_stats: {"cur_iter": "1244", "eta": "0:00:56", "split": "test_iter", "time_diff": 0.87156}
[05/04 16:43:41][INFO] logging.py:  99: json_stats: {"cur_iter": "1245", "eta": "0:01:07", "split": "test_iter", "time_diff": 1.06063}
[05/04 16:43:42][INFO] logging.py:  99: json_stats: {"cur_iter": "1246", "eta": "0:01:02", "split": "test_iter", "time_diff": 0.98659}
[05/04 16:43:43][INFO] logging.py:  99: json_stats: {"cur_iter": "1247", "eta": "0:01:02", "split": "test_iter", "time_diff": 1.00950}
[05/04 16:43:46][INFO] logging.py:  99: json_stats: {"cur_iter": "1248", "eta": "0:02:12", "split": "test_iter", "time_diff": 2.17177}
[05/04 16:43:47][INFO] logging.py:  99: json_stats: {"cur_iter": "1249", "eta": "0:01:39", "split": "test_iter", "time_diff": 1.66270}
[05/04 16:43:48][INFO] logging.py:  99: json_stats: {"cur_iter": "1250", "eta": "0:00:52", "split": "test_iter", "time_diff": 0.88205}
[05/04 16:43:49][INFO] logging.py:  99: json_stats: {"cur_iter": "1251", "eta": "0:00:55", "split": "test_iter", "time_diff": 0.96101}
[05/04 16:43:50][INFO] logging.py:  99: json_stats: {"cur_iter": "1252", "eta": "0:00:55", "split": "test_iter", "time_diff": 0.97393}
[05/04 16:43:51][INFO] logging.py:  99: json_stats: {"cur_iter": "1253", "eta": "0:00:55", "split": "test_iter", "time_diff": 0.98246}
[05/04 16:43:52][INFO] logging.py:  99: json_stats: {"cur_iter": "1254", "eta": "0:00:54", "split": "test_iter", "time_diff": 0.98592}
[05/04 16:43:53][INFO] logging.py:  99: json_stats: {"cur_iter": "1255", "eta": "0:00:53", "split": "test_iter", "time_diff": 0.98467}
[05/04 16:43:55][INFO] logging.py:  99: json_stats: {"cur_iter": "1256", "eta": "0:01:18", "split": "test_iter", "time_diff": 1.47917}
[05/04 16:43:56][INFO] logging.py:  99: json_stats: {"cur_iter": "1257", "eta": "0:00:55", "split": "test_iter", "time_diff": 1.07059}
[05/04 16:43:57][INFO] logging.py:  99: json_stats: {"cur_iter": "1258", "eta": "0:00:44", "split": "test_iter", "time_diff": 0.86888}
[05/04 16:43:58][INFO] logging.py:  99: json_stats: {"cur_iter": "1259", "eta": "0:00:49", "split": "test_iter", "time_diff": 0.98299}
[05/04 16:43:59][INFO] logging.py:  99: json_stats: {"cur_iter": "1260", "eta": "0:00:49", "split": "test_iter", "time_diff": 1.00995}
[05/04 16:43:59][INFO] logging.py:  99: json_stats: {"cur_iter": "1261", "eta": "0:00:41", "split": "test_iter", "time_diff": 0.86019}
[05/04 16:44:00][INFO] logging.py:  99: json_stats: {"cur_iter": "1262", "eta": "0:00:45", "split": "test_iter", "time_diff": 0.96668}
[05/04 16:44:02][INFO] logging.py:  99: json_stats: {"cur_iter": "1263", "eta": "0:00:51", "split": "test_iter", "time_diff": 1.12490}
[05/04 16:44:03][INFO] logging.py:  99: json_stats: {"cur_iter": "1264", "eta": "0:00:45", "split": "test_iter", "time_diff": 1.01312}
[05/04 16:44:04][INFO] logging.py:  99: json_stats: {"cur_iter": "1265", "eta": "0:00:52", "split": "test_iter", "time_diff": 1.19899}
[05/04 16:44:05][INFO] logging.py:  99: json_stats: {"cur_iter": "1266", "eta": "0:00:43", "split": "test_iter", "time_diff": 1.00203}
[05/04 16:44:06][INFO] logging.py:  99: json_stats: {"cur_iter": "1267", "eta": "0:00:43", "split": "test_iter", "time_diff": 1.03524}
[05/04 16:44:07][INFO] logging.py:  99: json_stats: {"cur_iter": "1268", "eta": "0:00:40", "split": "test_iter", "time_diff": 0.99775}
[05/04 16:44:08][INFO] logging.py:  99: json_stats: {"cur_iter": "1269", "eta": "0:00:38", "split": "test_iter", "time_diff": 0.96852}
[05/04 16:44:09][INFO] logging.py:  99: json_stats: {"cur_iter": "1270", "eta": "0:00:34", "split": "test_iter", "time_diff": 0.88511}
[05/04 16:44:10][INFO] logging.py:  99: json_stats: {"cur_iter": "1271", "eta": "0:00:41", "split": "test_iter", "time_diff": 1.08246}
[05/04 16:44:11][INFO] logging.py:  99: json_stats: {"cur_iter": "1272", "eta": "0:00:47", "split": "test_iter", "time_diff": 1.27904}
[05/04 16:44:12][INFO] logging.py:  99: json_stats: {"cur_iter": "1273", "eta": "0:00:47", "split": "test_iter", "time_diff": 1.31782}
[05/04 16:44:13][INFO] logging.py:  99: json_stats: {"cur_iter": "1274", "eta": "0:00:33", "split": "test_iter", "time_diff": 0.95770}
[05/04 16:44:14][INFO] logging.py:  99: json_stats: {"cur_iter": "1275", "eta": "0:00:32", "split": "test_iter", "time_diff": 0.96737}
[05/04 16:44:15][INFO] logging.py:  99: json_stats: {"cur_iter": "1276", "eta": "0:00:32", "split": "test_iter", "time_diff": 0.97146}
[05/04 16:44:16][INFO] logging.py:  99: json_stats: {"cur_iter": "1277", "eta": "0:00:31", "split": "test_iter", "time_diff": 0.99897}
[05/04 16:44:17][INFO] logging.py:  99: json_stats: {"cur_iter": "1278", "eta": "0:00:27", "split": "test_iter", "time_diff": 0.88306}
[05/04 16:44:18][INFO] logging.py:  99: json_stats: {"cur_iter": "1279", "eta": "0:00:32", "split": "test_iter", "time_diff": 1.09336}
[05/04 16:44:20][INFO] logging.py:  99: json_stats: {"cur_iter": "1280", "eta": "0:00:53", "split": "test_iter", "time_diff": 1.85967}
[05/04 16:44:22][INFO] logging.py:  99: json_stats: {"cur_iter": "1281", "eta": "0:00:42", "split": "test_iter", "time_diff": 1.51972}
[05/04 16:44:23][INFO] logging.py:  99: json_stats: {"cur_iter": "1282", "eta": "0:00:28", "split": "test_iter", "time_diff": 1.05357}
[05/04 16:44:24][INFO] logging.py:  99: json_stats: {"cur_iter": "1283", "eta": "0:00:23", "split": "test_iter", "time_diff": 0.89364}
[05/04 16:44:25][INFO] logging.py:  99: json_stats: {"cur_iter": "1284", "eta": "0:00:24", "split": "test_iter", "time_diff": 0.99738}
[05/04 16:44:26][INFO] logging.py:  99: json_stats: {"cur_iter": "1285", "eta": "0:00:21", "split": "test_iter", "time_diff": 0.88357}
[05/04 16:44:27][INFO] logging.py:  99: json_stats: {"cur_iter": "1286", "eta": "0:00:22", "split": "test_iter", "time_diff": 0.99961}
[05/04 16:44:28][INFO] logging.py:  99: json_stats: {"cur_iter": "1287", "eta": "0:00:21", "split": "test_iter", "time_diff": 0.98588}
[05/04 16:44:29][INFO] logging.py:  99: json_stats: {"cur_iter": "1288", "eta": "0:00:26", "split": "test_iter", "time_diff": 1.27581}
[05/04 16:44:30][INFO] logging.py:  99: json_stats: {"cur_iter": "1289", "eta": "0:00:26", "split": "test_iter", "time_diff": 1.31635}
[05/04 16:44:31][INFO] logging.py:  99: json_stats: {"cur_iter": "1290", "eta": "0:00:18", "split": "test_iter", "time_diff": 0.95636}
[05/04 16:44:32][INFO] logging.py:  99: json_stats: {"cur_iter": "1291", "eta": "0:00:17", "split": "test_iter", "time_diff": 0.96427}
[05/04 16:44:33][INFO] logging.py:  99: json_stats: {"cur_iter": "1292", "eta": "0:00:14", "split": "test_iter", "time_diff": 0.87353}
[05/04 16:44:34][INFO] logging.py:  99: json_stats: {"cur_iter": "1293", "eta": "0:00:16", "split": "test_iter", "time_diff": 1.05491}
[05/04 16:44:35][INFO] logging.py:  99: json_stats: {"cur_iter": "1294", "eta": "0:00:14", "split": "test_iter", "time_diff": 0.99791}
[05/04 16:44:36][INFO] logging.py:  99: json_stats: {"cur_iter": "1295", "eta": "0:00:13", "split": "test_iter", "time_diff": 0.97421}
[05/04 16:44:38][INFO] logging.py:  99: json_stats: {"cur_iter": "1296", "eta": "0:00:22", "split": "test_iter", "time_diff": 1.73760}
[05/04 16:44:39][INFO] logging.py:  99: json_stats: {"cur_iter": "1297", "eta": "0:00:11", "split": "test_iter", "time_diff": 0.95854}
[05/04 16:44:40][INFO] logging.py:  99: json_stats: {"cur_iter": "1298", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.85515}
[05/04 16:44:41][INFO] logging.py:  99: json_stats: {"cur_iter": "1299", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.96070}
[05/04 16:44:42][INFO] logging.py:  99: json_stats: {"cur_iter": "1300", "eta": "0:00:09", "split": "test_iter", "time_diff": 1.04548}
[05/04 16:44:43][INFO] logging.py:  99: json_stats: {"cur_iter": "1301", "eta": "0:00:07", "split": "test_iter", "time_diff": 0.87723}
[05/04 16:44:44][INFO] logging.py:  99: json_stats: {"cur_iter": "1302", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.92301}
[05/04 16:44:45][INFO] logging.py:  99: json_stats: {"cur_iter": "1303", "eta": "0:00:06", "split": "test_iter", "time_diff": 1.06232}
[05/04 16:44:46][INFO] logging.py:  99: json_stats: {"cur_iter": "1304", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.88155}
[05/04 16:44:47][INFO] logging.py:  99: json_stats: {"cur_iter": "1305", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.88406}
[05/04 16:44:47][INFO] logging.py:  99: json_stats: {"cur_iter": "1306", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.88468}
[05/04 16:44:48][INFO] logging.py:  99: json_stats: {"cur_iter": "1307", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.88563}
[05/04 16:44:48][INFO] logging.py:  99: json_stats: {"cur_iter": "1308", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.12085}
[05/04 16:44:48][WARNING] meters.py: 381: clip count 0: 9, 1: 9, 2: 9, 3: 9, 4: 9, 5: 9, 6: 9, 7: 9, 8: 9, 9: 9, 10: 9, 11: 9, 12: 9, 13: 9, 14: 9, 15: 9, 16: 9, 17: 9, 18: 9, 19: 9, 20: 9, 21: 9, 22: 9, 23: 9, 24: 9, 25: 9, 26: 9, 27: 9, 28: 9, 29: 9, 30: 9, 31: 9, 32: 9, 33: 9, 34: 9, 35: 9, 36: 9, 37: 9, 38: 9, 39: 9, 40: 9, 41: 9, 42: 9, 43: 9, 44: 9, 45: 9, 46: 9, 47: 9, 48: 9, 49: 9, 50: 9, 51: 9, 52: 9, 53: 9, 54: 9, 55: 9, 56: 9, 57: 9, 58: 9, 59: 9, 60: 9, 61: 9, 62: 9, 63: 9, 64: 9, 65: 9, 66: 9, 67: 9, 68: 9, 69: 9, 70: 9, 71: 9, 72: 9, 73: 9, 74: 9, 75: 9, 76: 9, 77: 9, 78: 9, 79: 9, 80: 9, 81: 9, 82: 9, 83: 9, 84: 9, 85: 9, 86: 9, 87: 9, 88: 9, 89: 9, 90: 9, 91: 9, 92: 9, 93: 9, 94: 9, 95: 9, 96: 9, 97: 9, 98: 9, 99: 9, 100: 9, 101: 9, 102: 9, 103: 9, 104: 9, 105: 9, 106: 9, 107: 9, 108: 9, 109: 9, 110: 9, 111: 9, 112: 9, 113: 9, 114: 9, 115: 9, 116: 9, 117: 9, 118: 9, 119: 9, 120: 9, 121: 9, 122: 9, 123: 9, 124: 9, 125: 9, 126: 9, 127: 9, 128: 9, 129: 9, 130: 9, 131: 9, 132: 9, 133: 9, 134: 9, 135: 9, 136: 9, 137: 9, 138: 9, 139: 9, 140: 9, 141: 9, 142: 9, 143: 9, 144: 9, 145: 9, 146: 9, 147: 9, 148: 9, 149: 9, 150: 9, 151: 9, 152: 9, 153: 9, 154: 9, 155: 9, 156: 9, 157: 9, 158: 9, 159: 9, 160: 9, 161: 9, 162: 9, 163: 9, 164: 9, 165: 9, 166: 9, 167: 9, 168: 9, 169: 9, 170: 9, 171: 9, 172: 9, 173: 9, 174: 9, 175: 9, 176: 9, 177: 9, 178: 9, 179: 9, 180: 9, 181: 9, 182: 9, 183: 9, 184: 9, 185: 9, 186: 9, 187: 9, 188: 9, 189: 9, 190: 9, 191: 9, 192: 9, 193: 9, 194: 9, 195: 9, 196: 9, 197: 9, 198: 9, 199: 9, 200: 9, 201: 9, 202: 9, 203: 9, 204: 9, 205: 9, 206: 9, 207: 9, 208: 9, 209: 9, 210: 9, 211: 9, 212: 9, 213: 9, 214: 9, 215: 9, 216: 9, 217: 9, 218: 9, 219: 9, 220: 9, 221: 9, 222: 9, 223: 9, 224: 9, 225: 9, 226: 9, 227: 9, 228: 9, 229: 9, 230: 9, 231: 9, 232: 9, 233: 9, 234: 9, 235: 9, 236: 9, 237: 9, 238: 9, 239: 9, 240: 9, 241: 9, 242: 9, 243: 9, 244: 9, 245: 9, 246: 9, 247: 9, 248: 9, 249: 9, 250: 9, 251: 9, 252: 9, 253: 9, 254: 9, 255: 9, 256: 9, 257: 9, 258: 9, 259: 9, 260: 9, 261: 9, 262: 9, 263: 9, 264: 9, 265: 9, 266: 9, 267: 9, 268: 9, 269: 9, 270: 9, 271: 9, 272: 9, 273: 9, 274: 9, 275: 9, 276: 9, 277: 9, 278: 9, 279: 9, 280: 9, 281: 9, 282: 9, 283: 9, 284: 9, 285: 9, 286: 9, 287: 9, 288: 9, 289: 9, 290: 9, 291: 9, 292: 9, 293: 9, 294: 9, 295: 9, 296: 9, 297: 9, 298: 9, 299: 9, 300: 9, 301: 9, 302: 9, 303: 9, 304: 9, 305: 9, 306: 9, 307: 9, 308: 9, 309: 9, 310: 9, 311: 9, 312: 9, 313: 9, 314: 9, 315: 9, 316: 9, 317: 9, 318: 9, 319: 9, 320: 9, 321: 9, 322: 9, 323: 9, 324: 9, 325: 9, 326: 9, 327: 9, 328: 9, 329: 9, 330: 9, 331: 9, 332: 9, 333: 9, 334: 9, 335: 9, 336: 9, 337: 9, 338: 9, 339: 9, 340: 9, 341: 9, 342: 9, 343: 9, 344: 9, 345: 9, 346: 9, 347: 9, 348: 9, 349: 9, 350: 9, 351: 9, 352: 9, 353: 9, 354: 9, 355: 9, 356: 9, 357: 9, 358: 9, 359: 9, 360: 9, 361: 9, 362: 9, 363: 9, 364: 9, 365: 9, 366: 9, 367: 9, 368: 9, 369: 9, 370: 9, 371: 9, 372: 9, 373: 9, 374: 9, 375: 9, 376: 9, 377: 9, 378: 9, 379: 9, 380: 9, 381: 9, 382: 9, 383: 9, 384: 9, 385: 9, 386: 9, 387: 9, 388: 9, 389: 9, 390: 9, 391: 9, 392: 9, 393: 9, 394: 9, 395: 9, 396: 9, 397: 9, 398: 9, 399: 9, 400: 9, 401: 9, 402: 9, 403: 9, 404: 9, 405: 9, 406: 9, 407: 9, 408: 9, 409: 9, 410: 9, 411: 9, 412: 9, 413: 9, 414: 9, 415: 9, 416: 9, 417: 9, 418: 9, 419: 9, 420: 9, 421: 9, 422: 9, 423: 9, 424: 9, 425: 9, 426: 9, 427: 9, 428: 9, 429: 9, 430: 9, 431: 9, 432: 9, 433: 9, 434: 9, 435: 9, 436: 9, 437: 9, 438: 9, 439: 9, 440: 9, 441: 9, 442: 9, 443: 9, 444: 9, 445: 9, 446: 9, 447: 9, 448: 9, 449: 9, 450: 9, 451: 9, 452: 9, 453: 9, 454: 9, 455: 9, 456: 9, 457: 9, 458: 9, 459: 9, 460: 9, 461: 9, 462: 9, 463: 9, 464: 9, 465: 9, 466: 9, 467: 9, 468: 9, 469: 9, 470: 9, 471: 9, 472: 9, 473: 9, 474: 9, 475: 9, 476: 9, 477: 9, 478: 9, 479: 9, 480: 9, 481: 9, 482: 9, 483: 9, 484: 9, 485: 9, 486: 9, 487: 9, 488: 9, 489: 9, 490: 9, 491: 9, 492: 9, 493: 9, 494: 9, 495: 9, 496: 9, 497: 9, 498: 9, 499: 9, 500: 9, 501: 9, 502: 9, 503: 9, 504: 9, 505: 9, 506: 9, 507: 9, 508: 9, 509: 9, 510: 9, 511: 9, 512: 9, 513: 9, 514: 9, 515: 9, 516: 9, 517: 9, 518: 9, 519: 9, 520: 9, 521: 9, 522: 9, 523: 9, 524: 9, 525: 9, 526: 9, 527: 9, 528: 9, 529: 9, 530: 9, 531: 9, 532: 9, 533: 9, 534: 9, 535: 9, 536: 9, 537: 9, 538: 9, 539: 9, 540: 9, 541: 9, 542: 9, 543: 9, 544: 9, 545: 9, 546: 9, 547: 9, 548: 9, 549: 9, 550: 9, 551: 9, 552: 9, 553: 9, 554: 9, 555: 9, 556: 9, 557: 9, 558: 9, 559: 9, 560: 9, 561: 9, 562: 9, 563: 9, 564: 9, 565: 9, 566: 9, 567: 9, 568: 9, 569: 9, 570: 9, 571: 9, 572: 9, 573: 9, 574: 9, 575: 9, 576: 9, 577: 9, 578: 9, 579: 9, 580: 9, 581: 9, 582: 9, 583: 9, 584: 9, 585: 9, 586: 9, 587: 9, 588: 9, 589: 9, 590: 9, 591: 9, 592: 9, 593: 9, 594: 9, 595: 9, 596: 9, 597: 9, 598: 9, 599: 9, 600: 9, 601: 9, 602: 9, 603: 9, 604: 9, 605: 9, 606: 9, 607: 9, 608: 9, 609: 9, 610: 9, 611: 9, 612: 9, 613: 9, 614: 9, 615: 9, 616: 9, 617: 9, 618: 9, 619: 9, 620: 9, 621: 9, 622: 9, 623: 9, 624: 9, 625: 9, 626: 9, 627: 9, 628: 9, 629: 9, 630: 9, 631: 9, 632: 9, 633: 9, 634: 9, 635: 9, 636: 9, 637: 9, 638: 9, 639: 9, 640: 9, 641: 9, 642: 9, 643: 9, 644: 9, 645: 9, 646: 9, 647: 9, 648: 9, 649: 9, 650: 9, 651: 9, 652: 9, 653: 9, 654: 9, 655: 9, 656: 9, 657: 9, 658: 9, 659: 9, 660: 9, 661: 9, 662: 9, 663: 9, 664: 9, 665: 9, 666: 9, 667: 9, 668: 9, 669: 9, 670: 9, 671: 9, 672: 9, 673: 9, 674: 9, 675: 9, 676: 9, 677: 9, 678: 9, 679: 9, 680: 9, 681: 9, 682: 9, 683: 9, 684: 9, 685: 9, 686: 9, 687: 9, 688: 9, 689: 9, 690: 9, 691: 9, 692: 9, 693: 9, 694: 9, 695: 9, 696: 9, 697: 9, 698: 9, 699: 9, 700: 9, 701: 9, 702: 9, 703: 9, 704: 9, 705: 9, 706: 9, 707: 9, 708: 9, 709: 9, 710: 9, 711: 9, 712: 9, 713: 9, 714: 9, 715: 9, 716: 9, 717: 9, 718: 9, 719: 9, 720: 9, 721: 9, 722: 9, 723: 9, 724: 9, 725: 9, 726: 9, 727: 9, 728: 9, 729: 9, 730: 9, 731: 9, 732: 9, 733: 9, 734: 9, 735: 9, 736: 9, 737: 9, 738: 9, 739: 9, 740: 9, 741: 9, 742: 9, 743: 9, 744: 9, 745: 9, 746: 9, 747: 9, 748: 9, 749: 9, 750: 9, 751: 9, 752: 9, 753: 9, 754: 9, 755: 9, 756: 9, 757: 9, 758: 9, 759: 9, 760: 9, 761: 9, 762: 9, 763: 9, 764: 9, 765: 9, 766: 9, 767: 9, 768: 9, 769: 9, 770: 9, 771: 9, 772: 9, 773: 9, 774: 9, 775: 9, 776: 9, 777: 9, 778: 9, 779: 9, 780: 9, 781: 9, 782: 9, 783: 9, 784: 9, 785: 9, 786: 9, 787: 9, 788: 9, 789: 9, 790: 9, 791: 9, 792: 9, 793: 9, 794: 9, 795: 9, 796: 9, 797: 9, 798: 9, 799: 9, 800: 9, 801: 9, 802: 9, 803: 9, 804: 9, 805: 9, 806: 9, 807: 9, 808: 9, 809: 9, 810: 9, 811: 9, 812: 9, 813: 9, 814: 9, 815: 9, 816: 9, 817: 9, 818: 9, 819: 9, 820: 9, 821: 9, 822: 9, 823: 9, 824: 9, 825: 9, 826: 9, 827: 9, 828: 9, 829: 9, 830: 9, 831: 9, 832: 9, 833: 9, 834: 9, 835: 9, 836: 9, 837: 9, 838: 9, 839: 9, 840: 9, 841: 9, 842: 9, 843: 9, 844: 9, 845: 9, 846: 9, 847: 9, 848: 9, 849: 9, 850: 9, 851: 9, 852: 9, 853: 9, 854: 9, 855: 9, 856: 9, 857: 9, 858: 9, 859: 9, 860: 9, 861: 9, 862: 9, 863: 9, 864: 9, 865: 9, 866: 9, 867: 9, 868: 9, 869: 9, 870: 9, 871: 9, 872: 9, 873: 9, 874: 9, 875: 9, 876: 9, 877: 9, 878: 9, 879: 9, 880: 9, 881: 9, 882: 9, 883: 9, 884: 9, 885: 9, 886: 9, 887: 9, 888: 9, 889: 9, 890: 9, 891: 9, 892: 9, 893: 9, 894: 9, 895: 9, 896: 9, 897: 9, 898: 9, 899: 9, 900: 9, 901: 9, 902: 9, 903: 9, 904: 9, 905: 9, 906: 9, 907: 9, 908: 9, 909: 9, 910: 9, 911: 9, 912: 9, 913: 9, 914: 9, 915: 9, 916: 9, 917: 9, 918: 9, 919: 9, 920: 9, 921: 9, 922: 9, 923: 9, 924: 9, 925: 9, 926: 9, 927: 9, 928: 9, 929: 9, 930: 9, 931: 9, 932: 9, 933: 9, 934: 9, 935: 9, 936: 9, 937: 9, 938: 9, 939: 9, 940: 9, 941: 9, 942: 9, 943: 9, 944: 9, 945: 9, 946: 9, 947: 9, 948: 9, 949: 9, 950: 9, 951: 9, 952: 9, 953: 9, 954: 9, 955: 9, 956: 9, 957: 9, 958: 9, 959: 9, 960: 9, 961: 9, 962: 9, 963: 9, 964: 9, 965: 9, 966: 9, 967: 9, 968: 9, 969: 9, 970: 9, 971: 9, 972: 9, 973: 9, 974: 9, 975: 9, 976: 9, 977: 9, 978: 9, 979: 9, 980: 9, 981: 9, 982: 9, 983: 9, 984: 9, 985: 9, 986: 9, 987: 9, 988: 9, 989: 9, 990: 9, 991: 9, 992: 9, 993: 9, 994: 9, 995: 9, 996: 9, 997: 9, 998: 9, 999: 9, 1000: 9, 1001: 9, 1002: 9, 1003: 9, 1004: 9, 1005: 9, 1006: 9, 1007: 9, 1008: 9, 1009: 9, 1010: 9, 1011: 9, 1012: 9, 1013: 9, 1014: 9, 1015: 9, 1016: 9, 1017: 9, 1018: 9, 1019: 9, 1020: 9, 1021: 9, 1022: 9, 1023: 9, 1024: 9, 1025: 9, 1026: 9, 1027: 9, 1028: 9, 1029: 9, 1030: 9, 1031: 9, 1032: 9, 1033: 9, 1034: 9, 1035: 9, 1036: 9, 1037: 9, 1038: 9, 1039: 9, 1040: 9, 1041: 9, 1042: 9, 1043: 9, 1044: 9, 1045: 9, 1046: 9, 1047: 9, 1048: 9, 1049: 9, 1050: 9, 1051: 9, 1052: 9, 1053: 9, 1054: 9, 1055: 9, 1056: 9, 1057: 9, 1058: 9, 1059: 9, 1060: 9, 1061: 9, 1062: 9, 1063: 9, 1064: 9, 1065: 9, 1066: 9, 1067: 9, 1068: 9, 1069: 9, 1070: 9, 1071: 9, 1072: 9, 1073: 9, 1074: 9, 1075: 9, 1076: 9, 1077: 9, 1078: 9, 1079: 9, 1080: 9, 1081: 9, 1082: 9, 1083: 9, 1084: 9, 1085: 9, 1086: 9, 1087: 9, 1088: 9, 1089: 9, 1090: 9, 1091: 9, 1092: 9, 1093: 9, 1094: 9, 1095: 9, 1096: 9, 1097: 9, 1098: 9, 1099: 9, 1100: 9, 1101: 9, 1102: 9, 1103: 9, 1104: 9, 1105: 9, 1106: 9, 1107: 9, 1108: 9, 1109: 9, 1110: 9, 1111: 9, 1112: 9, 1113: 9, 1114: 9, 1115: 9, 1116: 9, 1117: 9, 1118: 9, 1119: 9, 1120: 9, 1121: 9, 1122: 9, 1123: 9, 1124: 9, 1125: 9, 1126: 9, 1127: 9, 1128: 9, 1129: 9, 1130: 9, 1131: 9, 1132: 9, 1133: 9, 1134: 9, 1135: 9, 1136: 9, 1137: 9, 1138: 9, 1139: 9, 1140: 9, 1141: 9, 1142: 9, 1143: 9, 1144: 9, 1145: 9, 1146: 9, 1147: 9, 1148: 9, 1149: 9, 1150: 9, 1151: 9, 1152: 9, 1153: 9, 1154: 9, 1155: 9, 1156: 9, 1157: 9, 1158: 9, 1159: 9, 1160: 9, 1161: 9, 1162: 9, 1163: 9, 1164: 9, 1165: 9, 1166: 9, 1167: 9, 1168: 9, 1169: 9, 1170: 9, 1171: 9, 1172: 9, 1173: 9, 1174: 9, 1175: 9, 1176: 9, 1177: 9, 1178: 9, 1179: 9, 1180: 9, 1181: 9, 1182: 9, 1183: 9, 1184: 9, 1185: 9, 1186: 9, 1187: 9, 1188: 9, 1189: 9, 1190: 9, 1191: 9, 1192: 9, 1193: 9, 1194: 9, 1195: 9, 1196: 9, 1197: 9, 1198: 9, 1199: 9, 1200: 9, 1201: 9, 1202: 9, 1203: 9, 1204: 9, 1205: 9, 1206: 9, 1207: 9, 1208: 9, 1209: 9, 1210: 9, 1211: 9, 1212: 9, 1213: 9, 1214: 9, 1215: 9, 1216: 9, 1217: 9, 1218: 9, 1219: 9, 1220: 9, 1221: 9, 1222: 9, 1223: 9, 1224: 9, 1225: 9, 1226: 9, 1227: 9, 1228: 9, 1229: 9, 1230: 9, 1231: 9, 1232: 9, 1233: 9, 1234: 9, 1235: 9, 1236: 9, 1237: 9, 1238: 9, 1239: 9, 1240: 9, 1241: 9, 1242: 9, 1243: 9, 1244: 9, 1245: 9, 1246: 9, 1247: 9, 1248: 9, 1249: 9, 1250: 9, 1251: 9, 1252: 9, 1253: 9, 1254: 9, 1255: 9, 1256: 9, 1257: 9, 1258: 9, 1259: 9, 1260: 9, 1261: 9, 1262: 9, 1263: 9, 1264: 9, 1265: 9, 1266: 9, 1267: 9, 1268: 9, 1269: 9, 1270: 9, 1271: 9, 1272: 9, 1273: 9, 1274: 9, 1275: 9, 1276: 9, 1277: 9, 1278: 9, 1279: 9, 1280: 9, 1281: 9, 1282: 9, 1283: 9, 1284: 9, 1285: 9, 1286: 9, 1287: 9, 1288: 9, 1289: 9, 1290: 9, 1291: 9, 1292: 9, 1293: 9, 1294: 9, 1295: 9, 1296: 9, 1297: 9, 1298: 9, 1299: 9, 1300: 9, 1301: 9, 1302: 9, 1303: 9, 1304: 9, 1305: 9, 1306: 9, 1307: 9, 1308: 9, 1309: 9, 1310: 9, 1311: 9, 1312: 9, 1313: 9, 1314: 9, 1315: 9, 1316: 9, 1317: 9, 1318: 9, 1319: 9, 1320: 9, 1321: 9, 1322: 9, 1323: 9, 1324: 9, 1325: 9, 1326: 9, 1327: 9, 1328: 9, 1329: 9, 1330: 9, 1331: 9, 1332: 9, 1333: 9, 1334: 9, 1335: 9, 1336: 9, 1337: 9, 1338: 9, 1339: 9, 1340: 9, 1341: 9, 1342: 9, 1343: 9, 1344: 9, 1345: 9, 1346: 9, 1347: 9, 1348: 9, 1349: 9, 1350: 9, 1351: 9, 1352: 9, 1353: 9, 1354: 9, 1355: 9, 1356: 9, 1357: 9, 1358: 9, 1359: 9, 1360: 9, 1361: 9, 1362: 9, 1363: 9, 1364: 9, 1365: 9, 1366: 9, 1367: 9, 1368: 9, 1369: 9, 1370: 9, 1371: 9, 1372: 9, 1373: 9, 1374: 9, 1375: 9, 1376: 9, 1377: 9, 1378: 9, 1379: 9, 1380: 9, 1381: 9, 1382: 9, 1383: 9, 1384: 9, 1385: 9, 1386: 9, 1387: 9, 1388: 9, 1389: 9, 1390: 9, 1391: 9, 1392: 9, 1393: 9, 1394: 9, 1395: 9, 1396: 9, 1397: 9, 1398: 9, 1399: 9, 1400: 9, 1401: 9, 1402: 9, 1403: 9, 1404: 9, 1405: 9, 1406: 9, 1407: 9, 1408: 9, 1409: 9, 1410: 9, 1411: 9, 1412: 9, 1413: 9, 1414: 9, 1415: 9, 1416: 9, 1417: 9, 1418: 9, 1419: 9, 1420: 9, 1421: 9, 1422: 9, 1423: 9, 1424: 9, 1425: 9, 1426: 9, 1427: 9, 1428: 9, 1429: 9, 1430: 9, 1431: 9, 1432: 9, 1433: 9, 1434: 9, 1435: 9, 1436: 9, 1437: 9, 1438: 9, 1439: 9, 1440: 9, 1441: 9, 1442: 9, 1443: 9, 1444: 9, 1445: 9, 1446: 9, 1447: 9, 1448: 9, 1449: 9, 1450: 9, 1451: 9, 1452: 9, 1453: 9, 1454: 9, 1455: 9, 1456: 9, 1457: 9, 1458: 9, 1459: 9, 1460: 9, 1461: 9, 1462: 9, 1463: 9, 1464: 9, 1465: 9, 1466: 9, 1467: 9, 1468: 9, 1469: 9, 1470: 9, 1471: 9, 1472: 9, 1473: 9, 1474: 9, 1475: 9, 1476: 9, 1477: 9, 1478: 9, 1479: 9, 1480: 9, 1481: 9, 1482: 9, 1483: 9, 1484: 9, 1485: 9, 1486: 9, 1487: 9, 1488: 9, 1489: 9, 1490: 9, 1491: 9, 1492: 9, 1493: 9, 1494: 9, 1495: 9, 1496: 9, 1497: 9, 1498: 9, 1499: 9, 1500: 9, 1501: 9, 1502: 9, 1503: 9, 1504: 9, 1505: 9, 1506: 9, 1507: 9, 1508: 9, 1509: 9, 1510: 9, 1511: 9, 1512: 9, 1513: 9, 1514: 9, 1515: 9, 1516: 9, 1517: 9, 1518: 9, 1519: 9, 1520: 9, 1521: 9, 1522: 9, 1523: 9, 1524: 9, 1525: 9, 1526: 9, 1527: 9, 1528: 9, 1529: 9, 1530: 9, 1531: 9, 1532: 9, 1533: 9, 1534: 9, 1535: 9, 1536: 9, 1537: 9, 1538: 9, 1539: 9, 1540: 9, 1541: 9, 1542: 9, 1543: 9, 1544: 9, 1545: 9, 1546: 9, 1547: 9, 1548: 9, 1549: 9, 1550: 9, 1551: 9, 1552: 9, 1553: 9, 1554: 9, 1555: 9, 1556: 9, 1557: 9, 1558: 9, 1559: 9, 1560: 9, 1561: 9, 1562: 9, 1563: 9, 1564: 9, 1565: 9, 1566: 9, 1567: 9, 1568: 9, 1569: 9, 1570: 9, 1571: 9, 1572: 9, 1573: 9, 1574: 9, 1575: 9, 1576: 9, 1577: 9, 1578: 9, 1579: 9, 1580: 9, 1581: 9, 1582: 9, 1583: 9, 1584: 9, 1585: 9, 1586: 9, 1587: 9, 1588: 9, 1589: 9, 1590: 9, 1591: 9, 1592: 9, 1593: 9, 1594: 9, 1595: 9, 1596: 9, 1597: 9, 1598: 9, 1599: 9, 1600: 9, 1601: 9, 1602: 9, 1603: 9, 1604: 9, 1605: 9, 1606: 9, 1607: 9, 1608: 9, 1609: 9, 1610: 9, 1611: 9, 1612: 9, 1613: 9, 1614: 9, 1615: 9, 1616: 9, 1617: 9, 1618: 9, 1619: 9, 1620: 9, 1621: 9, 1622: 9, 1623: 9, 1624: 9, 1625: 9, 1626: 9, 1627: 9, 1628: 9, 1629: 9, 1630: 9, 1631: 9, 1632: 9, 1633: 9, 1634: 9, 1635: 9, 1636: 9, 1637: 9, 1638: 9, 1639: 9, 1640: 9, 1641: 9, 1642: 9, 1643: 9, 1644: 9, 1645: 9, 1646: 9, 1647: 9, 1648: 9, 1649: 9, 1650: 9, 1651: 9, 1652: 9, 1653: 9, 1654: 9, 1655: 9, 1656: 9, 1657: 9, 1658: 9, 1659: 9, 1660: 9, 1661: 9, 1662: 9, 1663: 9, 1664: 9, 1665: 9, 1666: 9, 1667: 9, 1668: 9, 1669: 9, 1670: 9, 1671: 9, 1672: 9, 1673: 9, 1674: 9, 1675: 9, 1676: 9, 1677: 9, 1678: 9, 1679: 9, 1680: 9, 1681: 9, 1682: 9, 1683: 9, 1684: 9, 1685: 9, 1686: 9, 1687: 9, 1688: 9, 1689: 9, 1690: 9, 1691: 9, 1692: 9, 1693: 9, 1694: 9, 1695: 9, 1696: 9, 1697: 9, 1698: 9, 1699: 9, 1700: 9, 1701: 9, 1702: 9, 1703: 9, 1704: 9, 1705: 9, 1706: 9, 1707: 9, 1708: 9, 1709: 9, 1710: 9, 1711: 9, 1712: 9, 1713: 9, 1714: 9, 1715: 9, 1716: 9, 1717: 9, 1718: 9, 1719: 9, 1720: 9, 1721: 9, 1722: 9, 1723: 9, 1724: 9, 1725: 9, 1726: 9, 1727: 9, 1728: 9, 1729: 9, 1730: 9, 1731: 9, 1732: 9, 1733: 9, 1734: 9, 1735: 9, 1736: 9, 1737: 9, 1738: 9, 1739: 9, 1740: 9, 1741: 9, 1742: 9, 1743: 9, 1744: 9, 1745: 9, 1746: 9, 1747: 9, 1748: 9, 1749: 9, 1750: 9, 1751: 9, 1752: 9, 1753: 9, 1754: 9, 1755: 9, 1756: 9, 1757: 9, 1758: 9, 1759: 9, 1760: 9, 1761: 9, 1762: 9, 1763: 9, 1764: 9, 1765: 9, 1766: 9, 1767: 9, 1768: 9, 1769: 9, 1770: 9, 1771: 9, 1772: 9, 1773: 9, 1774: 9, 1775: 9, 1776: 9, 1777: 9, 1778: 9, 1779: 9, 1780: 9, 1781: 9, 1782: 9, 1783: 9, 1784: 9, 1785: 9, 1786: 9, 1787: 9, 1788: 9, 1789: 9, 1790: 9, 1791: 9, 1792: 9, 1793: 9, 1794: 9, 1795: 9, 1796: 9, 1797: 9, 1798: 9, 1799: 9, 1800: 9, 1801: 9, 1802: 9, 1803: 9, 1804: 9, 1805: 9, 1806: 9, 1807: 9, 1808: 9, 1809: 9, 1810: 9, 1811: 9, 1812: 9, 1813: 9, 1814: 9, 1815: 9, 1816: 9, 1817: 9, 1818: 9, 1819: 9, 1820: 9, 1821: 9, 1822: 9, 1823: 9, 1824: 9, 1825: 9, 1826: 9, 1827: 9, 1828: 9, 1829: 9, 1830: 9, 1831: 9, 1832: 9, 1833: 9, 1834: 9, 1835: 9, 1836: 9, 1837: 9, 1838: 9, 1839: 9, 1840: 9, 1841: 9, 1842: 9, 1843: 9, 1844: 9, 1845: 9, 1846: 9, 1847: 9, 1848: 9, 1849: 9, 1850: 9, 1851: 9, 1852: 9, 1853: 9, 1854: 9, 1855: 9, 1856: 9, 1857: 9, 1858: 9, 1859: 9, 1860: 9, 1861: 9, 1862: 9, 1863: 9, 1864: 9, 1865: 9, 1866: 9, 1867: 9, 1868: 9, 1869: 9, 1870: 9, 1871: 9, 1872: 9, 1873: 9, 1874: 9, 1875: 9, 1876: 9, 1877: 9, 1878: 9, 1879: 9, 1880: 9, 1881: 9, 1882: 9, 1883: 9, 1884: 9, 1885: 9, 1886: 9, 1887: 9, 1888: 9, 1889: 9, 1890: 9, 1891: 9, 1892: 9, 1893: 9, 1894: 9, 1895: 9, 1896: 9, 1897: 9, 1898: 9, 1899: 9, 1900: 9, 1901: 9, 1902: 9, 1903: 9, 1904: 9, 1905: 9, 1906: 9, 1907: 9, 1908: 9, 1909: 9, 1910: 9, 1911: 9, 1912: 9, 1913: 9, 1914: 9, 1915: 9, 1916: 9, 1917: 9, 1918: 9, 1919: 9, 1920: 9, 1921: 9, 1922: 9, 1923: 9, 1924: 9, 1925: 9, 1926: 9, 1927: 9, 1928: 9, 1929: 9, 1930: 9, 1931: 9, 1932: 9, 1933: 9, 1934: 9, 1935: 9, 1936: 9, 1937: 9, 1938: 9, 1939: 9, 1940: 9, 1941: 9, 1942: 9, 1943: 9, 1944: 9, 1945: 9, 1946: 9, 1947: 9, 1948: 9, 1949: 9, 1950: 9, 1951: 9, 1952: 9, 1953: 9, 1954: 9, 1955: 9, 1956: 9, 1957: 9, 1958: 9, 1959: 9, 1960: 9, 1961: 9, 1962: 9, 1963: 9, 1964: 9, 1965: 9, 1966: 9, 1967: 9, 1968: 9, 1969: 9, 1970: 9, 1971: 9, 1972: 9, 1973: 9, 1974: 9, 1975: 9, 1976: 9, 1977: 9, 1978: 9, 1979: 9, 1980: 9, 1981: 9, 1982: 9, 1983: 9, 1984: 9, 1985: 9, 1986: 9, 1987: 9, 1988: 9, 1989: 9, 1990: 9, 1991: 9, 1992: 9, 1993: 9, 1994: 9, 1995: 9, 1996: 9, 1997: 9, 1998: 9, 1999: 9, 2000: 9, 2001: 9, 2002: 9, 2003: 9, 2004: 9, 2005: 9, 2006: 9, 2007: 9, 2008: 9, 2009: 9, 2010: 9, 2011: 9, 2012: 9, 2013: 9, 2014: 9, 2015: 9, 2016: 9, 2017: 9, 2018: 9, 2019: 9, 2020: 9, 2021: 9, 2022: 9, 2023: 9, 2024: 9, 2025: 9, 2026: 9, 2027: 9, 2028: 9, 2029: 9, 2030: 9, 2031: 9, 2032: 9, 2033: 9, 2034: 9, 2035: 9, 2036: 9, 2037: 9, 2038: 9, 2039: 9, 2040: 9, 2041: 9, 2042: 9, 2043: 9, 2044: 9, 2045: 9, 2046: 9, 2047: 9, 2048: 9, 2049: 9, 2050: 9, 2051: 9, 2052: 9, 2053: 9, 2054: 9, 2055: 9, 2056: 9, 2057: 9, 2058: 9, 2059: 9, 2060: 9, 2061: 9, 2062: 9, 2063: 9, 2064: 9, 2065: 9, 2066: 9, 2067: 9, 2068: 9, 2069: 9, 2070: 9, 2071: 9, 2072: 9, 2073: 9, 2074: 9, 2075: 9, 2076: 9, 2077: 9, 2078: 9, 2079: 9, 2080: 9, 2081: 9, 2082: 9, 2083: 9, 2084: 9, 2085: 9, 2086: 9, 2087: 9, 2088: 9, 2089: 9, 2090: 9, 2091: 9, 2092: 9, 2093: 9, 2094: 9, 2095: 9, 2096: 9, 2097: 9, 2098: 9, 2099: 9, 2100: 9, 2101: 9, 2102: 9, 2103: 9, 2104: 9, 2105: 9, 2106: 9, 2107: 9, 2108: 9, 2109: 9, 2110: 9, 2111: 9, 2112: 9, 2113: 9, 2114: 9, 2115: 9, 2116: 9, 2117: 9, 2118: 9, 2119: 9, 2120: 9, 2121: 9, 2122: 9, 2123: 9, 2124: 9, 2125: 9, 2126: 9, 2127: 9, 2128: 9, 2129: 9, 2130: 9, 2131: 9, 2132: 9, 2133: 9, 2134: 9, 2135: 9, 2136: 9, 2137: 9, 2138: 9, 2139: 9, 2140: 9, 2141: 9, 2142: 9, 2143: 9, 2144: 9, 2145: 9, 2146: 9, 2147: 9, 2148: 9, 2149: 9, 2150: 9, 2151: 9, 2152: 9, 2153: 9, 2154: 9, 2155: 9, 2156: 9, 2157: 9, 2158: 9, 2159: 9, 2160: 9, 2161: 9, 2162: 9, 2163: 9, 2164: 9, 2165: 9, 2166: 9, 2167: 9, 2168: 9, 2169: 9, 2170: 9, 2171: 9, 2172: 9, 2173: 9, 2174: 9, 2175: 9, 2176: 9, 2177: 9, 2178: 9, 2179: 9, 2180: 9, 2181: 9, 2182: 9, 2183: 9, 2184: 9, 2185: 9, 2186: 9, 2187: 9, 2188: 9, 2189: 9, 2190: 9, 2191: 9, 2192: 9, 2193: 9, 2194: 9, 2195: 9, 2196: 9, 2197: 9, 2198: 9, 2199: 9, 2200: 9, 2201: 9, 2202: 9, 2203: 9, 2204: 9, 2205: 9, 2206: 9, 2207: 9, 2208: 9, 2209: 9, 2210: 9, 2211: 9, 2212: 9, 2213: 9, 2214: 9, 2215: 9, 2216: 9, 2217: 9, 2218: 9, 2219: 9, 2220: 9, 2221: 9, 2222: 9, 2223: 9, 2224: 9, 2225: 9, 2226: 9, 2227: 9, 2228: 9, 2229: 9, 2230: 9, 2231: 9, 2232: 9, 2233: 9, 2234: 9, 2235: 9, 2236: 9, 2237: 9, 2238: 9, 2239: 9, 2240: 9, 2241: 9, 2242: 9, 2243: 9, 2244: 9, 2245: 9, 2246: 9, 2247: 9, 2248: 9, 2249: 9, 2250: 9, 2251: 9, 2252: 9, 2253: 9, 2254: 9, 2255: 9, 2256: 9, 2257: 9, 2258: 9, 2259: 9, 2260: 9, 2261: 9, 2262: 9, 2263: 9, 2264: 9, 2265: 9, 2266: 9, 2267: 9, 2268: 9, 2269: 9, 2270: 9, 2271: 9, 2272: 9, 2273: 9, 2274: 9, 2275: 9, 2276: 9, 2277: 9, 2278: 9, 2279: 9, 2280: 9, 2281: 9, 2282: 9, 2283: 9, 2284: 9, 2285: 9, 2286: 9, 2287: 9, 2288: 9, 2289: 9, 2290: 9, 2291: 9, 2292: 9, 2293: 9, 2294: 9, 2295: 9, 2296: 9, 2297: 9, 2298: 9, 2299: 9, 2300: 9, 2301: 9, 2302: 9, 2303: 9, 2304: 9, 2305: 9, 2306: 9, 2307: 9, 2308: 9, 2309: 9, 2310: 9, 2311: 9, 2312: 9, 2313: 9, 2314: 9, 2315: 9, 2316: 9, 2317: 9, 2318: 9, 2319: 9, 2320: 9, 2321: 9, 2322: 9, 2323: 9, 2324: 9, 2325: 9, 2326: 9, 2327: 9, 2328: 9, 2329: 9, 2330: 9, 2331: 9, 2332: 9, 2333: 9, 2334: 9, 2335: 9, 2336: 9, 2337: 9, 2338: 9, 2339: 9, 2340: 9, 2341: 9, 2342: 9, 2343: 9, 2344: 9, 2345: 9, 2346: 9, 2347: 9, 2348: 9, 2349: 9, 2350: 9, 2351: 9, 2352: 9, 2353: 9, 2354: 9, 2355: 9, 2356: 9, 2357: 9, 2358: 9, 2359: 9, 2360: 9, 2361: 9, 2362: 9, 2363: 9, 2364: 9, 2365: 9, 2366: 9, 2367: 9, 2368: 9, 2369: 9, 2370: 9, 2371: 9, 2372: 9, 2373: 9, 2374: 9, 2375: 9, 2376: 9, 2377: 9, 2378: 9, 2379: 9, 2380: 9, 2381: 9, 2382: 9, 2383: 9, 2384: 9, 2385: 9, 2386: 9, 2387: 9, 2388: 9, 2389: 9, 2390: 9, 2391: 9, 2392: 9, 2393: 9, 2394: 9, 2395: 9, 2396: 9, 2397: 9, 2398: 9, 2399: 9, 2400: 9, 2401: 9, 2402: 9, 2403: 9, 2404: 9, 2405: 9, 2406: 9, 2407: 9, 2408: 9, 2409: 9, 2410: 9, 2411: 9, 2412: 9, 2413: 9, 2414: 9, 2415: 9, 2416: 9, 2417: 9, 2418: 9, 2419: 9, 2420: 9, 2421: 9, 2422: 9, 2423: 9, 2424: 9, 2425: 9, 2426: 9, 2427: 9, 2428: 9, 2429: 9, 2430: 9, 2431: 9, 2432: 9, 2433: 9, 2434: 9, 2435: 9, 2436: 9, 2437: 9, 2438: 9, 2439: 9, 2440: 9, 2441: 9, 2442: 9, 2443: 9, 2444: 9, 2445: 9, 2446: 9, 2447: 9, 2448: 9, 2449: 9, 2450: 9, 2451: 9, 2452: 9, 2453: 9, 2454: 9, 2455: 9, 2456: 9, 2457: 9, 2458: 9, 2459: 9, 2460: 9, 2461: 9, 2462: 9, 2463: 9, 2464: 9, 2465: 9, 2466: 9, 2467: 9, 2468: 9, 2469: 9, 2470: 9, 2471: 9, 2472: 9, 2473: 9, 2474: 9, 2475: 9, 2476: 9, 2477: 9, 2478: 9, 2479: 9, 2480: 9, 2481: 9, 2482: 9, 2483: 9, 2484: 9, 2485: 9, 2486: 9, 2487: 9, 2488: 9, 2489: 9, 2490: 9, 2491: 9, 2492: 9, 2493: 9, 2494: 9, 2495: 9, 2496: 9, 2497: 9, 2498: 9, 2499: 9, 2500: 9, 2501: 9, 2502: 9, 2503: 9, 2504: 9, 2505: 9, 2506: 9, 2507: 9, 2508: 9, 2509: 9, 2510: 9, 2511: 9, 2512: 9, 2513: 9, 2514: 9, 2515: 9, 2516: 9, 2517: 9, 2518: 9, 2519: 9, 2520: 9, 2521: 9, 2522: 9, 2523: 9, 2524: 9, 2525: 9, 2526: 9, 2527: 9, 2528: 9, 2529: 9, 2530: 9, 2531: 9, 2532: 9, 2533: 9, 2534: 9, 2535: 9, 2536: 9, 2537: 9, 2538: 9, 2539: 9, 2540: 9, 2541: 9, 2542: 9, 2543: 9, 2544: 9, 2545: 9, 2546: 9, 2547: 9, 2548: 9, 2549: 9, 2550: 9, 2551: 9, 2552: 9, 2553: 9, 2554: 9, 2555: 9, 2556: 9, 2557: 9, 2558: 9, 2559: 9, 2560: 9, 2561: 9, 2562: 9, 2563: 9, 2564: 9, 2565: 9, 2566: 9, 2567: 9, 2568: 9, 2569: 9, 2570: 9, 2571: 9, 2572: 9, 2573: 9, 2574: 9, 2575: 9, 2576: 9, 2577: 9, 2578: 9, 2579: 9, 2580: 9, 2581: 9, 2582: 9, 2583: 9, 2584: 9, 2585: 9, 2586: 9, 2587: 9, 2588: 9, 2589: 9, 2590: 9, 2591: 9, 2592: 9, 2593: 9, 2594: 9, 2595: 9, 2596: 9, 2597: 9, 2598: 9, 2599: 9, 2600: 9, 2601: 9, 2602: 9, 2603: 9, 2604: 9, 2605: 9, 2606: 9, 2607: 9, 2608: 9, 2609: 9, 2610: 9, 2611: 9, 2612: 9, 2613: 9, 2614: 9, 2615: 9, 2616: 9, 2617: 9, 2618: 9, 2619: 9, 2620: 9, 2621: 9, 2622: 9, 2623: 9, 2624: 9, 2625: 9, 2626: 9, 2627: 9, 2628: 9, 2629: 9, 2630: 9, 2631: 9, 2632: 9, 2633: 9, 2634: 9, 2635: 9, 2636: 9, 2637: 9, 2638: 9, 2639: 9, 2640: 9, 2641: 9, 2642: 9, 2643: 9, 2644: 9, 2645: 9, 2646: 9, 2647: 9, 2648: 9, 2649: 9, 2650: 9, 2651: 9, 2652: 9, 2653: 9, 2654: 9, 2655: 9, 2656: 9, 2657: 9, 2658: 9, 2659: 9, 2660: 9, 2661: 9, 2662: 9, 2663: 9, 2664: 9, 2665: 9, 2666: 9, 2667: 9, 2668: 9, 2669: 9, 2670: 9, 2671: 9, 2672: 9, 2673: 9, 2674: 9, 2675: 9, 2676: 9, 2677: 9, 2678: 9, 2679: 9, 2680: 9, 2681: 9, 2682: 9, 2683: 9, 2684: 9, 2685: 9, 2686: 9, 2687: 9, 2688: 9, 2689: 9, 2690: 9, 2691: 9, 2692: 9, 2693: 9, 2694: 9, 2695: 9, 2696: 9, 2697: 9, 2698: 9, 2699: 9, 2700: 9, 2701: 9, 2702: 9, 2703: 9, 2704: 9, 2705: 9, 2706: 9, 2707: 9, 2708: 9, 2709: 9, 2710: 9, 2711: 9, 2712: 9, 2713: 9, 2714: 9, 2715: 9, 2716: 9, 2717: 9, 2718: 9, 2719: 9, 2720: 9, 2721: 9, 2722: 9, 2723: 9, 2724: 9, 2725: 9, 2726: 9, 2727: 9, 2728: 9, 2729: 9, 2730: 9, 2731: 9, 2732: 9, 2733: 9, 2734: 9, 2735: 9, 2736: 9, 2737: 9, 2738: 9, 2739: 9, 2740: 9, 2741: 9, 2742: 9, 2743: 9, 2744: 9, 2745: 9, 2746: 9, 2747: 9, 2748: 9, 2749: 9, 2750: 9, 2751: 9, 2752: 9, 2753: 9, 2754: 9, 2755: 9, 2756: 9, 2757: 9, 2758: 9, 2759: 9, 2760: 9, 2761: 9, 2762: 9, 2763: 9, 2764: 9, 2765: 9, 2766: 9, 2767: 9, 2768: 9, 2769: 9, 2770: 9, 2771: 9, 2772: 9, 2773: 9, 2774: 9, 2775: 9, 2776: 9, 2777: 9, 2778: 9, 2779: 9, 2780: 9, 2781: 9, 2782: 9, 2783: 9, 2784: 9, 2785: 9, 2786: 9, 2787: 9, 2788: 9, 2789: 9, 2790: 9, 2791: 9, 2792: 9, 2793: 9, 2794: 9, 2795: 9, 2796: 9, 2797: 9, 2798: 9, 2799: 9, 2800: 9, 2801: 9, 2802: 9, 2803: 9, 2804: 9, 2805: 9, 2806: 9, 2807: 9, 2808: 9, 2809: 9, 2810: 9, 2811: 9, 2812: 9, 2813: 9, 2814: 9, 2815: 9, 2816: 9, 2817: 9, 2818: 9, 2819: 9, 2820: 9, 2821: 9, 2822: 9, 2823: 9, 2824: 9, 2825: 9, 2826: 9, 2827: 9, 2828: 9, 2829: 9, 2830: 9, 2831: 9, 2832: 9, 2833: 9, 2834: 9, 2835: 9, 2836: 9, 2837: 9, 2838: 9, 2839: 9, 2840: 9, 2841: 9, 2842: 9, 2843: 9, 2844: 9, 2845: 9, 2846: 9, 2847: 9, 2848: 9, 2849: 9, 2850: 9, 2851: 9, 2852: 9, 2853: 9, 2854: 9, 2855: 9, 2856: 9, 2857: 9, 2858: 9, 2859: 9, 2860: 9, 2861: 9, 2862: 9, 2863: 9, 2864: 9, 2865: 9, 2866: 9, 2867: 9, 2868: 9, 2869: 9, 2870: 9, 2871: 9, 2872: 9, 2873: 9, 2874: 9, 2875: 9, 2876: 9, 2877: 9, 2878: 9, 2879: 9, 2880: 9, 2881: 9, 2882: 9, 2883: 9, 2884: 9, 2885: 9, 2886: 9, 2887: 9, 2888: 9, 2889: 9, 2890: 9, 2891: 9, 2892: 9, 2893: 9, 2894: 9, 2895: 9, 2896: 9, 2897: 9, 2898: 9, 2899: 9, 2900: 9, 2901: 9, 2902: 9, 2903: 9, 2904: 9, 2905: 9, 2906: 9, 2907: 9, 2908: 9, 2909: 9, 2910: 9, 2911: 9, 2912: 9, 2913: 9, 2914: 9, 2915: 9, 2916: 9, 2917: 9, 2918: 9, 2919: 9, 2920: 9, 2921: 9, 2922: 9, 2923: 9, 2924: 9, 2925: 9, 2926: 9, 2927: 9, 2928: 9, 2929: 9, 2930: 9, 2931: 9, 2932: 9, 2933: 9, 2934: 9, 2935: 9, 2936: 9, 2937: 9, 2938: 9, 2939: 9, 2940: 9, 2941: 9, 2942: 9, 2943: 9, 2944: 9, 2945: 9, 2946: 9, 2947: 9, 2948: 9, 2949: 9, 2950: 9, 2951: 9, 2952: 9, 2953: 9, 2954: 9, 2955: 9, 2956: 9, 2957: 9, 2958: 9, 2959: 9, 2960: 9, 2961: 9, 2962: 9, 2963: 9, 2964: 9, 2965: 9, 2966: 9, 2967: 9, 2968: 9, 2969: 9, 2970: 9, 2971: 9, 2972: 9, 2973: 9, 2974: 9, 2975: 9, 2976: 9, 2977: 9, 2978: 9, 2979: 9, 2980: 9, 2981: 9, 2982: 9, 2983: 9, 2984: 9, 2985: 9, 2986: 9, 2987: 9, 2988: 9, 2989: 9, 2990: 9, 2991: 9, 2992: 9, 2993: 9, 2994: 9, 2995: 9, 2996: 9, 2997: 9, 2998: 9, 2999: 9, 3000: 9, 3001: 9, 3002: 9, 3003: 9, 3004: 9, 3005: 9, 3006: 9, 3007: 9, 3008: 9, 3009: 9, 3010: 9, 3011: 9, 3012: 9, 3013: 9, 3014: 9, 3015: 9, 3016: 9, 3017: 9, 3018: 9, 3019: 9, 3020: 9, 3021: 9, 3022: 9, 3023: 9, 3024: 9, 3025: 9, 3026: 9, 3027: 9, 3028: 9, 3029: 9, 3030: 9, 3031: 9, 3032: 9, 3033: 9, 3034: 9, 3035: 9, 3036: 9, 3037: 9, 3038: 9, 3039: 9, 3040: 9, 3041: 9, 3042: 9, 3043: 9, 3044: 9, 3045: 9, 3046: 9, 3047: 9, 3048: 9, 3049: 9, 3050: 9, 3051: 9, 3052: 9, 3053: 9, 3054: 9, 3055: 9, 3056: 9, 3057: 9, 3058: 9, 3059: 9, 3060: 9, 3061: 9, 3062: 9, 3063: 9, 3064: 9, 3065: 9, 3066: 9, 3067: 9, 3068: 9, 3069: 9, 3070: 9, 3071: 9, 3072: 9, 3073: 9, 3074: 9, 3075: 9, 3076: 9, 3077: 9, 3078: 9, 3079: 9, 3080: 9, 3081: 9, 3082: 9, 3083: 9, 3084: 9, 3085: 9, 3086: 9, 3087: 9, 3088: 9, 3089: 9, 3090: 9, 3091: 9, 3092: 9, 3093: 9, 3094: 9, 3095: 9, 3096: 9, 3097: 9, 3098: 9, 3099: 9, 3100: 9, 3101: 9, 3102: 9, 3103: 9, 3104: 9, 3105: 9, 3106: 9, 3107: 9, 3108: 9, 3109: 9, 3110: 9, 3111: 9, 3112: 9, 3113: 9, 3114: 9, 3115: 9, 3116: 9, 3117: 9, 3118: 9, 3119: 9, 3120: 9, 3121: 9, 3122: 9, 3123: 9, 3124: 9, 3125: 9, 3126: 9, 3127: 9, 3128: 9, 3129: 9, 3130: 9, 3131: 9, 3132: 9, 3133: 9, 3134: 9, 3135: 9, 3136: 9, 3137: 9, 3138: 9, 3139: 9, 3140: 9, 3141: 9, 3142: 9, 3143: 9, 3144: 9, 3145: 9, 3146: 9, 3147: 9, 3148: 9, 3149: 9, 3150: 9, 3151: 9, 3152: 9, 3153: 9, 3154: 9, 3155: 9, 3156: 9, 3157: 9, 3158: 9, 3159: 9, 3160: 9, 3161: 9, 3162: 9, 3163: 9, 3164: 9, 3165: 9, 3166: 9, 3167: 9, 3168: 9, 3169: 9, 3170: 9, 3171: 9, 3172: 9, 3173: 9, 3174: 9, 3175: 9, 3176: 9, 3177: 9, 3178: 9, 3179: 9, 3180: 9, 3181: 9, 3182: 9, 3183: 9, 3184: 9, 3185: 9, 3186: 9, 3187: 9, 3188: 9, 3189: 9, 3190: 9, 3191: 9, 3192: 9, 3193: 9, 3194: 9, 3195: 9, 3196: 9, 3197: 9, 3198: 9, 3199: 9, 3200: 9, 3201: 9, 3202: 9, 3203: 9, 3204: 9, 3205: 9, 3206: 9, 3207: 9, 3208: 9, 3209: 9, 3210: 9, 3211: 9, 3212: 9, 3213: 9, 3214: 9, 3215: 9, 3216: 9, 3217: 9, 3218: 9, 3219: 9, 3220: 9, 3221: 9, 3222: 9, 3223: 9, 3224: 9, 3225: 9, 3226: 9, 3227: 9, 3228: 9, 3229: 9, 3230: 9, 3231: 9, 3232: 9, 3233: 9, 3234: 9, 3235: 9, 3236: 9, 3237: 9, 3238: 9, 3239: 9, 3240: 9, 3241: 9, 3242: 9, 3243: 9, 3244: 9, 3245: 9, 3246: 9, 3247: 9, 3248: 9, 3249: 9, 3250: 9, 3251: 9, 3252: 9, 3253: 9, 3254: 9, 3255: 9, 3256: 9, 3257: 9, 3258: 9, 3259: 9, 3260: 9, 3261: 9, 3262: 9, 3263: 9, 3264: 9, 3265: 9, 3266: 9, 3267: 9, 3268: 9, 3269: 9, 3270: 9, 3271: 9, 3272: 9, 3273: 9, 3274: 9, 3275: 9, 3276: 9, 3277: 9, 3278: 9, 3279: 9, 3280: 9, 3281: 9, 3282: 9, 3283: 9, 3284: 9, 3285: 9, 3286: 9, 3287: 9, 3288: 9, 3289: 9, 3290: 9, 3291: 9, 3292: 9, 3293: 9, 3294: 9, 3295: 9, 3296: 9, 3297: 9, 3298: 9, 3299: 9, 3300: 9, 3301: 9, 3302: 9, 3303: 9, 3304: 9, 3305: 9, 3306: 9, 3307: 9, 3308: 9, 3309: 9, 3310: 9, 3311: 9, 3312: 9, 3313: 9, 3314: 9, 3315: 9, 3316: 9, 3317: 9, 3318: 9, 3319: 9, 3320: 9, 3321: 9, 3322: 9, 3323: 9, 3324: 9, 3325: 9, 3326: 9, 3327: 9, 3328: 9, 3329: 9, 3330: 9, 3331: 9, 3332: 9, 3333: 9, 3334: 9, 3335: 9, 3336: 9, 3337: 9, 3338: 9, 3339: 9, 3340: 9, 3341: 9, 3342: 9, 3343: 9, 3344: 9, 3345: 9, 3346: 9, 3347: 9, 3348: 9, 3349: 9, 3350: 9, 3351: 9, 3352: 9, 3353: 9, 3354: 9, 3355: 9, 3356: 9, 3357: 9, 3358: 9, 3359: 9, 3360: 9, 3361: 9, 3362: 9, 3363: 9, 3364: 9, 3365: 9, 3366: 9, 3367: 9, 3368: 9, 3369: 9, 3370: 9, 3371: 9, 3372: 9, 3373: 9, 3374: 9, 3375: 9, 3376: 9, 3377: 9, 3378: 9, 3379: 9, 3380: 9, 3381: 9, 3382: 9, 3383: 9, 3384: 9, 3385: 9, 3386: 9, 3387: 9, 3388: 9, 3389: 9, 3390: 9, 3391: 9, 3392: 9, 3393: 9, 3394: 9, 3395: 9, 3396: 9, 3397: 9, 3398: 9, 3399: 9, 3400: 9, 3401: 9, 3402: 9, 3403: 9, 3404: 9, 3405: 9, 3406: 9, 3407: 9, 3408: 9, 3409: 9, 3410: 9, 3411: 9, 3412: 9, 3413: 9, 3414: 9, 3415: 9, 3416: 9, 3417: 9, 3418: 9, 3419: 9, 3420: 9, 3421: 9, 3422: 9, 3423: 9, 3424: 9, 3425: 9, 3426: 9, 3427: 9, 3428: 9, 3429: 9, 3430: 9, 3431: 9, 3432: 9, 3433: 9, 3434: 9, 3435: 9, 3436: 9, 3437: 9, 3438: 9, 3439: 9, 3440: 9, 3441: 9, 3442: 9, 3443: 9, 3444: 9, 3445: 9, 3446: 9, 3447: 9, 3448: 9, 3449: 9, 3450: 9, 3451: 9, 3452: 9, 3453: 9, 3454: 9, 3455: 9, 3456: 9, 3457: 9, 3458: 9, 3459: 9, 3460: 9, 3461: 9, 3462: 9, 3463: 9, 3464: 9, 3465: 9, 3466: 9, 3467: 9, 3468: 9, 3469: 9, 3470: 9, 3471: 9, 3472: 9, 3473: 9, 3474: 9, 3475: 9, 3476: 9, 3477: 9, 3478: 9, 3479: 9, 3480: 9, 3481: 9, 3482: 9, 3483: 9, 3484: 9, 3485: 9, 3486: 9, 3487: 9, 3488: 9, 3489: 9, 3490: 9, 3491: 9, 3492: 9, 3493: 9, 3494: 9, 3495: 9, 3496: 9, 3497: 9, 3498: 9, 3499: 9, 3500: 9, 3501: 9, 3502: 9, 3503: 9, 3504: 9, 3505: 9, 3506: 9, 3507: 9, 3508: 9, 3509: 9, 3510: 9, 3511: 9, 3512: 9, 3513: 9, 3514: 9, 3515: 9, 3516: 9, 3517: 9, 3518: 9, 3519: 9, 3520: 9, 3521: 9, 3522: 9, 3523: 9, 3524: 9, 3525: 9, 3526: 9, 3527: 9, 3528: 9, 3529: 9, 3530: 9, 3531: 9, 3532: 9, 3533: 9, 3534: 9, 3535: 9, 3536: 9, 3537: 9, 3538: 9, 3539: 9, 3540: 9, 3541: 9, 3542: 9, 3543: 9, 3544: 9, 3545: 9, 3546: 9, 3547: 9, 3548: 9, 3549: 9, 3550: 9, 3551: 9, 3552: 9, 3553: 9, 3554: 9, 3555: 9, 3556: 9, 3557: 9, 3558: 9, 3559: 9, 3560: 9, 3561: 9, 3562: 9, 3563: 9, 3564: 9, 3565: 9, 3566: 9, 3567: 9, 3568: 9, 3569: 9, 3570: 9, 3571: 9, 3572: 9, 3573: 9, 3574: 9, 3575: 9, 3576: 9, 3577: 9, 3578: 9, 3579: 9, 3580: 9, 3581: 9, 3582: 9, 3583: 9, 3584: 9, 3585: 9, 3586: 9, 3587: 9, 3588: 9, 3589: 9, 3590: 9, 3591: 9, 3592: 9, 3593: 9, 3594: 9, 3595: 9, 3596: 9, 3597: 9, 3598: 9, 3599: 9, 3600: 9, 3601: 9, 3602: 9, 3603: 9, 3604: 9, 3605: 9, 3606: 9, 3607: 9, 3608: 9, 3609: 9, 3610: 9, 3611: 9, 3612: 9, 3613: 9, 3614: 9, 3615: 9, 3616: 9, 3617: 9, 3618: 9, 3619: 9, 3620: 9, 3621: 9, 3622: 9, 3623: 9, 3624: 9, 3625: 9, 3626: 9, 3627: 9, 3628: 9, 3629: 9, 3630: 9, 3631: 9, 3632: 9, 3633: 9, 3634: 9, 3635: 9, 3636: 9, 3637: 9, 3638: 9, 3639: 9, 3640: 9, 3641: 9, 3642: 9, 3643: 9, 3644: 9, 3645: 9, 3646: 9, 3647: 9, 3648: 9, 3649: 9, 3650: 9, 3651: 9, 3652: 9, 3653: 9, 3654: 9, 3655: 9, 3656: 9, 3657: 9, 3658: 9, 3659: 9, 3660: 9, 3661: 9, 3662: 9, 3663: 9, 3664: 9, 3665: 9, 3666: 9, 3667: 9, 3668: 9, 3669: 9, 3670: 9, 3671: 9, 3672: 9, 3673: 9, 3674: 9, 3675: 9, 3676: 9, 3677: 9, 3678: 9, 3679: 9, 3680: 9, 3681: 9, 3682: 9, 3683: 9, 3684: 9, 3685: 9, 3686: 9, 3687: 9, 3688: 9, 3689: 9, 3690: 9, 3691: 9, 3692: 9, 3693: 9, 3694: 9, 3695: 9, 3696: 9, 3697: 9, 3698: 9, 3699: 9, 3700: 9, 3701: 9, 3702: 9, 3703: 9, 3704: 9, 3705: 9, 3706: 9, 3707: 9, 3708: 9, 3709: 9, 3710: 9, 3711: 9, 3712: 9, 3713: 9, 3714: 9, 3715: 9, 3716: 9, 3717: 9, 3718: 9, 3719: 9, 3720: 9, 3721: 9, 3722: 9, 3723: 9, 3724: 9, 3725: 9, 3726: 9, 3727: 9, 3728: 9, 3729: 9, 3730: 9, 3731: 9, 3732: 9, 3733: 9, 3734: 9, 3735: 9, 3736: 9, 3737: 9, 3738: 9, 3739: 9, 3740: 9, 3741: 9, 3742: 9, 3743: 9, 3744: 9, 3745: 9, 3746: 9, 3747: 9, 3748: 9, 3749: 9, 3750: 9, 3751: 9, 3752: 9, 3753: 9, 3754: 9, 3755: 9, 3756: 9, 3757: 9, 3758: 9, 3759: 9, 3760: 9, 3761: 9, 3762: 9, 3763: 9, 3764: 9, 3765: 9, 3766: 9, 3767: 9, 3768: 9, 3769: 9, 3770: 9, 3771: 9, 3772: 9, 3773: 9, 3774: 9, 3775: 9, 3776: 9, 3777: 9, 3778: 9, 3779: 9, 3780: 9, 3781: 9, 3782: 9, 3783: 9, 3784: 9, 3785: 9, 3786: 9, 3787: 9, 3788: 9, 3789: 9, 3790: 9, 3791: 9, 3792: 9, 3793: 9, 3794: 9, 3795: 9, 3796: 9, 3797: 9, 3798: 9, 3799: 9, 3800: 9, 3801: 9, 3802: 9, 3803: 9, 3804: 9, 3805: 9, 3806: 9, 3807: 9, 3808: 9, 3809: 9, 3810: 9, 3811: 9, 3812: 9, 3813: 9, 3814: 9, 3815: 9, 3816: 9, 3817: 9, 3818: 9, 3819: 9, 3820: 9, 3821: 9, 3822: 9, 3823: 9, 3824: 9, 3825: 9, 3826: 9, 3827: 9, 3828: 9, 3829: 9, 3830: 9, 3831: 9, 3832: 9, 3833: 9, 3834: 9, 3835: 9, 3836: 9, 3837: 9, 3838: 9, 3839: 9, 3840: 9, 3841: 9, 3842: 9, 3843: 9, 3844: 9, 3845: 9, 3846: 9, 3847: 9, 3848: 9, 3849: 9, 3850: 9, 3851: 9, 3852: 9, 3853: 9, 3854: 9, 3855: 9, 3856: 9, 3857: 9, 3858: 9, 3859: 9, 3860: 9, 3861: 9, 3862: 9, 3863: 9, 3864: 9, 3865: 9, 3866: 9, 3867: 9, 3868: 9, 3869: 9, 3870: 9, 3871: 9, 3872: 9, 3873: 9, 3874: 9, 3875: 9, 3876: 9, 3877: 9, 3878: 9, 3879: 9, 3880: 9, 3881: 9, 3882: 9, 3883: 9, 3884: 9, 3885: 9, 3886: 9, 3887: 9, 3888: 9, 3889: 9, 3890: 9, 3891: 9, 3892: 9, 3893: 9, 3894: 9, 3895: 9, 3896: 9, 3897: 9, 3898: 9, 3899: 9, 3900: 9, 3901: 9, 3902: 9, 3903: 9, 3904: 9, 3905: 9, 3906: 9, 3907: 9, 3908: 9, 3909: 9, 3910: 9, 3911: 9, 3912: 9, 3913: 9, 3914: 9, 3915: 9, 3916: 9, 3917: 9, 3918: 9, 3919: 9, 3920: 9, 3921: 9, 3922: 9, 3923: 9, 3924: 9, 3925: 9, 3926: 9, 3927: 9, 3928: 9, 3929: 9, 3930: 9, 3931: 9, 3932: 9, 3933: 9, 3934: 9, 3935: 9, 3936: 9, 3937: 9, 3938: 9, 3939: 9, 3940: 9, 3941: 9, 3942: 9, 3943: 9, 3944: 9, 3945: 9, 3946: 9, 3947: 9, 3948: 9, 3949: 9, 3950: 9, 3951: 9, 3952: 9, 3953: 9, 3954: 9, 3955: 9, 3956: 9, 3957: 9, 3958: 9, 3959: 9, 3960: 9, 3961: 9, 3962: 9, 3963: 9, 3964: 9, 3965: 9, 3966: 9, 3967: 9, 3968: 9, 3969: 9, 3970: 9, 3971: 9, 3972: 9, 3973: 9, 3974: 9, 3975: 9, 3976: 9, 3977: 9, 3978: 9, 3979: 9, 3980: 9, 3981: 9, 3982: 9, 3983: 9, 3984: 9, 3985: 9, 3986: 9, 3987: 9, 3988: 9, 3989: 9, 3990: 9, 3991: 9, 3992: 9, 3993: 9, 3994: 9, 3995: 9, 3996: 9, 3997: 9, 3998: 9, 3999: 9, 4000: 9, 4001: 9, 4002: 9, 4003: 9, 4004: 9, 4005: 9, 4006: 9, 4007: 9, 4008: 9, 4009: 9, 4010: 9, 4011: 9, 4012: 9, 4013: 9, 4014: 9, 4015: 9, 4016: 9, 4017: 9, 4018: 9, 4019: 9, 4020: 9, 4021: 9, 4022: 9, 4023: 9, 4024: 9, 4025: 9, 4026: 9, 4027: 9, 4028: 9, 4029: 9, 4030: 9, 4031: 9, 4032: 9, 4033: 9, 4034: 9, 4035: 9, 4036: 9, 4037: 9, 4038: 9, 4039: 9, 4040: 9, 4041: 9, 4042: 9, 4043: 9, 4044: 9, 4045: 9, 4046: 9, 4047: 9, 4048: 9, 4049: 9, 4050: 9, 4051: 9, 4052: 9, 4053: 9, 4054: 9, 4055: 9, 4056: 9, 4057: 9, 4058: 9, 4059: 9, 4060: 9, 4061: 9, 4062: 9, 4063: 9, 4064: 9, 4065: 9, 4066: 9, 4067: 9, 4068: 9, 4069: 9, 4070: 9, 4071: 9, 4072: 9, 4073: 9, 4074: 9, 4075: 9, 4076: 9, 4077: 9, 4078: 9, 4079: 9, 4080: 9, 4081: 9, 4082: 9, 4083: 9, 4084: 9, 4085: 9, 4086: 9, 4087: 9, 4088: 9, 4089: 9, 4090: 9, 4091: 9, 4092: 9, 4093: 9, 4094: 9, 4095: 9, 4096: 9, 4097: 9, 4098: 9, 4099: 9, 4100: 9, 4101: 9, 4102: 9, 4103: 9, 4104: 9, 4105: 9, 4106: 9, 4107: 9, 4108: 9, 4109: 9, 4110: 9, 4111: 9, 4112: 9, 4113: 9, 4114: 9, 4115: 9, 4116: 9, 4117: 9, 4118: 9, 4119: 9, 4120: 9, 4121: 9, 4122: 9, 4123: 9, 4124: 9, 4125: 9, 4126: 9, 4127: 9, 4128: 9, 4129: 9, 4130: 9, 4131: 9, 4132: 9, 4133: 9, 4134: 9, 4135: 9, 4136: 9, 4137: 9, 4138: 9, 4139: 9, 4140: 9, 4141: 9, 4142: 9, 4143: 9, 4144: 9, 4145: 9, 4146: 9, 4147: 9, 4148: 9, 4149: 9, 4150: 9, 4151: 9, 4152: 9, 4153: 9, 4154: 9, 4155: 9, 4156: 9, 4157: 9, 4158: 9, 4159: 9, 4160: 9, 4161: 9, 4162: 9, 4163: 9, 4164: 9, 4165: 9, 4166: 9, 4167: 9, 4168: 9, 4169: 9, 4170: 9, 4171: 9, 4172: 9, 4173: 9, 4174: 9, 4175: 9, 4176: 9, 4177: 9, 4178: 9, 4179: 9, 4180: 9, 4181: 9, 4182: 9, 4183: 9, 4184: 9, 4185: 9, 4186: 9, 4187: 9, 4188: 9, 4189: 9, 4190: 9, 4191: 9, 4192: 9, 4193: 9, 4194: 9, 4195: 9, 4196: 9, 4197: 9, 4198: 9, 4199: 9, 4200: 9, 4201: 9, 4202: 9, 4203: 9, 4204: 9, 4205: 9, 4206: 9, 4207: 9, 4208: 9, 4209: 9, 4210: 9, 4211: 9, 4212: 9, 4213: 9, 4214: 9, 4215: 9, 4216: 9, 4217: 9, 4218: 9, 4219: 9, 4220: 9, 4221: 9, 4222: 9, 4223: 9, 4224: 9, 4225: 9, 4226: 9, 4227: 9, 4228: 9, 4229: 9, 4230: 9, 4231: 9, 4232: 9, 4233: 9, 4234: 9, 4235: 9, 4236: 9, 4237: 9, 4238: 9, 4239: 9, 4240: 9, 4241: 9, 4242: 9, 4243: 9, 4244: 9, 4245: 9, 4246: 9, 4247: 9, 4248: 9, 4249: 9, 4250: 9, 4251: 9, 4252: 9, 4253: 9, 4254: 9, 4255: 9, 4256: 9, 4257: 9, 4258: 9, 4259: 9, 4260: 9, 4261: 9, 4262: 9, 4263: 9, 4264: 9, 4265: 9, 4266: 9, 4267: 9, 4268: 9, 4269: 9, 4270: 9, 4271: 9, 4272: 9, 4273: 9, 4274: 9, 4275: 9, 4276: 9, 4277: 9, 4278: 9, 4279: 9, 4280: 9, 4281: 9, 4282: 9, 4283: 9, 4284: 9, 4285: 9, 4286: 9, 4287: 9, 4288: 9, 4289: 9, 4290: 9, 4291: 9, 4292: 9, 4293: 9, 4294: 9, 4295: 9, 4296: 9, 4297: 9, 4298: 9, 4299: 9, 4300: 9, 4301: 9, 4302: 9, 4303: 9, 4304: 9, 4305: 9, 4306: 9, 4307: 9, 4308: 9, 4309: 9, 4310: 9, 4311: 9, 4312: 9, 4313: 9, 4314: 9, 4315: 9, 4316: 9, 4317: 9, 4318: 9, 4319: 9, 4320: 9, 4321: 9, 4322: 9, 4323: 9, 4324: 9, 4325: 9, 4326: 9, 4327: 9, 4328: 9, 4329: 9, 4330: 9, 4331: 9, 4332: 9, 4333: 9, 4334: 9, 4335: 9, 4336: 9, 4337: 9, 4338: 9, 4339: 9, 4340: 9, 4341: 9, 4342: 9, 4343: 9, 4344: 9, 4345: 9, 4346: 9, 4347: 9, 4348: 9, 4349: 9, 4350: 9, 4351: 9, 4352: 9, 4353: 9, 4354: 9, 4355: 9, 4356: 9, 4357: 9, 4358: 9, 4359: 9, 4360: 9, 4361: 9, 4362: 9, 4363: 9, 4364: 9, 4365: 9, 4366: 9, 4367: 9, 4368: 9, 4369: 9, 4370: 9, 4371: 9, 4372: 9, 4373: 9, 4374: 9, 4375: 9, 4376: 9, 4377: 9, 4378: 9, 4379: 9, 4380: 9, 4381: 9, 4382: 9, 4383: 9, 4384: 9, 4385: 9, 4386: 9, 4387: 9, 4388: 9, 4389: 9, 4390: 9, 4391: 9, 4392: 9, 4393: 9, 4394: 9, 4395: 9, 4396: 9, 4397: 9, 4398: 9, 4399: 9, 4400: 9, 4401: 9, 4402: 9, 4403: 9, 4404: 9, 4405: 9, 4406: 9, 4407: 9, 4408: 9, 4409: 9, 4410: 9, 4411: 9, 4412: 9, 4413: 9, 4414: 9, 4415: 9, 4416: 9, 4417: 9, 4418: 9, 4419: 9, 4420: 9, 4421: 9, 4422: 9, 4423: 9, 4424: 9, 4425: 9, 4426: 9, 4427: 9, 4428: 9, 4429: 9, 4430: 9, 4431: 9, 4432: 9, 4433: 9, 4434: 9, 4435: 9, 4436: 9, 4437: 9, 4438: 9, 4439: 9, 4440: 9, 4441: 9, 4442: 9, 4443: 9, 4444: 9, 4445: 9, 4446: 9, 4447: 9, 4448: 9, 4449: 9, 4450: 9, 4451: 9, 4452: 9, 4453: 9, 4454: 9, 4455: 9, 4456: 9, 4457: 9, 4458: 9, 4459: 9, 4460: 9, 4461: 9, 4462: 9, 4463: 9, 4464: 9, 4465: 9, 4466: 9, 4467: 9, 4468: 9, 4469: 9, 4470: 9, 4471: 9, 4472: 9, 4473: 9, 4474: 9, 4475: 9, 4476: 9, 4477: 9, 4478: 9, 4479: 9, 4480: 9, 4481: 9, 4482: 9, 4483: 9, 4484: 9, 4485: 9, 4486: 9, 4487: 9, 4488: 9, 4489: 9, 4490: 9, 4491: 9, 4492: 9, 4493: 9, 4494: 9, 4495: 9, 4496: 9, 4497: 9, 4498: 9, 4499: 9, 4500: 9, 4501: 9, 4502: 9, 4503: 9, 4504: 9, 4505: 9, 4506: 9, 4507: 9, 4508: 9, 4509: 9, 4510: 9, 4511: 9, 4512: 9, 4513: 9, 4514: 9, 4515: 9, 4516: 9, 4517: 9, 4518: 9, 4519: 9, 4520: 9, 4521: 9, 4522: 9, 4523: 9, 4524: 9, 4525: 9, 4526: 9, 4527: 9, 4528: 9, 4529: 9, 4530: 9, 4531: 9, 4532: 9, 4533: 9, 4534: 9, 4535: 9, 4536: 9, 4537: 9, 4538: 9, 4539: 9, 4540: 9, 4541: 9, 4542: 9, 4543: 9, 4544: 9, 4545: 9, 4546: 9, 4547: 9, 4548: 9, 4549: 9, 4550: 9, 4551: 9, 4552: 9, 4553: 9, 4554: 9, 4555: 9, 4556: 9, 4557: 9, 4558: 9, 4559: 9, 4560: 9, 4561: 9, 4562: 9, 4563: 9, 4564: 9, 4565: 9, 4566: 9, 4567: 9, 4568: 9, 4569: 9, 4570: 9, 4571: 9, 4572: 9, 4573: 9, 4574: 9, 4575: 9, 4576: 9, 4577: 9, 4578: 9, 4579: 9, 4580: 9, 4581: 9, 4582: 9, 4583: 9, 4584: 9, 4585: 9, 4586: 9, 4587: 9, 4588: 9, 4589: 9, 4590: 9, 4591: 9, 4592: 9, 4593: 9, 4594: 9, 4595: 9, 4596: 9, 4597: 9, 4598: 9, 4599: 9, 4600: 9, 4601: 9, 4602: 9, 4603: 9, 4604: 9, 4605: 9, 4606: 9, 4607: 9, 4608: 9, 4609: 9, 4610: 9, 4611: 9, 4612: 9, 4613: 9, 4614: 9, 4615: 9, 4616: 9, 4617: 9, 4618: 9, 4619: 9, 4620: 9, 4621: 9, 4622: 9, 4623: 9, 4624: 9, 4625: 9, 4626: 9, 4627: 9, 4628: 9, 4629: 9, 4630: 9, 4631: 9, 4632: 9, 4633: 9, 4634: 9, 4635: 9, 4636: 9, 4637: 9, 4638: 9, 4639: 9, 4640: 9, 4641: 9, 4642: 9, 4643: 9, 4644: 9, 4645: 9, 4646: 9, 4647: 9, 4648: 9, 4649: 9, 4650: 9, 4651: 9, 4652: 9, 4653: 9, 4654: 9, 4655: 9, 4656: 9, 4657: 9, 4658: 9, 4659: 9, 4660: 9, 4661: 9, 4662: 9, 4663: 9, 4664: 9, 4665: 9, 4666: 9, 4667: 9, 4668: 9, 4669: 9, 4670: 9, 4671: 9, 4672: 9, 4673: 9, 4674: 9, 4675: 9, 4676: 9, 4677: 9, 4678: 9, 4679: 9, 4680: 9, 4681: 9, 4682: 9, 4683: 9, 4684: 9, 4685: 9, 4686: 9, 4687: 9, 4688: 9, 4689: 9, 4690: 9, 4691: 9, 4692: 9, 4693: 9, 4694: 9, 4695: 9, 4696: 9, 4697: 9, 4698: 9, 4699: 9, 4700: 9, 4701: 9, 4702: 9, 4703: 9, 4704: 9, 4705: 9, 4706: 9, 4707: 9, 4708: 9, 4709: 9, 4710: 9, 4711: 9, 4712: 9, 4713: 9, 4714: 9, 4715: 9, 4716: 9, 4717: 9, 4718: 9, 4719: 9, 4720: 9, 4721: 9, 4722: 9, 4723: 9, 4724: 9, 4725: 9, 4726: 9, 4727: 9, 4728: 9, 4729: 9, 4730: 9, 4731: 9, 4732: 9, 4733: 9, 4734: 9, 4735: 9, 4736: 9, 4737: 9, 4738: 9, 4739: 9, 4740: 9, 4741: 9, 4742: 9, 4743: 9, 4744: 9, 4745: 9, 4746: 9, 4747: 9, 4748: 9, 4749: 9, 4750: 9, 4751: 9, 4752: 9, 4753: 9, 4754: 9, 4755: 9, 4756: 9, 4757: 9, 4758: 9, 4759: 9, 4760: 9, 4761: 9, 4762: 9, 4763: 9, 4764: 9, 4765: 9, 4766: 9, 4767: 9, 4768: 9, 4769: 9, 4770: 9, 4771: 9, 4772: 9, 4773: 9, 4774: 9, 4775: 9, 4776: 9, 4777: 9, 4778: 9, 4779: 9, 4780: 9, 4781: 9, 4782: 9, 4783: 9, 4784: 9, 4785: 9, 4786: 9, 4787: 9, 4788: 9, 4789: 9, 4790: 9, 4791: 9, 4792: 9, 4793: 9, 4794: 9, 4795: 9, 4796: 9, 4797: 9, 4798: 9, 4799: 9, 4800: 9, 4801: 9, 4802: 9, 4803: 9, 4804: 9, 4805: 9, 4806: 9, 4807: 9, 4808: 9, 4809: 9, 4810: 9, 4811: 9, 4812: 9, 4813: 9, 4814: 9, 4815: 9, 4816: 9, 4817: 9, 4818: 9, 4819: 9, 4820: 9, 4821: 9, 4822: 9, 4823: 9, 4824: 9, 4825: 9, 4826: 9, 4827: 9, 4828: 9, 4829: 9, 4830: 9, 4831: 9, 4832: 9, 4833: 9, 4834: 9, 4835: 9, 4836: 9, 4837: 9, 4838: 9, 4839: 9, 4840: 9, 4841: 9, 4842: 9, 4843: 9, 4844: 9, 4845: 9, 4846: 9, 4847: 9, 4848: 9, 4849: 9, 4850: 9, 4851: 9, 4852: 9, 4853: 9, 4854: 9, 4855: 9, 4856: 9, 4857: 9, 4858: 9, 4859: 9, 4860: 9, 4861: 9, 4862: 9, 4863: 9, 4864: 9, 4865: 9, 4866: 9, 4867: 9, 4868: 9, 4869: 9, 4870: 9, 4871: 9, 4872: 9, 4873: 9, 4874: 9, 4875: 9, 4876: 9, 4877: 9, 4878: 9, 4879: 9, 4880: 9, 4881: 9, 4882: 9, 4883: 9, 4884: 9, 4885: 9, 4886: 9, 4887: 9, 4888: 9, 4889: 9, 4890: 9, 4891: 9, 4892: 9, 4893: 9, 4894: 9, 4895: 9, 4896: 9, 4897: 9, 4898: 9, 4899: 9, 4900: 9, 4901: 9, 4902: 9, 4903: 9, 4904: 9, 4905: 9, 4906: 9, 4907: 9, 4908: 9, 4909: 9, 4910: 9, 4911: 9, 4912: 9, 4913: 9, 4914: 9, 4915: 9, 4916: 9, 4917: 9, 4918: 9, 4919: 9, 4920: 9, 4921: 9, 4922: 9, 4923: 9, 4924: 9, 4925: 9, 4926: 9, 4927: 9, 4928: 9, 4929: 9, 4930: 9, 4931: 9, 4932: 9, 4933: 9, 4934: 9, 4935: 9, 4936: 9, 4937: 9, 4938: 9, 4939: 9, 4940: 9, 4941: 9, 4942: 9, 4943: 9, 4944: 9, 4945: 9, 4946: 9, 4947: 9, 4948: 9, 4949: 9, 4950: 9, 4951: 9, 4952: 9, 4953: 9, 4954: 9, 4955: 9, 4956: 9, 4957: 9, 4958: 9, 4959: 9, 4960: 9, 4961: 9, 4962: 9, 4963: 9, 4964: 9, 4965: 9, 4966: 9, 4967: 9, 4968: 9, 4969: 9, 4970: 9, 4971: 9, 4972: 9, 4973: 9, 4974: 9, 4975: 9, 4976: 9, 4977: 9, 4978: 9, 4979: 9, 4980: 9, 4981: 9, 4982: 9, 4983: 9, 4984: 9, 4985: 9, 4986: 9, 4987: 9, 4988: 9, 4989: 9, 4990: 9, 4991: 9, 4992: 9, 4993: 9, 4994: 9, 4995: 9, 4996: 9, 4997: 9, 4998: 9, 4999: 9, 5000: 9, 5001: 9, 5002: 9, 5003: 9, 5004: 9, 5005: 9, 5006: 9, 5007: 9, 5008: 9, 5009: 9, 5010: 9, 5011: 9, 5012: 9, 5013: 9, 5014: 9, 5015: 9, 5016: 9, 5017: 9, 5018: 9, 5019: 9, 5020: 9, 5021: 9, 5022: 9, 5023: 9, 5024: 9, 5025: 9, 5026: 9, 5027: 9, 5028: 9, 5029: 9, 5030: 9, 5031: 9, 5032: 9, 5033: 9, 5034: 9, 5035: 9, 5036: 9, 5037: 9, 5038: 9, 5039: 9, 5040: 9, 5041: 9, 5042: 9, 5043: 9, 5044: 9, 5045: 9, 5046: 9, 5047: 9, 5048: 9, 5049: 9, 5050: 9, 5051: 9, 5052: 9, 5053: 9, 5054: 9, 5055: 9, 5056: 9, 5057: 9, 5058: 9, 5059: 9, 5060: 9, 5061: 9, 5062: 9, 5063: 9, 5064: 9, 5065: 9, 5066: 9, 5067: 9, 5068: 9, 5069: 9, 5070: 9, 5071: 9, 5072: 9, 5073: 9, 5074: 9, 5075: 9, 5076: 9, 5077: 9, 5078: 9, 5079: 9, 5080: 9, 5081: 9, 5082: 9, 5083: 9, 5084: 9, 5085: 9, 5086: 9, 5087: 9, 5088: 9, 5089: 9, 5090: 9, 5091: 9, 5092: 9, 5093: 9, 5094: 9, 5095: 9, 5096: 9, 5097: 9, 5098: 9, 5099: 9, 5100: 9, 5101: 9, 5102: 9, 5103: 9, 5104: 9, 5105: 9, 5106: 9, 5107: 9, 5108: 9, 5109: 9, 5110: 9, 5111: 9, 5112: 9, 5113: 9, 5114: 9, 5115: 9, 5116: 9, 5117: 9, 5118: 9, 5119: 9, 5120: 9, 5121: 9, 5122: 9, 5123: 9, 5124: 9, 5125: 9, 5126: 9, 5127: 9, 5128: 9, 5129: 9, 5130: 9, 5131: 9, 5132: 9, 5133: 9, 5134: 9, 5135: 9, 5136: 9, 5137: 9, 5138: 9, 5139: 9, 5140: 9, 5141: 9, 5142: 9, 5143: 9, 5144: 9, 5145: 9, 5146: 9, 5147: 9, 5148: 9, 5149: 9, 5150: 9, 5151: 9, 5152: 9, 5153: 9, 5154: 9, 5155: 9, 5156: 9, 5157: 9, 5158: 9, 5159: 9, 5160: 9, 5161: 9, 5162: 9, 5163: 9, 5164: 9, 5165: 9, 5166: 9, 5167: 9, 5168: 9, 5169: 9, 5170: 9, 5171: 9, 5172: 9, 5173: 9, 5174: 9, 5175: 9, 5176: 9, 5177: 9, 5178: 9, 5179: 9, 5180: 9, 5181: 9, 5182: 9, 5183: 9, 5184: 9, 5185: 9, 5186: 9, 5187: 9, 5188: 9, 5189: 9, 5190: 9, 5191: 9, 5192: 9, 5193: 9, 5194: 9, 5195: 9, 5196: 9, 5197: 9, 5198: 9, 5199: 9, 5200: 9, 5201: 9, 5202: 9, 5203: 9, 5204: 9, 5205: 9, 5206: 9, 5207: 9, 5208: 9, 5209: 9, 5210: 9, 5211: 9, 5212: 9, 5213: 9, 5214: 9, 5215: 9, 5216: 9, 5217: 9, 5218: 9, 5219: 9, 5220: 9, 5221: 9, 5222: 9, 5223: 9, 5224: 9, 5225: 9, 5226: 9, 5227: 9, 5228: 9, 5229: 9, 5230: 9, 5231: 9, 5232: 9, 5233: 9, 5234: 9, 5235: 9, 5236: 9, 5237: 9, 5238: 9, 5239: 9, 5240: 9, 5241: 9, 5242: 9, 5243: 9, 5244: 9, 5245: 9, 5246: 9, 5247: 9, 5248: 9, 5249: 9, 5250: 9, 5251: 9, 5252: 9, 5253: 9, 5254: 9, 5255: 9, 5256: 9, 5257: 9, 5258: 9, 5259: 9, 5260: 9, 5261: 9, 5262: 9, 5263: 9, 5264: 9, 5265: 9, 5266: 9, 5267: 9, 5268: 9, 5269: 9, 5270: 9, 5271: 9, 5272: 9, 5273: 9, 5274: 9, 5275: 9, 5276: 9, 5277: 9, 5278: 9, 5279: 9, 5280: 9, 5281: 9, 5282: 9, 5283: 9, 5284: 9, 5285: 9, 5286: 9, 5287: 9, 5288: 9, 5289: 9, 5290: 9, 5291: 9, 5292: 9, 5293: 9, 5294: 9, 5295: 9, 5296: 9, 5297: 9, 5298: 9, 5299: 9, 5300: 9, 5301: 9, 5302: 9, 5303: 9, 5304: 9, 5305: 9, 5306: 9, 5307: 9, 5308: 9, 5309: 9, 5310: 9, 5311: 9, 5312: 9, 5313: 9, 5314: 9, 5315: 9, 5316: 9, 5317: 9, 5318: 9, 5319: 9, 5320: 9, 5321: 9, 5322: 9, 5323: 9, 5324: 9, 5325: 9, 5326: 9, 5327: 9, 5328: 9, 5329: 9, 5330: 9, 5331: 9, 5332: 9, 5333: 9, 5334: 9, 5335: 9, 5336: 9, 5337: 9, 5338: 9, 5339: 9, 5340: 9, 5341: 9, 5342: 9, 5343: 9, 5344: 9, 5345: 9, 5346: 9, 5347: 9, 5348: 9, 5349: 9, 5350: 9, 5351: 9, 5352: 9, 5353: 9, 5354: 9, 5355: 9, 5356: 9, 5357: 9, 5358: 9, 5359: 9, 5360: 9, 5361: 9, 5362: 9, 5363: 9, 5364: 9, 5365: 9, 5366: 9, 5367: 9, 5368: 9, 5369: 9, 5370: 9, 5371: 9, 5372: 9, 5373: 9, 5374: 9, 5375: 9, 5376: 9, 5377: 9, 5378: 9, 5379: 9, 5380: 9, 5381: 9, 5382: 9, 5383: 9, 5384: 9, 5385: 9, 5386: 9, 5387: 9, 5388: 9, 5389: 9, 5390: 9, 5391: 9, 5392: 9, 5393: 9, 5394: 9, 5395: 9, 5396: 9, 5397: 9, 5398: 9, 5399: 9, 5400: 9, 5401: 9, 5402: 9, 5403: 9, 5404: 9, 5405: 9, 5406: 9, 5407: 9, 5408: 9, 5409: 9, 5410: 9, 5411: 9, 5412: 9, 5413: 9, 5414: 9, 5415: 9, 5416: 9, 5417: 9, 5418: 9, 5419: 9, 5420: 9, 5421: 9, 5422: 9, 5423: 9, 5424: 9, 5425: 9, 5426: 9, 5427: 9, 5428: 9, 5429: 9, 5430: 9, 5431: 9, 5432: 9, 5433: 9, 5434: 9, 5435: 9, 5436: 9, 5437: 9, 5438: 9, 5439: 9, 5440: 9, 5441: 9, 5442: 9, 5443: 9, 5444: 9, 5445: 9, 5446: 9, 5447: 9, 5448: 9, 5449: 9, 5450: 9, 5451: 9, 5452: 9, 5453: 9, 5454: 9, 5455: 9, 5456: 9, 5457: 9, 5458: 9, 5459: 9, 5460: 9, 5461: 9, 5462: 9, 5463: 9, 5464: 9, 5465: 9, 5466: 9, 5467: 9, 5468: 9, 5469: 9, 5470: 9, 5471: 9, 5472: 9, 5473: 9, 5474: 9, 5475: 9, 5476: 9, 5477: 9, 5478: 9, 5479: 9, 5480: 9, 5481: 9, 5482: 9, 5483: 9, 5484: 9, 5485: 9, 5486: 9, 5487: 9, 5488: 9, 5489: 9, 5490: 9, 5491: 9, 5492: 9, 5493: 9, 5494: 9, 5495: 9, 5496: 9, 5497: 9, 5498: 9, 5499: 9, 5500: 9, 5501: 9, 5502: 9, 5503: 9, 5504: 9, 5505: 9, 5506: 9, 5507: 9, 5508: 9, 5509: 9, 5510: 9, 5511: 9, 5512: 9, 5513: 9, 5514: 9, 5515: 9, 5516: 9, 5517: 9, 5518: 9, 5519: 9, 5520: 9, 5521: 9, 5522: 9, 5523: 9, 5524: 9, 5525: 9, 5526: 9, 5527: 9, 5528: 9, 5529: 9, 5530: 9, 5531: 9, 5532: 9, 5533: 9, 5534: 9, 5535: 9, 5536: 9, 5537: 9, 5538: 9, 5539: 9, 5540: 9, 5541: 9, 5542: 9, 5543: 9, 5544: 9, 5545: 9, 5546: 9, 5547: 9, 5548: 9, 5549: 9, 5550: 9, 5551: 9, 5552: 9, 5553: 9, 5554: 9, 5555: 9, 5556: 9, 5557: 9, 5558: 9, 5559: 9, 5560: 9, 5561: 9, 5562: 9, 5563: 9, 5564: 9, 5565: 9, 5566: 9, 5567: 9, 5568: 9, 5569: 9, 5570: 9, 5571: 9, 5572: 9, 5573: 9, 5574: 9, 5575: 9, 5576: 9, 5577: 9, 5578: 9, 5579: 9, 5580: 9, 5581: 9, 5582: 9, 5583: 9, 5584: 9, 5585: 9, 5586: 9, 5587: 9, 5588: 9, 5589: 9, 5590: 9, 5591: 9, 5592: 9, 5593: 9, 5594: 9, 5595: 9, 5596: 9, 5597: 9, 5598: 9, 5599: 9, 5600: 9, 5601: 9, 5602: 9, 5603: 9, 5604: 9, 5605: 9, 5606: 9, 5607: 9, 5608: 9, 5609: 9, 5610: 9, 5611: 9, 5612: 9, 5613: 9, 5614: 9, 5615: 9, 5616: 9, 5617: 9, 5618: 9, 5619: 9, 5620: 9, 5621: 9, 5622: 9, 5623: 9, 5624: 9, 5625: 9, 5626: 9, 5627: 9, 5628: 9, 5629: 9, 5630: 9, 5631: 9, 5632: 9, 5633: 9, 5634: 9, 5635: 9, 5636: 9, 5637: 9, 5638: 9, 5639: 9, 5640: 9, 5641: 9, 5642: 9, 5643: 9, 5644: 9, 5645: 9, 5646: 9, 5647: 9, 5648: 9, 5649: 9, 5650: 9, 5651: 9, 5652: 9, 5653: 9, 5654: 9, 5655: 9, 5656: 9, 5657: 9, 5658: 9, 5659: 9, 5660: 9, 5661: 9, 5662: 9, 5663: 9, 5664: 9, 5665: 9, 5666: 9, 5667: 9, 5668: 9, 5669: 9, 5670: 9, 5671: 9, 5672: 9, 5673: 9, 5674: 9, 5675: 9, 5676: 9, 5677: 9, 5678: 9, 5679: 9, 5680: 9, 5681: 9, 5682: 9, 5683: 9, 5684: 9, 5685: 9, 5686: 9, 5687: 9, 5688: 9, 5689: 9, 5690: 9, 5691: 9, 5692: 9, 5693: 9, 5694: 9, 5695: 9, 5696: 9, 5697: 9, 5698: 9, 5699: 9, 5700: 9, 5701: 9, 5702: 9, 5703: 9, 5704: 9, 5705: 9, 5706: 9, 5707: 9, 5708: 9, 5709: 9, 5710: 9, 5711: 9, 5712: 9, 5713: 9, 5714: 9, 5715: 9, 5716: 9, 5717: 9, 5718: 9, 5719: 9, 5720: 9, 5721: 9, 5722: 9, 5723: 9, 5724: 9, 5725: 9, 5726: 9, 5727: 9, 5728: 9, 5729: 9, 5730: 9, 5731: 9, 5732: 9, 5733: 9, 5734: 9, 5735: 9, 5736: 9, 5737: 9, 5738: 9, 5739: 9, 5740: 9, 5741: 9, 5742: 9, 5743: 9, 5744: 9, 5745: 9, 5746: 9, 5747: 9, 5748: 9, 5749: 9, 5750: 9, 5751: 9, 5752: 9, 5753: 9, 5754: 9, 5755: 9, 5756: 9, 5757: 9, 5758: 9, 5759: 9, 5760: 9, 5761: 9, 5762: 9, 5763: 9, 5764: 9, 5765: 9, 5766: 9, 5767: 9, 5768: 9, 5769: 9, 5770: 9, 5771: 9, 5772: 9, 5773: 9, 5774: 9, 5775: 9, 5776: 9, 5777: 9, 5778: 9, 5779: 9, 5780: 9, 5781: 9, 5782: 9, 5783: 9, 5784: 9, 5785: 9, 5786: 9, 5787: 9, 5788: 9, 5789: 9, 5790: 9, 5791: 9, 5792: 9, 5793: 9, 5794: 9, 5795: 9, 5796: 9, 5797: 9, 5798: 9, 5799: 9, 5800: 9, 5801: 9, 5802: 9, 5803: 9, 5804: 9, 5805: 9, 5806: 9, 5807: 9, 5808: 9, 5809: 9, 5810: 9, 5811: 9, 5812: 9, 5813: 9, 5814: 9, 5815: 9, 5816: 9, 5817: 9, 5818: 9, 5819: 9, 5820: 9, 5821: 9, 5822: 9, 5823: 9, 5824: 9, 5825: 9, 5826: 9, 5827: 9, 5828: 9, 5829: 9, 5830: 9, 5831: 9, 5832: 9, 5833: 9, 5834: 9, 5835: 9, 5836: 9, 5837: 9, 5838: 9, 5839: 9, 5840: 9, 5841: 9, 5842: 9, 5843: 9, 5844: 9, 5845: 9, 5846: 9, 5847: 9, 5848: 9, 5849: 9, 5850: 9, 5851: 9, 5852: 9, 5853: 9, 5854: 9, 5855: 9, 5856: 9, 5857: 9, 5858: 9, 5859: 9, 5860: 9, 5861: 9, 5862: 9, 5863: 9, 5864: 9, 5865: 9, 5866: 9, 5867: 9, 5868: 9, 5869: 9, 5870: 9, 5871: 9, 5872: 9, 5873: 9, 5874: 9, 5875: 9, 5876: 9, 5877: 9, 5878: 9, 5879: 9, 5880: 9, 5881: 9, 5882: 9, 5883: 9, 5884: 9, 5885: 9, 5886: 9, 5887: 9, 5888: 9, 5889: 9, 5890: 9, 5891: 9, 5892: 9, 5893: 9, 5894: 9, 5895: 9, 5896: 9, 5897: 9, 5898: 9, 5899: 9, 5900: 9, 5901: 9, 5902: 9, 5903: 9, 5904: 9, 5905: 9, 5906: 9, 5907: 9, 5908: 9, 5909: 9, 5910: 9, 5911: 9, 5912: 9, 5913: 9, 5914: 9, 5915: 9, 5916: 9, 5917: 9, 5918: 9, 5919: 9, 5920: 9, 5921: 9, 5922: 9, 5923: 9, 5924: 9, 5925: 9, 5926: 9, 5927: 9, 5928: 9, 5929: 9, 5930: 9, 5931: 9, 5932: 9, 5933: 9, 5934: 9, 5935: 9, 5936: 9, 5937: 9, 5938: 9, 5939: 9, 5940: 9, 5941: 9, 5942: 9, 5943: 9, 5944: 9, 5945: 9, 5946: 9, 5947: 9, 5948: 9, 5949: 9, 5950: 9, 5951: 9, 5952: 9, 5953: 9, 5954: 9, 5955: 9, 5956: 9, 5957: 9, 5958: 9, 5959: 9, 5960: 9, 5961: 9, 5962: 9, 5963: 9, 5964: 9, 5965: 9, 5966: 9, 5967: 9, 5968: 9, 5969: 9, 5970: 9, 5971: 9, 5972: 9, 5973: 9, 5974: 9, 5975: 9, 5976: 9, 5977: 9, 5978: 9, 5979: 9, 5980: 9, 5981: 9, 5982: 9, 5983: 9, 5984: 9, 5985: 9, 5986: 9, 5987: 9, 5988: 9, 5989: 9, 5990: 9, 5991: 9, 5992: 9, 5993: 9, 5994: 9, 5995: 9, 5996: 9, 5997: 9, 5998: 9, 5999: 9, 6000: 9, 6001: 9, 6002: 9, 6003: 9, 6004: 9, 6005: 9, 6006: 9, 6007: 9, 6008: 9, 6009: 9, 6010: 9, 6011: 9, 6012: 9, 6013: 9, 6014: 9, 6015: 9, 6016: 9, 6017: 9, 6018: 9, 6019: 9, 6020: 9, 6021: 9, 6022: 9, 6023: 9, 6024: 9, 6025: 9, 6026: 9, 6027: 9, 6028: 9, 6029: 9, 6030: 9, 6031: 9, 6032: 9, 6033: 9, 6034: 9, 6035: 9, 6036: 9, 6037: 9, 6038: 9, 6039: 9, 6040: 9, 6041: 9, 6042: 9, 6043: 9, 6044: 9, 6045: 9, 6046: 9, 6047: 9, 6048: 9, 6049: 9, 6050: 9, 6051: 9, 6052: 9, 6053: 9, 6054: 9, 6055: 9, 6056: 9, 6057: 9, 6058: 9, 6059: 9, 6060: 9, 6061: 9, 6062: 9, 6063: 9, 6064: 9, 6065: 9, 6066: 9, 6067: 9, 6068: 9, 6069: 9, 6070: 9, 6071: 9, 6072: 9, 6073: 9, 6074: 9, 6075: 9, 6076: 9, 6077: 9, 6078: 9, 6079: 9, 6080: 9, 6081: 9, 6082: 9, 6083: 9, 6084: 9, 6085: 9, 6086: 9, 6087: 9, 6088: 9, 6089: 9, 6090: 9, 6091: 9, 6092: 9, 6093: 9, 6094: 9, 6095: 9, 6096: 9, 6097: 9, 6098: 9, 6099: 9, 6100: 9, 6101: 9, 6102: 9, 6103: 9, 6104: 9, 6105: 9, 6106: 9, 6107: 9, 6108: 9, 6109: 9, 6110: 9, 6111: 9, 6112: 9, 6113: 9, 6114: 9, 6115: 9, 6116: 9, 6117: 9, 6118: 9, 6119: 9, 6120: 9, 6121: 9, 6122: 9, 6123: 9, 6124: 9, 6125: 9, 6126: 9, 6127: 9, 6128: 9, 6129: 9, 6130: 9, 6131: 9, 6132: 9, 6133: 9, 6134: 9, 6135: 9, 6136: 9, 6137: 9, 6138: 9, 6139: 9, 6140: 9, 6141: 9, 6142: 9, 6143: 9, 6144: 9, 6145: 9, 6146: 9, 6147: 9, 6148: 9, 6149: 9, 6150: 9, 6151: 9, 6152: 9, 6153: 9, 6154: 9, 6155: 9, 6156: 9, 6157: 9, 6158: 9, 6159: 9, 6160: 9, 6161: 9, 6162: 9, 6163: 9, 6164: 9, 6165: 9, 6166: 9, 6167: 9, 6168: 9, 6169: 9, 6170: 9, 6171: 9, 6172: 9, 6173: 9, 6174: 9, 6175: 9, 6176: 9, 6177: 9, 6178: 9, 6179: 9, 6180: 9, 6181: 9, 6182: 9, 6183: 9, 6184: 9, 6185: 9, 6186: 9, 6187: 9, 6188: 9, 6189: 9, 6190: 9, 6191: 9, 6192: 9, 6193: 9, 6194: 9, 6195: 9, 6196: 9, 6197: 9, 6198: 9, 6199: 9, 6200: 9, 6201: 9, 6202: 9, 6203: 9, 6204: 9, 6205: 9, 6206: 9, 6207: 9, 6208: 9, 6209: 9, 6210: 9, 6211: 9, 6212: 9, 6213: 9, 6214: 9, 6215: 9, 6216: 9, 6217: 9, 6218: 9, 6219: 9, 6220: 9, 6221: 9, 6222: 9, 6223: 9, 6224: 9, 6225: 9, 6226: 9, 6227: 9, 6228: 9, 6229: 9, 6230: 9, 6231: 9, 6232: 9, 6233: 9, 6234: 9, 6235: 9, 6236: 9, 6237: 9, 6238: 9, 6239: 9, 6240: 9, 6241: 9, 6242: 9, 6243: 9, 6244: 9, 6245: 9, 6246: 9, 6247: 9, 6248: 9, 6249: 9, 6250: 9, 6251: 9, 6252: 9, 6253: 9, 6254: 9, 6255: 9, 6256: 9, 6257: 9, 6258: 9, 6259: 9, 6260: 9, 6261: 9, 6262: 9, 6263: 9, 6264: 9, 6265: 9, 6266: 9, 6267: 9, 6268: 9, 6269: 9, 6270: 9, 6271: 9, 6272: 9, 6273: 9, 6274: 9, 6275: 9, 6276: 9, 6277: 9, 6278: 9, 6279: 9, 6280: 9, 6281: 9, 6282: 9, 6283: 9, 6284: 9, 6285: 9, 6286: 9, 6287: 9, 6288: 9, 6289: 9, 6290: 9, 6291: 9, 6292: 9, 6293: 9, 6294: 9, 6295: 9, 6296: 9, 6297: 9, 6298: 9, 6299: 9, 6300: 9, 6301: 9, 6302: 9, 6303: 9, 6304: 9, 6305: 9, 6306: 9, 6307: 9, 6308: 9, 6309: 9, 6310: 9, 6311: 9, 6312: 9, 6313: 9, 6314: 9, 6315: 9, 6316: 9, 6317: 9, 6318: 9, 6319: 9, 6320: 9, 6321: 9, 6322: 9, 6323: 9, 6324: 9, 6325: 9, 6326: 9, 6327: 9, 6328: 9, 6329: 9, 6330: 9, 6331: 9, 6332: 9, 6333: 9, 6334: 9, 6335: 9, 6336: 9, 6337: 9, 6338: 9, 6339: 9, 6340: 9, 6341: 9, 6342: 9, 6343: 9, 6344: 9, 6345: 9, 6346: 9, 6347: 9, 6348: 9, 6349: 9, 6350: 9, 6351: 9, 6352: 9, 6353: 9, 6354: 9, 6355: 9, 6356: 9, 6357: 9, 6358: 9, 6359: 9, 6360: 9, 6361: 9, 6362: 9, 6363: 9, 6364: 9, 6365: 9, 6366: 9, 6367: 9, 6368: 9, 6369: 9, 6370: 9, 6371: 9, 6372: 9, 6373: 9, 6374: 9, 6375: 9, 6376: 9, 6377: 9, 6378: 9, 6379: 9, 6380: 9, 6381: 9, 6382: 9, 6383: 9, 6384: 9, 6385: 9, 6386: 9, 6387: 9, 6388: 9, 6389: 9, 6390: 9, 6391: 9, 6392: 9, 6393: 9, 6394: 9, 6395: 9, 6396: 9, 6397: 9, 6398: 9, 6399: 9, 6400: 9, 6401: 9, 6402: 9, 6403: 9, 6404: 9, 6405: 9, 6406: 9, 6407: 9, 6408: 9, 6409: 9, 6410: 9, 6411: 9, 6412: 9, 6413: 9, 6414: 9, 6415: 9, 6416: 9, 6417: 9, 6418: 9, 6419: 9, 6420: 9, 6421: 9, 6422: 9, 6423: 9, 6424: 9, 6425: 9, 6426: 9, 6427: 9, 6428: 9, 6429: 9, 6430: 9, 6431: 9, 6432: 9, 6433: 9, 6434: 9, 6435: 9, 6436: 9, 6437: 9, 6438: 9, 6439: 9, 6440: 9, 6441: 9, 6442: 9, 6443: 9, 6444: 9, 6445: 9, 6446: 9, 6447: 9, 6448: 9, 6449: 9, 6450: 9, 6451: 9, 6452: 9, 6453: 9, 6454: 9, 6455: 9, 6456: 9, 6457: 9, 6458: 9, 6459: 9, 6460: 9, 6461: 9, 6462: 9, 6463: 9, 6464: 9, 6465: 9, 6466: 9, 6467: 9, 6468: 9, 6469: 9, 6470: 9, 6471: 9, 6472: 9, 6473: 9, 6474: 9, 6475: 9, 6476: 9, 6477: 9, 6478: 9, 6479: 9, 6480: 9, 6481: 9, 6482: 9, 6483: 9, 6484: 9, 6485: 9, 6486: 9, 6487: 9, 6488: 9, 6489: 9, 6490: 9, 6491: 9, 6492: 9, 6493: 9, 6494: 9, 6495: 9, 6496: 9, 6497: 9, 6498: 9, 6499: 9, 6500: 9, 6501: 9, 6502: 9, 6503: 9, 6504: 9, 6505: 9, 6506: 9, 6507: 9, 6508: 9, 6509: 9, 6510: 9, 6511: 9, 6512: 9, 6513: 9, 6514: 9, 6515: 9, 6516: 9, 6517: 9, 6518: 9, 6519: 9, 6520: 9, 6521: 9, 6522: 9, 6523: 9, 6524: 9, 6525: 9, 6526: 9, 6527: 9, 6528: 9, 6529: 9, 6530: 9, 6531: 9, 6532: 9, 6533: 9, 6534: 9, 6535: 9, 6536: 9, 6537: 9, 6538: 9, 6539: 9, 6540: 9, 6541: 9, 6542: 9, 6543: 9, 6544: 9, 6545: 9, 6546: 9, 6547: 9, 6548: 9, 6549: 9, 6550: 9, 6551: 9, 6552: 9, 6553: 9, 6554: 9, 6555: 9, 6556: 9, 6557: 9, 6558: 9, 6559: 9, 6560: 9, 6561: 9, 6562: 9, 6563: 9, 6564: 9, 6565: 9, 6566: 9, 6567: 9, 6568: 9, 6569: 9, 6570: 9, 6571: 9, 6572: 9, 6573: 9, 6574: 9, 6575: 9, 6576: 9, 6577: 9, 6578: 9, 6579: 9, 6580: 9, 6581: 9, 6582: 9, 6583: 9, 6584: 9, 6585: 9, 6586: 9, 6587: 9, 6588: 9, 6589: 9, 6590: 9, 6591: 9, 6592: 9, 6593: 9, 6594: 9, 6595: 9, 6596: 9, 6597: 9, 6598: 9, 6599: 9, 6600: 9, 6601: 9, 6602: 9, 6603: 9, 6604: 9, 6605: 9, 6606: 9, 6607: 9, 6608: 9, 6609: 9, 6610: 9, 6611: 9, 6612: 9, 6613: 9, 6614: 9, 6615: 9, 6616: 9, 6617: 9, 6618: 9, 6619: 9, 6620: 9, 6621: 9, 6622: 9, 6623: 9, 6624: 9, 6625: 9, 6626: 9, 6627: 9, 6628: 9, 6629: 9, 6630: 9, 6631: 9, 6632: 9, 6633: 9, 6634: 9, 6635: 9, 6636: 9, 6637: 9, 6638: 9, 6639: 9, 6640: 9, 6641: 9, 6642: 9, 6643: 9, 6644: 9, 6645: 9, 6646: 9, 6647: 9, 6648: 9, 6649: 9, 6650: 9, 6651: 9, 6652: 9, 6653: 9, 6654: 9, 6655: 9, 6656: 9, 6657: 9, 6658: 9, 6659: 9, 6660: 9, 6661: 9, 6662: 9, 6663: 9, 6664: 9, 6665: 9, 6666: 9, 6667: 9, 6668: 9, 6669: 9, 6670: 9, 6671: 9, 6672: 9, 6673: 9, 6674: 9, 6675: 9, 6676: 9, 6677: 9, 6678: 9, 6679: 9, 6680: 9, 6681: 9, 6682: 9, 6683: 9, 6684: 9, 6685: 9, 6686: 9, 6687: 9, 6688: 9, 6689: 9, 6690: 9, 6691: 9, 6692: 9, 6693: 9, 6694: 9, 6695: 9, 6696: 9, 6697: 9, 6698: 9, 6699: 9, 6700: 9, 6701: 9, 6702: 9, 6703: 9, 6704: 9, 6705: 9, 6706: 9, 6707: 9, 6708: 9, 6709: 9, 6710: 9, 6711: 9, 6712: 9, 6713: 9, 6714: 9, 6715: 9, 6716: 9, 6717: 9, 6718: 9, 6719: 9, 6720: 9, 6721: 9, 6722: 9, 6723: 9, 6724: 9, 6725: 9, 6726: 9, 6727: 9, 6728: 9, 6729: 9, 6730: 9, 6731: 9, 6732: 9, 6733: 9, 6734: 9, 6735: 9, 6736: 9, 6737: 9, 6738: 9, 6739: 9, 6740: 9, 6741: 9, 6742: 9, 6743: 9, 6744: 9, 6745: 9, 6746: 9, 6747: 9, 6748: 9, 6749: 9, 6750: 9, 6751: 9, 6752: 9, 6753: 9, 6754: 9, 6755: 9, 6756: 9, 6757: 9, 6758: 9, 6759: 9, 6760: 9, 6761: 9, 6762: 9, 6763: 9, 6764: 9, 6765: 9, 6766: 9, 6767: 9, 6768: 9, 6769: 9, 6770: 9, 6771: 9, 6772: 9, 6773: 9, 6774: 9, 6775: 9, 6776: 9, 6777: 9, 6778: 9, 6779: 9, 6780: 9, 6781: 9, 6782: 9, 6783: 9, 6784: 9, 6785: 9, 6786: 9, 6787: 9, 6788: 9, 6789: 9, 6790: 9, 6791: 9, 6792: 9, 6793: 9, 6794: 9, 6795: 9, 6796: 9, 6797: 9, 6798: 9, 6799: 9, 6800: 9, 6801: 9, 6802: 9, 6803: 9, 6804: 9, 6805: 9, 6806: 9, 6807: 9, 6808: 9, 6809: 9, 6810: 9, 6811: 9, 6812: 9, 6813: 9, 6814: 9, 6815: 9, 6816: 9, 6817: 9, 6818: 9, 6819: 9, 6820: 9, 6821: 9, 6822: 9, 6823: 9, 6824: 9, 6825: 9, 6826: 9, 6827: 9, 6828: 9, 6829: 9, 6830: 9, 6831: 9, 6832: 9, 6833: 9, 6834: 9, 6835: 9, 6836: 9, 6837: 9, 6838: 9, 6839: 9, 6840: 9, 6841: 9, 6842: 9, 6843: 9, 6844: 9, 6845: 9, 6846: 9, 6847: 9, 6848: 9, 6849: 9, 6850: 9, 6851: 9, 6852: 9, 6853: 9, 6854: 9, 6855: 9, 6856: 9, 6857: 9, 6858: 9, 6859: 9, 6860: 9, 6861: 9, 6862: 9, 6863: 9, 6864: 9, 6865: 9, 6866: 9, 6867: 9, 6868: 9, 6869: 9, 6870: 9, 6871: 9, 6872: 9, 6873: 9, 6874: 9, 6875: 9, 6876: 9, 6877: 9, 6878: 9, 6879: 9, 6880: 9, 6881: 9, 6882: 9, 6883: 9, 6884: 9, 6885: 9, 6886: 9, 6887: 9, 6888: 9, 6889: 9, 6890: 9, 6891: 9, 6892: 9, 6893: 9, 6894: 9, 6895: 9, 6896: 9, 6897: 9, 6898: 9, 6899: 9, 6900: 9, 6901: 9, 6902: 9, 6903: 9, 6904: 9, 6905: 9, 6906: 9, 6907: 9, 6908: 9, 6909: 9, 6910: 9, 6911: 9, 6912: 9, 6913: 9, 6914: 9, 6915: 9, 6916: 9, 6917: 9, 6918: 9, 6919: 9, 6920: 9, 6921: 9, 6922: 9, 6923: 9, 6924: 9, 6925: 9, 6926: 9, 6927: 9, 6928: 9, 6929: 9, 6930: 9, 6931: 9, 6932: 9, 6933: 9, 6934: 9, 6935: 9, 6936: 9, 6937: 9, 6938: 9, 6939: 9, 6940: 9, 6941: 9, 6942: 9, 6943: 9, 6944: 9, 6945: 9, 6946: 9, 6947: 9, 6948: 9, 6949: 9, 6950: 9, 6951: 9, 6952: 9, 6953: 9, 6954: 9, 6955: 9, 6956: 9, 6957: 9, 6958: 9, 6959: 9, 6960: 9, 6961: 9, 6962: 9, 6963: 9, 6964: 9, 6965: 9, 6966: 9, 6967: 9, 6968: 9, 6969: 9, 6970: 9, 6971: 9, 6972: 9, 6973: 9, 6974: 9, 6975: 9, 6976: 9, 6977: 9, 6978: 9, 6979: 9, 6980: 9, 6981: 9, 6982: 9, 6983: 9, 6984: 9, 6985: 9, 6986: 9, 6987: 9, 6988: 9, 6989: 9, 6990: 9, 6991: 9, 6992: 9, 6993: 9, 6994: 9, 6995: 9, 6996: 9, 6997: 9, 6998: 9, 6999: 9, 7000: 9, 7001: 9, 7002: 9, 7003: 9, 7004: 9, 7005: 9, 7006: 9, 7007: 9, 7008: 9, 7009: 9, 7010: 9, 7011: 9, 7012: 9, 7013: 9, 7014: 9, 7015: 9, 7016: 9, 7017: 9, 7018: 9, 7019: 9, 7020: 9, 7021: 9, 7022: 9, 7023: 9, 7024: 9, 7025: 9, 7026: 9, 7027: 9, 7028: 9, 7029: 9, 7030: 9, 7031: 9, 7032: 9, 7033: 9, 7034: 9, 7035: 9, 7036: 9, 7037: 9, 7038: 9, 7039: 9, 7040: 9, 7041: 9, 7042: 9, 7043: 9, 7044: 9, 7045: 9, 7046: 9, 7047: 9, 7048: 9, 7049: 9, 7050: 9, 7051: 9, 7052: 9, 7053: 9, 7054: 9, 7055: 9, 7056: 9, 7057: 9, 7058: 9, 7059: 9, 7060: 9, 7061: 9, 7062: 9, 7063: 9, 7064: 9, 7065: 9, 7066: 9, 7067: 9, 7068: 9, 7069: 9, 7070: 9, 7071: 9, 7072: 9, 7073: 9, 7074: 9, 7075: 9, 7076: 9, 7077: 9, 7078: 9, 7079: 9, 7080: 9, 7081: 9, 7082: 9, 7083: 9, 7084: 9, 7085: 9, 7086: 9, 7087: 9, 7088: 9, 7089: 9, 7090: 9, 7091: 9, 7092: 9, 7093: 9, 7094: 9, 7095: 9, 7096: 9, 7097: 9, 7098: 9, 7099: 9, 7100: 9, 7101: 9, 7102: 9, 7103: 9, 7104: 9, 7105: 9, 7106: 9, 7107: 9, 7108: 9, 7109: 9, 7110: 9, 7111: 9, 7112: 9, 7113: 9, 7114: 9, 7115: 9, 7116: 9, 7117: 9, 7118: 9, 7119: 9, 7120: 9, 7121: 9, 7122: 9, 7123: 9, 7124: 9, 7125: 9, 7126: 9, 7127: 9, 7128: 9, 7129: 9, 7130: 9, 7131: 9, 7132: 9, 7133: 9, 7134: 9, 7135: 9, 7136: 9, 7137: 9, 7138: 9, 7139: 9, 7140: 9, 7141: 9, 7142: 9, 7143: 9, 7144: 9, 7145: 9, 7146: 9, 7147: 9, 7148: 9, 7149: 9, 7150: 9, 7151: 9, 7152: 9, 7153: 9, 7154: 9, 7155: 9, 7156: 9, 7157: 9, 7158: 9, 7159: 9, 7160: 9, 7161: 9, 7162: 9, 7163: 9, 7164: 9, 7165: 9, 7166: 9, 7167: 9, 7168: 9, 7169: 9, 7170: 9, 7171: 9, 7172: 9, 7173: 9, 7174: 9, 7175: 9, 7176: 9, 7177: 9, 7178: 9, 7179: 9, 7180: 9, 7181: 9, 7182: 9, 7183: 9, 7184: 9, 7185: 9, 7186: 9, 7187: 9, 7188: 9, 7189: 9, 7190: 9, 7191: 9, 7192: 9, 7193: 9, 7194: 9, 7195: 9, 7196: 9, 7197: 9, 7198: 9, 7199: 9, 7200: 9, 7201: 9, 7202: 9, 7203: 9, 7204: 9, 7205: 9, 7206: 9, 7207: 9, 7208: 9, 7209: 9, 7210: 9, 7211: 9, 7212: 9, 7213: 9, 7214: 9, 7215: 9, 7216: 9, 7217: 9, 7218: 9, 7219: 9, 7220: 9, 7221: 9, 7222: 9, 7223: 9, 7224: 9, 7225: 9, 7226: 9, 7227: 9, 7228: 9, 7229: 9, 7230: 9, 7231: 9, 7232: 9, 7233: 9, 7234: 9, 7235: 9, 7236: 9, 7237: 9, 7238: 9, 7239: 9, 7240: 9, 7241: 9, 7242: 9, 7243: 9, 7244: 9, 7245: 9, 7246: 9, 7247: 9, 7248: 9, 7249: 9, 7250: 9, 7251: 9, 7252: 9, 7253: 9, 7254: 9, 7255: 9, 7256: 9, 7257: 9, 7258: 9, 7259: 9, 7260: 9, 7261: 9, 7262: 9, 7263: 9, 7264: 9, 7265: 9, 7266: 9, 7267: 9, 7268: 9, 7269: 9, 7270: 9, 7271: 9, 7272: 9, 7273: 9, 7274: 9, 7275: 9, 7276: 9, 7277: 9, 7278: 9, 7279: 9, 7280: 9, 7281: 9, 7282: 9, 7283: 9, 7284: 9, 7285: 9, 7286: 9, 7287: 9, 7288: 9, 7289: 9, 7290: 9, 7291: 9, 7292: 9, 7293: 9, 7294: 9, 7295: 9, 7296: 9, 7297: 9, 7298: 9, 7299: 9, 7300: 9, 7301: 9, 7302: 9, 7303: 9, 7304: 9, 7305: 9, 7306: 9, 7307: 9, 7308: 9, 7309: 9, 7310: 9, 7311: 9, 7312: 9, 7313: 9, 7314: 9, 7315: 9, 7316: 9, 7317: 9, 7318: 9, 7319: 9, 7320: 9, 7321: 9, 7322: 9, 7323: 9, 7324: 9, 7325: 9, 7326: 9, 7327: 9, 7328: 9, 7329: 9, 7330: 9, 7331: 9, 7332: 9, 7333: 9, 7334: 9, 7335: 9, 7336: 9, 7337: 9, 7338: 9, 7339: 9, 7340: 9, 7341: 9, 7342: 9, 7343: 9, 7344: 9, 7345: 9, 7346: 9, 7347: 9, 7348: 9, 7349: 9, 7350: 9, 7351: 9, 7352: 9, 7353: 9, 7354: 9, 7355: 9, 7356: 9, 7357: 9, 7358: 9, 7359: 9, 7360: 9, 7361: 9, 7362: 9, 7363: 9, 7364: 9, 7365: 9, 7366: 9, 7367: 9, 7368: 9, 7369: 9, 7370: 9, 7371: 9, 7372: 9, 7373: 9, 7374: 9, 7375: 9, 7376: 9, 7377: 9, 7378: 9, 7379: 9, 7380: 9, 7381: 9, 7382: 9, 7383: 9, 7384: 9, 7385: 9, 7386: 9, 7387: 9, 7388: 9, 7389: 9, 7390: 9, 7391: 9, 7392: 9, 7393: 9, 7394: 9, 7395: 9, 7396: 9, 7397: 9, 7398: 9, 7399: 9, 7400: 9, 7401: 9, 7402: 9, 7403: 9, 7404: 9, 7405: 9, 7406: 9, 7407: 9, 7408: 9, 7409: 9, 7410: 9, 7411: 9, 7412: 9, 7413: 9, 7414: 9, 7415: 9, 7416: 9, 7417: 9, 7418: 9, 7419: 9, 7420: 9, 7421: 9, 7422: 9, 7423: 9, 7424: 9, 7425: 9, 7426: 9, 7427: 9, 7428: 9, 7429: 9, 7430: 9, 7431: 9, 7432: 9, 7433: 9, 7434: 9, 7435: 9, 7436: 9, 7437: 9, 7438: 9, 7439: 9, 7440: 9, 7441: 9, 7442: 9, 7443: 9, 7444: 9, 7445: 9, 7446: 9, 7447: 9, 7448: 9, 7449: 9, 7450: 9, 7451: 9, 7452: 9, 7453: 9, 7454: 9, 7455: 9, 7456: 9, 7457: 9, 7458: 9, 7459: 9, 7460: 9, 7461: 9, 7462: 9, 7463: 9, 7464: 9, 7465: 9, 7466: 9, 7467: 9, 7468: 9, 7469: 9, 7470: 9, 7471: 9, 7472: 9, 7473: 9, 7474: 9, 7475: 9, 7476: 9, 7477: 9, 7478: 9, 7479: 9, 7480: 9, 7481: 9, 7482: 9, 7483: 9, 7484: 9, 7485: 9, 7486: 9, 7487: 9, 7488: 9, 7489: 9, 7490: 9, 7491: 9, 7492: 9, 7493: 9, 7494: 9, 7495: 9, 7496: 9, 7497: 9, 7498: 9, 7499: 9, 7500: 9, 7501: 9, 7502: 9, 7503: 9, 7504: 9, 7505: 9, 7506: 9, 7507: 9, 7508: 9, 7509: 9, 7510: 9, 7511: 9, 7512: 9, 7513: 9, 7514: 9, 7515: 9, 7516: 9, 7517: 9, 7518: 9, 7519: 9, 7520: 9, 7521: 9, 7522: 9, 7523: 9, 7524: 9, 7525: 9, 7526: 9, 7527: 9, 7528: 9, 7529: 9, 7530: 9, 7531: 9, 7532: 9, 7533: 9, 7534: 9, 7535: 9, 7536: 9, 7537: 9, 7538: 9, 7539: 9, 7540: 9, 7541: 9, 7542: 9, 7543: 9, 7544: 9, 7545: 9, 7546: 9, 7547: 9, 7548: 9, 7549: 9, 7550: 9, 7551: 9, 7552: 9, 7553: 9, 7554: 9, 7555: 9, 7556: 9, 7557: 9, 7558: 9, 7559: 9, 7560: 9, 7561: 9, 7562: 9, 7563: 9, 7564: 9, 7565: 9, 7566: 9, 7567: 9, 7568: 9, 7569: 9, 7570: 9, 7571: 9, 7572: 9, 7573: 9, 7574: 9, 7575: 9, 7576: 9, 7577: 9, 7578: 9, 7579: 9, 7580: 9, 7581: 9, 7582: 9, 7583: 9, 7584: 9, 7585: 9, 7586: 9, 7587: 9, 7588: 9, 7589: 9, 7590: 9, 7591: 9, 7592: 9, 7593: 9, 7594: 9, 7595: 9, 7596: 9, 7597: 9, 7598: 9, 7599: 9, 7600: 9, 7601: 9, 7602: 9, 7603: 9, 7604: 9, 7605: 9, 7606: 9, 7607: 9, 7608: 9, 7609: 9, 7610: 9, 7611: 9, 7612: 9, 7613: 9, 7614: 9, 7615: 9, 7616: 9, 7617: 9, 7618: 9, 7619: 9, 7620: 9, 7621: 9, 7622: 9, 7623: 9, 7624: 9, 7625: 9, 7626: 9, 7627: 9, 7628: 9, 7629: 9, 7630: 9, 7631: 9, 7632: 9, 7633: 9, 7634: 9, 7635: 9, 7636: 9, 7637: 9, 7638: 9, 7639: 9, 7640: 9, 7641: 9, 7642: 9, 7643: 9, 7644: 9, 7645: 9, 7646: 9, 7647: 9, 7648: 9, 7649: 9, 7650: 9, 7651: 9, 7652: 9, 7653: 9, 7654: 9, 7655: 9, 7656: 9, 7657: 9, 7658: 9, 7659: 9, 7660: 9, 7661: 9, 7662: 9, 7663: 9, 7664: 9, 7665: 9, 7666: 9, 7667: 9, 7668: 9, 7669: 9, 7670: 9, 7671: 9, 7672: 9, 7673: 9, 7674: 9, 7675: 9, 7676: 9, 7677: 9, 7678: 9, 7679: 9, 7680: 9, 7681: 9, 7682: 9, 7683: 9, 7684: 9, 7685: 9, 7686: 9, 7687: 9, 7688: 9, 7689: 9, 7690: 9, 7691: 9, 7692: 9, 7693: 9, 7694: 9, 7695: 9, 7696: 9, 7697: 9, 7698: 9, 7699: 9, 7700: 9, 7701: 9, 7702: 9, 7703: 9, 7704: 9, 7705: 9, 7706: 9, 7707: 9, 7708: 9, 7709: 9, 7710: 9, 7711: 9, 7712: 9, 7713: 9, 7714: 9, 7715: 9, 7716: 9, 7717: 9, 7718: 9, 7719: 9, 7720: 9, 7721: 9, 7722: 9, 7723: 9, 7724: 9, 7725: 9, 7726: 9, 7727: 9, 7728: 9, 7729: 9, 7730: 9, 7731: 9, 7732: 9, 7733: 9, 7734: 9, 7735: 9, 7736: 9, 7737: 9, 7738: 9, 7739: 9, 7740: 9, 7741: 9, 7742: 9, 7743: 9, 7744: 9, 7745: 9, 7746: 9, 7747: 9, 7748: 9, 7749: 9, 7750: 9, 7751: 9, 7752: 9, 7753: 9, 7754: 9, 7755: 9, 7756: 9, 7757: 9, 7758: 9, 7759: 9, 7760: 9, 7761: 9, 7762: 9, 7763: 9, 7764: 9, 7765: 9, 7766: 9, 7767: 9, 7768: 9, 7769: 9, 7770: 9, 7771: 9, 7772: 9, 7773: 9, 7774: 9, 7775: 9, 7776: 9, 7777: 9, 7778: 9, 7779: 9, 7780: 9, 7781: 9, 7782: 9, 7783: 9, 7784: 9, 7785: 9, 7786: 9, 7787: 9, 7788: 9, 7789: 9, 7790: 9, 7791: 9, 7792: 9, 7793: 9, 7794: 9, 7795: 9, 7796: 9, 7797: 9, 7798: 9, 7799: 9, 7800: 9, 7801: 9, 7802: 9, 7803: 9, 7804: 9, 7805: 9, 7806: 9, 7807: 9, 7808: 9, 7809: 9, 7810: 9, 7811: 9, 7812: 9, 7813: 9, 7814: 9, 7815: 9, 7816: 9, 7817: 9, 7818: 9, 7819: 9, 7820: 9, 7821: 9, 7822: 9, 7823: 9, 7824: 9, 7825: 9, 7826: 9, 7827: 9, 7828: 9, 7829: 9, 7830: 9, 7831: 9, 7832: 9, 7833: 9, 7834: 9, 7835: 9, 7836: 9, 7837: 9, 7838: 9, 7839: 9, 7840: 9, 7841: 9, 7842: 9, 7843: 9, 7844: 9, 7845: 9, 7846: 9, 7847: 9, 7848: 9, 7849: 9, 7850: 9, 7851: 9, 7852: 9, 7853: 9, 7854: 9, 7855: 9, 7856: 9, 7857: 9, 7858: 9, 7859: 9, 7860: 9, 7861: 9, 7862: 9, 7863: 9, 7864: 9, 7865: 9, 7866: 9, 7867: 9, 7868: 9, 7869: 9, 7870: 9, 7871: 9, 7872: 9, 7873: 9, 7874: 9, 7875: 9, 7876: 9, 7877: 9, 7878: 9, 7879: 9, 7880: 9, 7881: 9, 7882: 9, 7883: 9, 7884: 9, 7885: 9, 7886: 9, 7887: 9, 7888: 9, 7889: 9, 7890: 9, 7891: 9, 7892: 9, 7893: 9, 7894: 9, 7895: 9, 7896: 9, 7897: 9, 7898: 9, 7899: 9, 7900: 9, 7901: 9, 7902: 9, 7903: 9, 7904: 9, 7905: 9, 7906: 9, 7907: 9, 7908: 9, 7909: 9, 7910: 9, 7911: 9, 7912: 9, 7913: 9, 7914: 9, 7915: 9, 7916: 9, 7917: 9, 7918: 9, 7919: 9, 7920: 9, 7921: 9, 7922: 9, 7923: 9, 7924: 9, 7925: 9, 7926: 9, 7927: 9, 7928: 9, 7929: 9, 7930: 9, 7931: 9, 7932: 9, 7933: 9, 7934: 9, 7935: 9, 7936: 9, 7937: 9, 7938: 9, 7939: 9, 7940: 9, 7941: 9, 7942: 9, 7943: 9, 7944: 9, 7945: 9, 7946: 9, 7947: 9, 7948: 9, 7949: 9, 7950: 9, 7951: 9, 7952: 9, 7953: 9, 7954: 9, 7955: 9, 7956: 9, 7957: 9, 7958: 9, 7959: 9, 7960: 9, 7961: 9, 7962: 9, 7963: 9, 7964: 9, 7965: 9, 7966: 9, 7967: 9, 7968: 9, 7969: 9, 7970: 9, 7971: 9, 7972: 9, 7973: 9, 7974: 9, 7975: 9, 7976: 9, 7977: 9, 7978: 9, 7979: 9, 7980: 9, 7981: 9, 7982: 9, 7983: 9, 7984: 9, 7985: 9, 7986: 9, 7987: 9, 7988: 9, 7989: 9, 7990: 9, 7991: 9, 7992: 9, 7993: 9, 7994: 9, 7995: 9, 7996: 9, 7997: 9, 7998: 9, 7999: 9, 8000: 9, 8001: 9, 8002: 9, 8003: 9, 8004: 9, 8005: 9, 8006: 9, 8007: 9, 8008: 9, 8009: 9, 8010: 9, 8011: 9, 8012: 9, 8013: 9, 8014: 9, 8015: 9, 8016: 9, 8017: 9, 8018: 9, 8019: 9, 8020: 9, 8021: 9, 8022: 9, 8023: 9, 8024: 9, 8025: 9, 8026: 9, 8027: 9, 8028: 9, 8029: 9, 8030: 9, 8031: 9, 8032: 9, 8033: 9, 8034: 9, 8035: 9, 8036: 9, 8037: 9, 8038: 9, 8039: 9, 8040: 9, 8041: 9, 8042: 9, 8043: 9, 8044: 9, 8045: 9, 8046: 9, 8047: 9, 8048: 9, 8049: 9, 8050: 9, 8051: 9, 8052: 9, 8053: 9, 8054: 9, 8055: 9, 8056: 9, 8057: 9, 8058: 9, 8059: 9, 8060: 9, 8061: 9, 8062: 9, 8063: 9, 8064: 9, 8065: 9, 8066: 9, 8067: 9, 8068: 9, 8069: 9, 8070: 9, 8071: 9, 8072: 9, 8073: 9, 8074: 9, 8075: 9, 8076: 9, 8077: 9, 8078: 9, 8079: 9, 8080: 9, 8081: 9, 8082: 9, 8083: 9, 8084: 10, 8085: 9, 8086: 9, 8087: 9, 8088: 9, 8089: 9, 8090: 9, 8091: 9, 8092: 9, 8093: 9, 8094: 9, 8095: 9, 8096: 9, 8097: 9, 8098: 9, 8099: 9, 8100: 9, 8101: 9, 8102: 9, 8103: 9, 8104: 9, 8105: 9, 8106: 9, 8107: 9, 8108: 9, 8109: 9, 8110: 9, 8111: 9, 8112: 9, 8113: 9, 8114: 9, 8115: 9, 8116: 9, 8117: 9, 8118: 9, 8119: 9, 8120: 9, 8121: 9, 8122: 9, 8123: 9, 8124: 9, 8125: 9, 8126: 9, 8127: 9, 8128: 9, 8129: 9, 8130: 9, 8131: 9, 8132: 9, 8133: 9, 8134: 9, 8135: 9, 8136: 9, 8137: 9, 8138: 9, 8139: 9, 8140: 9, 8141: 9, 8142: 9, 8143: 9, 8144: 9, 8145: 9, 8146: 9, 8147: 9, 8148: 9, 8149: 9, 8150: 9, 8151: 9, 8152: 9, 8153: 9, 8154: 9, 8155: 9, 8156: 9, 8157: 9, 8158: 9, 8159: 9, 8160: 9, 8161: 9, 8162: 9, 8163: 9, 8164: 9, 8165: 9, 8166: 9, 8167: 9, 8168: 9, 8169: 9, 8170: 9, 8171: 9, 8172: 9, 8173: 9, 8174: 9, 8175: 9, 8176: 9, 8177: 9, 8178: 9, 8179: 9, 8180: 9, 8181: 9, 8182: 9, 8183: 9, 8184: 9, 8185: 9, 8186: 9, 8187: 9, 8188: 9, 8189: 9, 8190: 9, 8191: 9, 8192: 9, 8193: 9, 8194: 9, 8195: 9, 8196: 9, 8197: 9, 8198: 9, 8199: 9, 8200: 9, 8201: 9, 8202: 9, 8203: 9, 8204: 9, 8205: 9, 8206: 9, 8207: 9, 8208: 9, 8209: 9, 8210: 9, 8211: 9, 8212: 9, 8213: 9, 8214: 9, 8215: 9, 8216: 9, 8217: 9, 8218: 9, 8219: 9, 8220: 9, 8221: 9, 8222: 9, 8223: 9, 8224: 9, 8225: 9, 8226: 9, 8227: 9, 8228: 9, 8229: 9, 8230: 9, 8231: 9, 8232: 9, 8233: 9, 8234: 9, 8235: 9, 8236: 9, 8237: 9, 8238: 9, 8239: 9, 8240: 9, 8241: 9, 8242: 9, 8243: 9, 8244: 9, 8245: 9, 8246: 9, 8247: 9, 8248: 9, 8249: 9, 8250: 9, 8251: 9, 8252: 9, 8253: 9, 8254: 9, 8255: 9, 8256: 9, 8257: 9, 8258: 9, 8259: 9, 8260: 9, 8261: 9, 8262: 9, 8263: 9, 8264: 9, 8265: 9, 8266: 9, 8267: 9, 8268: 9, 8269: 9, 8270: 9, 8271: 9, 8272: 9, 8273: 9, 8274: 9, 8275: 9, 8276: 9, 8277: 9, 8278: 9, 8279: 9, 8280: 9, 8281: 9, 8282: 9, 8283: 9, 8284: 9, 8285: 9, 8286: 9, 8287: 9, 8288: 9, 8289: 9, 8290: 9, 8291: 9, 8292: 9, 8293: 9, 8294: 9, 8295: 9, 8296: 9, 8297: 9, 8298: 9, 8299: 9, 8300: 9, 8301: 9, 8302: 9, 8303: 9, 8304: 9, 8305: 9, 8306: 9, 8307: 9, 8308: 9, 8309: 9, 8310: 9, 8311: 9, 8312: 9, 8313: 9, 8314: 9, 8315: 9, 8316: 9, 8317: 9, 8318: 9, 8319: 9, 8320: 9, 8321: 9, 8322: 9, 8323: 9, 8324: 9, 8325: 9, 8326: 9, 8327: 9, 8328: 9, 8329: 9, 8330: 9, 8331: 9, 8332: 9, 8333: 9, 8334: 9, 8335: 9, 8336: 9, 8337: 9, 8338: 9, 8339: 9, 8340: 9, 8341: 9, 8342: 9, 8343: 9, 8344: 9, 8345: 9, 8346: 9, 8347: 9, 8348: 9, 8349: 9, 8350: 9, 8351: 9, 8352: 9, 8353: 9, 8354: 9, 8355: 9, 8356: 9, 8357: 9, 8358: 9, 8359: 9, 8360: 9, 8361: 9, 8362: 9, 8363: 9, 8364: 9, 8365: 9, 8366: 9, 8367: 9, 8368: 9, 8369: 9, 8370: 9, 8371: 9, 8372: 9, 8373: 9, 8374: 9, 8375: 9, 8376: 9, 8377: 9, 8378: 9, 8379: 9, 8380: 9, 8381: 9, 8382: 9, 8383: 9, 8384: 9, 8385: 9, 8386: 9, 8387: 9, 8388: 9, 8389: 9, 8390: 9, 8391: 9, 8392: 9, 8393: 9, 8394: 9, 8395: 9, 8396: 9, 8397: 9, 8398: 9, 8399: 9, 8400: 9, 8401: 9, 8402: 9, 8403: 9, 8404: 9, 8405: 9, 8406: 9, 8407: 9, 8408: 9, 8409: 9, 8410: 9, 8411: 9, 8412: 9, 8413: 9, 8414: 9, 8415: 9, 8416: 9, 8417: 9, 8418: 9, 8419: 9, 8420: 9, 8421: 9, 8422: 9, 8423: 9, 8424: 9, 8425: 9, 8426: 9, 8427: 9, 8428: 9, 8429: 9, 8430: 9, 8431: 9, 8432: 9, 8433: 9, 8434: 9, 8435: 9, 8436: 9, 8437: 9, 8438: 9, 8439: 9, 8440: 9, 8441: 9, 8442: 9, 8443: 9, 8444: 9, 8445: 9, 8446: 9, 8447: 9, 8448: 9, 8449: 9, 8450: 9, 8451: 9, 8452: 9, 8453: 9, 8454: 9, 8455: 9, 8456: 9, 8457: 9, 8458: 9, 8459: 9, 8460: 9, 8461: 9, 8462: 9, 8463: 9, 8464: 9, 8465: 9, 8466: 9, 8467: 9, 8468: 9, 8469: 9, 8470: 9, 8471: 9, 8472: 9, 8473: 9, 8474: 9, 8475: 9, 8476: 9, 8477: 9, 8478: 9, 8479: 9, 8480: 9, 8481: 9, 8482: 9, 8483: 9, 8484: 9, 8485: 9, 8486: 9, 8487: 9, 8488: 9, 8489: 9, 8490: 9, 8491: 9, 8492: 9, 8493: 9, 8494: 9, 8495: 9, 8496: 9, 8497: 9, 8498: 9, 8499: 9, 8500: 9, 8501: 9, 8502: 9, 8503: 9, 8504: 9, 8505: 9, 8506: 9, 8507: 9, 8508: 9, 8509: 9, 8510: 9, 8511: 9, 8512: 9, 8513: 9, 8514: 9, 8515: 9, 8516: 9, 8517: 9, 8518: 9, 8519: 9, 8520: 9, 8521: 9, 8522: 9, 8523: 9, 8524: 9, 8525: 9, 8526: 9, 8527: 9, 8528: 9, 8529: 9, 8530: 9, 8531: 9, 8532: 9, 8533: 9, 8534: 9, 8535: 9, 8536: 9, 8537: 9, 8538: 9, 8539: 9, 8540: 9, 8541: 9, 8542: 9, 8543: 9, 8544: 9, 8545: 9, 8546: 9, 8547: 9, 8548: 9, 8549: 9, 8550: 9, 8551: 9, 8552: 9, 8553: 9, 8554: 9, 8555: 9, 8556: 9, 8557: 9, 8558: 9, 8559: 9, 8560: 9, 8561: 9, 8562: 9, 8563: 9, 8564: 9, 8565: 9, 8566: 9, 8567: 9, 8568: 9, 8569: 9, 8570: 9, 8571: 9, 8572: 9, 8573: 9, 8574: 9, 8575: 9, 8576: 9, 8577: 9, 8578: 9, 8579: 9, 8580: 9, 8581: 9, 8582: 9, 8583: 9, 8584: 9, 8585: 9, 8586: 9, 8587: 9, 8588: 9, 8589: 9, 8590: 9, 8591: 9, 8592: 9, 8593: 9, 8594: 9, 8595: 9, 8596: 9, 8597: 9, 8598: 9, 8599: 9, 8600: 9, 8601: 9, 8602: 9, 8603: 9, 8604: 9, 8605: 9, 8606: 9, 8607: 9, 8608: 9, 8609: 9, 8610: 9, 8611: 9, 8612: 9, 8613: 9, 8614: 9, 8615: 9, 8616: 9, 8617: 9, 8618: 9, 8619: 9, 8620: 9, 8621: 9, 8622: 9, 8623: 9, 8624: 9, 8625: 9, 8626: 9, 8627: 9, 8628: 9, 8629: 9, 8630: 9, 8631: 9, 8632: 9, 8633: 9, 8634: 9, 8635: 9, 8636: 9, 8637: 9, 8638: 9, 8639: 9, 8640: 9, 8641: 9, 8642: 9, 8643: 9, 8644: 9, 8645: 9, 8646: 9, 8647: 9, 8648: 9, 8649: 9, 8650: 9, 8651: 9, 8652: 9, 8653: 9, 8654: 9, 8655: 9, 8656: 9, 8657: 9, 8658: 9, 8659: 9, 8660: 9, 8661: 9, 8662: 9, 8663: 9, 8664: 9, 8665: 9, 8666: 9, 8667: 9, 8668: 9, 8669: 9, 8670: 9, 8671: 9, 8672: 9, 8673: 9, 8674: 9, 8675: 9, 8676: 9, 8677: 9, 8678: 9, 8679: 9, 8680: 9, 8681: 9, 8682: 9, 8683: 9, 8684: 9, 8685: 9, 8686: 9, 8687: 9, 8688: 9, 8689: 9, 8690: 9, 8691: 9, 8692: 9, 8693: 9, 8694: 9, 8695: 9, 8696: 9, 8697: 9, 8698: 9, 8699: 9, 8700: 9, 8701: 9, 8702: 9, 8703: 9, 8704: 9, 8705: 9, 8706: 9, 8707: 9, 8708: 9, 8709: 9, 8710: 9, 8711: 9, 8712: 9, 8713: 9, 8714: 9, 8715: 9, 8716: 9, 8717: 9, 8718: 9, 8719: 9, 8720: 9, 8721: 9, 8722: 9, 8723: 9, 8724: 9, 8725: 9, 8726: 9, 8727: 9, 8728: 9, 8729: 9, 8730: 9, 8731: 9, 8732: 9, 8733: 9, 8734: 9, 8735: 9, 8736: 9, 8737: 9, 8738: 9, 8739: 9, 8740: 9, 8741: 9, 8742: 9, 8743: 9, 8744: 9, 8745: 9, 8746: 9, 8747: 9, 8748: 9, 8749: 9, 8750: 9, 8751: 9, 8752: 9, 8753: 9, 8754: 9, 8755: 9, 8756: 9, 8757: 9, 8758: 9, 8759: 9, 8760: 9, 8761: 9, 8762: 9, 8763: 9, 8764: 9, 8765: 9, 8766: 9, 8767: 9, 8768: 9, 8769: 9, 8770: 9, 8771: 9, 8772: 9, 8773: 9, 8774: 9, 8775: 9, 8776: 9, 8777: 9, 8778: 9, 8779: 9, 8780: 9, 8781: 9, 8782: 9, 8783: 9, 8784: 9, 8785: 9, 8786: 9, 8787: 9, 8788: 9, 8789: 9, 8790: 9, 8791: 9, 8792: 9, 8793: 9, 8794: 9, 8795: 9, 8796: 9, 8797: 9, 8798: 9, 8799: 9, 8800: 9, 8801: 9, 8802: 9, 8803: 9, 8804: 9, 8805: 9, 8806: 9, 8807: 9, 8808: 9, 8809: 9, 8810: 9, 8811: 9, 8812: 9, 8813: 9, 8814: 9, 8815: 9, 8816: 9, 8817: 9, 8818: 9, 8819: 9, 8820: 9, 8821: 9, 8822: 9, 8823: 9, 8824: 9, 8825: 9, 8826: 9, 8827: 9, 8828: 9, 8829: 9, 8830: 9, 8831: 9, 8832: 9, 8833: 9, 8834: 9, 8835: 9, 8836: 9, 8837: 9, 8838: 9, 8839: 9, 8840: 9, 8841: 9, 8842: 9, 8843: 9, 8844: 9, 8845: 9, 8846: 9, 8847: 9, 8848: 9, 8849: 9, 8850: 9, 8851: 9, 8852: 9, 8853: 9, 8854: 9, 8855: 9, 8856: 9, 8857: 9, 8858: 9, 8859: 9, 8860: 9, 8861: 9, 8862: 9, 8863: 9, 8864: 9, 8865: 9, 8866: 9, 8867: 9, 8868: 9, 8869: 9, 8870: 9, 8871: 9, 8872: 9, 8873: 9, 8874: 9, 8875: 9, 8876: 9, 8877: 9, 8878: 9, 8879: 9, 8880: 9, 8881: 9, 8882: 9, 8883: 9, 8884: 9, 8885: 9, 8886: 9, 8887: 9, 8888: 9, 8889: 9, 8890: 9, 8891: 9, 8892: 9, 8893: 9, 8894: 9, 8895: 9, 8896: 9, 8897: 9, 8898: 9, 8899: 9, 8900: 9, 8901: 9, 8902: 9, 8903: 9, 8904: 9, 8905: 9, 8906: 9, 8907: 9, 8908: 9, 8909: 9, 8910: 9, 8911: 9, 8912: 9, 8913: 9, 8914: 9, 8915: 9, 8916: 9, 8917: 9, 8918: 9, 8919: 9, 8920: 9, 8921: 9, 8922: 9, 8923: 9, 8924: 9, 8925: 9, 8926: 9, 8927: 9, 8928: 9, 8929: 9, 8930: 9, 8931: 9, 8932: 9, 8933: 9, 8934: 9, 8935: 9, 8936: 9, 8937: 9, 8938: 9, 8939: 9, 8940: 9, 8941: 9, 8942: 9, 8943: 9, 8944: 9, 8945: 9, 8946: 9, 8947: 9, 8948: 9, 8949: 9, 8950: 9, 8951: 9, 8952: 9, 8953: 9, 8954: 9, 8955: 9, 8956: 9, 8957: 9, 8958: 9, 8959: 9, 8960: 9, 8961: 9, 8962: 9, 8963: 9, 8964: 9, 8965: 9, 8966: 9, 8967: 9, 8968: 9, 8969: 9, 8970: 9, 8971: 9, 8972: 9, 8973: 9, 8974: 9, 8975: 9, 8976: 9, 8977: 9, 8978: 9, 8979: 9, 8980: 9, 8981: 9, 8982: 9, 8983: 9, 8984: 9, 8985: 9, 8986: 9, 8987: 9, 8988: 9, 8989: 9, 8990: 9, 8991: 9, 8992: 9, 8993: 9, 8994: 9, 8995: 9, 8996: 9, 8997: 9, 8998: 9, 8999: 9, 9000: 9, 9001: 9, 9002: 9, 9003: 9, 9004: 9, 9005: 9, 9006: 9, 9007: 9, 9008: 9, 9009: 9, 9010: 9, 9011: 9, 9012: 9, 9013: 9, 9014: 9, 9015: 9, 9016: 9, 9017: 9, 9018: 9, 9019: 9, 9020: 9, 9021: 9, 9022: 9, 9023: 9, 9024: 9, 9025: 9, 9026: 9, 9027: 9, 9028: 9, 9029: 9, 9030: 9, 9031: 9, 9032: 9, 9033: 9, 9034: 9, 9035: 9, 9036: 9, 9037: 9, 9038: 9, 9039: 9, 9040: 9, 9041: 9, 9042: 9, 9043: 9, 9044: 9, 9045: 9, 9046: 9, 9047: 9, 9048: 9, 9049: 9, 9050: 9, 9051: 9, 9052: 9, 9053: 9, 9054: 9, 9055: 9, 9056: 9, 9057: 9, 9058: 9, 9059: 9, 9060: 9, 9061: 9, 9062: 9, 9063: 9, 9064: 9, 9065: 9, 9066: 9, 9067: 9, 9068: 9, 9069: 9, 9070: 9, 9071: 9, 9072: 9, 9073: 9, 9074: 9, 9075: 9, 9076: 9, 9077: 9, 9078: 9, 9079: 9, 9080: 9, 9081: 9, 9082: 9, 9083: 9, 9084: 9, 9085: 9, 9086: 9, 9087: 9, 9088: 9, 9089: 9, 9090: 9, 9091: 9, 9092: 9, 9093: 9, 9094: 9, 9095: 9, 9096: 9, 9097: 9, 9098: 9, 9099: 9, 9100: 9, 9101: 9, 9102: 9, 9103: 9, 9104: 9, 9105: 9, 9106: 9, 9107: 9, 9108: 9, 9109: 9, 9110: 9, 9111: 9, 9112: 9, 9113: 9, 9114: 9, 9115: 9, 9116: 9, 9117: 9, 9118: 9, 9119: 9, 9120: 9, 9121: 9, 9122: 9, 9123: 9, 9124: 9, 9125: 9, 9126: 9, 9127: 9, 9128: 9, 9129: 9, 9130: 9, 9131: 9, 9132: 9, 9133: 9, 9134: 9, 9135: 9, 9136: 9, 9137: 9, 9138: 9, 9139: 9, 9140: 9, 9141: 9, 9142: 9, 9143: 9, 9144: 9, 9145: 9, 9146: 9, 9147: 9, 9148: 9, 9149: 9, 9150: 9, 9151: 9, 9152: 9, 9153: 9, 9154: 9, 9155: 9, 9156: 9, 9157: 9, 9158: 9, 9159: 9, 9160: 9, 9161: 9, 9162: 9, 9163: 9, 9164: 9, 9165: 9, 9166: 9, 9167: 9, 9168: 9, 9169: 9, 9170: 9, 9171: 9, 9172: 9, 9173: 9, 9174: 9, 9175: 9, 9176: 9, 9177: 9, 9178: 9, 9179: 9, 9180: 9, 9181: 9, 9182: 9, 9183: 9, 9184: 9, 9185: 9, 9186: 9, 9187: 9, 9188: 9, 9189: 9, 9190: 9, 9191: 9, 9192: 9, 9193: 9, 9194: 9, 9195: 9, 9196: 9, 9197: 9, 9198: 9, 9199: 9, 9200: 9, 9201: 9, 9202: 9, 9203: 9, 9204: 9, 9205: 9, 9206: 9, 9207: 9, 9208: 9, 9209: 9, 9210: 9, 9211: 9, 9212: 9, 9213: 9, 9214: 9, 9215: 9, 9216: 9, 9217: 9, 9218: 9, 9219: 9, 9220: 9, 9221: 9, 9222: 9, 9223: 9, 9224: 9, 9225: 9, 9226: 9, 9227: 9, 9228: 9, 9229: 9, 9230: 9, 9231: 9, 9232: 9, 9233: 9, 9234: 9, 9235: 9, 9236: 9, 9237: 9, 9238: 9, 9239: 9, 9240: 9, 9241: 9, 9242: 9, 9243: 9, 9244: 9, 9245: 9, 9246: 9, 9247: 9, 9248: 9, 9249: 9, 9250: 9, 9251: 9, 9252: 9, 9253: 9, 9254: 9, 9255: 9, 9256: 9, 9257: 9, 9258: 9, 9259: 9, 9260: 9, 9261: 9, 9262: 9, 9263: 9, 9264: 9, 9265: 9, 9266: 9, 9267: 9, 9268: 9, 9269: 9, 9270: 9, 9271: 9, 9272: 9, 9273: 9, 9274: 9, 9275: 9, 9276: 9, 9277: 9, 9278: 9, 9279: 9, 9280: 9, 9281: 9, 9282: 9, 9283: 9, 9284: 9, 9285: 9, 9286: 9, 9287: 9, 9288: 9, 9289: 9, 9290: 9, 9291: 9, 9292: 9, 9293: 9, 9294: 9 ~= num clips 9
[05/04 16:44:49][INFO] logging.py:  99: json_stats: {"split": "test_final", "top1_acc": "90.42", "top5_acc": "96.58"}
